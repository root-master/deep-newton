2017-12-04 14:02:24.126110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 14:02:24.377340: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5f75010 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 14:02:24.378151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 14:02:24.638354: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5f794f0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 14:02:24.639319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:82:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 14:02:24.906919: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5f7d9d0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 14:02:24.907648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:83:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 14:02:24.907904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 2
2017-12-04 14:02:24.907921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 3
2017-12-04 14:02:24.907944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 2
2017-12-04 14:02:24.907954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 3
2017-12-04 14:02:24.907963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 0
2017-12-04 14:02:24.907972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 1
2017-12-04 14:02:24.908164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 0
2017-12-04 14:02:24.908177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 1
2017-12-04 14:02:24.908245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3 
2017-12-04 14:02:24.908252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y N N 
2017-12-04 14:02:24.908257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y N N 
2017-12-04 14:02:24.908260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   N N Y Y 
2017-12-04 14:02:24.908264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   N N Y Y 
2017-12-04 14:02:24.908274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 14:02:24.908280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
2017-12-04 14:02:24.908284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K20m, pci bus id: 0000:82:00.0)
2017-12-04 14:02:24.908288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K20m, pci bus id: 0000:83:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.320223331451416, train acuracy: 0.15625
step: 0, val loss: 2.5773212909698486, val acuracy: 0.09816665947437286
step: 1, train loss: 2.2329354286193848, train acuracy: 0.265625
step: 1, val loss: 2.3159468173980713, val acuracy: 0.13333334028720856
step: 2, train loss: 2.236936330795288, train acuracy: 0.1875
step: 2, val loss: 2.332606792449951, val acuracy: 0.09666665643453598
step: 3, train loss: 2.1662893295288086, train acuracy: 0.265625
step: 3, val loss: 2.420942783355713, val acuracy: 0.13633333146572113
step: 4, train loss: 2.386049747467041, train acuracy: 0.109375
step: 4, val loss: 2.3785288333892822, val acuracy: 0.09666666388511658
step: 5, train loss: 2.260737419128418, train acuracy: 0.125
step: 5, val loss: 2.321202278137207, val acuracy: 0.09666666388511658
step: 6, train loss: 2.2340521812438965, train acuracy: 0.109375
step: 6, val loss: 2.3192367553710938, val acuracy: 0.09666666388511658
step: 7, train loss: 2.253711223602295, train acuracy: 0.1875
step: 7, val loss: 2.3949828147888184, val acuracy: 0.1836666613817215
step: 8, train loss: 2.233292579650879, train acuracy: 0.140625
step: 8, val loss: 2.3112595081329346, val acuracy: 0.09666666388511658
step: 9, train loss: 2.1647531986236572, train acuracy: 0.234375
step: 9, val loss: 2.2722792625427246, val acuracy: 0.1326666623353958
step: 10, train loss: 2.249192953109741, train acuracy: 0.15625
step: 10, val loss: 2.267625331878662, val acuracy: 0.11816666275262833
step: 11, train loss: 2.2444615364074707, train acuracy: 0.125
step: 11, val loss: 2.284196615219116, val acuracy: 0.14166666567325592
step: 12, train loss: 1.857912302017212, train acuracy: 0.390625
step: 12, val loss: 2.2485337257385254, val acuracy: 0.24416667222976685
step: 13, train loss: 1.7987029552459717, train acuracy: 0.46875
step: 13, val loss: 1.950657844543457, val acuracy: 0.3205000162124634
step: 14, train loss: 1.7656227350234985, train acuracy: 0.484375
step: 14, val loss: 1.903511643409729, val acuracy: 0.40533334016799927
step: 15, train loss: 1.8180322647094727, train acuracy: 0.515625
step: 15, val loss: 1.8225685358047485, val acuracy: 0.4541666805744171
step: 16, train loss: 5.61643648147583, train acuracy: 0.234375
step: 16, val loss: 6.266031265258789, val acuracy: 0.19733333587646484
step: 17, train loss: 2.165104627609253, train acuracy: 0.3125
step: 17, val loss: 2.1470987796783447, val acuracy: 0.2670000195503235
step: 18, train loss: 2.0075182914733887, train acuracy: 0.359375
step: 18, val loss: 2.041963577270508, val acuracy: 0.3371667265892029
step: 19, train loss: 1.9647812843322754, train acuracy: 0.390625
step: 19, val loss: 2.0121970176696777, val acuracy: 0.3580000102519989
step: 20, train loss: 1.9893214702606201, train acuracy: 0.4375
step: 20, val loss: 2.0118026733398438, val acuracy: 0.3564999997615814
step: 21, train loss: 1.914675235748291, train acuracy: 0.421875
step: 21, val loss: 2.0360822677612305, val acuracy: 0.34200000762939453
step: 22, train loss: 2.0265302658081055, train acuracy: 0.390625
step: 22, val loss: 2.032277822494507, val acuracy: 0.34066668152809143
step: 23, train loss: 2.033133029937744, train acuracy: 0.328125
step: 23, val loss: 2.026658296585083, val acuracy: 0.34383338689804077
step: 24, train loss: 1.891607642173767, train acuracy: 0.390625
step: 24, val loss: 1.9493604898452759, val acuracy: 0.37150001525878906
step: 25, train loss: 2.004730224609375, train acuracy: 0.234375
step: 25, val loss: 1.9769377708435059, val acuracy: 0.19450001418590546
step: 26, train loss: 1.6475099325180054, train acuracy: 0.421875
step: 26, val loss: 1.7567729949951172, val acuracy: 0.3606667220592499
step: 27, train loss: 1.6233439445495605, train acuracy: 0.4375
step: 27, val loss: 2.282334089279175, val acuracy: 0.34716668725013733
step: 28, train loss: 2.127986431121826, train acuracy: 0.25
step: 28, val loss: 2.233738422393799, val acuracy: 0.2043333351612091
step: 29, train loss: 1.7566416263580322, train acuracy: 0.4375
step: 29, val loss: 1.8149513006210327, val acuracy: 0.37533333897590637
step: 30, train loss: 1.445989727973938, train acuracy: 0.65625
step: 30, val loss: 1.6122252941131592, val acuracy: 0.5205000638961792
step: 31, train loss: 1.5488944053649902, train acuracy: 0.484375
step: 31, val loss: 1.6552181243896484, val acuracy: 0.45883333683013916
step: 32, train loss: 1.6460061073303223, train acuracy: 0.4375
step: 32, val loss: 1.6362940073013306, val acuracy: 0.46566668152809143
step: 33, train loss: 1.7051684856414795, train acuracy: 0.453125
step: 33, val loss: 1.634350299835205, val acuracy: 0.4651666581630707
step: 34, train loss: 1.6139358282089233, train acuracy: 0.390625
step: 34, val loss: 1.6307778358459473, val acuracy: 0.46533334255218506
step: 35, train loss: 1.5631675720214844, train acuracy: 0.53125
step: 35, val loss: 1.627469539642334, val acuracy: 0.4648333489894867
step: 36, train loss: 1.6611289978027344, train acuracy: 0.4375
step: 36, val loss: 1.6261730194091797, val acuracy: 0.4658333361148834
step: 37, train loss: 1.763911247253418, train acuracy: 0.46875
step: 37, val loss: 1.62446129322052, val acuracy: 0.46566668152809143
step: 38, train loss: 1.5425912141799927, train acuracy: 0.515625
step: 38, val loss: 1.6234698295593262, val acuracy: 0.46533340215682983
step: 39, train loss: 1.5590906143188477, train acuracy: 0.53125
step: 39, val loss: 1.6231456995010376, val acuracy: 0.46516668796539307
step: 40, train loss: 1.6730258464813232, train acuracy: 0.453125
step: 40, val loss: 1.673791527748108, val acuracy: 0.48383334279060364
step: 41, train loss: 1.7061767578125, train acuracy: 0.625
step: 41, val loss: 1.6727510690689087, val acuracy: 0.48483332991600037
step: 42, train loss: 1.726644515991211, train acuracy: 0.4375
step: 42, val loss: 1.6709686517715454, val acuracy: 0.484000027179718
step: 43, train loss: 1.5558578968048096, train acuracy: 0.4375
step: 43, val loss: 1.6621184349060059, val acuracy: 0.45733338594436646
step: 44, train loss: 1.778048038482666, train acuracy: 0.453125
step: 44, val loss: 1.7402706146240234, val acuracy: 0.47850000858306885
step: 45, train loss: 1.5783333778381348, train acuracy: 0.515625
step: 45, val loss: 1.6573119163513184, val acuracy: 0.46916666626930237
step: 46, train loss: 1.7751178741455078, train acuracy: 0.421875
step: 46, val loss: 1.6714025735855103, val acuracy: 0.47683337330818176
step: 47, train loss: 1.5256868600845337, train acuracy: 0.53125
step: 47, val loss: 1.6672335863113403, val acuracy: 0.4793333411216736
step: 48, train loss: 1.7860949039459229, train acuracy: 0.4375
step: 48, val loss: 1.778396487236023, val acuracy: 0.42883336544036865
step: 49, train loss: 1.6618701219558716, train acuracy: 0.515625
step: 49, val loss: 1.8130069971084595, val acuracy: 0.46016669273376465
step: 50, train loss: 1.8565529584884644, train acuracy: 0.46875
step: 50, val loss: 1.796428918838501, val acuracy: 0.46433335542678833
step: 51, train loss: 1.8516664505004883, train acuracy: 0.421875
step: 51, val loss: 1.7922148704528809, val acuracy: 0.4673333764076233
step: 52, train loss: 1.7674486637115479, train acuracy: 0.484375
step: 52, val loss: 1.7865183353424072, val acuracy: 0.468500018119812
step: 53, train loss: 1.8816862106323242, train acuracy: 0.390625
step: 53, val loss: 1.7671147584915161, val acuracy: 0.46150004863739014
step: 54, train loss: 1.6908152103424072, train acuracy: 0.453125
step: 54, val loss: 1.8885689973831177, val acuracy: 0.4104999899864197
step: 55, train loss: 1.892849087715149, train acuracy: 0.390625
step: 55, val loss: 1.8254104852676392, val acuracy: 0.453166663646698
step: 56, train loss: 1.7207565307617188, train acuracy: 0.484375
step: 56, val loss: 1.791663646697998, val acuracy: 0.42650002241134644
step: 57, train loss: 1.7618763446807861, train acuracy: 0.40625
step: 57, val loss: 1.8422486782073975, val acuracy: 0.37183335423469543
step: 58, train loss: 1.5128943920135498, train acuracy: 0.484375
step: 58, val loss: 1.7699264287948608, val acuracy: 0.3645000159740448
step: 59, train loss: 1.859807014465332, train acuracy: 0.28125
step: 59, val loss: 1.7574028968811035, val acuracy: 0.36733338236808777
step: 60, train loss: 1.7595199346542358, train acuracy: 0.3125
step: 60, val loss: 1.7553911209106445, val acuracy: 0.37000006437301636
step: 61, train loss: 1.6994874477386475, train acuracy: 0.3125
step: 61, val loss: 1.7556321620941162, val acuracy: 0.3710000514984131
step: 62, train loss: 1.7122547626495361, train acuracy: 0.4375
step: 62, val loss: 1.7548965215682983, val acuracy: 0.3706667125225067
step: 63, train loss: 1.5935287475585938, train acuracy: 0.453125
step: 63, val loss: 1.8474586009979248, val acuracy: 0.3504999876022339
step: 64, train loss: 1.5966463088989258, train acuracy: 0.453125
step: 64, val loss: 1.753427267074585, val acuracy: 0.3723333179950714
step: 65, train loss: 1.9165313243865967, train acuracy: 0.359375
step: 65, val loss: 1.7312287092208862, val acuracy: 0.3461666703224182
step: 66, train loss: 1.5457344055175781, train acuracy: 0.40625
step: 66, val loss: 1.8302466869354248, val acuracy: 0.37800002098083496
step: 67, train loss: 1.583458662033081, train acuracy: 0.5
step: 67, val loss: 1.6989445686340332, val acuracy: 0.4775000512599945
step: 68, train loss: 2.030122995376587, train acuracy: 0.265625
step: 68, val loss: 1.9724370241165161, val acuracy: 0.3305000066757202
step: 69, train loss: 1.6226316690444946, train acuracy: 0.53125
step: 69, val loss: 1.802526831626892, val acuracy: 0.48733335733413696
step: 70, train loss: 1.6540216207504272, train acuracy: 0.46875
step: 70, val loss: 1.6963367462158203, val acuracy: 0.4650000333786011
step: 71, train loss: 1.499518632888794, train acuracy: 0.5625
step: 71, val loss: 1.6649950742721558, val acuracy: 0.48499998450279236
step: 72, train loss: 2.3883678913116455, train acuracy: 0.109375
step: 72, val loss: 2.3378984928131104, val acuracy: 0.14033332467079163
step: 73, train loss: 2.3724160194396973, train acuracy: 0.0625
step: 73, val loss: 2.3314671516418457, val acuracy: 0.14433333277702332
step: 74, train loss: 2.456681728363037, train acuracy: 0.0625
step: 74, val loss: 2.3297119140625, val acuracy: 0.14433333277702332
step: 75, train loss: 2.309922695159912, train acuracy: 0.125
step: 75, val loss: 2.328033924102783, val acuracy: 0.14433333277702332
step: 76, train loss: 2.116014242172241, train acuracy: 0.25
step: 76, val loss: 2.2435691356658936, val acuracy: 0.15799999237060547
step: 77, train loss: 2.0608479976654053, train acuracy: 0.234375
step: 77, val loss: 2.3144099712371826, val acuracy: 0.1966666579246521
step: 78, train loss: 2.1087803840637207, train acuracy: 0.21875
step: 78, val loss: 2.1746163368225098, val acuracy: 0.1706666648387909
step: 79, train loss: 2.272962808609009, train acuracy: 0.109375
step: 79, val loss: 2.1684224605560303, val acuracy: 0.17299999296665192
step: 80, train loss: 2.134756088256836, train acuracy: 0.1875
step: 80, val loss: 2.1678454875946045, val acuracy: 0.1733333319425583
step: 81, train loss: 2.3413500785827637, train acuracy: 0.09375
step: 81, val loss: 2.2274506092071533, val acuracy: 0.16949999332427979
step: 82, train loss: 2.2640433311462402, train acuracy: 0.125
step: 82, val loss: 2.2220544815063477, val acuracy: 0.17249999940395355
step: 83, train loss: 2.17722225189209, train acuracy: 0.1875
step: 83, val loss: 2.220954656600952, val acuracy: 0.17266666889190674
step: 84, train loss: 2.132890462875366, train acuracy: 0.203125
step: 84, val loss: 2.2185072898864746, val acuracy: 0.1718333214521408
step: 85, train loss: 2.146705389022827, train acuracy: 0.15625
step: 85, val loss: 2.182326316833496, val acuracy: 0.1628333330154419
step: 86, train loss: 2.272420883178711, train acuracy: 0.125
step: 86, val loss: 2.1796255111694336, val acuracy: 0.16383333504199982
step: 87, train loss: 2.641338586807251, train acuracy: 0.28125
step: 87, val loss: 2.83215069770813, val acuracy: 0.2685000002384186
step: 88, train loss: 2.3469972610473633, train acuracy: 0.265625
step: 88, val loss: 2.613788366317749, val acuracy: 0.22200000286102295
step: 89, train loss: 2.5197665691375732, train acuracy: 0.265625
step: 89, val loss: 2.3892812728881836, val acuracy: 0.265500009059906
step: 90, train loss: 1.835935354232788, train acuracy: 0.34375
step: 90, val loss: 1.947338581085205, val acuracy: 0.273000031709671
step: 91, train loss: 1.8178882598876953, train acuracy: 0.34375
step: 91, val loss: 1.926177978515625, val acuracy: 0.28683334589004517
step: 92, train loss: 1.957560420036316, train acuracy: 0.265625
step: 92, val loss: 1.8802690505981445, val acuracy: 0.3333333432674408
step: 93, train loss: 1.6649158000946045, train acuracy: 0.375
step: 93, val loss: 2.004997968673706, val acuracy: 0.2586666941642761
step: 94, train loss: 1.9225438833236694, train acuracy: 0.3125
step: 94, val loss: 1.9108787775039673, val acuracy: 0.3205000162124634
step: 95, train loss: 1.947843074798584, train acuracy: 0.328125
step: 95, val loss: 1.9487416744232178, val acuracy: 0.3368333578109741
step: 96, train loss: 1.8699922561645508, train acuracy: 0.390625
step: 96, val loss: 1.9432921409606934, val acuracy: 0.3400000333786011
step: 97, train loss: 1.8874366283416748, train acuracy: 0.234375
step: 97, val loss: 2.0243000984191895, val acuracy: 0.23116666078567505
step: 98, train loss: 1.8547985553741455, train acuracy: 0.359375
step: 98, val loss: 1.9326956272125244, val acuracy: 0.3021667003631592
step: 99, train loss: 2.0071423053741455, train acuracy: 0.25
step: 99, val loss: 1.930866003036499, val acuracy: 0.30383336544036865
step: 100, train loss: 1.973741888999939, train acuracy: 0.28125
step: 100, val loss: 1.9664043188095093, val acuracy: 0.27666667103767395
step: 101, train loss: 1.8897007703781128, train acuracy: 0.375
step: 101, val loss: 2.1758289337158203, val acuracy: 0.22633333504199982
step: 102, train loss: 1.9739468097686768, train acuracy: 0.328125
step: 102, val loss: 2.0991954803466797, val acuracy: 0.25583335757255554
step: 103, train loss: 1.916722297668457, train acuracy: 0.34375
step: 103, val loss: 2.2509453296661377, val acuracy: 0.2748333513736725
step: 104, train loss: 1.6522555351257324, train acuracy: 0.515625
step: 104, val loss: 1.8878874778747559, val acuracy: 0.3501667082309723
step: 105, train loss: 1.9290539026260376, train acuracy: 0.234375
step: 105, val loss: 1.9670312404632568, val acuracy: 0.24716666340827942
step: 106, train loss: 1.8821685314178467, train acuracy: 0.34375
step: 106, val loss: 1.9443939924240112, val acuracy: 0.2613333463668823
step: 107, train loss: 1.968395471572876, train acuracy: 0.21875
step: 107, val loss: 1.9451637268066406, val acuracy: 0.2600000202655792
step: 108, train loss: 1.8800268173217773, train acuracy: 0.296875
step: 108, val loss: 1.9510009288787842, val acuracy: 0.25550001859664917
step: 109, train loss: 2.057745933532715, train acuracy: 0.28125
step: 109, val loss: 1.9493579864501953, val acuracy: 0.2586666941642761
step: 110, train loss: 1.936204195022583, train acuracy: 0.234375
step: 110, val loss: 1.94830322265625, val acuracy: 0.25950002670288086
step: 111, train loss: 1.9790223836898804, train acuracy: 0.21875
step: 111, val loss: 1.9477888345718384, val acuracy: 0.25866666436195374
step: 112, train loss: 1.867032527923584, train acuracy: 0.3125
step: 112, val loss: 1.9464507102966309, val acuracy: 0.2600000202655792
step: 113, train loss: 2.029879093170166, train acuracy: 0.15625
step: 113, val loss: 1.9460570812225342, val acuracy: 0.25966668128967285
step: 114, train loss: 1.9412611722946167, train acuracy: 0.140625
step: 114, val loss: 1.9470666646957397, val acuracy: 0.2473333477973938
step: 115, train loss: 1.9443703889846802, train acuracy: 0.1875
step: 115, val loss: 1.9463417530059814, val acuracy: 0.24766667187213898
step: 116, train loss: 1.9251519441604614, train acuracy: 0.390625
step: 116, val loss: 1.9486150741577148, val acuracy: 0.2735000252723694
step: 117, train loss: 1.9498798847198486, train acuracy: 0.3125
step: 117, val loss: 1.9657561779022217, val acuracy: 0.29866668581962585
step: 118, train loss: 1.9464876651763916, train acuracy: 0.171875
step: 118, val loss: 1.9259752035140991, val acuracy: 0.20999999344348907
step: 119, train loss: 1.9536155462265015, train acuracy: 0.25
step: 119, val loss: 1.9238080978393555, val acuracy: 0.20983333885669708
step: 120, train loss: 1.9870083332061768, train acuracy: 0.1875
step: 120, val loss: 1.9474619626998901, val acuracy: 0.2786666750907898
step: 121, train loss: 1.9406847953796387, train acuracy: 0.25
step: 121, val loss: 1.9751949310302734, val acuracy: 0.22833332419395447
step: 122, train loss: 1.9374653100967407, train acuracy: 0.265625
step: 122, val loss: 1.9084008932113647, val acuracy: 0.2876666784286499
step: 123, train loss: 1.9741437435150146, train acuracy: 0.21875
step: 123, val loss: 1.9009761810302734, val acuracy: 0.2915000021457672
step: 124, train loss: 1.975838303565979, train acuracy: 0.359375
step: 124, val loss: 1.97371506690979, val acuracy: 0.3240000307559967
step: 125, train loss: 1.9826786518096924, train acuracy: 0.265625
step: 125, val loss: 1.9668796062469482, val acuracy: 0.32883337140083313
step: 126, train loss: 1.9191064834594727, train acuracy: 0.375
step: 126, val loss: 1.9612629413604736, val acuracy: 0.3293333649635315
step: 127, train loss: 1.950981855392456, train acuracy: 0.265625
step: 127, val loss: 1.9633923768997192, val acuracy: 0.31166666746139526
step: 128, train loss: 1.9040257930755615, train acuracy: 0.3125
step: 128, val loss: 1.9542994499206543, val acuracy: 0.31550002098083496
step: 129, train loss: 1.8954219818115234, train acuracy: 0.375
step: 129, val loss: 1.9536505937576294, val acuracy: 0.31433334946632385
step: 130, train loss: 2.1382827758789062, train acuracy: 0.21875
step: 130, val loss: 1.9525293111801147, val acuracy: 0.31550002098083496
step: 131, train loss: 1.837620735168457, train acuracy: 0.328125
step: 131, val loss: 1.952155351638794, val acuracy: 0.30900001525878906
step: 132, train loss: 1.9580464363098145, train acuracy: 0.390625
step: 132, val loss: 2.083259105682373, val acuracy: 0.2993333339691162
step: 133, train loss: 2.0028347969055176, train acuracy: 0.3125
step: 133, val loss: 2.002697229385376, val acuracy: 0.3020000159740448
step: 134, train loss: 1.9945778846740723, train acuracy: 0.265625
step: 134, val loss: 1.9870492219924927, val acuracy: 0.31033337116241455
step: 135, train loss: 1.6819720268249512, train acuracy: 0.40625
step: 135, val loss: 2.166543960571289, val acuracy: 0.24533334374427795
step: 136, train loss: 2.042167901992798, train acuracy: 0.359375
step: 136, val loss: 2.197413921356201, val acuracy: 0.281166672706604
step: 137, train loss: 2.0656161308288574, train acuracy: 0.3125
step: 137, val loss: 2.15958309173584, val acuracy: 0.28583332896232605
step: 138, train loss: 2.1661362648010254, train acuracy: 0.234375
step: 138, val loss: 2.146977424621582, val acuracy: 0.22083333134651184
step: 139, train loss: 2.163198947906494, train acuracy: 0.25
step: 139, val loss: 2.146012306213379, val acuracy: 0.22066667675971985
step: 140, train loss: 1.7674617767333984, train acuracy: 0.4375
step: 140, val loss: 2.306453227996826, val acuracy: 0.3410000205039978
step: 141, train loss: 2.025698184967041, train acuracy: 0.28125
step: 141, val loss: 2.1828789710998535, val acuracy: 0.20616668462753296
step: 142, train loss: 2.137862205505371, train acuracy: 0.265625
step: 142, val loss: 2.1785736083984375, val acuracy: 0.20750001072883606
step: 143, train loss: 2.245619535446167, train acuracy: 0.15625
step: 143, val loss: 2.1768851280212402, val acuracy: 0.2071666717529297
step: 144, train loss: 2.083648681640625, train acuracy: 0.28125
step: 144, val loss: 2.3166239261627197, val acuracy: 0.2633333206176758
step: 145, train loss: 2.1035640239715576, train acuracy: 0.25
step: 145, val loss: 2.2284252643585205, val acuracy: 0.19883334636688232
step: 146, train loss: 2.211927890777588, train acuracy: 0.1875
step: 146, val loss: 2.231585741043091, val acuracy: 0.16716666519641876
step: 147, train loss: 2.113973617553711, train acuracy: 0.25
step: 147, val loss: 2.189296007156372, val acuracy: 0.22283333539962769
step: 148, train loss: 2.0706629753112793, train acuracy: 0.25
step: 148, val loss: 2.182492256164551, val acuracy: 0.2240000069141388
step: 149, train loss: 2.1327197551727295, train acuracy: 0.234375
step: 149, val loss: 2.243332624435425, val acuracy: 0.16616666316986084
step: 150, train loss: 1.999300479888916, train acuracy: 0.3125
step: 150, val loss: 2.2243685722351074, val acuracy: 0.24183332920074463
step: 151, train loss: 2.238062858581543, train acuracy: 0.15625
step: 151, val loss: 2.233417510986328, val acuracy: 0.16483332216739655
step: 152, train loss: 2.214751720428467, train acuracy: 0.234375
step: 152, val loss: 2.191279888153076, val acuracy: 0.22550000250339508
step: 153, train loss: 2.2813706398010254, train acuracy: 0.28125
step: 153, val loss: 2.1885857582092285, val acuracy: 0.23016667366027832
step: 154, train loss: 2.2440414428710938, train acuracy: 0.1875
step: 154, val loss: 2.1839053630828857, val acuracy: 0.23150001466274261
step: 155, train loss: 2.007676601409912, train acuracy: 0.296875
step: 155, val loss: 2.246151924133301, val acuracy: 0.26333338022232056
step: 156, train loss: 1.9605250358581543, train acuracy: 0.375
step: 156, val loss: 2.241166114807129, val acuracy: 0.2630000114440918
step: 157, train loss: 2.305845260620117, train acuracy: 0.21875
step: 157, val loss: 2.2372641563415527, val acuracy: 0.2615000009536743
step: 158, train loss: 2.1423964500427246, train acuracy: 0.265625
step: 158, val loss: 2.2332065105438232, val acuracy: 0.26216667890548706
step: 159, train loss: 1.861348032951355, train acuracy: 0.359375
step: 159, val loss: 2.2333462238311768, val acuracy: 0.26366665959358215
step: 160, train loss: 2.3256943225860596, train acuracy: 0.25
step: 160, val loss: 2.2326083183288574, val acuracy: 0.2628333568572998
step: 161, train loss: 2.523782253265381, train acuracy: 0.21875
step: 161, val loss: 2.361538887023926, val acuracy: 0.210666686296463
step: 162, train loss: 2.157536506652832, train acuracy: 0.3125
step: 162, val loss: 2.4036941528320312, val acuracy: 0.257666677236557
step: 163, train loss: 2.3295655250549316, train acuracy: 0.15625
step: 163, val loss: 2.281096935272217, val acuracy: 0.1771666556596756
step: 164, train loss: 2.4280147552490234, train acuracy: 0.09375
step: 164, val loss: 2.2552437782287598, val acuracy: 0.1574999988079071
step: 165, train loss: 2.3314993381500244, train acuracy: 0.109375
step: 165, val loss: 2.249460458755493, val acuracy: 0.1588333249092102
step: 166, train loss: 2.074319362640381, train acuracy: 0.25
step: 166, val loss: 2.2502682209014893, val acuracy: 0.19566667079925537
step: 167, train loss: 2.0050015449523926, train acuracy: 0.28125
step: 167, val loss: 2.243466854095459, val acuracy: 0.24633334577083588
step: 168, train loss: 2.5103204250335693, train acuracy: 0.171875
step: 168, val loss: 2.5262699127197266, val acuracy: 0.148499995470047
step: 169, train loss: 2.2680084705352783, train acuracy: 0.171875
step: 169, val loss: 2.355292320251465, val acuracy: 0.11516666412353516
step: 170, train loss: 2.246403694152832, train acuracy: 0.09375
step: 170, val loss: 2.362941026687622, val acuracy: 0.11249999701976776
step: 171, train loss: 2.3917346000671387, train acuracy: 0.125
step: 171, val loss: 2.339956760406494, val acuracy: 0.16516666114330292
step: 172, train loss: 2.1911239624023438, train acuracy: 0.21875
step: 172, val loss: 2.229423761367798, val acuracy: 0.19233334064483643
step: 173, train loss: 2.157310962677002, train acuracy: 0.203125
step: 173, val loss: 2.1792335510253906, val acuracy: 0.20116668939590454
step: 174, train loss: 2.1862618923187256, train acuracy: 0.203125
step: 174, val loss: 2.1707208156585693, val acuracy: 0.20233333110809326
step: 175, train loss: 2.1411542892456055, train acuracy: 0.203125
step: 175, val loss: 2.166303873062134, val acuracy: 0.20250000059604645
step: 176, train loss: 2.108273983001709, train acuracy: 0.265625
step: 176, val loss: 2.166417360305786, val acuracy: 0.20216667652130127
step: 177, train loss: 1.8958320617675781, train acuracy: 0.359375
step: 177, val loss: 2.133922576904297, val acuracy: 0.27550002932548523
step: 178, train loss: 2.28251314163208, train acuracy: 0.25
step: 178, val loss: 2.1290340423583984, val acuracy: 0.27383333444595337
step: 179, train loss: 2.210132122039795, train acuracy: 0.265625
step: 179, val loss: 2.1278841495513916, val acuracy: 0.27383336424827576
step: 180, train loss: 2.082493543624878, train acuracy: 0.265625
step: 180, val loss: 2.1955037117004395, val acuracy: 0.203166663646698
step: 181, train loss: 2.067383289337158, train acuracy: 0.21875
step: 181, val loss: 2.1487197875976562, val acuracy: 0.21066667139530182
step: 182, train loss: 2.0253801345825195, train acuracy: 0.28125
step: 182, val loss: 2.184736728668213, val acuracy: 0.23766668140888214
step: 183, train loss: 2.113182544708252, train acuracy: 0.234375
step: 183, val loss: 2.0886282920837402, val acuracy: 0.21433334052562714
step: 184, train loss: 1.9134747982025146, train acuracy: 0.296875
step: 184, val loss: 2.2380945682525635, val acuracy: 0.23083335161209106
step: 185, train loss: 2.160069465637207, train acuracy: 0.1875
step: 185, val loss: 2.1678731441497803, val acuracy: 0.2161666601896286
step: 186, train loss: 2.1645352840423584, train acuracy: 0.203125
step: 186, val loss: 2.156424045562744, val acuracy: 0.21666666865348816
step: 187, train loss: 2.240696668624878, train acuracy: 0.140625
step: 187, val loss: 2.1540257930755615, val acuracy: 0.21766667068004608
step: 188, train loss: 2.1039648056030273, train acuracy: 0.265625
step: 188, val loss: 2.151634693145752, val acuracy: 0.21833333373069763
step: 189, train loss: 2.199079990386963, train acuracy: 0.234375
step: 189, val loss: 2.1513936519622803, val acuracy: 0.21833333373069763
step: 190, train loss: 2.130934238433838, train acuracy: 0.234375
step: 190, val loss: 2.150599956512451, val acuracy: 0.21850000321865082
step: 191, train loss: 2.0513720512390137, train acuracy: 0.265625
step: 191, val loss: 2.1502249240875244, val acuracy: 0.218666672706604
step: 192, train loss: 2.1065146923065186, train acuracy: 0.21875
step: 192, val loss: 2.1937034130096436, val acuracy: 0.20683333277702332
step: 193, train loss: 2.0089550018310547, train acuracy: 0.28125
step: 193, val loss: 2.2217726707458496, val acuracy: 0.18316668272018433
step: 194, train loss: 2.0069785118103027, train acuracy: 0.296875
step: 194, val loss: 2.2381646633148193, val acuracy: 0.19166666269302368
step: 195, train loss: 2.2151236534118652, train acuracy: 0.234375
step: 195, val loss: 2.235464096069336, val acuracy: 0.19233334064483643
step: 196, train loss: 2.233614444732666, train acuracy: 0.21875
step: 196, val loss: 2.234102487564087, val acuracy: 0.19216667115688324
step: 197, train loss: 2.2441606521606445, train acuracy: 0.265625
step: 197, val loss: 2.233710765838623, val acuracy: 0.1926666796207428
step: 198, train loss: 2.3466010093688965, train acuracy: 0.109375
step: 198, val loss: 2.2330825328826904, val acuracy: 0.1925000101327896
step: 199, train loss: 2.349769353866577, train acuracy: 0.140625
step: 199, val loss: 2.2321057319641113, val acuracy: 0.19333332777023315
step: 200, train loss: 2.10396409034729, train acuracy: 0.21875
step: 200, val loss: 2.2397665977478027, val acuracy: 0.18766666948795319
step: 201, train loss: 2.2898669242858887, train acuracy: 0.15625
step: 201, val loss: 2.237422466278076, val acuracy: 0.19333334267139435
step: 202, train loss: 2.0229973793029785, train acuracy: 0.25
step: 202, val loss: 2.2358553409576416, val acuracy: 0.19333332777023315
step: 203, train loss: 2.0888407230377197, train acuracy: 0.203125
step: 203, val loss: 2.235581874847412, val acuracy: 0.19316667318344116
step: 204, train loss: 2.211899518966675, train acuracy: 0.171875
step: 204, val loss: 2.232693672180176, val acuracy: 0.19499999284744263
step: 205, train loss: 2.231812000274658, train acuracy: 0.1875
step: 205, val loss: 2.2318177223205566, val acuracy: 0.195166677236557
step: 206, train loss: 2.2041304111480713, train acuracy: 0.21875
step: 206, val loss: 2.2314329147338867, val acuracy: 0.19483333826065063
step: 207, train loss: 2.36185359954834, train acuracy: 0.109375
step: 207, val loss: 2.2358546257019043, val acuracy: 0.19183333218097687
step: 208, train loss: 2.3059492111206055, train acuracy: 0.140625
step: 208, val loss: 2.222764492034912, val acuracy: 0.18950000405311584
step: 209, train loss: 2.219789505004883, train acuracy: 0.203125
step: 209, val loss: 2.267143964767456, val acuracy: 0.17866665124893188
step: 210, train loss: 2.0565171241760254, train acuracy: 0.21875
step: 210, val loss: 2.1972148418426514, val acuracy: 0.19283334910869598
step: 211, train loss: 2.1269760131835938, train acuracy: 0.265625
step: 211, val loss: 2.2444422245025635, val acuracy: 0.2004999965429306
step: 212, train loss: 2.2510123252868652, train acuracy: 0.15625
step: 212, val loss: 2.233917713165283, val acuracy: 0.20216667652130127
step: 213, train loss: 2.279979705810547, train acuracy: 0.15625
step: 213, val loss: 2.2027552127838135, val acuracy: 0.21533332765102386
step: 214, train loss: 2.1002254486083984, train acuracy: 0.265625
step: 214, val loss: 2.0040671825408936, val acuracy: 0.273000031709671
step: 215, train loss: 1.8046623468399048, train acuracy: 0.390625
step: 215, val loss: 1.9564533233642578, val acuracy: 0.33233335614204407
step: 216, train loss: 1.9234436750411987, train acuracy: 0.359375
step: 216, val loss: 1.9517868757247925, val acuracy: 0.27800002694129944
step: 217, train loss: 2.0176753997802734, train acuracy: 0.1875
step: 217, val loss: 1.9455934762954712, val acuracy: 0.2815000116825104
step: 218, train loss: 1.8293757438659668, train acuracy: 0.328125
step: 218, val loss: 1.943044662475586, val acuracy: 0.2821666896343231
step: 219, train loss: 1.7930653095245361, train acuracy: 0.3125
step: 219, val loss: 1.9367082118988037, val acuracy: 0.28200000524520874
step: 220, train loss: 1.9779812097549438, train acuracy: 0.25
step: 220, val loss: 1.9356324672698975, val acuracy: 0.2826666831970215
step: 221, train loss: 1.9789434671401978, train acuracy: 0.234375
step: 221, val loss: 1.9346526861190796, val acuracy: 0.2828333377838135
step: 222, train loss: 1.9917960166931152, train acuracy: 0.3125
step: 222, val loss: 1.9334818124771118, val acuracy: 0.2825000286102295
step: 223, train loss: 1.8911843299865723, train acuracy: 0.296875
step: 223, val loss: 1.9639954566955566, val acuracy: 0.2695000171661377
step: 224, train loss: 15.697959899902344, train acuracy: 0.109375
step: 224, val loss: 17.10529899597168, val acuracy: 0.10449999570846558
step: 225, train loss: 8.008992195129395, train acuracy: 0.109375
step: 225, val loss: 7.786084175109863, val acuracy: 0.1236666738986969
step: 226, train loss: 5.334287166595459, train acuracy: 0.109375
step: 226, val loss: 5.517613410949707, val acuracy: 0.1053333431482315
step: 227, train loss: 3.1253738403320312, train acuracy: 0.125
step: 227, val loss: 2.964724063873291, val acuracy: 0.09783332794904709
step: 228, train loss: 2.4339895248413086, train acuracy: 0.109375
step: 228, val loss: 2.470243453979492, val acuracy: 0.09833332896232605
step: 229, train loss: 2.1329431533813477, train acuracy: 0.125
step: 229, val loss: 2.359300374984741, val acuracy: 0.11099998652935028
step: 230, train loss: 2.330451011657715, train acuracy: 0.171875
step: 230, val loss: 2.3846139907836914, val acuracy: 0.12733332812786102
step: 231, train loss: 2.4440152645111084, train acuracy: 0.078125
step: 231, val loss: 2.379993200302124, val acuracy: 0.12849998474121094
step: 232, train loss: 2.3691351413726807, train acuracy: 0.109375
step: 232, val loss: 2.3798141479492188, val acuracy: 0.12600000202655792
step: 233, train loss: 2.4171178340911865, train acuracy: 0.0625
step: 233, val loss: 2.3790173530578613, val acuracy: 0.1264999955892563
step: 234, train loss: 2.34403133392334, train acuracy: 0.078125
step: 234, val loss: 2.33524751663208, val acuracy: 0.10533333569765091
step: 235, train loss: 2.2490768432617188, train acuracy: 0.15625
step: 235, val loss: 2.3481054306030273, val acuracy: 0.09666666388511658
step: 236, train loss: 2.3426079750061035, train acuracy: 0.109375
step: 236, val loss: 2.3388242721557617, val acuracy: 0.11416665464639664
step: 237, train loss: 2.2526679039001465, train acuracy: 0.25
step: 237, val loss: 2.3845772743225098, val acuracy: 0.09749999642372131
step: 238, train loss: 2.271304130554199, train acuracy: 0.203125
step: 238, val loss: 2.4235148429870605, val acuracy: 0.10400000214576721
step: 239, train loss: 2.3763723373413086, train acuracy: 0.09375
step: 239, val loss: 2.3661258220672607, val acuracy: 0.10533333569765091
step: 240, train loss: 2.3966963291168213, train acuracy: 0.078125
step: 240, val loss: 2.3623390197753906, val acuracy: 0.10533333569765091
step: 241, train loss: 2.3721060752868652, train acuracy: 0.03125
step: 241, val loss: 2.3559188842773438, val acuracy: 0.1053333431482315
step: 242, train loss: 2.354151964187622, train acuracy: 0.078125
step: 242, val loss: 2.3481521606445312, val acuracy: 0.1055000051856041
step: 243, train loss: 2.4021148681640625, train acuracy: 0.109375
step: 243, val loss: 2.352261543273926, val acuracy: 0.10533333569765091
step: 244, train loss: 2.2190637588500977, train acuracy: 0.1875
step: 244, val loss: 2.2972495555877686, val acuracy: 0.13449998199939728
step: 245, train loss: 2.2262861728668213, train acuracy: 0.125
step: 245, val loss: 2.2745554447174072, val acuracy: 0.1391666680574417
step: 246, train loss: 38.4810791015625, train acuracy: 0.1875
step: 246, val loss: 42.82532501220703, val acuracy: 0.132999986410141
step: 247, train loss: 30.555891036987305, train acuracy: 0.1875
step: 247, val loss: 31.01189613342285, val acuracy: 0.18266665935516357
step: 248, train loss: 28.456178665161133, train acuracy: 0.28125
step: 248, val loss: 29.076467514038086, val acuracy: 0.1914999932050705
step: 249, train loss: 23.956552505493164, train acuracy: 0.296875
step: 249, val loss: 34.286705017089844, val acuracy: 0.2291666567325592
step: 250, train loss: 8.253874778747559, train acuracy: 0.296875
step: 250, val loss: 10.216937065124512, val acuracy: 0.2408333569765091
step: 251, train loss: 10.47476577758789, train acuracy: 0.046875
step: 251, val loss: 11.97537899017334, val acuracy: 0.08866667747497559
step: 252, train loss: 11.680171966552734, train acuracy: 0.078125
step: 252, val loss: 11.322429656982422, val acuracy: 0.10433334112167358
step: 253, train loss: 10.204622268676758, train acuracy: 0.125
step: 253, val loss: 10.611414909362793, val acuracy: 0.1054999977350235
step: 254, train loss: 9.75905990600586, train acuracy: 0.046875
step: 254, val loss: 9.494714736938477, val acuracy: 0.07566666603088379
step: 255, train loss: 7.375504493713379, train acuracy: 0.09375
step: 255, val loss: 5.92162561416626, val acuracy: 0.13916665315628052
step: 256, train loss: 6.604888916015625, train acuracy: 0.125
step: 256, val loss: 7.289188861846924, val acuracy: 0.12049999833106995
step: 257, train loss: 6.695612907409668, train acuracy: 0.21875
step: 257, val loss: 7.85774564743042, val acuracy: 0.16116665303707123
step: 258, train loss: 21.832265853881836, train acuracy: 0.140625
step: 258, val loss: 24.633737564086914, val acuracy: 0.14099998772144318
step: 259, train loss: 57.15642547607422, train acuracy: 0.09375
step: 259, val loss: 51.391998291015625, val acuracy: 0.16733333468437195
step: 260, train loss: 51.691253662109375, train acuracy: 0.21875
step: 260, val loss: 60.65205383300781, val acuracy: 0.1576666533946991
step: 261, train loss: 71.65536499023438, train acuracy: 0.203125
step: 261, val loss: 87.32391357421875, val acuracy: 0.12916666269302368
step: 262, train loss: 109.59434509277344, train acuracy: 0.28125
step: 262, val loss: 110.24034118652344, val acuracy: 0.21383333206176758
step: 263, train loss: 108.33201599121094, train acuracy: 0.078125
step: 263, val loss: 103.9559326171875, val acuracy: 0.10583332180976868
step: 264, train loss: 105.46571350097656, train acuracy: 0.09375
step: 264, val loss: 108.83045959472656, val acuracy: 0.10400000214576721
step: 265, train loss: 96.89955139160156, train acuracy: 0.109375
step: 265, val loss: 102.48650360107422, val acuracy: 0.07916665822267532
step: 266, train loss: 176.56600952148438, train acuracy: 0.0625
step: 266, val loss: 167.53311157226562, val acuracy: 0.09649999439716339
step: 267, train loss: 226.43267822265625, train acuracy: 0.171875
step: 267, val loss: 304.5671081542969, val acuracy: 0.1903333216905594
step: 268, train loss: 102.92987060546875, train acuracy: 0.125
step: 268, val loss: 103.548828125, val acuracy: 0.09816665947437286
step: 269, train loss: 98.04237365722656, train acuracy: 0.15625
step: 269, val loss: 100.40280151367188, val acuracy: 0.1538333296775818
step: 270, train loss: 6102.1259765625, train acuracy: 0.15625
step: 270, val loss: 6853.74951171875, val acuracy: 0.10899999737739563
step: 271, train loss: 28618012.0, train acuracy: 0.078125
step: 271, val loss: 27251446.0, val acuracy: 0.09533333778381348
step: 272, train loss: 4.635522812042281e+17, train acuracy: 0.109375
step: 272, val loss: 4.7745804527887974e+17, val acuracy: 0.1054999977350235
step: 273, train loss: nan, train acuracy: 0.109375
step: 273, val loss: nan, val acuracy: 0.09816667437553406
step: 274, train loss: nan, train acuracy: 0.140625
step: 274, val loss: nan, val acuracy: 0.10400000214576721
step: 275, train loss: nan, train acuracy: 0.03125
step: 275, val loss: nan, val acuracy: 0.10400000214576721
step: 276, train loss: nan, train acuracy: 0.046875
step: 276, val loss: nan, val acuracy: 0.10400000214576721
step: 277, train loss: nan, train acuracy: 0.03125
step: 277, val loss: nan, val acuracy: 0.10400000214576721
step: 278, train loss: nan, train acuracy: 0.140625
step: 278, val loss: nan, val acuracy: 0.10400000214576721
step: 279, train loss: nan, train acuracy: 0.09375
step: 279, val loss: nan, val acuracy: 0.10400000214576721
step: 280, train loss: nan, train acuracy: 0.046875
step: 280, val loss: nan, val acuracy: 0.10400000214576721
step: 281, train loss: nan, train acuracy: 0.046875
step: 281, val loss: nan, val acuracy: 0.10400000214576721
step: 282, train loss: nan, train acuracy: 0.0625
step: 282, val loss: nan, val acuracy: 0.10400000214576721
step: 283, train loss: nan, train acuracy: 0.078125
step: 283, val loss: nan, val acuracy: 0.10400000214576721
step: 284, train loss: nan, train acuracy: 0.109375
step: 284, val loss: nan, val acuracy: 0.10400000214576721
step: 285, train loss: nan, train acuracy: 0.125
step: 285, val loss: nan, val acuracy: 0.10400000214576721
step: 286, train loss: nan, train acuracy: 0.0625
step: 286, val loss: nan, val acuracy: 0.10400000214576721
step: 287, train loss: nan, train acuracy: 0.078125
step: 287, val loss: nan, val acuracy: 0.10400000214576721
step: 288, train loss: nan, train acuracy: 0.09375
step: 288, val loss: nan, val acuracy: 0.10400000214576721
step: 289, train loss: nan, train acuracy: 0.09375
step: 289, val loss: nan, val acuracy: 0.10400000214576721
step: 290, train loss: nan, train acuracy: 0.078125
step: 290, val loss: nan, val acuracy: 0.10400000214576721
step: 291, train loss: nan, train acuracy: 0.09375
step: 291, val loss: nan, val acuracy: 0.10400000214576721
step: 292, train loss: nan, train acuracy: 0.046875
step: 292, val loss: nan, val acuracy: 0.10400000214576721
step: 293, train loss: nan, train acuracy: 0.15625
step: 293, val loss: nan, val acuracy: 0.10400000214576721
step: 294, train loss: nan, train acuracy: 0.09375
step: 294, val loss: nan, val acuracy: 0.10400000214576721
step: 295, train loss: nan, train acuracy: 0.09375
step: 295, val loss: nan, val acuracy: 0.10400000214576721
step: 296, train loss: nan, train acuracy: 0.046875
step: 296, val loss: nan, val acuracy: 0.10400000214576721
step: 297, train loss: nan, train acuracy: 0.078125
step: 297, val loss: nan, val acuracy: 0.10400000214576721
step: 298, train loss: nan, train acuracy: 0.1875
step: 298, val loss: nan, val acuracy: 0.10400000214576721
step: 299, train loss: nan, train acuracy: 0.1875
step: 299, val loss: nan, val acuracy: 0.10400000214576721
step: 300, train loss: nan, train acuracy: 0.109375
step: 300, val loss: nan, val acuracy: 0.10400000214576721
step: 301, train loss: nan, train acuracy: 0.125
step: 301, val loss: nan, val acuracy: 0.10400000214576721
step: 302, train loss: nan, train acuracy: 0.078125
step: 302, val loss: nan, val acuracy: 0.10400000214576721
step: 303, train loss: nan, train acuracy: 0.125
step: 303, val loss: nan, val acuracy: 0.10400000214576721
step: 304, train loss: nan, train acuracy: 0.078125
step: 304, val loss: nan, val acuracy: 0.10400000214576721
step: 305, train loss: nan, train acuracy: 0.078125
step: 305, val loss: nan, val acuracy: 0.10400000214576721
step: 306, train loss: nan, train acuracy: 0.03125
step: 306, val loss: nan, val acuracy: 0.10400000214576721
step: 307, train loss: nan, train acuracy: 0.1875
step: 307, val loss: nan, val acuracy: 0.10400000214576721
step: 308, train loss: nan, train acuracy: 0.078125
step: 308, val loss: nan, val acuracy: 0.10400000214576721
step: 309, train loss: nan, train acuracy: 0.0625
step: 309, val loss: nan, val acuracy: 0.10400000214576721
step: 310, train loss: nan, train acuracy: 0.0625
step: 310, val loss: nan, val acuracy: 0.10400000214576721
step: 311, train loss: nan, train acuracy: 0.171875
step: 311, val loss: nan, val acuracy: 0.10400000214576721
step: 312, train loss: nan, train acuracy: 0.09375
step: 312, val loss: nan, val acuracy: 0.10400000214576721
step: 313, train loss: nan, train acuracy: 0.078125
step: 313, val loss: nan, val acuracy: 0.10400000214576721
step: 314, train loss: nan, train acuracy: 0.125
step: 314, val loss: nan, val acuracy: 0.10400000214576721
step: 315, train loss: nan, train acuracy: 0.0625
step: 315, val loss: nan, val acuracy: 0.10400000214576721
step: 316, train loss: nan, train acuracy: 0.03125
step: 316, val loss: nan, val acuracy: 0.10400000214576721
step: 317, train loss: nan, train acuracy: 0.09375
step: 317, val loss: nan, val acuracy: 0.10400000214576721
step: 318, train loss: nan, train acuracy: 0.046875
step: 318, val loss: nan, val acuracy: 0.10400000214576721
step: 319, train loss: nan, train acuracy: 0.125
step: 319, val loss: nan, val acuracy: 0.10400000214576721
step: 320, train loss: nan, train acuracy: 0.109375
step: 320, val loss: nan, val acuracy: 0.10400000214576721
step: 321, train loss: nan, train acuracy: 0.125
step: 321, val loss: nan, val acuracy: 0.10400000214576721
step: 322, train loss: nan, train acuracy: 0.171875
step: 322, val loss: nan, val acuracy: 0.10400000214576721
step: 323, train loss: nan, train acuracy: 0.0625
step: 323, val loss: nan, val acuracy: 0.10400000214576721
step: 324, train loss: nan, train acuracy: 0.09375
step: 324, val loss: nan, val acuracy: 0.10400000214576721
step: 325, train loss: nan, train acuracy: 0.0625
step: 325, val loss: nan, val acuracy: 0.10400000214576721
step: 326, train loss: nan, train acuracy: 0.03125
step: 326, val loss: nan, val acuracy: 0.10400000214576721
step: 327, train loss: nan, train acuracy: 0.078125
step: 327, val loss: nan, val acuracy: 0.10400000214576721
step: 328, train loss: nan, train acuracy: 0.09375
step: 328, val loss: nan, val acuracy: 0.10400000214576721
step: 329, train loss: nan, train acuracy: 0.09375
step: 329, val loss: nan, val acuracy: 0.10400000214576721
step: 330, train loss: nan, train acuracy: 0.109375
step: 330, val loss: nan, val acuracy: 0.10400000214576721
step: 331, train loss: nan, train acuracy: 0.09375
step: 331, val loss: nan, val acuracy: 0.10400000214576721
step: 332, train loss: nan, train acuracy: 0.09375
step: 332, val loss: nan, val acuracy: 0.10400000214576721
step: 333, train loss: nan, train acuracy: 0.171875
step: 333, val loss: nan, val acuracy: 0.10400000214576721
step: 334, train loss: nan, train acuracy: 0.078125
step: 334, val loss: nan, val acuracy: 0.10400000214576721
step: 335, train loss: nan, train acuracy: 0.140625
step: 335, val loss: nan, val acuracy: 0.10400000214576721
step: 336, train loss: nan, train acuracy: 0.140625
step: 336, val loss: nan, val acuracy: 0.10400000214576721
step: 337, train loss: nan, train acuracy: 0.078125
step: 337, val loss: nan, val acuracy: 0.10400000214576721
step: 338, train loss: nan, train acuracy: 0.125
step: 338, val loss: nan, val acuracy: 0.10400000214576721
step: 339, train loss: nan, train acuracy: 0.125
step: 339, val loss: nan, val acuracy: 0.10400000214576721
step: 340, train loss: nan, train acuracy: 0.140625
step: 340, val loss: nan, val acuracy: 0.10400000214576721
step: 341, train loss: nan, train acuracy: 0.171875
step: 341, val loss: nan, val acuracy: 0.10400000214576721
step: 342, train loss: nan, train acuracy: 0.109375
step: 342, val loss: nan, val acuracy: 0.10400000214576721
step: 343, train loss: nan, train acuracy: 0.078125
step: 343, val loss: nan, val acuracy: 0.10400000214576721
step: 344, train loss: nan, train acuracy: 0.09375
step: 344, val loss: nan, val acuracy: 0.10400000214576721
step: 345, train loss: nan, train acuracy: 0.078125
step: 345, val loss: nan, val acuracy: 0.10400000214576721
step: 346, train loss: nan, train acuracy: 0.078125
step: 346, val loss: nan, val acuracy: 0.10400000214576721
step: 347, train loss: nan, train acuracy: 0.109375
step: 347, val loss: nan, val acuracy: 0.10400000214576721
step: 348, train loss: nan, train acuracy: 0.046875
step: 348, val loss: nan, val acuracy: 0.10400000214576721
step: 349, train loss: nan, train acuracy: 0.078125
step: 349, val loss: nan, val acuracy: 0.10400000214576721
step: 350, train loss: nan, train acuracy: 0.0625
step: 350, val loss: nan, val acuracy: 0.10400000214576721
step: 351, train loss: nan, train acuracy: 0.078125
step: 351, val loss: nan, val acuracy: 0.10400000214576721
step: 352, train loss: nan, train acuracy: 0.09375
step: 352, val loss: nan, val acuracy: 0.10400000214576721
step: 353, train loss: nan, train acuracy: 0.109375
step: 353, val loss: nan, val acuracy: 0.10400000214576721
step: 354, train loss: nan, train acuracy: 0.09375
step: 354, val loss: nan, val acuracy: 0.10400000214576721
step: 355, train loss: nan, train acuracy: 0.125
step: 355, val loss: nan, val acuracy: 0.10400000214576721
step: 356, train loss: nan, train acuracy: 0.125
step: 356, val loss: nan, val acuracy: 0.10400000214576721
step: 357, train loss: nan, train acuracy: 0.0625
step: 357, val loss: nan, val acuracy: 0.10400000214576721
step: 358, train loss: nan, train acuracy: 0.125
step: 358, val loss: nan, val acuracy: 0.10400000214576721
step: 359, train loss: nan, train acuracy: 0.078125
step: 359, val loss: nan, val acuracy: 0.10400000214576721
step: 360, train loss: nan, train acuracy: 0.09375
step: 360, val loss: nan, val acuracy: 0.10400000214576721
step: 361, train loss: nan, train acuracy: 0.171875
step: 361, val loss: nan, val acuracy: 0.10400000214576721
step: 362, train loss: nan, train acuracy: 0.078125
step: 362, val loss: nan, val acuracy: 0.10400000214576721
step: 363, train loss: nan, train acuracy: 0.125
step: 363, val loss: nan, val acuracy: 0.10400000214576721
step: 364, train loss: nan, train acuracy: 0.0625
step: 364, val loss: nan, val acuracy: 0.10400000214576721
step: 365, train loss: nan, train acuracy: 0.078125
step: 365, val loss: nan, val acuracy: 0.10400000214576721
step: 366, train loss: nan, train acuracy: 0.109375
step: 366, val loss: nan, val acuracy: 0.10400000214576721
step: 367, train loss: nan, train acuracy: 0.15625
step: 367, val loss: nan, val acuracy: 0.10400000214576721
step: 368, train loss: nan, train acuracy: 0.15625
step: 368, val loss: nan, val acuracy: 0.10400000214576721
step: 369, train loss: nan, train acuracy: 0.0625
step: 369, val loss: nan, val acuracy: 0.10400000214576721
step: 370, train loss: nan, train acuracy: 0.109375
step: 370, val loss: nan, val acuracy: 0.10400000214576721
step: 371, train loss: nan, train acuracy: 0.03125
step: 371, val loss: nan, val acuracy: 0.10400000214576721
step: 372, train loss: nan, train acuracy: 0.15625
step: 372, val loss: nan, val acuracy: 0.10400000214576721
step: 373, train loss: nan, train acuracy: 0.09375
step: 373, val loss: nan, val acuracy: 0.10400000214576721
step: 374, train loss: nan, train acuracy: 0.078125
step: 374, val loss: nan, val acuracy: 0.10400000214576721
step: 375, train loss: nan, train acuracy: 0.09375
step: 375, val loss: nan, val acuracy: 0.10400000214576721
step: 376, train loss: nan, train acuracy: 0.09375
step: 376, val loss: nan, val acuracy: 0.10400000214576721
step: 377, train loss: nan, train acuracy: 0.109375
step: 377, val loss: nan, val acuracy: 0.10400000214576721
step: 378, train loss: nan, train acuracy: 0.140625
step: 378, val loss: nan, val acuracy: 0.10400000214576721
step: 379, train loss: nan, train acuracy: 0.125
step: 379, val loss: nan, val acuracy: 0.10400000214576721
step: 380, train loss: nan, train acuracy: 0.09375
step: 380, val loss: nan, val acuracy: 0.10400000214576721
step: 381, train loss: nan, train acuracy: 0.078125
step: 381, val loss: nan, val acuracy: 0.10400000214576721
step: 382, train loss: nan, train acuracy: 0.0625
step: 382, val loss: nan, val acuracy: 0.10400000214576721
step: 383, train loss: nan, train acuracy: 0.125
step: 383, val loss: nan, val acuracy: 0.10400000214576721
step: 384, train loss: nan, train acuracy: 0.125
step: 384, val loss: nan, val acuracy: 0.10400000214576721
step: 385, train loss: nan, train acuracy: 0.09375
step: 385, val loss: nan, val acuracy: 0.10400000214576721
step: 386, train loss: nan, train acuracy: 0.125
step: 386, val loss: nan, val acuracy: 0.10400000214576721
step: 387, train loss: nan, train acuracy: 0.09375
step: 387, val loss: nan, val acuracy: 0.10400000214576721
step: 388, train loss: nan, train acuracy: 0.15625
step: 388, val loss: nan, val acuracy: 0.10400000214576721
step: 389, train loss: nan, train acuracy: 0.078125
step: 389, val loss: nan, val acuracy: 0.10400000214576721
step: 390, train loss: nan, train acuracy: 0.109375
step: 390, val loss: nan, val acuracy: 0.10400000214576721
step: 391, train loss: nan, train acuracy: 0.03125
step: 391, val loss: nan, val acuracy: 0.10400000959634781
step: 392, train loss: nan, train acuracy: 0.046875
step: 392, val loss: nan, val acuracy: 0.10400000214576721
step: 393, train loss: nan, train acuracy: 0.125
step: 393, val loss: nan, val acuracy: 0.10400000214576721
step: 394, train loss: nan, train acuracy: 0.09375
step: 394, val loss: nan, val acuracy: 0.10400000214576721
step: 395, train loss: nan, train acuracy: 0.140625
step: 395, val loss: nan, val acuracy: 0.10400000214576721
step: 396, train loss: nan, train acuracy: 0.0625
step: 396, val loss: nan, val acuracy: 0.10400000214576721
step: 397, train loss: nan, train acuracy: 0.125
step: 397, val loss: nan, val acuracy: 0.10400000214576721
step: 398, train loss: nan, train acuracy: 0.125
step: 398, val loss: nan, val acuracy: 0.10400000214576721
step: 399, train loss: nan, train acuracy: 0.078125
step: 399, val loss: nan, val acuracy: 0.10400000214576721
step: 400, train loss: nan, train acuracy: 0.0625
step: 400, val loss: nan, val acuracy: 0.10400000214576721
step: 401, train loss: nan, train acuracy: 0.078125
step: 401, val loss: nan, val acuracy: 0.10400000214576721
step: 402, train loss: nan, train acuracy: 0.15625
step: 402, val loss: nan, val acuracy: 0.10400000214576721
step: 403, train loss: nan, train acuracy: 0.109375
step: 403, val loss: nan, val acuracy: 0.10400000214576721
step: 404, train loss: nan, train acuracy: 0.109375
step: 404, val loss: nan, val acuracy: 0.10400000214576721
step: 405, train loss: nan, train acuracy: 0.078125
step: 405, val loss: nan, val acuracy: 0.10400000214576721
step: 406, train loss: nan, train acuracy: 0.15625
step: 406, val loss: nan, val acuracy: 0.10400000214576721
step: 407, train loss: nan, train acuracy: 0.125
step: 407, val loss: nan, val acuracy: 0.10400000214576721
step: 408, train loss: nan, train acuracy: 0.09375
step: 408, val loss: nan, val acuracy: 0.10400000214576721
step: 409, train loss: nan, train acuracy: 0.078125
step: 409, val loss: nan, val acuracy: 0.10400000214576721
step: 410, train loss: nan, train acuracy: 0.140625
step: 410, val loss: nan, val acuracy: 0.10400000214576721
step: 411, train loss: nan, train acuracy: 0.0625
step: 411, val loss: nan, val acuracy: 0.10400000214576721
step: 412, train loss: nan, train acuracy: 0.109375
step: 412, val loss: nan, val acuracy: 0.10400000214576721
step: 413, train loss: nan, train acuracy: 0.125
step: 413, val loss: nan, val acuracy: 0.10400000214576721
step: 414, train loss: nan, train acuracy: 0.109375
step: 414, val loss: nan, val acuracy: 0.10400000214576721
step: 415, train loss: nan, train acuracy: 0.078125
step: 415, val loss: nan, val acuracy: 0.10400000214576721
step: 416, train loss: nan, train acuracy: 0.0625
step: 416, val loss: nan, val acuracy: 0.10400000214576721
step: 417, train loss: nan, train acuracy: 0.046875
step: 417, val loss: nan, val acuracy: 0.10400000214576721
step: 418, train loss: nan, train acuracy: 0.109375
step: 418, val loss: nan, val acuracy: 0.10400000214576721
step: 419, train loss: nan, train acuracy: 0.0625
step: 419, val loss: nan, val acuracy: 0.10400000214576721
step: 420, train loss: nan, train acuracy: 0.046875
step: 420, val loss: nan, val acuracy: 0.10400000214576721
step: 421, train loss: nan, train acuracy: 0.078125
step: 421, val loss: nan, val acuracy: 0.10400000214576721
step: 422, train loss: nan, train acuracy: 0.0625
step: 422, val loss: nan, val acuracy: 0.10400000214576721
step: 423, train loss: nan, train acuracy: 0.046875
step: 423, val loss: nan, val acuracy: 0.10400000214576721
step: 424, train loss: nan, train acuracy: 0.0625
step: 424, val loss: nan, val acuracy: 0.10400000214576721
step: 425, train loss: nan, train acuracy: 0.09375
step: 425, val loss: nan, val acuracy: 0.10400000214576721
step: 426, train loss: nan, train acuracy: 0.078125
step: 426, val loss: nan, val acuracy: 0.10400000214576721
step: 427, train loss: nan, train acuracy: 0.109375
step: 427, val loss: nan, val acuracy: 0.10400000214576721
step: 428, train loss: nan, train acuracy: 0.078125
step: 428, val loss: nan, val acuracy: 0.10400000214576721
step: 429, train loss: nan, train acuracy: 0.0625
step: 429, val loss: nan, val acuracy: 0.10400000214576721
step: 430, train loss: nan, train acuracy: 0.0625
step: 430, val loss: nan, val acuracy: 0.10400000214576721
step: 431, train loss: nan, train acuracy: 0.078125
step: 431, val loss: nan, val acuracy: 0.10400000214576721
step: 432, train loss: nan, train acuracy: 0.203125
step: 432, val loss: nan, val acuracy: 0.10400000214576721
step: 433, train loss: nan, train acuracy: 0.125
step: 433, val loss: nan, val acuracy: 0.10400000959634781
step: 434, train loss: nan, train acuracy: 0.109375
step: 434, val loss: nan, val acuracy: 0.10400000214576721
step: 435, train loss: nan, train acuracy: 0.078125
step: 435, val loss: nan, val acuracy: 0.10400000214576721
step: 436, train loss: nan, train acuracy: 0.109375
step: 436, val loss: nan, val acuracy: 0.10400000214576721
step: 437, train loss: nan, train acuracy: 0.109375
step: 437, val loss: nan, val acuracy: 0.10400000214576721
step: 438, train loss: nan, train acuracy: 0.0625
step: 438, val loss: nan, val acuracy: 0.10400000214576721
step: 439, train loss: nan, train acuracy: 0.15625
step: 439, val loss: nan, val acuracy: 0.10400000214576721
step: 440, train loss: nan, train acuracy: 0.125
step: 440, val loss: nan, val acuracy: 0.10400000214576721
step: 441, train loss: nan, train acuracy: 0.09375
step: 441, val loss: nan, val acuracy: 0.10400000214576721
step: 442, train loss: nan, train acuracy: 0.140625
step: 442, val loss: nan, val acuracy: 0.10400000214576721
step: 443, train loss: nan, train acuracy: 0.140625
step: 443, val loss: nan, val acuracy: 0.10400000214576721
step: 444, train loss: nan, train acuracy: 0.078125
step: 444, val loss: nan, val acuracy: 0.10400000214576721
step: 445, train loss: nan, train acuracy: 0.09375
step: 445, val loss: nan, val acuracy: 0.10400000214576721
step: 446, train loss: nan, train acuracy: 0.140625
step: 446, val loss: nan, val acuracy: 0.10400000214576721
step: 447, train loss: nan, train acuracy: 0.15625
step: 447, val loss: nan, val acuracy: 0.10400000214576721
step: 448, train loss: nan, train acuracy: 0.140625
step: 448, val loss: nan, val acuracy: 0.10400000214576721
step: 449, train loss: nan, train acuracy: 0.109375
step: 449, val loss: nan, val acuracy: 0.10400000214576721
step: 450, train loss: nan, train acuracy: 0.09375
step: 450, val loss: nan, val acuracy: 0.10400000214576721
step: 451, train loss: nan, train acuracy: 0.078125
step: 451, val loss: nan, val acuracy: 0.10400000214576721
step: 452, train loss: nan, train acuracy: 0.109375
step: 452, val loss: nan, val acuracy: 0.10400000214576721
step: 453, train loss: nan, train acuracy: 0.078125
step: 453, val loss: nan, val acuracy: 0.10400000214576721
step: 454, train loss: nan, train acuracy: 0.09375
step: 454, val loss: nan, val acuracy: 0.10400000214576721
step: 455, train loss: nan, train acuracy: 0.046875
step: 455, val loss: nan, val acuracy: 0.10400000214576721
step: 456, train loss: nan, train acuracy: 0.125
step: 456, val loss: nan, val acuracy: 0.10400000214576721
step: 457, train loss: nan, train acuracy: 0.140625
step: 457, val loss: nan, val acuracy: 0.10400000214576721
step: 458, train loss: nan, train acuracy: 0.125
step: 458, val loss: nan, val acuracy: 0.10400000214576721
step: 459, train loss: nan, train acuracy: 0.140625
step: 459, val loss: nan, val acuracy: 0.10400000214576721
step: 460, train loss: nan, train acuracy: 0.109375
step: 460, val loss: nan, val acuracy: 0.10400000214576721
step: 461, train loss: nan, train acuracy: 0.046875
step: 461, val loss: nan, val acuracy: 0.10400000214576721
step: 462, train loss: nan, train acuracy: 0.109375
step: 462, val loss: nan, val acuracy: 0.10400000214576721
step: 463, train loss: nan, train acuracy: 0.0625
step: 463, val loss: nan, val acuracy: 0.10400000214576721
step: 464, train loss: nan, train acuracy: 0.09375
step: 464, val loss: nan, val acuracy: 0.10400000214576721
step: 465, train loss: nan, train acuracy: 0.09375
step: 465, val loss: nan, val acuracy: 0.10400000214576721
step: 466, train loss: nan, train acuracy: 0.109375
step: 466, val loss: nan, val acuracy: 0.10400000214576721
step: 467, train loss: nan, train acuracy: 0.15625
step: 467, val loss: nan, val acuracy: 0.10400000214576721
step: 468, train loss: nan, train acuracy: 0.078125
step: 468, val loss: nan, val acuracy: 0.10400000214576721
step: 469, train loss: nan, train acuracy: 0.09375
step: 469, val loss: nan, val acuracy: 0.10400000214576721
step: 470, train loss: nan, train acuracy: 0.15625
step: 470, val loss: nan, val acuracy: 0.10400000214576721
step: 471, train loss: nan, train acuracy: 0.09375
step: 471, val loss: nan, val acuracy: 0.10400000214576721
step: 472, train loss: nan, train acuracy: 0.09375
step: 472, val loss: nan, val acuracy: 0.10400000214576721
step: 473, train loss: nan, train acuracy: 0.109375
step: 473, val loss: nan, val acuracy: 0.10400000214576721
step: 474, train loss: nan, train acuracy: 0.125
step: 474, val loss: nan, val acuracy: 0.10400000214576721
step: 475, train loss: nan, train acuracy: 0.125
step: 475, val loss: nan, val acuracy: 0.10400000214576721
step: 476, train loss: nan, train acuracy: 0.0625
step: 476, val loss: nan, val acuracy: 0.10400000214576721
step: 477, train loss: nan, train acuracy: 0.046875
step: 477, val loss: nan, val acuracy: 0.10400000214576721
step: 478, train loss: nan, train acuracy: 0.03125
step: 478, val loss: nan, val acuracy: 0.10400000214576721
step: 479, train loss: nan, train acuracy: 0.09375
step: 479, val loss: nan, val acuracy: 0.10400000214576721
step: 480, train loss: nan, train acuracy: 0.140625
step: 480, val loss: nan, val acuracy: 0.10400000214576721
step: 481, train loss: nan, train acuracy: 0.109375
step: 481, val loss: nan, val acuracy: 0.10400000214576721
step: 482, train loss: nan, train acuracy: 0.109375
step: 482, val loss: nan, val acuracy: 0.10400000214576721
step: 483, train loss: nan, train acuracy: 0.109375
step: 483, val loss: nan, val acuracy: 0.10400000214576721
step: 484, train loss: nan, train acuracy: 0.078125
step: 484, val loss: nan, val acuracy: 0.10400000214576721
step: 485, train loss: nan, train acuracy: 0.078125
step: 485, val loss: nan, val acuracy: 0.10400000214576721
step: 486, train loss: nan, train acuracy: 0.15625
step: 486, val loss: nan, val acuracy: 0.10400000214576721
step: 487, train loss: nan, train acuracy: 0.078125
step: 487, val loss: nan, val acuracy: 0.10400000214576721
step: 488, train loss: nan, train acuracy: 0.09375
step: 488, val loss: nan, val acuracy: 0.10400000214576721
step: 489, train loss: nan, train acuracy: 0.0625
step: 489, val loss: nan, val acuracy: 0.10400000214576721
step: 490, train loss: nan, train acuracy: 0.0625
step: 490, val loss: nan, val acuracy: 0.10400000214576721
step: 491, train loss: nan, train acuracy: 0.125
step: 491, val loss: nan, val acuracy: 0.10400000214576721
step: 492, train loss: nan, train acuracy: 0.1875
step: 492, val loss: nan, val acuracy: 0.10400000214576721
step: 493, train loss: nan, train acuracy: 0.078125
step: 493, val loss: nan, val acuracy: 0.10400000214576721
step: 494, train loss: nan, train acuracy: 0.125
step: 494, val loss: nan, val acuracy: 0.10400000214576721
step: 495, train loss: nan, train acuracy: 0.125
step: 495, val loss: nan, val acuracy: 0.10400000214576721
step: 496, train loss: nan, train acuracy: 0.09375
step: 496, val loss: nan, val acuracy: 0.10400000214576721
step: 497, train loss: nan, train acuracy: 0.109375
step: 497, val loss: nan, val acuracy: 0.10400000214576721
step: 498, train loss: nan, train acuracy: 0.046875
step: 498, val loss: nan, val acuracy: 0.10400000214576721
step: 499, train loss: nan, train acuracy: 0.078125
step: 499, val loss: nan, val acuracy: 0.10400000214576721
step: 500, train loss: nan, train acuracy: 0.078125
step: 500, val loss: nan, val acuracy: 0.10400000214576721
step: 501, train loss: nan, train acuracy: 0.078125
step: 501, val loss: nan, val acuracy: 0.10400000214576721
step: 502, train loss: nan, train acuracy: 0.0625
step: 502, val loss: nan, val acuracy: 0.10400000214576721
step: 503, train loss: nan, train acuracy: 0.078125
step: 503, val loss: nan, val acuracy: 0.10400000214576721
step: 504, train loss: nan, train acuracy: 0.046875
step: 504, val loss: nan, val acuracy: 0.10400000214576721
step: 505, train loss: nan, train acuracy: 0.125
step: 505, val loss: nan, val acuracy: 0.10400000214576721
step: 506, train loss: nan, train acuracy: 0.203125
step: 506, val loss: nan, val acuracy: 0.10400000214576721
step: 507, train loss: nan, train acuracy: 0.1875
step: 507, val loss: nan, val acuracy: 0.10400000214576721
step: 508, train loss: nan, train acuracy: 0.109375
step: 508, val loss: nan, val acuracy: 0.10400000214576721
step: 509, train loss: nan, train acuracy: 0.125
step: 509, val loss: nan, val acuracy: 0.10400000214576721
step: 510, train loss: nan, train acuracy: 0.046875
step: 510, val loss: nan, val acuracy: 0.10400000214576721
step: 511, train loss: nan, train acuracy: 0.109375
step: 511, val loss: nan, val acuracy: 0.10400000214576721
step: 512, train loss: nan, train acuracy: 0.109375
step: 512, val loss: nan, val acuracy: 0.10400000214576721
step: 513, train loss: nan, train acuracy: 0.140625
step: 513, val loss: nan, val acuracy: 0.10400000214576721
step: 514, train loss: nan, train acuracy: 0.09375
step: 514, val loss: nan, val acuracy: 0.10400000214576721
step: 515, train loss: nan, train acuracy: 0.15625
step: 515, val loss: nan, val acuracy: 0.10400000214576721
step: 516, train loss: nan, train acuracy: 0.0625
step: 516, val loss: nan, val acuracy: 0.10400000214576721
step: 517, train loss: nan, train acuracy: 0.09375
step: 517, val loss: nan, val acuracy: 0.10400000214576721
step: 518, train loss: nan, train acuracy: 0.09375
step: 518, val loss: nan, val acuracy: 0.10400000214576721
step: 519, train loss: nan, train acuracy: 0.03125
step: 519, val loss: nan, val acuracy: 0.10400000214576721
step: 520, train loss: nan, train acuracy: 0.09375
step: 520, val loss: nan, val acuracy: 0.10400000214576721
step: 521, train loss: nan, train acuracy: 0.046875
step: 521, val loss: nan, val acuracy: 0.10400000214576721
step: 522, train loss: nan, train acuracy: 0.15625
step: 522, val loss: nan, val acuracy: 0.10400000214576721
step: 523, train loss: nan, train acuracy: 0.09375
step: 523, val loss: nan, val acuracy: 0.10400000214576721
step: 524, train loss: nan, train acuracy: 0.125
step: 524, val loss: nan, val acuracy: 0.10400000214576721
step: 525, train loss: nan, train acuracy: 0.03125
step: 525, val loss: nan, val acuracy: 0.10400000214576721
step: 526, train loss: nan, train acuracy: 0.125
step: 526, val loss: nan, val acuracy: 0.10400000214576721
step: 527, train loss: nan, train acuracy: 0.15625
step: 527, val loss: nan, val acuracy: 0.10400000214576721
step: 528, train loss: nan, train acuracy: 0.125
step: 528, val loss: nan, val acuracy: 0.10400000214576721
step: 529, train loss: nan, train acuracy: 0.078125
step: 529, val loss: nan, val acuracy: 0.10400000214576721
step: 530, train loss: nan, train acuracy: 0.078125
step: 530, val loss: nan, val acuracy: 0.10400000214576721
step: 531, train loss: nan, train acuracy: 0.109375
step: 531, val loss: nan, val acuracy: 0.10400000214576721
step: 532, train loss: nan, train acuracy: 0.09375
step: 532, val loss: nan, val acuracy: 0.10400000214576721
step: 533, train loss: nan, train acuracy: 0.046875
step: 533, val loss: nan, val acuracy: 0.10400000214576721
step: 534, train loss: nan, train acuracy: 0.09375
step: 534, val loss: nan, val acuracy: 0.10400000214576721
step: 535, train loss: nan, train acuracy: 0.046875
step: 535, val loss: nan, val acuracy: 0.10400000214576721
step: 536, train loss: nan, train acuracy: 0.125
step: 536, val loss: nan, val acuracy: 0.10400000214576721
step: 537, train loss: nan, train acuracy: 0.078125
step: 537, val loss: nan, val acuracy: 0.10400000214576721
step: 538, train loss: nan, train acuracy: 0.0625
step: 538, val loss: nan, val acuracy: 0.10400000214576721
step: 539, train loss: nan, train acuracy: 0.140625
step: 539, val loss: nan, val acuracy: 0.10400000214576721
step: 540, train loss: nan, train acuracy: 0.15625
step: 540, val loss: nan, val acuracy: 0.10400000214576721
step: 541, train loss: nan, train acuracy: 0.140625
step: 541, val loss: nan, val acuracy: 0.10400000214576721
step: 542, train loss: nan, train acuracy: 0.109375
step: 542, val loss: nan, val acuracy: 0.10400000214576721
step: 543, train loss: nan, train acuracy: 0.046875
step: 543, val loss: nan, val acuracy: 0.10400000214576721
step: 544, train loss: nan, train acuracy: 0.140625
step: 544, val loss: nan, val acuracy: 0.10400000214576721
step: 545, train loss: nan, train acuracy: 0.140625
step: 545, val loss: nan, val acuracy: 0.10400000214576721
step: 546, train loss: nan, train acuracy: 0.0625
step: 546, val loss: nan, val acuracy: 0.10400000214576721
step: 547, train loss: nan, train acuracy: 0.0625
step: 547, val loss: nan, val acuracy: 0.10400000214576721
step: 548, train loss: nan, train acuracy: 0.078125
step: 548, val loss: nan, val acuracy: 0.10400000214576721
step: 549, train loss: nan, train acuracy: 0.0625
step: 549, val loss: nan, val acuracy: 0.10400000214576721
step: 550, train loss: nan, train acuracy: 0.109375
step: 550, val loss: nan, val acuracy: 0.10400000214576721
step: 551, train loss: nan, train acuracy: 0.09375
step: 551, val loss: nan, val acuracy: 0.10400000214576721
step: 552, train loss: nan, train acuracy: 0.109375
step: 552, val loss: nan, val acuracy: 0.10400000214576721
step: 553, train loss: nan, train acuracy: 0.125
step: 553, val loss: nan, val acuracy: 0.10400000214576721
step: 554, train loss: nan, train acuracy: 0.046875
step: 554, val loss: nan, val acuracy: 0.10400000214576721
step: 555, train loss: nan, train acuracy: 0.171875
step: 555, val loss: nan, val acuracy: 0.10400000214576721
step: 556, train loss: nan, train acuracy: 0.03125
step: 556, val loss: nan, val acuracy: 0.10400000214576721
step: 557, train loss: nan, train acuracy: 0.09375
step: 557, val loss: nan, val acuracy: 0.10400000214576721
step: 558, train loss: nan, train acuracy: 0.140625
step: 558, val loss: nan, val acuracy: 0.10400000214576721
step: 559, train loss: nan, train acuracy: 0.171875
step: 559, val loss: nan, val acuracy: 0.10400000214576721
step: 560, train loss: nan, train acuracy: 0.078125
step: 560, val loss: nan, val acuracy: 0.10400000214576721
step: 561, train loss: nan, train acuracy: 0.109375
step: 561, val loss: nan, val acuracy: 0.10400000214576721
step: 562, train loss: nan, train acuracy: 0.046875
step: 562, val loss: nan, val acuracy: 0.10400000214576721
step: 563, train loss: nan, train acuracy: 0.0625
step: 563, val loss: nan, val acuracy: 0.10400000214576721
step: 564, train loss: nan, train acuracy: 0.046875
step: 564, val loss: nan, val acuracy: 0.10400000214576721
step: 565, train loss: nan, train acuracy: 0.09375
step: 565, val loss: nan, val acuracy: 0.10400000214576721
step: 566, train loss: nan, train acuracy: 0.09375
step: 566, val loss: nan, val acuracy: 0.10400000214576721
step: 567, train loss: nan, train acuracy: 0.09375
step: 567, val loss: nan, val acuracy: 0.10400000214576721
step: 568, train loss: nan, train acuracy: 0.046875
step: 568, val loss: nan, val acuracy: 0.10400000214576721
step: 569, train loss: nan, train acuracy: 0.125
step: 569, val loss: nan, val acuracy: 0.10400000214576721
step: 570, train loss: nan, train acuracy: 0.125
step: 570, val loss: nan, val acuracy: 0.10400000214576721
step: 571, train loss: nan, train acuracy: 0.109375
step: 571, val loss: nan, val acuracy: 0.10400000214576721
step: 572, train loss: nan, train acuracy: 0.046875
step: 572, val loss: nan, val acuracy: 0.10400000214576721
step: 573, train loss: nan, train acuracy: 0.078125
step: 573, val loss: nan, val acuracy: 0.10400000214576721
step: 574, train loss: nan, train acuracy: 0.109375
step: 574, val loss: nan, val acuracy: 0.10400000214576721
step: 575, train loss: nan, train acuracy: 0.125
step: 575, val loss: nan, val acuracy: 0.10400000214576721
step: 576, train loss: nan, train acuracy: 0.125
step: 576, val loss: nan, val acuracy: 0.10400000214576721
step: 577, train loss: nan, train acuracy: 0.0625
step: 577, val loss: nan, val acuracy: 0.10400000214576721
step: 578, train loss: nan, train acuracy: 0.140625
step: 578, val loss: nan, val acuracy: 0.10400000214576721
step: 579, train loss: nan, train acuracy: 0.078125
step: 579, val loss: nan, val acuracy: 0.10400000214576721
step: 580, train loss: nan, train acuracy: 0.015625
step: 580, val loss: nan, val acuracy: 0.10400000214576721
step: 581, train loss: nan, train acuracy: 0.046875
step: 581, val loss: nan, val acuracy: 0.10400000214576721
step: 582, train loss: nan, train acuracy: 0.109375
step: 582, val loss: nan, val acuracy: 0.10400000214576721
step: 583, train loss: nan, train acuracy: 0.0625
step: 583, val loss: nan, val acuracy: 0.10400000214576721
step: 584, train loss: nan, train acuracy: 0.0625
step: 584, val loss: nan, val acuracy: 0.10400000214576721
step: 585, train loss: nan, train acuracy: 0.078125
step: 585, val loss: nan, val acuracy: 0.10400000214576721
step: 586, train loss: nan, train acuracy: 0.046875
step: 586, val loss: nan, val acuracy: 0.10400000214576721
step: 587, train loss: nan, train acuracy: 0.0625
step: 587, val loss: nan, val acuracy: 0.10400000214576721
step: 588, train loss: nan, train acuracy: 0.09375
step: 588, val loss: nan, val acuracy: 0.10400000214576721
step: 589, train loss: nan, train acuracy: 0.140625
step: 589, val loss: nan, val acuracy: 0.10400000214576721
step: 590, train loss: nan, train acuracy: 0.09375
step: 590, val loss: nan, val acuracy: 0.10400000214576721
step: 591, train loss: nan, train acuracy: 0.078125
step: 591, val loss: nan, val acuracy: 0.10400000214576721
step: 592, train loss: nan, train acuracy: 0.078125
step: 592, val loss: nan, val acuracy: 0.10400000214576721
step: 593, train loss: nan, train acuracy: 0.09375
step: 593, val loss: nan, val acuracy: 0.10400000214576721
step: 594, train loss: nan, train acuracy: 0.109375
step: 594, val loss: nan, val acuracy: 0.10400000214576721
step: 595, train loss: nan, train acuracy: 0.140625
step: 595, val loss: nan, val acuracy: 0.10400000214576721
step: 596, train loss: nan, train acuracy: 0.0625
step: 596, val loss: nan, val acuracy: 0.10400000214576721
step: 597, train loss: nan, train acuracy: 0.109375
step: 597, val loss: nan, val acuracy: 0.10400000214576721
step: 598, train loss: nan, train acuracy: 0.09375
step: 598, val loss: nan, val acuracy: 0.10400000214576721
step: 599, train loss: nan, train acuracy: 0.078125
step: 599, val loss: nan, val acuracy: 0.10400000214576721
step: 600, train loss: nan, train acuracy: 0.0625
step: 600, val loss: nan, val acuracy: 0.10400000214576721
step: 601, train loss: nan, train acuracy: 0.125
step: 601, val loss: nan, val acuracy: 0.10400000214576721
step: 602, train loss: nan, train acuracy: 0.140625
step: 602, val loss: nan, val acuracy: 0.10400000214576721
step: 603, train loss: nan, train acuracy: 0.0625
step: 603, val loss: nan, val acuracy: 0.10400000214576721
step: 604, train loss: nan, train acuracy: 0.078125
step: 604, val loss: nan, val acuracy: 0.10400000214576721
step: 605, train loss: nan, train acuracy: 0.109375
step: 605, val loss: nan, val acuracy: 0.10400000214576721
step: 606, train loss: nan, train acuracy: 0.140625
step: 606, val loss: nan, val acuracy: 0.10400000214576721
step: 607, train loss: nan, train acuracy: 0.125
step: 607, val loss: nan, val acuracy: 0.10400000214576721
step: 608, train loss: nan, train acuracy: 0.109375
step: 608, val loss: nan, val acuracy: 0.10400000214576721
step: 609, train loss: nan, train acuracy: 0.09375
step: 609, val loss: nan, val acuracy: 0.10400000214576721
step: 610, train loss: nan, train acuracy: 0.03125
step: 610, val loss: nan, val acuracy: 0.10400000214576721
step: 611, train loss: nan, train acuracy: 0.0625
step: 611, val loss: nan, val acuracy: 0.10400000214576721
step: 612, train loss: nan, train acuracy: 0.125
step: 612, val loss: nan, val acuracy: 0.10400000214576721
step: 613, train loss: nan, train acuracy: 0.109375
step: 613, val loss: nan, val acuracy: 0.10400000214576721
step: 614, train loss: nan, train acuracy: 0.203125
step: 614, val loss: nan, val acuracy: 0.10400000214576721
step: 615, train loss: nan, train acuracy: 0.125
step: 615, val loss: nan, val acuracy: 0.10400000214576721
step: 616, train loss: nan, train acuracy: 0.078125
step: 616, val loss: nan, val acuracy: 0.10400000214576721
step: 617, train loss: nan, train acuracy: 0.078125
step: 617, val loss: nan, val acuracy: 0.10400000214576721
step: 618, train loss: nan, train acuracy: 0.109375
step: 618, val loss: nan, val acuracy: 0.10400000214576721
step: 619, train loss: nan, train acuracy: 0.125
step: 619, val loss: nan, val acuracy: 0.10400000214576721
step: 620, train loss: nan, train acuracy: 0.078125
step: 620, val loss: nan, val acuracy: 0.10400000214576721
step: 621, train loss: nan, train acuracy: 0.109375
step: 621, val loss: nan, val acuracy: 0.10400000214576721
step: 622, train loss: nan, train acuracy: 0.078125
step: 622, val loss: nan, val acuracy: 0.10400000214576721
step: 623, train loss: nan, train acuracy: 0.015625
step: 623, val loss: nan, val acuracy: 0.10400000214576721
step: 624, train loss: nan, train acuracy: 0.09375
step: 624, val loss: nan, val acuracy: 0.10400000214576721
step: 625, train loss: nan, train acuracy: 0.109375
step: 625, val loss: nan, val acuracy: 0.10400000214576721
step: 626, train loss: nan, train acuracy: 0.109375
step: 626, val loss: nan, val acuracy: 0.10400000214576721
step: 627, train loss: nan, train acuracy: 0.078125
step: 627, val loss: nan, val acuracy: 0.10400000214576721
step: 628, train loss: nan, train acuracy: 0.171875
step: 628, val loss: nan, val acuracy: 0.10400000214576721
step: 629, train loss: nan, train acuracy: 0.109375
step: 629, val loss: nan, val acuracy: 0.10400000214576721
step: 630, train loss: nan, train acuracy: 0.0625
step: 630, val loss: nan, val acuracy: 0.10400000214576721
step: 631, train loss: nan, train acuracy: 0.140625
step: 631, val loss: nan, val acuracy: 0.10400000214576721
step: 632, train loss: nan, train acuracy: 0.140625
step: 632, val loss: nan, val acuracy: 0.10400000214576721
step: 633, train loss: nan, train acuracy: 0.109375
step: 633, val loss: nan, val acuracy: 0.10400000214576721
step: 634, train loss: nan, train acuracy: 0.15625
step: 634, val loss: nan, val acuracy: 0.10400000214576721
step: 635, train loss: nan, train acuracy: 0.125
step: 635, val loss: nan, val acuracy: 0.10400000214576721
step: 636, train loss: nan, train acuracy: 0.125
step: 636, val loss: nan, val acuracy: 0.10400000214576721
step: 637, train loss: nan, train acuracy: 0.109375
step: 637, val loss: nan, val acuracy: 0.10400000214576721
step: 638, train loss: nan, train acuracy: 0.078125
step: 638, val loss: nan, val acuracy: 0.10400000214576721
step: 639, train loss: nan, train acuracy: 0.078125
step: 639, val loss: nan, val acuracy: 0.10400000214576721
step: 640, train loss: nan, train acuracy: 0.09375
step: 640, val loss: nan, val acuracy: 0.10400000214576721
step: 641, train loss: nan, train acuracy: 0.078125
step: 641, val loss: nan, val acuracy: 0.10400000959634781
step: 642, train loss: nan, train acuracy: 0.078125
step: 642, val loss: nan, val acuracy: 0.10400000214576721
step: 643, train loss: nan, train acuracy: 0.0625
step: 643, val loss: nan, val acuracy: 0.10400000214576721
step: 644, train loss: nan, train acuracy: 0.078125
step: 644, val loss: nan, val acuracy: 0.10400000214576721
step: 645, train loss: nan, train acuracy: 0.203125
step: 645, val loss: nan, val acuracy: 0.10400000214576721
step: 646, train loss: nan, train acuracy: 0.15625
step: 646, val loss: nan, val acuracy: 0.10400000214576721
step: 647, train loss: nan, train acuracy: 0.0625
step: 647, val loss: nan, val acuracy: 0.10400000214576721
step: 648, train loss: nan, train acuracy: 0.109375
step: 648, val loss: nan, val acuracy: 0.10400000214576721
step: 649, train loss: nan, train acuracy: 0.109375
step: 649, val loss: nan, val acuracy: 0.10400000214576721
step: 650, train loss: nan, train acuracy: 0.109375
step: 650, val loss: nan, val acuracy: 0.10400000214576721
step: 651, train loss: nan, train acuracy: 0.140625
step: 651, val loss: nan, val acuracy: 0.10400000214576721
step: 652, train loss: nan, train acuracy: 0.078125
step: 652, val loss: nan, val acuracy: 0.10400000214576721
step: 653, train loss: nan, train acuracy: 0.171875
step: 653, val loss: nan, val acuracy: 0.10400000214576721
step: 654, train loss: nan, train acuracy: 0.03125
step: 654, val loss: nan, val acuracy: 0.10400000214576721
step: 655, train loss: nan, train acuracy: 0.109375
step: 655, val loss: nan, val acuracy: 0.10400000214576721
step: 656, train loss: nan, train acuracy: 0.078125
step: 656, val loss: nan, val acuracy: 0.10400000214576721
step: 657, train loss: nan, train acuracy: 0.109375
step: 657, val loss: nan, val acuracy: 0.10400000214576721
step: 658, train loss: nan, train acuracy: 0.109375
step: 658, val loss: nan, val acuracy: 0.10400000214576721
step: 659, train loss: nan, train acuracy: 0.0625
step: 659, val loss: nan, val acuracy: 0.10400000214576721
step: 660, train loss: nan, train acuracy: 0.140625
step: 660, val loss: nan, val acuracy: 0.10400000214576721
step: 661, train loss: nan, train acuracy: 0.0625
step: 661, val loss: nan, val acuracy: 0.10400000214576721
step: 662, train loss: nan, train acuracy: 0.09375
step: 662, val loss: nan, val acuracy: 0.10400000214576721
step: 663, train loss: nan, train acuracy: 0.125
step: 663, val loss: nan, val acuracy: 0.10400000214576721
step: 664, train loss: nan, train acuracy: 0.09375
step: 664, val loss: nan, val acuracy: 0.10400000214576721
step: 665, train loss: nan, train acuracy: 0.125
step: 665, val loss: nan, val acuracy: 0.10400000214576721
step: 666, train loss: nan, train acuracy: 0.0625
step: 666, val loss: nan, val acuracy: 0.10400000214576721
step: 667, train loss: nan, train acuracy: 0.140625
step: 667, val loss: nan, val acuracy: 0.10400000214576721
step: 668, train loss: nan, train acuracy: 0.09375
step: 668, val loss: nan, val acuracy: 0.10400000214576721
step: 669, train loss: nan, train acuracy: 0.0625
step: 669, val loss: nan, val acuracy: 0.10400000214576721
step: 670, train loss: nan, train acuracy: 0.140625
step: 670, val loss: nan, val acuracy: 0.10400000214576721
step: 671, train loss: nan, train acuracy: 0.171875
step: 671, val loss: nan, val acuracy: 0.10400000214576721
step: 672, train loss: nan, train acuracy: 0.0625
step: 672, val loss: nan, val acuracy: 0.10400000214576721
step: 673, train loss: nan, train acuracy: 0.0625
step: 673, val loss: nan, val acuracy: 0.10400000214576721
step: 674, train loss: nan, train acuracy: 0.15625
step: 674, val loss: nan, val acuracy: 0.10400000214576721
step: 675, train loss: nan, train acuracy: 0.09375
step: 675, val loss: nan, val acuracy: 0.10400000214576721
step: 676, train loss: nan, train acuracy: 0.078125
step: 676, val loss: nan, val acuracy: 0.10400000214576721
step: 677, train loss: nan, train acuracy: 0.09375
step: 677, val loss: nan, val acuracy: 0.10400000214576721
step: 678, train loss: nan, train acuracy: 0.109375
step: 678, val loss: nan, val acuracy: 0.10400000214576721
step: 679, train loss: nan, train acuracy: 0.15625
step: 679, val loss: nan, val acuracy: 0.10400000214576721
step: 680, train loss: nan, train acuracy: 0.078125
step: 680, val loss: nan, val acuracy: 0.10400000214576721
step: 681, train loss: nan, train acuracy: 0.125
step: 681, val loss: nan, val acuracy: 0.10400000214576721
step: 682, train loss: nan, train acuracy: 0.109375
step: 682, val loss: nan, val acuracy: 0.10400000214576721
step: 683, train loss: nan, train acuracy: 0.03125
step: 683, val loss: nan, val acuracy: 0.10400000214576721
step: 684, train loss: nan, train acuracy: 0.046875
step: 684, val loss: nan, val acuracy: 0.10400000214576721
step: 685, train loss: nan, train acuracy: 0.046875
step: 685, val loss: nan, val acuracy: 0.10400000214576721
step: 686, train loss: nan, train acuracy: 0.09375
step: 686, val loss: nan, val acuracy: 0.10400000214576721
step: 687, train loss: nan, train acuracy: 0.046875
step: 687, val loss: nan, val acuracy: 0.10400000214576721
step: 688, train loss: nan, train acuracy: 0.140625
step: 688, val loss: nan, val acuracy: 0.10400000214576721
step: 689, train loss: nan, train acuracy: 0.078125
step: 689, val loss: nan, val acuracy: 0.10400000214576721
step: 690, train loss: nan, train acuracy: 0.15625
step: 690, val loss: nan, val acuracy: 0.10400000214576721
step: 691, train loss: nan, train acuracy: 0.03125
step: 691, val loss: nan, val acuracy: 0.10400000214576721
step: 692, train loss: nan, train acuracy: 0.09375
step: 692, val loss: nan, val acuracy: 0.10400000214576721
step: 693, train loss: nan, train acuracy: 0.078125
step: 693, val loss: nan, val acuracy: 0.10400000214576721
step: 694, train loss: nan, train acuracy: 0.125
step: 694, val loss: nan, val acuracy: 0.10400000214576721
step: 695, train loss: nan, train acuracy: 0.171875
step: 695, val loss: nan, val acuracy: 0.10400000214576721
step: 696, train loss: nan, train acuracy: 0.109375
step: 696, val loss: nan, val acuracy: 0.10400000214576721
step: 697, train loss: nan, train acuracy: 0.0625
step: 697, val loss: nan, val acuracy: 0.10400000214576721
step: 698, train loss: nan, train acuracy: 0.09375
step: 698, val loss: nan, val acuracy: 0.10400000214576721
step: 699, train loss: nan, train acuracy: 0.078125
step: 699, val loss: nan, val acuracy: 0.10400000214576721
step: 700, train loss: nan, train acuracy: 0.109375
step: 700, val loss: nan, val acuracy: 0.10400000214576721
step: 701, train loss: nan, train acuracy: 0.09375
step: 701, val loss: nan, val acuracy: 0.10400000214576721
step: 702, train loss: nan, train acuracy: 0.0625
step: 702, val loss: nan, val acuracy: 0.10400000214576721
step: 703, train loss: nan, train acuracy: 0.109375
step: 703, val loss: nan, val acuracy: 0.10400000214576721
step: 704, train loss: nan, train acuracy: 0.078125
step: 704, val loss: nan, val acuracy: 0.10400000214576721
step: 705, train loss: nan, train acuracy: 0.09375
step: 705, val loss: nan, val acuracy: 0.10400000214576721
step: 706, train loss: nan, train acuracy: 0.109375
step: 706, val loss: nan, val acuracy: 0.10400000214576721
step: 707, train loss: nan, train acuracy: 0.109375
step: 707, val loss: nan, val acuracy: 0.10400000214576721
step: 708, train loss: nan, train acuracy: 0.125
step: 708, val loss: nan, val acuracy: 0.10400000214576721
step: 709, train loss: nan, train acuracy: 0.078125
step: 709, val loss: nan, val acuracy: 0.10400000214576721
step: 710, train loss: nan, train acuracy: 0.109375
step: 710, val loss: nan, val acuracy: 0.10400000214576721
step: 711, train loss: nan, train acuracy: 0.09375
step: 711, val loss: nan, val acuracy: 0.10400000214576721
step: 712, train loss: nan, train acuracy: 0.15625
step: 712, val loss: nan, val acuracy: 0.10400000214576721
step: 713, train loss: nan, train acuracy: 0.109375
step: 713, val loss: nan, val acuracy: 0.10400000214576721
step: 714, train loss: nan, train acuracy: 0.09375
step: 714, val loss: nan, val acuracy: 0.10400000214576721
step: 715, train loss: nan, train acuracy: 0.0625
step: 715, val loss: nan, val acuracy: 0.10400000214576721
step: 716, train loss: nan, train acuracy: 0.09375
step: 716, val loss: nan, val acuracy: 0.10400000214576721
step: 717, train loss: nan, train acuracy: 0.109375
step: 717, val loss: nan, val acuracy: 0.10400000214576721
step: 718, train loss: nan, train acuracy: 0.09375
step: 718, val loss: nan, val acuracy: 0.10400000214576721
step: 719, train loss: nan, train acuracy: 0.078125
step: 719, val loss: nan, val acuracy: 0.10400000214576721
step: 720, train loss: nan, train acuracy: 0.078125
step: 720, val loss: nan, val acuracy: 0.10400000214576721
step: 721, train loss: nan, train acuracy: 0.0625
step: 721, val loss: nan, val acuracy: 0.10400000214576721
step: 722, train loss: nan, train acuracy: 0.0625
step: 722, val loss: nan, val acuracy: 0.10400000214576721
step: 723, train loss: nan, train acuracy: 0.125
step: 723, val loss: nan, val acuracy: 0.10400000214576721
step: 724, train loss: nan, train acuracy: 0.0625
step: 724, val loss: nan, val acuracy: 0.10400000214576721
step: 725, train loss: nan, train acuracy: 0.109375
step: 725, val loss: nan, val acuracy: 0.10400000214576721
step: 726, train loss: nan, train acuracy: 0.078125
step: 726, val loss: nan, val acuracy: 0.10400000214576721
step: 727, train loss: nan, train acuracy: 0.125
step: 727, val loss: nan, val acuracy: 0.10400000214576721
step: 728, train loss: nan, train acuracy: 0.0625
step: 728, val loss: nan, val acuracy: 0.10400000214576721
step: 729, train loss: nan, train acuracy: 0.09375
step: 729, val loss: nan, val acuracy: 0.10400000214576721
step: 730, train loss: nan, train acuracy: 0.125
step: 730, val loss: nan, val acuracy: 0.10400000214576721
step: 731, train loss: nan, train acuracy: 0.125
step: 731, val loss: nan, val acuracy: 0.10400000214576721
step: 732, train loss: nan, train acuracy: 0.046875
step: 732, val loss: nan, val acuracy: 0.10400000214576721
step: 733, train loss: nan, train acuracy: 0.125
step: 733, val loss: nan, val acuracy: 0.10400000214576721
step: 734, train loss: nan, train acuracy: 0.109375
step: 734, val loss: nan, val acuracy: 0.10400000214576721
step: 735, train loss: nan, train acuracy: 0.140625
step: 735, val loss: nan, val acuracy: 0.10400000214576721
step: 736, train loss: nan, train acuracy: 0.125
step: 736, val loss: nan, val acuracy: 0.10400000214576721
step: 737, train loss: nan, train acuracy: 0.03125
step: 737, val loss: nan, val acuracy: 0.10400000214576721
step: 738, train loss: nan, train acuracy: 0.109375
step: 738, val loss: nan, val acuracy: 0.10400000214576721
step: 739, train loss: nan, train acuracy: 0.109375
step: 739, val loss: nan, val acuracy: 0.10400000214576721
step: 740, train loss: nan, train acuracy: 0.140625
step: 740, val loss: nan, val acuracy: 0.10400000214576721
step: 741, train loss: nan, train acuracy: 0.03125
step: 741, val loss: nan, val acuracy: 0.10400000214576721
step: 742, train loss: nan, train acuracy: 0.109375
step: 742, val loss: nan, val acuracy: 0.10400000214576721
step: 743, train loss: nan, train acuracy: 0.109375
step: 743, val loss: nan, val acuracy: 0.10400000214576721
step: 744, train loss: nan, train acuracy: 0.078125
step: 744, val loss: nan, val acuracy: 0.10400000214576721
step: 745, train loss: nan, train acuracy: 0.09375
step: 745, val loss: nan, val acuracy: 0.10400000214576721
step: 746, train loss: nan, train acuracy: 0.046875
step: 746, val loss: nan, val acuracy: 0.10400000214576721
step: 747, train loss: nan, train acuracy: 0.078125
step: 747, val loss: nan, val acuracy: 0.10400000214576721
step: 748, train loss: nan, train acuracy: 0.140625
step: 748, val loss: nan, val acuracy: 0.10400000214576721
step: 749, train loss: nan, train acuracy: 0.0625
step: 749, val loss: nan, val acuracy: 0.10400000214576721
step: 750, train loss: nan, train acuracy: 0.0625
step: 750, val loss: nan, val acuracy: 0.10400000214576721
step: 751, train loss: nan, train acuracy: 0.078125
step: 751, val loss: nan, val acuracy: 0.10400000214576721
step: 752, train loss: nan, train acuracy: 0.078125
step: 752, val loss: nan, val acuracy: 0.10400000214576721
step: 753, train loss: nan, train acuracy: 0.171875
step: 753, val loss: nan, val acuracy: 0.10400000214576721
step: 754, train loss: nan, train acuracy: 0.109375
step: 754, val loss: nan, val acuracy: 0.10400000214576721
step: 755, train loss: nan, train acuracy: 0.09375
step: 755, val loss: nan, val acuracy: 0.10400000214576721
step: 756, train loss: nan, train acuracy: 0.078125
step: 756, val loss: nan, val acuracy: 0.10400000214576721
step: 757, train loss: nan, train acuracy: 0.078125
step: 757, val loss: nan, val acuracy: 0.10400000214576721
step: 758, train loss: nan, train acuracy: 0.140625
step: 758, val loss: nan, val acuracy: 0.10400000214576721
step: 759, train loss: nan, train acuracy: 0.125
step: 759, val loss: nan, val acuracy: 0.10400000214576721
step: 760, train loss: nan, train acuracy: 0.078125
step: 760, val loss: nan, val acuracy: 0.10400000214576721
step: 761, train loss: nan, train acuracy: 0.109375
step: 761, val loss: nan, val acuracy: 0.10400000214576721
step: 762, train loss: nan, train acuracy: 0.078125
step: 762, val loss: nan, val acuracy: 0.10400000214576721
step: 763, train loss: nan, train acuracy: 0.140625
step: 763, val loss: nan, val acuracy: 0.10400000214576721
step: 764, train loss: nan, train acuracy: 0.03125
step: 764, val loss: nan, val acuracy: 0.10400000214576721
step: 765, train loss: nan, train acuracy: 0.125
step: 765, val loss: nan, val acuracy: 0.10400000214576721
step: 766, train loss: nan, train acuracy: 0.078125
step: 766, val loss: nan, val acuracy: 0.10400000214576721
step: 767, train loss: nan, train acuracy: 0.125
step: 767, val loss: nan, val acuracy: 0.10400000214576721
step: 768, train loss: nan, train acuracy: 0.125
step: 768, val loss: nan, val acuracy: 0.10400000214576721
step: 769, train loss: nan, train acuracy: 0.125
step: 769, val loss: nan, val acuracy: 0.10400000214576721
step: 770, train loss: nan, train acuracy: 0.046875
step: 770, val loss: nan, val acuracy: 0.10400000214576721
step: 771, train loss: nan, train acuracy: 0.140625
step: 771, val loss: nan, val acuracy: 0.10400000214576721
step: 772, train loss: nan, train acuracy: 0.109375
step: 772, val loss: nan, val acuracy: 0.10400000214576721
step: 773, train loss: nan, train acuracy: 0.0625
step: 773, val loss: nan, val acuracy: 0.10400000214576721
step: 774, train loss: nan, train acuracy: 0.171875
step: 774, val loss: nan, val acuracy: 0.10400000214576721
step: 775, train loss: nan, train acuracy: 0.109375
step: 775, val loss: nan, val acuracy: 0.10400000214576721
step: 776, train loss: nan, train acuracy: 0.109375
step: 776, val loss: nan, val acuracy: 0.10400000214576721
step: 777, train loss: nan, train acuracy: 0.0625
step: 777, val loss: nan, val acuracy: 0.10400000214576721
step: 778, train loss: nan, train acuracy: 0.0625
step: 778, val loss: nan, val acuracy: 0.10400000214576721
step: 779, train loss: nan, train acuracy: 0.09375
step: 779, val loss: nan, val acuracy: 0.10400000214576721
step: 780, train loss: nan, train acuracy: 0.125
step: 780, val loss: nan, val acuracy: 0.10400000214576721
step: 781, train loss: nan, train acuracy: 0.09375
step: 781, val loss: nan, val acuracy: 0.10400000214576721
step: 782, train loss: nan, train acuracy: 0.078125
step: 782, val loss: nan, val acuracy: 0.10400000214576721
step: 783, train loss: nan, train acuracy: 0.078125
step: 783, val loss: nan, val acuracy: 0.10400000214576721
step: 784, train loss: nan, train acuracy: 0.171875
step: 784, val loss: nan, val acuracy: 0.10400000214576721
step: 785, train loss: nan, train acuracy: 0.125
step: 785, val loss: nan, val acuracy: 0.10400000214576721
step: 786, train loss: nan, train acuracy: 0.09375
step: 786, val loss: nan, val acuracy: 0.10400000214576721
step: 787, train loss: nan, train acuracy: 0.109375
step: 787, val loss: nan, val acuracy: 0.10400000214576721
step: 788, train loss: nan, train acuracy: 0.125
step: 788, val loss: nan, val acuracy: 0.10400000214576721
step: 789, train loss: nan, train acuracy: 0.125
step: 789, val loss: nan, val acuracy: 0.10400000214576721
step: 790, train loss: nan, train acuracy: 0.09375
step: 790, val loss: nan, val acuracy: 0.10400000214576721
step: 791, train loss: nan, train acuracy: 0.125
step: 791, val loss: nan, val acuracy: 0.10400000214576721
step: 792, train loss: nan, train acuracy: 0.109375
step: 792, val loss: nan, val acuracy: 0.10400000214576721
step: 793, train loss: nan, train acuracy: 0.078125
step: 793, val loss: nan, val acuracy: 0.10400000214576721
step: 794, train loss: nan, train acuracy: 0.0625
step: 794, val loss: nan, val acuracy: 0.10400000959634781
step: 795, train loss: nan, train acuracy: 0.078125
step: 795, val loss: nan, val acuracy: 0.10400000959634781
step: 796, train loss: nan, train acuracy: 0.0625
step: 796, val loss: nan, val acuracy: 0.10400000214576721
step: 797, train loss: nan, train acuracy: 0.140625
step: 797, val loss: nan, val acuracy: 0.10400000214576721
step: 798, train loss: nan, train acuracy: 0.125
step: 798, val loss: nan, val acuracy: 0.10400000214576721
step: 799, train loss: nan, train acuracy: 0.109375
step: 799, val loss: nan, val acuracy: 0.10400000214576721
step: 800, train loss: nan, train acuracy: 0.0625
step: 800, val loss: nan, val acuracy: 0.10400000214576721
step: 801, train loss: nan, train acuracy: 0.078125
step: 801, val loss: nan, val acuracy: 0.10400000214576721
step: 802, train loss: nan, train acuracy: 0.09375
step: 802, val loss: nan, val acuracy: 0.10400000214576721
step: 803, train loss: nan, train acuracy: 0.125
step: 803, val loss: nan, val acuracy: 0.10400000214576721
step: 804, train loss: nan, train acuracy: 0.140625
step: 804, val loss: nan, val acuracy: 0.10400000214576721
step: 805, train loss: nan, train acuracy: 0.078125
step: 805, val loss: nan, val acuracy: 0.10400000214576721
step: 806, train loss: nan, train acuracy: 0.125
step: 806, val loss: nan, val acuracy: 0.10400000214576721
step: 807, train loss: nan, train acuracy: 0.140625
step: 807, val loss: nan, val acuracy: 0.10400000214576721
step: 808, train loss: nan, train acuracy: 0.078125
step: 808, val loss: nan, val acuracy: 0.10400000214576721
step: 809, train loss: nan, train acuracy: 0.078125
step: 809, val loss: nan, val acuracy: 0.10400000214576721
step: 810, train loss: nan, train acuracy: 0.0625
step: 810, val loss: nan, val acuracy: 0.10400000214576721
step: 811, train loss: nan, train acuracy: 0.015625
step: 811, val loss: nan, val acuracy: 0.10400000214576721
step: 812, train loss: nan, train acuracy: 0.078125
step: 812, val loss: nan, val acuracy: 0.10400000214576721
step: 813, train loss: nan, train acuracy: 0.09375
step: 813, val loss: nan, val acuracy: 0.10400000214576721
step: 814, train loss: nan, train acuracy: 0.109375
step: 814, val loss: nan, val acuracy: 0.10400000214576721
step: 815, train loss: nan, train acuracy: 0.125
step: 815, val loss: nan, val acuracy: 0.10400000214576721
step: 816, train loss: nan, train acuracy: 0.21875
step: 816, val loss: nan, val acuracy: 0.10400000214576721
step: 817, train loss: nan, train acuracy: 0.046875
step: 817, val loss: nan, val acuracy: 0.10400000214576721
step: 818, train loss: nan, train acuracy: 0.0625
step: 818, val loss: nan, val acuracy: 0.10400000214576721
step: 819, train loss: nan, train acuracy: 0.109375
step: 819, val loss: nan, val acuracy: 0.10400000214576721
step: 820, train loss: nan, train acuracy: 0.109375
step: 820, val loss: nan, val acuracy: 0.10400000214576721
step: 821, train loss: nan, train acuracy: 0.125
step: 821, val loss: nan, val acuracy: 0.10400000214576721
step: 822, train loss: nan, train acuracy: 0.15625
step: 822, val loss: nan, val acuracy: 0.10400000214576721
step: 823, train loss: nan, train acuracy: 0.15625
step: 823, val loss: nan, val acuracy: 0.10400000214576721
step: 824, train loss: nan, train acuracy: 0.125
step: 824, val loss: nan, val acuracy: 0.10400000214576721
step: 825, train loss: nan, train acuracy: 0.234375
step: 825, val loss: nan, val acuracy: 0.10400000214576721
step: 826, train loss: nan, train acuracy: 0.046875
step: 826, val loss: nan, val acuracy: 0.10400000214576721
step: 827, train loss: nan, train acuracy: 0.109375
step: 827, val loss: nan, val acuracy: 0.10400000214576721
step: 828, train loss: nan, train acuracy: 0.078125
step: 828, val loss: nan, val acuracy: 0.10400000214576721
step: 829, train loss: nan, train acuracy: 0.078125
step: 829, val loss: nan, val acuracy: 0.10400000214576721
step: 830, train loss: nan, train acuracy: 0.1875
step: 830, val loss: nan, val acuracy: 0.10400000214576721
step: 831, train loss: nan, train acuracy: 0.078125
step: 831, val loss: nan, val acuracy: 0.10400000214576721
step: 832, train loss: nan, train acuracy: 0.15625
step: 832, val loss: nan, val acuracy: 0.10400000214576721
step: 833, train loss: nan, train acuracy: 0.125
step: 833, val loss: nan, val acuracy: 0.10400000214576721
step: 834, train loss: nan, train acuracy: 0.09375
step: 834, val loss: nan, val acuracy: 0.10400000214576721
step: 835, train loss: nan, train acuracy: 0.109375
step: 835, val loss: nan, val acuracy: 0.10400000214576721
step: 836, train loss: nan, train acuracy: 0.09375
step: 836, val loss: nan, val acuracy: 0.10400000214576721
step: 837, train loss: nan, train acuracy: 0.09375
step: 837, val loss: nan, val acuracy: 0.10400000214576721
step: 838, train loss: nan, train acuracy: 0.046875
step: 838, val loss: nan, val acuracy: 0.10400000214576721
step: 839, train loss: nan, train acuracy: 0.109375
step: 839, val loss: nan, val acuracy: 0.10400000214576721
step: 840, train loss: nan, train acuracy: 0.125
step: 840, val loss: nan, val acuracy: 0.10400000214576721
step: 841, train loss: nan, train acuracy: 0.078125
step: 841, val loss: nan, val acuracy: 0.10400000214576721
step: 842, train loss: nan, train acuracy: 0.0625
step: 842, val loss: nan, val acuracy: 0.10400000214576721
step: 843, train loss: nan, train acuracy: 0.109375
step: 843, val loss: nan, val acuracy: 0.10400000214576721
step: 844, train loss: nan, train acuracy: 0.15625
step: 844, val loss: nan, val acuracy: 0.10400000214576721
step: 845, train loss: nan, train acuracy: 0.09375
step: 845, val loss: nan, val acuracy: 0.10400000214576721
step: 846, train loss: nan, train acuracy: 0.0625
step: 846, val loss: nan, val acuracy: 0.10400000214576721
step: 847, train loss: nan, train acuracy: 0.140625
step: 847, val loss: nan, val acuracy: 0.10400000214576721
step: 848, train loss: nan, train acuracy: 0.109375
step: 848, val loss: nan, val acuracy: 0.10400000214576721
step: 849, train loss: nan, train acuracy: 0.125
step: 849, val loss: nan, val acuracy: 0.10400000214576721
step: 850, train loss: nan, train acuracy: 0.109375
step: 850, val loss: nan, val acuracy: 0.10400000214576721
step: 851, train loss: nan, train acuracy: 0.046875
step: 851, val loss: nan, val acuracy: 0.10400000214576721
step: 852, train loss: nan, train acuracy: 0.09375
step: 852, val loss: nan, val acuracy: 0.10400000214576721
step: 853, train loss: nan, train acuracy: 0.109375
step: 853, val loss: nan, val acuracy: 0.10400000214576721
step: 854, train loss: nan, train acuracy: 0.09375
step: 854, val loss: nan, val acuracy: 0.10400000214576721
step: 855, train loss: nan, train acuracy: 0.0625
step: 855, val loss: nan, val acuracy: 0.10400000214576721
step: 856, train loss: nan, train acuracy: 0.09375
step: 856, val loss: nan, val acuracy: 0.10400000214576721
step: 857, train loss: nan, train acuracy: 0.046875
step: 857, val loss: nan, val acuracy: 0.10400000214576721
step: 858, train loss: nan, train acuracy: 0.0625
step: 858, val loss: nan, val acuracy: 0.10400000214576721
step: 859, train loss: nan, train acuracy: 0.09375
step: 859, val loss: nan, val acuracy: 0.10400000214576721
step: 860, train loss: nan, train acuracy: 0.109375
step: 860, val loss: nan, val acuracy: 0.10400000214576721
step: 861, train loss: nan, train acuracy: 0.171875
step: 861, val loss: nan, val acuracy: 0.10400000214576721
step: 862, train loss: nan, train acuracy: 0.078125
step: 862, val loss: nan, val acuracy: 0.10400000214576721
step: 863, train loss: nan, train acuracy: 0.09375
step: 863, val loss: nan, val acuracy: 0.10400000214576721
step: 864, train loss: nan, train acuracy: 0.140625
step: 864, val loss: nan, val acuracy: 0.10400000214576721
step: 865, train loss: nan, train acuracy: 0.0625
step: 865, val loss: nan, val acuracy: 0.10400000214576721
step: 866, train loss: nan, train acuracy: 0.109375
step: 866, val loss: nan, val acuracy: 0.10400000214576721
step: 867, train loss: nan, train acuracy: 0.15625
step: 867, val loss: nan, val acuracy: 0.10400000214576721
step: 868, train loss: nan, train acuracy: 0.0625
step: 868, val loss: nan, val acuracy: 0.10400000214576721
step: 869, train loss: nan, train acuracy: 0.140625
step: 869, val loss: nan, val acuracy: 0.10400000214576721
step: 870, train loss: nan, train acuracy: 0.0625
step: 870, val loss: nan, val acuracy: 0.10400000214576721
step: 871, train loss: nan, train acuracy: 0.0625
step: 871, val loss: nan, val acuracy: 0.10400000214576721
step: 872, train loss: nan, train acuracy: 0.09375
step: 872, val loss: nan, val acuracy: 0.10400000214576721
step: 873, train loss: nan, train acuracy: 0.125
step: 873, val loss: nan, val acuracy: 0.10400000214576721
step: 874, train loss: nan, train acuracy: 0.078125
step: 874, val loss: nan, val acuracy: 0.10400000214576721
step: 875, train loss: nan, train acuracy: 0.09375
step: 875, val loss: nan, val acuracy: 0.10400000214576721
step: 876, train loss: nan, train acuracy: 0.09375
step: 876, val loss: nan, val acuracy: 0.10400000214576721
step: 877, train loss: nan, train acuracy: 0.09375
step: 877, val loss: nan, val acuracy: 0.10400000214576721
step: 878, train loss: nan, train acuracy: 0.0625
step: 878, val loss: nan, val acuracy: 0.10400000214576721
step: 879, train loss: nan, train acuracy: 0.109375
step: 879, val loss: nan, val acuracy: 0.10400000214576721
step: 880, train loss: nan, train acuracy: 0.046875
step: 880, val loss: nan, val acuracy: 0.10400000214576721
step: 881, train loss: nan, train acuracy: 0.078125
step: 881, val loss: nan, val acuracy: 0.10400000214576721
step: 882, train loss: nan, train acuracy: 0.0625
step: 882, val loss: nan, val acuracy: 0.10400000214576721
step: 883, train loss: nan, train acuracy: 0.09375
step: 883, val loss: nan, val acuracy: 0.10400000214576721
step: 884, train loss: nan, train acuracy: 0.0625
step: 884, val loss: nan, val acuracy: 0.10400000214576721
step: 885, train loss: nan, train acuracy: 0.078125
step: 885, val loss: nan, val acuracy: 0.10400000214576721
step: 886, train loss: nan, train acuracy: 0.0625
step: 886, val loss: nan, val acuracy: 0.10400000214576721
step: 887, train loss: nan, train acuracy: 0.0625
step: 887, val loss: nan, val acuracy: 0.10400000214576721
step: 888, train loss: nan, train acuracy: 0.140625
step: 888, val loss: nan, val acuracy: 0.10400000214576721
step: 889, train loss: nan, train acuracy: 0.109375
step: 889, val loss: nan, val acuracy: 0.10400000214576721
step: 890, train loss: nan, train acuracy: 0.09375
step: 890, val loss: nan, val acuracy: 0.10400000214576721
step: 891, train loss: nan, train acuracy: 0.0625
step: 891, val loss: nan, val acuracy: 0.10400000214576721
step: 892, train loss: nan, train acuracy: 0.109375
step: 892, val loss: nan, val acuracy: 0.10400000214576721
step: 893, train loss: nan, train acuracy: 0.078125
step: 893, val loss: nan, val acuracy: 0.10400000214576721
step: 894, train loss: nan, train acuracy: 0.09375
step: 894, val loss: nan, val acuracy: 0.10400000214576721
step: 895, train loss: nan, train acuracy: 0.078125
step: 895, val loss: nan, val acuracy: 0.10400000214576721
step: 896, train loss: nan, train acuracy: 0.109375
step: 896, val loss: nan, val acuracy: 0.10400000214576721
step: 897, train loss: nan, train acuracy: 0.078125
step: 897, val loss: nan, val acuracy: 0.10400000214576721
step: 898, train loss: nan, train acuracy: 0.09375
step: 898, val loss: nan, val acuracy: 0.10400000214576721
step: 899, train loss: nan, train acuracy: 0.125
step: 899, val loss: nan, val acuracy: 0.10400000214576721
step: 900, train loss: nan, train acuracy: 0.109375
step: 900, val loss: nan, val acuracy: 0.10400000214576721
step: 901, train loss: nan, train acuracy: 0.09375
step: 901, val loss: nan, val acuracy: 0.10400000214576721
step: 902, train loss: nan, train acuracy: 0.078125
step: 902, val loss: nan, val acuracy: 0.10400000214576721
step: 903, train loss: nan, train acuracy: 0.15625
step: 903, val loss: nan, val acuracy: 0.10400000214576721
step: 904, train loss: nan, train acuracy: 0.03125
step: 904, val loss: nan, val acuracy: 0.10400000214576721
step: 905, train loss: nan, train acuracy: 0.171875
step: 905, val loss: nan, val acuracy: 0.10400000214576721
step: 906, train loss: nan, train acuracy: 0.125
step: 906, val loss: nan, val acuracy: 0.10400000214576721
step: 907, train loss: nan, train acuracy: 0.15625
step: 907, val loss: nan, val acuracy: 0.10400000214576721
step: 908, train loss: nan, train acuracy: 0.078125
step: 908, val loss: nan, val acuracy: 0.10400000214576721
step: 909, train loss: nan, train acuracy: 0.109375
step: 909, val loss: nan, val acuracy: 0.10400000214576721
step: 910, train loss: nan, train acuracy: 0.078125
step: 910, val loss: nan, val acuracy: 0.10400000214576721
step: 911, train loss: nan, train acuracy: 0.0625
step: 911, val loss: nan, val acuracy: 0.10400000214576721
step: 912, train loss: nan, train acuracy: 0.09375
step: 912, val loss: nan, val acuracy: 0.10400000214576721
step: 913, train loss: nan, train acuracy: 0.046875
step: 913, val loss: nan, val acuracy: 0.10400000214576721
step: 914, train loss: nan, train acuracy: 0.125
step: 914, val loss: nan, val acuracy: 0.10400000214576721
step: 915, train loss: nan, train acuracy: 0.125
step: 915, val loss: nan, val acuracy: 0.10400000214576721
step: 916, train loss: nan, train acuracy: 0.109375
step: 916, val loss: nan, val acuracy: 0.10400000214576721
step: 917, train loss: nan, train acuracy: 0.109375
step: 917, val loss: nan, val acuracy: 0.10400000214576721
step: 918, train loss: nan, train acuracy: 0.03125
step: 918, val loss: nan, val acuracy: 0.10400000214576721
step: 919, train loss: nan, train acuracy: 0.109375
step: 919, val loss: nan, val acuracy: 0.10400000214576721
step: 920, train loss: nan, train acuracy: 0.1875
step: 920, val loss: nan, val acuracy: 0.10400000214576721
step: 921, train loss: nan, train acuracy: 0.09375
step: 921, val loss: nan, val acuracy: 0.10400000214576721
step: 922, train loss: nan, train acuracy: 0.109375
step: 922, val loss: nan, val acuracy: 0.10400000214576721
step: 923, train loss: nan, train acuracy: 0.109375
step: 923, val loss: nan, val acuracy: 0.10400000214576721
step: 924, train loss: nan, train acuracy: 0.09375
step: 924, val loss: nan, val acuracy: 0.10400000214576721
step: 925, train loss: nan, train acuracy: 0.109375
step: 925, val loss: nan, val acuracy: 0.10400000214576721
step: 926, train loss: nan, train acuracy: 0.03125
step: 926, val loss: nan, val acuracy: 0.10400000214576721
step: 927, train loss: nan, train acuracy: 0.078125
step: 927, val loss: nan, val acuracy: 0.10400000214576721
step: 928, train loss: nan, train acuracy: 0.125
step: 928, val loss: nan, val acuracy: 0.10400000214576721
step: 929, train loss: nan, train acuracy: 0.109375
step: 929, val loss: nan, val acuracy: 0.10400000214576721
step: 930, train loss: nan, train acuracy: 0.09375
step: 930, val loss: nan, val acuracy: 0.10400000214576721
step: 931, train loss: nan, train acuracy: 0.046875
step: 931, val loss: nan, val acuracy: 0.10400000214576721
step: 932, train loss: nan, train acuracy: 0.109375
step: 932, val loss: nan, val acuracy: 0.10400000214576721
step: 933, train loss: nan, train acuracy: 0.15625
step: 933, val loss: nan, val acuracy: 0.10400000214576721
step: 934, train loss: nan, train acuracy: 0.140625
step: 934, val loss: nan, val acuracy: 0.10400000214576721
step: 935, train loss: nan, train acuracy: 0.109375
step: 935, val loss: nan, val acuracy: 0.10400000214576721
step: 936, train loss: nan, train acuracy: 0.109375
step: 936, val loss: nan, val acuracy: 0.10400000214576721
step: 937, train loss: nan, train acuracy: 0.0625
step: 937, val loss: nan, val acuracy: 0.10400000214576721
step: 938, train loss: nan, train acuracy: 0.0625
step: 938, val loss: nan, val acuracy: 0.10400000214576721
step: 939, train loss: nan, train acuracy: 0.0625
step: 939, val loss: nan, val acuracy: 0.10400000214576721
step: 940, train loss: nan, train acuracy: 0.125
step: 940, val loss: nan, val acuracy: 0.10400000214576721
step: 941, train loss: nan, train acuracy: 0.078125
step: 941, val loss: nan, val acuracy: 0.10400000214576721
step: 942, train loss: nan, train acuracy: 0.125
step: 942, val loss: nan, val acuracy: 0.10400000214576721
step: 943, train loss: nan, train acuracy: 0.046875
step: 943, val loss: nan, val acuracy: 0.10400000214576721
step: 944, train loss: nan, train acuracy: 0.1875
step: 944, val loss: nan, val acuracy: 0.10400000214576721
step: 945, train loss: nan, train acuracy: 0.09375
step: 945, val loss: nan, val acuracy: 0.10400000214576721
step: 946, train loss: nan, train acuracy: 0.15625
step: 946, val loss: nan, val acuracy: 0.10400000214576721
step: 947, train loss: nan, train acuracy: 0.1875
step: 947, val loss: nan, val acuracy: 0.10400000214576721
step: 948, train loss: nan, train acuracy: 0.09375
step: 948, val loss: nan, val acuracy: 0.10400000214576721
step: 949, train loss: nan, train acuracy: 0.15625
step: 949, val loss: nan, val acuracy: 0.10400000214576721
step: 950, train loss: nan, train acuracy: 0.09375
step: 950, val loss: nan, val acuracy: 0.10400000214576721
step: 951, train loss: nan, train acuracy: 0.15625
step: 951, val loss: nan, val acuracy: 0.10400000214576721
step: 952, train loss: nan, train acuracy: 0.03125
step: 952, val loss: nan, val acuracy: 0.10400000214576721
step: 953, train loss: nan, train acuracy: 0.109375
step: 953, val loss: nan, val acuracy: 0.10400000214576721
step: 954, train loss: nan, train acuracy: 0.09375
step: 954, val loss: nan, val acuracy: 0.10400000214576721
step: 955, train loss: nan, train acuracy: 0.125
step: 955, val loss: nan, val acuracy: 0.10400000214576721
step: 956, train loss: nan, train acuracy: 0.140625
step: 956, val loss: nan, val acuracy: 0.10400000214576721
step: 957, train loss: nan, train acuracy: 0.09375
step: 957, val loss: nan, val acuracy: 0.10400000214576721
step: 958, train loss: nan, train acuracy: 0.109375
step: 958, val loss: nan, val acuracy: 0.10400000214576721
step: 959, train loss: nan, train acuracy: 0.0625
step: 959, val loss: nan, val acuracy: 0.10400000214576721
step: 960, train loss: nan, train acuracy: 0.109375
step: 960, val loss: nan, val acuracy: 0.10400000214576721
step: 961, train loss: nan, train acuracy: 0.109375
step: 961, val loss: nan, val acuracy: 0.10400000214576721
step: 962, train loss: nan, train acuracy: 0.0625
step: 962, val loss: nan, val acuracy: 0.10400000214576721
step: 963, train loss: nan, train acuracy: 0.078125
step: 963, val loss: nan, val acuracy: 0.10400000214576721
step: 964, train loss: nan, train acuracy: 0.0625
step: 964, val loss: nan, val acuracy: 0.10400000214576721
step: 965, train loss: nan, train acuracy: 0.0625
step: 965, val loss: nan, val acuracy: 0.10400000214576721
step: 966, train loss: nan, train acuracy: 0.1875
step: 966, val loss: nan, val acuracy: 0.10400000214576721
step: 967, train loss: nan, train acuracy: 0.078125
step: 967, val loss: nan, val acuracy: 0.10400000214576721
step: 968, train loss: nan, train acuracy: 0.046875
step: 968, val loss: nan, val acuracy: 0.10400000214576721
step: 969, train loss: nan, train acuracy: 0.125
step: 969, val loss: nan, val acuracy: 0.10400000214576721
step: 970, train loss: nan, train acuracy: 0.046875
step: 970, val loss: nan, val acuracy: 0.10400000214576721
step: 971, train loss: nan, train acuracy: 0.109375
step: 971, val loss: nan, val acuracy: 0.10400000214576721
step: 972, train loss: nan, train acuracy: 0.078125
step: 972, val loss: nan, val acuracy: 0.10400000214576721
step: 973, train loss: nan, train acuracy: 0.15625
step: 973, val loss: nan, val acuracy: 0.10400000214576721
step: 974, train loss: nan, train acuracy: 0.140625
step: 974, val loss: nan, val acuracy: 0.10400000214576721
step: 975, train loss: nan, train acuracy: 0.09375
step: 975, val loss: nan, val acuracy: 0.10400000214576721
step: 976, train loss: nan, train acuracy: 0.15625
step: 976, val loss: nan, val acuracy: 0.10400000214576721
step: 977, train loss: nan, train acuracy: 0.09375
step: 977, val loss: nan, val acuracy: 0.10400000214576721
step: 978, train loss: nan, train acuracy: 0.0625
step: 978, val loss: nan, val acuracy: 0.10400000214576721
step: 979, train loss: nan, train acuracy: 0.109375
step: 979, val loss: nan, val acuracy: 0.10400000214576721
step: 980, train loss: nan, train acuracy: 0.125
step: 980, val loss: nan, val acuracy: 0.10400000214576721
step: 981, train loss: nan, train acuracy: 0.078125
step: 981, val loss: nan, val acuracy: 0.10400000214576721
step: 982, train loss: nan, train acuracy: 0.09375
step: 982, val loss: nan, val acuracy: 0.10400000214576721
step: 983, train loss: nan, train acuracy: 0.046875
step: 983, val loss: nan, val acuracy: 0.10400000214576721
step: 984, train loss: nan, train acuracy: 0.140625
step: 984, val loss: nan, val acuracy: 0.10400000214576721
step: 985, train loss: nan, train acuracy: 0.140625
step: 985, val loss: nan, val acuracy: 0.10400000214576721
step: 986, train loss: nan, train acuracy: 0.015625
step: 986, val loss: nan, val acuracy: 0.10400000214576721
step: 987, train loss: nan, train acuracy: 0.09375
step: 987, val loss: nan, val acuracy: 0.10400000214576721
step: 988, train loss: nan, train acuracy: 0.0625
step: 988, val loss: nan, val acuracy: 0.10400000214576721
step: 989, train loss: nan, train acuracy: 0.078125
step: 989, val loss: nan, val acuracy: 0.10400000214576721
step: 990, train loss: nan, train acuracy: 0.03125
step: 990, val loss: nan, val acuracy: 0.10400000214576721
step: 991, train loss: nan, train acuracy: 0.0625
step: 991, val loss: nan, val acuracy: 0.10400000214576721
step: 992, train loss: nan, train acuracy: 0.046875
step: 992, val loss: nan, val acuracy: 0.10400000214576721
step: 993, train loss: nan, train acuracy: 0.140625
step: 993, val loss: nan, val acuracy: 0.10400000214576721
step: 994, train loss: nan, train acuracy: 0.09375
step: 994, val loss: nan, val acuracy: 0.10400000214576721
step: 995, train loss: nan, train acuracy: 0.09375
step: 995, val loss: nan, val acuracy: 0.10400000214576721
step: 996, train loss: nan, train acuracy: 0.1875
step: 996, val loss: nan, val acuracy: 0.10400000214576721
step: 997, train loss: nan, train acuracy: 0.140625
step: 997, val loss: nan, val acuracy: 0.10400000214576721
step: 998, train loss: nan, train acuracy: 0.109375
step: 998, val loss: nan, val acuracy: 0.10400000214576721
step: 999, train loss: nan, train acuracy: 0.078125
step: 999, val loss: nan, val acuracy: 0.10400000214576721
step: 1000, train loss: nan, train acuracy: 0.09375
step: 1000, val loss: nan, val acuracy: 0.10400000214576721
step: 1001, train loss: nan, train acuracy: 0.109375
step: 1001, val loss: nan, val acuracy: 0.10400000214576721
step: 1002, train loss: nan, train acuracy: 0.09375
step: 1002, val loss: nan, val acuracy: 0.10400000214576721
step: 1003, train loss: nan, train acuracy: 0.125
step: 1003, val loss: nan, val acuracy: 0.10400000214576721
step: 1004, train loss: nan, train acuracy: 0.046875
step: 1004, val loss: nan, val acuracy: 0.10400000214576721
step: 1005, train loss: nan, train acuracy: 0.09375
step: 1005, val loss: nan, val acuracy: 0.10400000214576721
step: 1006, train loss: nan, train acuracy: 0.09375
step: 1006, val loss: nan, val acuracy: 0.10400000214576721
step: 1007, train loss: nan, train acuracy: 0.078125
step: 1007, val loss: nan, val acuracy: 0.10400000214576721
step: 1008, train loss: nan, train acuracy: 0.109375
step: 1008, val loss: nan, val acuracy: 0.10400000214576721
step: 1009, train loss: nan, train acuracy: 0.046875
step: 1009, val loss: nan, val acuracy: 0.10400000214576721
step: 1010, train loss: nan, train acuracy: 0.125
step: 1010, val loss: nan, val acuracy: 0.10400000214576721
step: 1011, train loss: nan, train acuracy: 0.078125
step: 1011, val loss: nan, val acuracy: 0.10400000214576721
step: 1012, train loss: nan, train acuracy: 0.046875
step: 1012, val loss: nan, val acuracy: 0.10400000214576721
step: 1013, train loss: nan, train acuracy: 0.046875
step: 1013, val loss: nan, val acuracy: 0.10400000214576721
step: 1014, train loss: nan, train acuracy: 0.171875
step: 1014, val loss: nan, val acuracy: 0.10400000214576721
step: 1015, train loss: nan, train acuracy: 0.09375
step: 1015, val loss: nan, val acuracy: 0.10400000214576721
step: 1016, train loss: nan, train acuracy: 0.078125
step: 1016, val loss: nan, val acuracy: 0.10400000214576721
step: 1017, train loss: nan, train acuracy: 0.0625
step: 1017, val loss: nan, val acuracy: 0.10400000214576721
step: 1018, train loss: nan, train acuracy: 0.09375
step: 1018, val loss: nan, val acuracy: 0.10400000214576721
step: 1019, train loss: nan, train acuracy: 0.0625
step: 1019, val loss: nan, val acuracy: 0.10400000214576721
step: 1020, train loss: nan, train acuracy: 0.09375
step: 1020, val loss: nan, val acuracy: 0.10400000214576721
step: 1021, train loss: nan, train acuracy: 0.140625
step: 1021, val loss: nan, val acuracy: 0.10400000214576721
step: 1022, train loss: nan, train acuracy: 0.109375
step: 1022, val loss: nan, val acuracy: 0.10400000214576721
step: 1023, train loss: nan, train acuracy: 0.0625
step: 1023, val loss: nan, val acuracy: 0.10400000214576721
step: 1024, train loss: nan, train acuracy: 0.09375
step: 1024, val loss: nan, val acuracy: 0.10400000214576721
step: 1025, train loss: nan, train acuracy: 0.046875
step: 1025, val loss: nan, val acuracy: 0.10400000214576721
step: 1026, train loss: nan, train acuracy: 0.078125
step: 1026, val loss: nan, val acuracy: 0.10400000214576721
step: 1027, train loss: nan, train acuracy: 0.0625
step: 1027, val loss: nan, val acuracy: 0.10400000214576721
step: 1028, train loss: nan, train acuracy: 0.09375
step: 1028, val loss: nan, val acuracy: 0.10400000214576721
step: 1029, train loss: nan, train acuracy: 0.078125
step: 1029, val loss: nan, val acuracy: 0.10400000214576721
step: 1030, train loss: nan, train acuracy: 0.109375
step: 1030, val loss: nan, val acuracy: 0.10400000214576721
step: 1031, train loss: nan, train acuracy: 0.0
step: 1031, val loss: nan, val acuracy: 0.10400000214576721
step: 1032, train loss: nan, train acuracy: 0.03125
step: 1032, val loss: nan, val acuracy: 0.10400000214576721
step: 1033, train loss: nan, train acuracy: 0.15625
step: 1033, val loss: nan, val acuracy: 0.10400000214576721
step: 1034, train loss: nan, train acuracy: 0.078125
step: 1034, val loss: nan, val acuracy: 0.10400000214576721
step: 1035, train loss: nan, train acuracy: 0.109375
step: 1035, val loss: nan, val acuracy: 0.10400000214576721
step: 1036, train loss: nan, train acuracy: 0.09375
step: 1036, val loss: nan, val acuracy: 0.10400000214576721
step: 1037, train loss: nan, train acuracy: 0.109375
step: 1037, val loss: nan, val acuracy: 0.10400000214576721
step: 1038, train loss: nan, train acuracy: 0.0625
step: 1038, val loss: nan, val acuracy: 0.10400000214576721
step: 1039, train loss: nan, train acuracy: 0.09375
step: 1039, val loss: nan, val acuracy: 0.10400000214576721
step: 1040, train loss: nan, train acuracy: 0.125
step: 1040, val loss: nan, val acuracy: 0.10400000214576721
step: 1041, train loss: nan, train acuracy: 0.203125
step: 1041, val loss: nan, val acuracy: 0.10400000214576721
step: 1042, train loss: nan, train acuracy: 0.125
step: 1042, val loss: nan, val acuracy: 0.10400000214576721
step: 1043, train loss: nan, train acuracy: 0.109375
step: 1043, val loss: nan, val acuracy: 0.10400000214576721
step: 1044, train loss: nan, train acuracy: 0.125
step: 1044, val loss: nan, val acuracy: 0.10400000214576721
step: 1045, train loss: nan, train acuracy: 0.0625
step: 1045, val loss: nan, val acuracy: 0.10400000214576721
step: 1046, train loss: nan, train acuracy: 0.046875
step: 1046, val loss: nan, val acuracy: 0.10400000214576721
step: 1047, train loss: nan, train acuracy: 0.03125
step: 1047, val loss: nan, val acuracy: 0.10400000214576721
step: 1048, train loss: nan, train acuracy: 0.078125
step: 1048, val loss: nan, val acuracy: 0.10400000214576721
step: 1049, train loss: nan, train acuracy: 0.03125
step: 1049, val loss: nan, val acuracy: 0.10400000214576721
step: 1050, train loss: nan, train acuracy: 0.078125
step: 1050, val loss: nan, val acuracy: 0.10400000214576721
step: 1051, train loss: nan, train acuracy: 0.078125
step: 1051, val loss: nan, val acuracy: 0.10400000214576721
step: 1052, train loss: nan, train acuracy: 0.140625
step: 1052, val loss: nan, val acuracy: 0.10400000214576721
step: 1053, train loss: nan, train acuracy: 0.09375
step: 1053, val loss: nan, val acuracy: 0.10400000214576721
step: 1054, train loss: nan, train acuracy: 0.078125
step: 1054, val loss: nan, val acuracy: 0.10400000214576721
step: 1055, train loss: nan, train acuracy: 0.078125
step: 1055, val loss: nan, val acuracy: 0.10400000214576721
step: 1056, train loss: nan, train acuracy: 0.171875
step: 1056, val loss: nan, val acuracy: 0.10400000214576721
step: 1057, train loss: nan, train acuracy: 0.078125
step: 1057, val loss: nan, val acuracy: 0.10400000214576721
step: 1058, train loss: nan, train acuracy: 0.15625
step: 1058, val loss: nan, val acuracy: 0.10400000214576721
step: 1059, train loss: nan, train acuracy: 0.140625
step: 1059, val loss: nan, val acuracy: 0.10400000214576721
step: 1060, train loss: nan, train acuracy: 0.03125
step: 1060, val loss: nan, val acuracy: 0.10400000214576721
step: 1061, train loss: nan, train acuracy: 0.15625
step: 1061, val loss: nan, val acuracy: 0.10400000214576721
step: 1062, train loss: nan, train acuracy: 0.09375
step: 1062, val loss: nan, val acuracy: 0.10400000214576721
step: 1063, train loss: nan, train acuracy: 0.09375
step: 1063, val loss: nan, val acuracy: 0.10400000214576721
step: 1064, train loss: nan, train acuracy: 0.0625
step: 1064, val loss: nan, val acuracy: 0.10400000214576721
step: 1065, train loss: nan, train acuracy: 0.078125
step: 1065, val loss: nan, val acuracy: 0.10400000214576721
step: 1066, train loss: nan, train acuracy: 0.046875
step: 1066, val loss: nan, val acuracy: 0.10400000214576721
step: 1067, train loss: nan, train acuracy: 0.109375
step: 1067, val loss: nan, val acuracy: 0.10400000214576721
step: 1068, train loss: nan, train acuracy: 0.125
step: 1068, val loss: nan, val acuracy: 0.10400000214576721
step: 1069, train loss: nan, train acuracy: 0.09375
step: 1069, val loss: nan, val acuracy: 0.10400000214576721
step: 1070, train loss: nan, train acuracy: 0.125
step: 1070, val loss: nan, val acuracy: 0.10400000214576721
step: 1071, train loss: nan, train acuracy: 0.046875
step: 1071, val loss: nan, val acuracy: 0.10400000214576721
step: 1072, train loss: nan, train acuracy: 0.125
step: 1072, val loss: nan, val acuracy: 0.10400000214576721
step: 1073, train loss: nan, train acuracy: 0.125
step: 1073, val loss: nan, val acuracy: 0.10400000214576721
step: 1074, train loss: nan, train acuracy: 0.078125
step: 1074, val loss: nan, val acuracy: 0.10400000214576721
step: 1075, train loss: nan, train acuracy: 0.078125
step: 1075, val loss: nan, val acuracy: 0.10400000214576721
step: 1076, train loss: nan, train acuracy: 0.171875
step: 1076, val loss: nan, val acuracy: 0.10400000214576721
step: 1077, train loss: nan, train acuracy: 0.09375
step: 1077, val loss: nan, val acuracy: 0.10400000214576721
step: 1078, train loss: nan, train acuracy: 0.0625
step: 1078, val loss: nan, val acuracy: 0.10400000214576721
step: 1079, train loss: nan, train acuracy: 0.09375
step: 1079, val loss: nan, val acuracy: 0.10400000214576721
step: 1080, train loss: nan, train acuracy: 0.109375
step: 1080, val loss: nan, val acuracy: 0.10400000214576721
step: 1081, train loss: nan, train acuracy: 0.203125
step: 1081, val loss: nan, val acuracy: 0.10400000214576721
step: 1082, train loss: nan, train acuracy: 0.09375
step: 1082, val loss: nan, val acuracy: 0.10400000214576721
step: 1083, train loss: nan, train acuracy: 0.078125
step: 1083, val loss: nan, val acuracy: 0.10400000214576721
step: 1084, train loss: nan, train acuracy: 0.109375
step: 1084, val loss: nan, val acuracy: 0.10400000214576721
step: 1085, train loss: nan, train acuracy: 0.09375
step: 1085, val loss: nan, val acuracy: 0.10400000214576721
step: 1086, train loss: nan, train acuracy: 0.078125
step: 1086, val loss: nan, val acuracy: 0.10400000214576721
step: 1087, train loss: nan, train acuracy: 0.203125
step: 1087, val loss: nan, val acuracy: 0.10400000214576721
step: 1088, train loss: nan, train acuracy: 0.046875
step: 1088, val loss: nan, val acuracy: 0.10400000214576721
step: 1089, train loss: nan, train acuracy: 0.046875
step: 1089, val loss: nan, val acuracy: 0.10400000214576721
step: 1090, train loss: nan, train acuracy: 0.109375
step: 1090, val loss: nan, val acuracy: 0.10400000214576721
step: 1091, train loss: nan, train acuracy: 0.078125
step: 1091, val loss: nan, val acuracy: 0.10400000214576721
step: 1092, train loss: nan, train acuracy: 0.09375
step: 1092, val loss: nan, val acuracy: 0.10400000214576721
step: 1093, train loss: nan, train acuracy: 0.109375
step: 1093, val loss: nan, val acuracy: 0.10400000214576721
step: 1094, train loss: nan, train acuracy: 0.015625
step: 1094, val loss: nan, val acuracy: 0.10400000214576721
step: 1095, train loss: nan, train acuracy: 0.125
step: 1095, val loss: nan, val acuracy: 0.10400000214576721
step: 1096, train loss: nan, train acuracy: 0.0625
step: 1096, val loss: nan, val acuracy: 0.10400000214576721
step: 1097, train loss: nan, train acuracy: 0.09375
step: 1097, val loss: nan, val acuracy: 0.10400000214576721
step: 1098, train loss: nan, train acuracy: 0.046875
step: 1098, val loss: nan, val acuracy: 0.10400000214576721
step: 1099, train loss: nan, train acuracy: 0.1875
step: 1099, val loss: nan, val acuracy: 0.10400000214576721
step: 1100, train loss: nan, train acuracy: 0.046875
step: 1100, val loss: nan, val acuracy: 0.10400000214576721
step: 1101, train loss: nan, train acuracy: 0.09375
step: 1101, val loss: nan, val acuracy: 0.10400000214576721
step: 1102, train loss: nan, train acuracy: 0.109375
step: 1102, val loss: nan, val acuracy: 0.10400000214576721
step: 1103, train loss: nan, train acuracy: 0.171875
step: 1103, val loss: nan, val acuracy: 0.10400000214576721
step: 1104, train loss: nan, train acuracy: 0.078125
step: 1104, val loss: nan, val acuracy: 0.10400000214576721
step: 1105, train loss: nan, train acuracy: 0.0625
step: 1105, val loss: nan, val acuracy: 0.10400000214576721
step: 1106, train loss: nan, train acuracy: 0.109375
step: 1106, val loss: nan, val acuracy: 0.10400000214576721
step: 1107, train loss: nan, train acuracy: 0.125
step: 1107, val loss: nan, val acuracy: 0.10400000214576721
step: 1108, train loss: nan, train acuracy: 0.109375
step: 1108, val loss: nan, val acuracy: 0.10400000214576721
step: 1109, train loss: nan, train acuracy: 0.09375
step: 1109, val loss: nan, val acuracy: 0.10400000214576721
step: 1110, train loss: nan, train acuracy: 0.078125
step: 1110, val loss: nan, val acuracy: 0.10400000214576721
step: 1111, train loss: nan, train acuracy: 0.109375
step: 1111, val loss: nan, val acuracy: 0.10400000214576721
step: 1112, train loss: nan, train acuracy: 0.078125
step: 1112, val loss: nan, val acuracy: 0.10400000214576721
step: 1113, train loss: nan, train acuracy: 0.078125
step: 1113, val loss: nan, val acuracy: 0.10400000214576721
step: 1114, train loss: nan, train acuracy: 0.125
step: 1114, val loss: nan, val acuracy: 0.10400000214576721
step: 1115, train loss: nan, train acuracy: 0.125
step: 1115, val loss: nan, val acuracy: 0.10400000214576721
step: 1116, train loss: nan, train acuracy: 0.125
step: 1116, val loss: nan, val acuracy: 0.10400000214576721
step: 1117, train loss: nan, train acuracy: 0.140625
step: 1117, val loss: nan, val acuracy: 0.10400000214576721
step: 1118, train loss: nan, train acuracy: 0.03125
step: 1118, val loss: nan, val acuracy: 0.10400000214576721
step: 1119, train loss: nan, train acuracy: 0.046875
step: 1119, val loss: nan, val acuracy: 0.10400000214576721
step: 1120, train loss: nan, train acuracy: 0.03125
step: 1120, val loss: nan, val acuracy: 0.10400000214576721
step: 1121, train loss: nan, train acuracy: 0.140625
step: 1121, val loss: nan, val acuracy: 0.10400000214576721
step: 1122, train loss: nan, train acuracy: 0.09375
step: 1122, val loss: nan, val acuracy: 0.10400000214576721
step: 1123, train loss: nan, train acuracy: 0.046875
step: 1123, val loss: nan, val acuracy: 0.10400000214576721
step: 1124, train loss: nan, train acuracy: 0.046875
step: 1124, val loss: nan, val acuracy: 0.10400000214576721
step: 1125, train loss: nan, train acuracy: 0.0625
step: 1125, val loss: nan, val acuracy: 0.10400000214576721
step: 1126, train loss: nan, train acuracy: 0.078125
step: 1126, val loss: nan, val acuracy: 0.10400000214576721
step: 1127, train loss: nan, train acuracy: 0.109375
step: 1127, val loss: nan, val acuracy: 0.10400000214576721
step: 1128, train loss: nan, train acuracy: 0.125
step: 1128, val loss: nan, val acuracy: 0.10400000214576721
step: 1129, train loss: nan, train acuracy: 0.0625
step: 1129, val loss: nan, val acuracy: 0.10400000214576721
step: 1130, train loss: nan, train acuracy: 0.078125
step: 1130, val loss: nan, val acuracy: 0.10400000214576721
step: 1131, train loss: nan, train acuracy: 0.09375
step: 1131, val loss: nan, val acuracy: 0.10400000214576721
step: 1132, train loss: nan, train acuracy: 0.09375
step: 1132, val loss: nan, val acuracy: 0.10400000214576721
step: 1133, train loss: nan, train acuracy: 0.078125
step: 1133, val loss: nan, val acuracy: 0.10400000214576721
step: 1134, train loss: nan, train acuracy: 0.09375
step: 1134, val loss: nan, val acuracy: 0.10400000214576721
step: 1135, train loss: nan, train acuracy: 0.046875
step: 1135, val loss: nan, val acuracy: 0.10400000214576721
step: 1136, train loss: nan, train acuracy: 0.15625
step: 1136, val loss: nan, val acuracy: 0.10400000214576721
step: 1137, train loss: nan, train acuracy: 0.09375
step: 1137, val loss: nan, val acuracy: 0.10400000214576721
step: 1138, train loss: nan, train acuracy: 0.09375
step: 1138, val loss: nan, val acuracy: 0.10400000214576721
step: 1139, train loss: nan, train acuracy: 0.046875
step: 1139, val loss: nan, val acuracy: 0.10400000214576721
step: 1140, train loss: nan, train acuracy: 0.078125
step: 1140, val loss: nan, val acuracy: 0.10400000214576721
step: 1141, train loss: nan, train acuracy: 0.1875
step: 1141, val loss: nan, val acuracy: 0.10400000214576721
step: 1142, train loss: nan, train acuracy: 0.1875
step: 1142, val loss: nan, val acuracy: 0.10400000214576721
step: 1143, train loss: nan, train acuracy: 0.109375
step: 1143, val loss: nan, val acuracy: 0.10400000214576721
step: 1144, train loss: nan, train acuracy: 0.125
step: 1144, val loss: nan, val acuracy: 0.10400000214576721
step: 1145, train loss: nan, train acuracy: 0.078125
step: 1145, val loss: nan, val acuracy: 0.10400000214576721
step: 1146, train loss: nan, train acuracy: 0.125
step: 1146, val loss: nan, val acuracy: 0.10400000214576721
step: 1147, train loss: nan, train acuracy: 0.078125
step: 1147, val loss: nan, val acuracy: 0.10400000214576721
step: 1148, train loss: nan, train acuracy: 0.078125
step: 1148, val loss: nan, val acuracy: 0.10400000214576721
step: 1149, train loss: nan, train acuracy: 0.03125
step: 1149, val loss: nan, val acuracy: 0.10400000214576721
step: 1150, train loss: nan, train acuracy: 0.1875
step: 1150, val loss: nan, val acuracy: 0.10400000214576721
step: 1151, train loss: nan, train acuracy: 0.078125
step: 1151, val loss: nan, val acuracy: 0.10400000214576721
step: 1152, train loss: nan, train acuracy: 0.0625
step: 1152, val loss: nan, val acuracy: 0.10400000214576721
step: 1153, train loss: nan, train acuracy: 0.0625
step: 1153, val loss: nan, val acuracy: 0.10400000214576721
step: 1154, train loss: nan, train acuracy: 0.171875
step: 1154, val loss: nan, val acuracy: 0.10400000214576721
step: 1155, train loss: nan, train acuracy: 0.09375
step: 1155, val loss: nan, val acuracy: 0.10400000214576721
step: 1156, train loss: nan, train acuracy: 0.078125
step: 1156, val loss: nan, val acuracy: 0.10400000214576721
step: 1157, train loss: nan, train acuracy: 0.125
step: 1157, val loss: nan, val acuracy: 0.10400000214576721
step: 1158, train loss: nan, train acuracy: 0.0625
step: 1158, val loss: nan, val acuracy: 0.10400000214576721
step: 1159, train loss: nan, train acuracy: 0.03125
step: 1159, val loss: nan, val acuracy: 0.10400000214576721
step: 1160, train loss: nan, train acuracy: 0.09375
step: 1160, val loss: nan, val acuracy: 0.10400000214576721
step: 1161, train loss: nan, train acuracy: 0.046875
step: 1161, val loss: nan, val acuracy: 0.10400000214576721
step: 1162, train loss: nan, train acuracy: 0.125
step: 1162, val loss: nan, val acuracy: 0.10400000214576721
step: 1163, train loss: nan, train acuracy: 0.109375
step: 1163, val loss: nan, val acuracy: 0.10400000214576721
step: 1164, train loss: nan, train acuracy: 0.125
step: 1164, val loss: nan, val acuracy: 0.10400000214576721
step: 1165, train loss: nan, train acuracy: 0.171875
step: 1165, val loss: nan, val acuracy: 0.10400000214576721
step: 1166, train loss: nan, train acuracy: 0.0625
step: 1166, val loss: nan, val acuracy: 0.10400000214576721
step: 1167, train loss: nan, train acuracy: 0.09375
step: 1167, val loss: nan, val acuracy: 0.10400000214576721
step: 1168, train loss: nan, train acuracy: 0.0625
step: 1168, val loss: nan, val acuracy: 0.10400000214576721
step: 1169, train loss: nan, train acuracy: 0.03125
step: 1169, val loss: nan, val acuracy: 0.10400000214576721
step: 1170, train loss: nan, train acuracy: 0.078125
step: 1170, val loss: nan, val acuracy: 0.10400000214576721
step: 1171, train loss: nan, train acuracy: 0.09375
step: 1171, val loss: nan, val acuracy: 0.10400000214576721
step: 1172, train loss: nan, train acuracy: 0.09375
step: 1172, val loss: nan, val acuracy: 0.10400000214576721
step: 1173, train loss: nan, train acuracy: 0.109375
step: 1173, val loss: nan, val acuracy: 0.10400000214576721
step: 1174, train loss: nan, train acuracy: 0.09375
step: 1174, val loss: nan, val acuracy: 0.10400000214576721
step: 1175, train loss: nan, train acuracy: 0.09375
step: 1175, val loss: nan, val acuracy: 0.10400000214576721
step: 1176, train loss: nan, train acuracy: 0.171875
step: 1176, val loss: nan, val acuracy: 0.10400000214576721
step: 1177, train loss: nan, train acuracy: 0.078125
step: 1177, val loss: nan, val acuracy: 0.10400000214576721
step: 1178, train loss: nan, train acuracy: 0.140625
step: 1178, val loss: nan, val acuracy: 0.10400000214576721
step: 1179, train loss: nan, train acuracy: 0.140625
step: 1179, val loss: nan, val acuracy: 0.10400000214576721
step: 1180, train loss: nan, train acuracy: 0.078125
step: 1180, val loss: nan, val acuracy: 0.10400000214576721
step: 1181, train loss: nan, train acuracy: 0.125
step: 1181, val loss: nan, val acuracy: 0.10400000214576721
step: 1182, train loss: nan, train acuracy: 0.125
step: 1182, val loss: nan, val acuracy: 0.10400000214576721
step: 1183, train loss: nan, train acuracy: 0.140625
step: 1183, val loss: nan, val acuracy: 0.10400000214576721
step: 1184, train loss: nan, train acuracy: 0.171875
step: 1184, val loss: nan, val acuracy: 0.10400000214576721
step: 1185, train loss: nan, train acuracy: 0.109375
step: 1185, val loss: nan, val acuracy: 0.10400000214576721
step: 1186, train loss: nan, train acuracy: 0.078125
step: 1186, val loss: nan, val acuracy: 0.10400000214576721
step: 1187, train loss: nan, train acuracy: 0.09375
step: 1187, val loss: nan, val acuracy: 0.10400000214576721
step: 1188, train loss: nan, train acuracy: 0.078125
step: 1188, val loss: nan, val acuracy: 0.10400000214576721
step: 1189, train loss: nan, train acuracy: 0.078125
step: 1189, val loss: nan, val acuracy: 0.10400000214576721
step: 1190, train loss: nan, train acuracy: 0.109375
step: 1190, val loss: nan, val acuracy: 0.10400000214576721
step: 1191, train loss: nan, train acuracy: 0.046875
step: 1191, val loss: nan, val acuracy: 0.10400000214576721
step: 1192, train loss: nan, train acuracy: 0.078125
step: 1192, val loss: nan, val acuracy: 0.10400000214576721
step: 1193, train loss: nan, train acuracy: 0.0625
step: 1193, val loss: nan, val acuracy: 0.10400000214576721
step: 1194, train loss: nan, train acuracy: 0.078125
step: 1194, val loss: nan, val acuracy: 0.10400000214576721
step: 1195, train loss: nan, train acuracy: 0.09375
step: 1195, val loss: nan, val acuracy: 0.10400000214576721
step: 1196, train loss: nan, train acuracy: 0.109375
step: 1196, val loss: nan, val acuracy: 0.10400000214576721
step: 1197, train loss: nan, train acuracy: 0.09375
step: 1197, val loss: nan, val acuracy: 0.10400000214576721
step: 1198, train loss: nan, train acuracy: 0.125
step: 1198, val loss: nan, val acuracy: 0.10400000214576721
step: 1199, train loss: nan, train acuracy: 0.125
step: 1199, val loss: nan, val acuracy: 0.10400000214576721
step: 1200, train loss: nan, train acuracy: 0.0625
step: 1200, val loss: nan, val acuracy: 0.10400000214576721
step: 1201, train loss: nan, train acuracy: 0.125
step: 1201, val loss: nan, val acuracy: 0.10400000214576721
step: 1202, train loss: nan, train acuracy: 0.078125
step: 1202, val loss: nan, val acuracy: 0.10400000214576721
step: 1203, train loss: nan, train acuracy: 0.09375
step: 1203, val loss: nan, val acuracy: 0.10400000214576721
step: 1204, train loss: nan, train acuracy: 0.171875
step: 1204, val loss: nan, val acuracy: 0.10400000214576721
step: 1205, train loss: nan, train acuracy: 0.078125
step: 1205, val loss: nan, val acuracy: 0.10400000214576721
step: 1206, train loss: nan, train acuracy: 0.125
step: 1206, val loss: nan, val acuracy: 0.10400000214576721
step: 1207, train loss: nan, train acuracy: 0.0625
step: 1207, val loss: nan, val acuracy: 0.10400000214576721
step: 1208, train loss: nan, train acuracy: 0.078125
step: 1208, val loss: nan, val acuracy: 0.10400000214576721
step: 1209, train loss: nan, train acuracy: 0.109375
step: 1209, val loss: nan, val acuracy: 0.10400000214576721
step: 1210, train loss: nan, train acuracy: 0.15625
step: 1210, val loss: nan, val acuracy: 0.10400000214576721
step: 1211, train loss: nan, train acuracy: 0.15625
step: 1211, val loss: nan, val acuracy: 0.10400000214576721
step: 1212, train loss: nan, train acuracy: 0.0625
step: 1212, val loss: nan, val acuracy: 0.10400000214576721
step: 1213, train loss: nan, train acuracy: 0.109375
step: 1213, val loss: nan, val acuracy: 0.10400000214576721
step: 1214, train loss: nan, train acuracy: 0.03125
step: 1214, val loss: nan, val acuracy: 0.10400000214576721
step: 1215, train loss: nan, train acuracy: 0.15625
step: 1215, val loss: nan, val acuracy: 0.10400000214576721
step: 1216, train loss: nan, train acuracy: 0.09375
step: 1216, val loss: nan, val acuracy: 0.10400000214576721
step: 1217, train loss: nan, train acuracy: 0.078125
step: 1217, val loss: nan, val acuracy: 0.10400000214576721
step: 1218, train loss: nan, train acuracy: 0.09375
step: 1218, val loss: nan, val acuracy: 0.10400000214576721
step: 1219, train loss: nan, train acuracy: 0.09375
step: 1219, val loss: nan, val acuracy: 0.10400000214576721
step: 1220, train loss: nan, train acuracy: 0.109375
step: 1220, val loss: nan, val acuracy: 0.10400000214576721
step: 1221, train loss: nan, train acuracy: 0.140625
step: 1221, val loss: nan, val acuracy: 0.10400000214576721
step: 1222, train loss: nan, train acuracy: 0.125
step: 1222, val loss: nan, val acuracy: 0.10400000214576721
step: 1223, train loss: nan, train acuracy: 0.09375
step: 1223, val loss: nan, val acuracy: 0.10400000214576721
step: 1224, train loss: nan, train acuracy: 0.078125
step: 1224, val loss: nan, val acuracy: 0.10400000214576721
step: 1225, train loss: nan, train acuracy: 0.0625
step: 1225, val loss: nan, val acuracy: 0.10400000214576721
step: 1226, train loss: nan, train acuracy: 0.125
step: 1226, val loss: nan, val acuracy: 0.10400000214576721
step: 1227, train loss: nan, train acuracy: 0.125
step: 1227, val loss: nan, val acuracy: 0.10400000214576721
step: 1228, train loss: nan, train acuracy: 0.09375
step: 1228, val loss: nan, val acuracy: 0.10400000214576721
step: 1229, train loss: nan, train acuracy: 0.125
step: 1229, val loss: nan, val acuracy: 0.10400000214576721
step: 1230, train loss: nan, train acuracy: 0.09375
step: 1230, val loss: nan, val acuracy: 0.10400000214576721
step: 1231, train loss: nan, train acuracy: 0.15625
step: 1231, val loss: nan, val acuracy: 0.10400000214576721
step: 1232, train loss: nan, train acuracy: 0.078125
step: 1232, val loss: nan, val acuracy: 0.10400000214576721
step: 1233, train loss: nan, train acuracy: 0.109375
step: 1233, val loss: nan, val acuracy: 0.10400000214576721
step: 1234, train loss: nan, train acuracy: 0.03125
step: 1234, val loss: nan, val acuracy: 0.10400000214576721
step: 1235, train loss: nan, train acuracy: 0.046875
step: 1235, val loss: nan, val acuracy: 0.10400000214576721
step: 1236, train loss: nan, train acuracy: 0.125
step: 1236, val loss: nan, val acuracy: 0.10400000214576721
step: 1237, train loss: nan, train acuracy: 0.09375
step: 1237, val loss: nan, val acuracy: 0.10400000214576721
step: 1238, train loss: nan, train acuracy: 0.140625
step: 1238, val loss: nan, val acuracy: 0.10400000214576721
step: 1239, train loss: nan, train acuracy: 0.0625
step: 1239, val loss: nan, val acuracy: 0.10400000214576721
step: 1240, train loss: nan, train acuracy: 0.125
step: 1240, val loss: nan, val acuracy: 0.10400000214576721
step: 1241, train loss: nan, train acuracy: 0.125
step: 1241, val loss: nan, val acuracy: 0.10400000214576721
step: 1242, train loss: nan, train acuracy: 0.078125
step: 1242, val loss: nan, val acuracy: 0.10400000214576721
step: 1243, train loss: nan, train acuracy: 0.0625
step: 1243, val loss: nan, val acuracy: 0.10400000214576721
step: 1244, train loss: nan, train acuracy: 0.078125
step: 1244, val loss: nan, val acuracy: 0.10400000214576721
step: 1245, train loss: nan, train acuracy: 0.15625
step: 1245, val loss: nan, val acuracy: 0.10400000214576721
step: 1246, train loss: nan, train acuracy: 0.109375
step: 1246, val loss: nan, val acuracy: 0.10400000214576721
step: 1247, train loss: nan, train acuracy: 0.109375
step: 1247, val loss: nan, val acuracy: 0.10400000214576721
step: 1248, train loss: nan, train acuracy: 0.078125
step: 1248, val loss: nan, val acuracy: 0.10400000959634781
step: 1249, train loss: nan, train acuracy: 0.15625
step: 1249, val loss: nan, val acuracy: 0.10400000214576721
step: 1250, train loss: nan, train acuracy: 0.125
step: 1250, val loss: nan, val acuracy: 0.10400000214576721
step: 1251, train loss: nan, train acuracy: 0.09375
step: 1251, val loss: nan, val acuracy: 0.10400000214576721
step: 1252, train loss: nan, train acuracy: 0.078125
step: 1252, val loss: nan, val acuracy: 0.10400000214576721
step: 1253, train loss: nan, train acuracy: 0.140625
step: 1253, val loss: nan, val acuracy: 0.10400000214576721
step: 1254, train loss: nan, train acuracy: 0.0625
step: 1254, val loss: nan, val acuracy: 0.10400000214576721
step: 1255, train loss: nan, train acuracy: 0.109375
step: 1255, val loss: nan, val acuracy: 0.10400000214576721
step: 1256, train loss: nan, train acuracy: 0.125
step: 1256, val loss: nan, val acuracy: 0.10400000214576721
step: 1257, train loss: nan, train acuracy: 0.109375
step: 1257, val loss: nan, val acuracy: 0.10400000214576721
step: 1258, train loss: nan, train acuracy: 0.078125
step: 1258, val loss: nan, val acuracy: 0.10400000214576721
step: 1259, train loss: nan, train acuracy: 0.0625
step: 1259, val loss: nan, val acuracy: 0.10400000214576721
step: 1260, train loss: nan, train acuracy: 0.046875
step: 1260, val loss: nan, val acuracy: 0.10400000214576721
step: 1261, train loss: nan, train acuracy: 0.109375
step: 1261, val loss: nan, val acuracy: 0.10400000214576721
step: 1262, train loss: nan, train acuracy: 0.0625
step: 1262, val loss: nan, val acuracy: 0.10400000214576721
step: 1263, train loss: nan, train acuracy: 0.046875
step: 1263, val loss: nan, val acuracy: 0.10400000214576721
step: 1264, train loss: nan, train acuracy: 0.078125
step: 1264, val loss: nan, val acuracy: 0.10400000959634781
step: 1265, train loss: nan, train acuracy: 0.0625
step: 1265, val loss: nan, val acuracy: 0.10400000214576721
step: 1266, train loss: nan, train acuracy: 0.046875
step: 1266, val loss: nan, val acuracy: 0.10400000214576721
step: 1267, train loss: nan, train acuracy: 0.0625
step: 1267, val loss: nan, val acuracy: 0.10400000214576721
step: 1268, train loss: nan, train acuracy: 0.09375
step: 1268, val loss: nan, val acuracy: 0.10400000214576721
step: 1269, train loss: nan, train acuracy: 0.078125
step: 1269, val loss: nan, val acuracy: 0.10400000214576721
step: 1270, train loss: nan, train acuracy: 0.109375
step: 1270, val loss: nan, val acuracy: 0.10400000214576721
step: 1271, train loss: nan, train acuracy: 0.078125
step: 1271, val loss: nan, val acuracy: 0.10400000214576721
step: 1272, train loss: nan, train acuracy: 0.0625
step: 1272, val loss: nan, val acuracy: 0.10400000214576721
step: 1273, train loss: nan, train acuracy: 0.0625
step: 1273, val loss: nan, val acuracy: 0.10400000214576721
step: 1274, train loss: nan, train acuracy: 0.078125
step: 1274, val loss: nan, val acuracy: 0.10400000214576721
step: 1275, train loss: nan, train acuracy: 0.203125
step: 1275, val loss: nan, val acuracy: 0.10400000214576721
step: 1276, train loss: nan, train acuracy: 0.125
step: 1276, val loss: nan, val acuracy: 0.10400000214576721
step: 1277, train loss: nan, train acuracy: 0.109375
step: 1277, val loss: nan, val acuracy: 0.10400000214576721
step: 1278, train loss: nan, train acuracy: 0.078125
step: 1278, val loss: nan, val acuracy: 0.10400000214576721
step: 1279, train loss: nan, train acuracy: 0.109375
step: 1279, val loss: nan, val acuracy: 0.10400000214576721
step: 1280, train loss: nan, train acuracy: 0.109375
step: 1280, val loss: nan, val acuracy: 0.10400000214576721
step: 1281, train loss: nan, train acuracy: 0.0625
step: 1281, val loss: nan, val acuracy: 0.10400000214576721
step: 1282, train loss: nan, train acuracy: 0.15625
step: 1282, val loss: nan, val acuracy: 0.10400000214576721
step: 1283, train loss: nan, train acuracy: 0.125
step: 1283, val loss: nan, val acuracy: 0.10400000214576721
step: 1284, train loss: nan, train acuracy: 0.09375
step: 1284, val loss: nan, val acuracy: 0.10400000959634781
step: 1285, train loss: nan, train acuracy: 0.140625
step: 1285, val loss: nan, val acuracy: 0.10400000214576721
step: 1286, train loss: nan, train acuracy: 0.140625
step: 1286, val loss: nan, val acuracy: 0.10400000214576721
step: 1287, train loss: nan, train acuracy: 0.078125
step: 1287, val loss: nan, val acuracy: 0.10400000214576721
step: 1288, train loss: nan, train acuracy: 0.09375
step: 1288, val loss: nan, val acuracy: 0.10400000214576721
step: 1289, train loss: nan, train acuracy: 0.140625
step: 1289, val loss: nan, val acuracy: 0.10400000214576721
step: 1290, train loss: nan, train acuracy: 0.15625
step: 1290, val loss: nan, val acuracy: 0.10400000214576721
step: 1291, train loss: nan, train acuracy: 0.140625
step: 1291, val loss: nan, val acuracy: 0.10400000214576721
step: 1292, train loss: nan, train acuracy: 0.109375
step: 1292, val loss: nan, val acuracy: 0.10400000214576721
step: 1293, train loss: nan, train acuracy: 0.09375
step: 1293, val loss: nan, val acuracy: 0.10400000214576721
step: 1294, train loss: nan, train acuracy: 0.078125
step: 1294, val loss: nan, val acuracy: 0.10400000214576721
step: 1295, train loss: nan, train acuracy: 0.109375
step: 1295, val loss: nan, val acuracy: 0.10400000214576721
step: 1296, train loss: nan, train acuracy: 0.078125
step: 1296, val loss: nan, val acuracy: 0.10400000214576721
step: 1297, train loss: nan, train acuracy: 0.09375
step: 1297, val loss: nan, val acuracy: 0.10400000214576721
step: 1298, train loss: nan, train acuracy: 0.046875
step: 1298, val loss: nan, val acuracy: 0.10400000214576721
step: 1299, train loss: nan, train acuracy: 0.125
step: 1299, val loss: nan, val acuracy: 0.10400000214576721
step: 1300, train loss: nan, train acuracy: 0.140625
step: 1300, val loss: nan, val acuracy: 0.10400000214576721
step: 1301, train loss: nan, train acuracy: 0.125
step: 1301, val loss: nan, val acuracy: 0.10400000214576721
step: 1302, train loss: nan, train acuracy: 0.140625
step: 1302, val loss: nan, val acuracy: 0.10400000214576721
step: 1303, train loss: nan, train acuracy: 0.109375
step: 1303, val loss: nan, val acuracy: 0.10400000214576721
step: 1304, train loss: nan, train acuracy: 0.046875
step: 1304, val loss: nan, val acuracy: 0.10400000214576721
step: 1305, train loss: nan, train acuracy: 0.109375
step: 1305, val loss: nan, val acuracy: 0.10400000214576721
step: 1306, train loss: nan, train acuracy: 0.0625
step: 1306, val loss: nan, val acuracy: 0.10400000214576721
step: 1307, train loss: nan, train acuracy: 0.09375
step: 1307, val loss: nan, val acuracy: 0.10400000214576721
step: 1308, train loss: nan, train acuracy: 0.09375
step: 1308, val loss: nan, val acuracy: 0.10400000214576721
step: 1309, train loss: nan, train acuracy: 0.109375
step: 1309, val loss: nan, val acuracy: 0.10400000214576721
step: 1310, train loss: nan, train acuracy: 0.15625
step: 1310, val loss: nan, val acuracy: 0.10400000214576721
step: 1311, train loss: nan, train acuracy: 0.078125
step: 1311, val loss: nan, val acuracy: 0.10400000214576721
step: 1312, train loss: nan, train acuracy: 0.09375
step: 1312, val loss: nan, val acuracy: 0.10400000214576721
step: 1313, train loss: nan, train acuracy: 0.15625
step: 1313, val loss: nan, val acuracy: 0.10400000214576721
step: 1314, train loss: nan, train acuracy: 0.09375
step: 1314, val loss: nan, val acuracy: 0.10400000214576721
step: 1315, train loss: nan, train acuracy: 0.09375
step: 1315, val loss: nan, val acuracy: 0.10400000214576721
step: 1316, train loss: nan, train acuracy: 0.109375
step: 1316, val loss: nan, val acuracy: 0.10400000214576721
step: 1317, train loss: nan, train acuracy: 0.125
step: 1317, val loss: nan, val acuracy: 0.10400000214576721
step: 1318, train loss: nan, train acuracy: 0.125
step: 1318, val loss: nan, val acuracy: 0.10400000214576721
step: 1319, train loss: nan, train acuracy: 0.0625
step: 1319, val loss: nan, val acuracy: 0.10400000214576721
step: 1320, train loss: nan, train acuracy: 0.046875
step: 1320, val loss: nan, val acuracy: 0.10400000214576721
step: 1321, train loss: nan, train acuracy: 0.03125
step: 1321, val loss: nan, val acuracy: 0.10400000214576721
step: 1322, train loss: nan, train acuracy: 0.09375
step: 1322, val loss: nan, val acuracy: 0.10400000214576721
step: 1323, train loss: nan, train acuracy: 0.140625
step: 1323, val loss: nan, val acuracy: 0.10400000214576721
step: 1324, train loss: nan, train acuracy: 0.109375
step: 1324, val loss: nan, val acuracy: 0.10400000214576721
step: 1325, train loss: nan, train acuracy: 0.109375
step: 1325, val loss: nan, val acuracy: 0.10400000214576721
step: 1326, train loss: nan, train acuracy: 0.109375
step: 1326, val loss: nan, val acuracy: 0.10400000214576721
step: 1327, train loss: nan, train acuracy: 0.078125
step: 1327, val loss: nan, val acuracy: 0.10400000214576721
step: 1328, train loss: nan, train acuracy: 0.078125
step: 1328, val loss: nan, val acuracy: 0.10400000214576721
step: 1329, train loss: nan, train acuracy: 0.15625
step: 1329, val loss: nan, val acuracy: 0.10400000214576721
step: 1330, train loss: nan, train acuracy: 0.078125
step: 1330, val loss: nan, val acuracy: 0.10400000214576721
step: 1331, train loss: nan, train acuracy: 0.09375
step: 1331, val loss: nan, val acuracy: 0.10400000214576721
step: 1332, train loss: nan, train acuracy: 0.0625
step: 1332, val loss: nan, val acuracy: 0.10400000214576721
step: 1333, train loss: nan, train acuracy: 0.0625
step: 1333, val loss: nan, val acuracy: 0.10400000214576721
step: 1334, train loss: nan, train acuracy: 0.125
step: 1334, val loss: nan, val acuracy: 0.10400000214576721
step: 1335, train loss: nan, train acuracy: 0.1875
step: 1335, val loss: nan, val acuracy: 0.10400000214576721
step: 1336, train loss: nan, train acuracy: 0.078125
step: 1336, val loss: nan, val acuracy: 0.10400000214576721
step: 1337, train loss: nan, train acuracy: 0.125
step: 1337, val loss: nan, val acuracy: 0.10400000214576721
step: 1338, train loss: nan, train acuracy: 0.125
step: 1338, val loss: nan, val acuracy: 0.10400000214576721
step: 1339, train loss: nan, train acuracy: 0.09375
step: 1339, val loss: nan, val acuracy: 0.10400000214576721
step: 1340, train loss: nan, train acuracy: 0.109375
step: 1340, val loss: nan, val acuracy: 0.10400000214576721
step: 1341, train loss: nan, train acuracy: 0.046875
step: 1341, val loss: nan, val acuracy: 0.10400000214576721
step: 1342, train loss: nan, train acuracy: 0.078125
step: 1342, val loss: nan, val acuracy: 0.10400000214576721
step: 1343, train loss: nan, train acuracy: 0.078125
step: 1343, val loss: nan, val acuracy: 0.10400000214576721
step: 1344, train loss: nan, train acuracy: 0.078125
step: 1344, val loss: nan, val acuracy: 0.10400000214576721
step: 1345, train loss: nan, train acuracy: 0.0625
step: 1345, val loss: nan, val acuracy: 0.10400000214576721
step: 1346, train loss: nan, train acuracy: 0.078125
step: 1346, val loss: nan, val acuracy: 0.10400000214576721
step: 1347, train loss: nan, train acuracy: 0.046875
step: 1347, val loss: nan, val acuracy: 0.10400000214576721
step: 1348, train loss: nan, train acuracy: 0.125
step: 1348, val loss: nan, val acuracy: 0.10400000214576721
step: 1349, train loss: nan, train acuracy: 0.203125
step: 1349, val loss: nan, val acuracy: 0.10400000214576721
step: 1350, train loss: nan, train acuracy: 0.1875
step: 1350, val loss: nan, val acuracy: 0.10400000214576721
step: 1351, train loss: nan, train acuracy: 0.109375
step: 1351, val loss: nan, val acuracy: 0.10400000214576721
step: 1352, train loss: nan, train acuracy: 0.125
step: 1352, val loss: nan, val acuracy: 0.10400000214576721
step: 1353, train loss: nan, train acuracy: 0.046875
step: 1353, val loss: nan, val acuracy: 0.10400000214576721
step: 1354, train loss: nan, train acuracy: 0.109375
step: 1354, val loss: nan, val acuracy: 0.10400000214576721
step: 1355, train loss: nan, train acuracy: 0.109375
step: 1355, val loss: nan, val acuracy: 0.10400000214576721
step: 1356, train loss: nan, train acuracy: 0.140625
step: 1356, val loss: nan, val acuracy: 0.10400000214576721
step: 1357, train loss: nan, train acuracy: 0.09375
step: 1357, val loss: nan, val acuracy: 0.10400000214576721
step: 1358, train loss: nan, train acuracy: 0.15625
step: 1358, val loss: nan, val acuracy: 0.10400000214576721
step: 1359, train loss: nan, train acuracy: 0.0625
step: 1359, val loss: nan, val acuracy: 0.10400000214576721
step: 1360, train loss: nan, train acuracy: 0.09375
step: 1360, val loss: nan, val acuracy: 0.10400000214576721
step: 1361, train loss: nan, train acuracy: 0.09375
step: 1361, val loss: nan, val acuracy: 0.10400000214576721
step: 1362, train loss: nan, train acuracy: 0.03125
step: 1362, val loss: nan, val acuracy: 0.10400000214576721
step: 1363, train loss: nan, train acuracy: 0.09375
step: 1363, val loss: nan, val acuracy: 0.10400000214576721
step: 1364, train loss: nan, train acuracy: 0.046875
step: 1364, val loss: nan, val acuracy: 0.10400000214576721
step: 1365, train loss: nan, train acuracy: 0.15625
step: 1365, val loss: nan, val acuracy: 0.10400000214576721
step: 1366, train loss: nan, train acuracy: 0.09375
step: 1366, val loss: nan, val acuracy: 0.10400000214576721
step: 1367, train loss: nan, train acuracy: 0.125
step: 1367, val loss: nan, val acuracy: 0.10400000214576721
step: 1368, train loss: nan, train acuracy: 0.03125
step: 1368, val loss: nan, val acuracy: 0.10400000214576721
step: 1369, train loss: nan, train acuracy: 0.125
step: 1369, val loss: nan, val acuracy: 0.10400000214576721
step: 1370, train loss: nan, train acuracy: 0.15625
step: 1370, val loss: nan, val acuracy: 0.10400000214576721
step: 1371, train loss: nan, train acuracy: 0.125
step: 1371, val loss: nan, val acuracy: 0.10400000214576721
step: 1372, train loss: nan, train acuracy: 0.078125
step: 1372, val loss: nan, val acuracy: 0.10400000214576721
step: 1373, train loss: nan, train acuracy: 0.078125
step: 1373, val loss: nan, val acuracy: 0.10400000214576721
step: 1374, train loss: nan, train acuracy: 0.109375
step: 1374, val loss: nan, val acuracy: 0.10400000214576721
step: 1375, train loss: nan, train acuracy: 0.09375
step: 1375, val loss: nan, val acuracy: 0.10400000214576721
step: 1376, train loss: nan, train acuracy: 0.046875
step: 1376, val loss: nan, val acuracy: 0.10400000214576721
step: 1377, train loss: nan, train acuracy: 0.09375
step: 1377, val loss: nan, val acuracy: 0.10400000214576721
step: 1378, train loss: nan, train acuracy: 0.046875
step: 1378, val loss: nan, val acuracy: 0.10400000214576721
step: 1379, train loss: nan, train acuracy: 0.125
step: 1379, val loss: nan, val acuracy: 0.10400000214576721
step: 1380, train loss: nan, train acuracy: 0.078125
step: 1380, val loss: nan, val acuracy: 0.10400000214576721
step: 1381, train loss: nan, train acuracy: 0.0625
step: 1381, val loss: nan, val acuracy: 0.10400000214576721
step: 1382, train loss: nan, train acuracy: 0.140625
step: 1382, val loss: nan, val acuracy: 0.10400000214576721
step: 1383, train loss: nan, train acuracy: 0.15625
step: 1383, val loss: nan, val acuracy: 0.10400000214576721
step: 1384, train loss: nan, train acuracy: 0.140625
step: 1384, val loss: nan, val acuracy: 0.10400000214576721
step: 1385, train loss: nan, train acuracy: 0.109375
step: 1385, val loss: nan, val acuracy: 0.10400000214576721
step: 1386, train loss: nan, train acuracy: 0.046875
step: 1386, val loss: nan, val acuracy: 0.10400000214576721
step: 1387, train loss: nan, train acuracy: 0.140625
step: 1387, val loss: nan, val acuracy: 0.10400000214576721
step: 1388, train loss: nan, train acuracy: 0.140625
step: 1388, val loss: nan, val acuracy: 0.10400000214576721
step: 1389, train loss: nan, train acuracy: 0.0625
step: 1389, val loss: nan, val acuracy: 0.10400000214576721
step: 1390, train loss: nan, train acuracy: 0.0625
step: 1390, val loss: nan, val acuracy: 0.10400000214576721
step: 1391, train loss: nan, train acuracy: 0.078125
step: 1391, val loss: nan, val acuracy: 0.10400000214576721
step: 1392, train loss: nan, train acuracy: 0.0625
step: 1392, val loss: nan, val acuracy: 0.10400000214576721
step: 1393, train loss: nan, train acuracy: 0.109375
step: 1393, val loss: nan, val acuracy: 0.10400000214576721
step: 1394, train loss: nan, train acuracy: 0.09375
step: 1394, val loss: nan, val acuracy: 0.10400000214576721
step: 1395, train loss: nan, train acuracy: 0.109375
step: 1395, val loss: nan, val acuracy: 0.10400000214576721
step: 1396, train loss: nan, train acuracy: 0.125
step: 1396, val loss: nan, val acuracy: 0.10400000214576721
step: 1397, train loss: nan, train acuracy: 0.046875
step: 1397, val loss: nan, val acuracy: 0.10400000214576721
step: 1398, train loss: nan, train acuracy: 0.171875
step: 1398, val loss: nan, val acuracy: 0.10400000214576721
step: 1399, train loss: nan, train acuracy: 0.03125
step: 1399, val loss: nan, val acuracy: 0.10400000214576721
step: 1400, train loss: nan, train acuracy: 0.09375
step: 1400, val loss: nan, val acuracy: 0.10400000214576721
step: 1401, train loss: nan, train acuracy: 0.140625
step: 1401, val loss: nan, val acuracy: 0.10400000214576721
step: 1402, train loss: nan, train acuracy: 0.171875
step: 1402, val loss: nan, val acuracy: 0.10400000214576721
step: 1403, train loss: nan, train acuracy: 0.078125
step: 1403, val loss: nan, val acuracy: 0.10400000214576721
step: 1404, train loss: nan, train acuracy: 0.109375
step: 1404, val loss: nan, val acuracy: 0.10400000214576721
step: 1405, train loss: nan, train acuracy: 0.046875
step: 1405, val loss: nan, val acuracy: 0.10400000214576721
step: 1406, train loss: nan, train acuracy: 0.0625
step: 1406, val loss: nan, val acuracy: 0.10400000214576721
step: 1407, train loss: nan, train acuracy: 0.046875
step: 1407, val loss: nan, val acuracy: 0.10400000214576721
step: 1408, train loss: nan, train acuracy: 0.09375
step: 1408, val loss: nan, val acuracy: 0.10400000214576721
step: 1409, train loss: nan, train acuracy: 0.09375
step: 1409, val loss: nan, val acuracy: 0.10400000214576721
step: 1410, train loss: nan, train acuracy: 0.09375
step: 1410, val loss: nan, val acuracy: 0.10400000214576721
step: 1411, train loss: nan, train acuracy: 0.046875
step: 1411, val loss: nan, val acuracy: 0.10400000214576721
step: 1412, train loss: nan, train acuracy: 0.125
step: 1412, val loss: nan, val acuracy: 0.10400000214576721
step: 1413, train loss: nan, train acuracy: 0.125
step: 1413, val loss: nan, val acuracy: 0.10400000214576721
step: 1414, train loss: nan, train acuracy: 0.109375
step: 1414, val loss: nan, val acuracy: 0.10400000214576721
step: 1415, train loss: nan, train acuracy: 0.046875
step: 1415, val loss: nan, val acuracy: 0.10400000214576721
step: 1416, train loss: nan, train acuracy: 0.078125
step: 1416, val loss: nan, val acuracy: 0.10400000214576721
step: 1417, train loss: nan, train acuracy: 0.109375
step: 1417, val loss: nan, val acuracy: 0.10400000214576721
step: 1418, train loss: nan, train acuracy: 0.125
step: 1418, val loss: nan, val acuracy: 0.10400000214576721
step: 1419, train loss: nan, train acuracy: 0.125
step: 1419, val loss: nan, val acuracy: 0.10400000214576721
step: 1420, train loss: nan, train acuracy: 0.0625
step: 1420, val loss: nan, val acuracy: 0.10400000214576721
step: 1421, train loss: nan, train acuracy: 0.140625
step: 1421, val loss: nan, val acuracy: 0.10400000214576721
step: 1422, train loss: nan, train acuracy: 0.078125
step: 1422, val loss: nan, val acuracy: 0.10400000214576721
step: 1423, train loss: nan, train acuracy: 0.015625
step: 1423, val loss: nan, val acuracy: 0.10400000214576721
step: 1424, train loss: nan, train acuracy: 0.046875
step: 1424, val loss: nan, val acuracy: 0.10400000214576721
step: 1425, train loss: nan, train acuracy: 0.109375
step: 1425, val loss: nan, val acuracy: 0.10400000214576721
step: 1426, train loss: nan, train acuracy: 0.0625
step: 1426, val loss: nan, val acuracy: 0.10400000214576721
step: 1427, train loss: nan, train acuracy: 0.0625
step: 1427, val loss: nan, val acuracy: 0.10400000214576721
step: 1428, train loss: nan, train acuracy: 0.078125
step: 1428, val loss: nan, val acuracy: 0.10400000214576721
step: 1429, train loss: nan, train acuracy: 0.046875
step: 1429, val loss: nan, val acuracy: 0.10400000214576721
step: 1430, train loss: nan, train acuracy: 0.0625
step: 1430, val loss: nan, val acuracy: 0.10400000959634781
step: 1431, train loss: nan, train acuracy: 0.09375
step: 1431, val loss: nan, val acuracy: 0.10400000214576721
step: 1432, train loss: nan, train acuracy: 0.140625
step: 1432, val loss: nan, val acuracy: 0.10400000214576721
step: 1433, train loss: nan, train acuracy: 0.09375
step: 1433, val loss: nan, val acuracy: 0.10400000214576721
step: 1434, train loss: nan, train acuracy: 0.078125
step: 1434, val loss: nan, val acuracy: 0.10400000214576721
step: 1435, train loss: nan, train acuracy: 0.078125
step: 1435, val loss: nan, val acuracy: 0.10400000214576721
step: 1436, train loss: nan, train acuracy: 0.09375
step: 1436, val loss: nan, val acuracy: 0.10400000214576721
step: 1437, train loss: nan, train acuracy: 0.109375
step: 1437, val loss: nan, val acuracy: 0.10400000214576721
step: 1438, train loss: nan, train acuracy: 0.140625
step: 1438, val loss: nan, val acuracy: 0.10400000214576721
step: 1439, train loss: nan, train acuracy: 0.0625
step: 1439, val loss: nan, val acuracy: 0.10400000214576721
step: 1440, train loss: nan, train acuracy: 0.109375
step: 1440, val loss: nan, val acuracy: 0.10400000214576721
step: 1441, train loss: nan, train acuracy: 0.09375
step: 1441, val loss: nan, val acuracy: 0.10400000214576721
step: 1442, train loss: nan, train acuracy: 0.078125
step: 1442, val loss: nan, val acuracy: 0.10400000214576721
step: 1443, train loss: nan, train acuracy: 0.0625
step: 1443, val loss: nan, val acuracy: 0.10400000214576721
step: 1444, train loss: nan, train acuracy: 0.125
step: 1444, val loss: nan, val acuracy: 0.10400000214576721
step: 1445, train loss: nan, train acuracy: 0.140625
step: 1445, val loss: nan, val acuracy: 0.10400000214576721
step: 1446, train loss: nan, train acuracy: 0.0625
step: 1446, val loss: nan, val acuracy: 0.10400000214576721
step: 1447, train loss: nan, train acuracy: 0.078125
step: 1447, val loss: nan, val acuracy: 0.10400000214576721
step: 1448, train loss: nan, train acuracy: 0.109375
step: 1448, val loss: nan, val acuracy: 0.10400000214576721
step: 1449, train loss: nan, train acuracy: 0.140625
step: 1449, val loss: nan, val acuracy: 0.10400000214576721
step: 1450, train loss: nan, train acuracy: 0.125
step: 1450, val loss: nan, val acuracy: 0.10400000214576721
step: 1451, train loss: nan, train acuracy: 0.109375
step: 1451, val loss: nan, val acuracy: 0.10400000214576721
step: 1452, train loss: nan, train acuracy: 0.09375
step: 1452, val loss: nan, val acuracy: 0.10400000214576721
step: 1453, train loss: nan, train acuracy: 0.03125
step: 1453, val loss: nan, val acuracy: 0.10400000214576721
step: 1454, train loss: nan, train acuracy: 0.0625
step: 1454, val loss: nan, val acuracy: 0.10400000214576721
step: 1455, train loss: nan, train acuracy: 0.125
step: 1455, val loss: nan, val acuracy: 0.10400000214576721
step: 1456, train loss: nan, train acuracy: 0.109375
step: 1456, val loss: nan, val acuracy: 0.10400000214576721
step: 1457, train loss: nan, train acuracy: 0.203125
step: 1457, val loss: nan, val acuracy: 0.10400000214576721
step: 1458, train loss: nan, train acuracy: 0.125
step: 1458, val loss: nan, val acuracy: 0.10400000214576721
step: 1459, train loss: nan, train acuracy: 0.078125
step: 1459, val loss: nan, val acuracy: 0.10400000214576721
step: 1460, train loss: nan, train acuracy: 0.078125
step: 1460, val loss: nan, val acuracy: 0.10400000214576721
step: 1461, train loss: nan, train acuracy: 0.109375
step: 1461, val loss: nan, val acuracy: 0.10400000214576721
step: 1462, train loss: nan, train acuracy: 0.125
step: 1462, val loss: nan, val acuracy: 0.10400000214576721
step: 1463, train loss: nan, train acuracy: 0.078125
step: 1463, val loss: nan, val acuracy: 0.10400000214576721
step: 1464, train loss: nan, train acuracy: 0.109375
step: 1464, val loss: nan, val acuracy: 0.10400000214576721
step: 1465, train loss: nan, train acuracy: 0.078125
step: 1465, val loss: nan, val acuracy: 0.10400000214576721
step: 1466, train loss: nan, train acuracy: 0.015625
step: 1466, val loss: nan, val acuracy: 0.10400000214576721
step: 1467, train loss: nan, train acuracy: 0.09375
step: 1467, val loss: nan, val acuracy: 0.10400000214576721
step: 1468, train loss: nan, train acuracy: 0.109375
step: 1468, val loss: nan, val acuracy: 0.10400000214576721
step: 1469, train loss: nan, train acuracy: 0.109375
step: 1469, val loss: nan, val acuracy: 0.10400000214576721
step: 1470, train loss: nan, train acuracy: 0.078125
step: 1470, val loss: nan, val acuracy: 0.10400000214576721
step: 1471, train loss: nan, train acuracy: 0.171875
step: 1471, val loss: nan, val acuracy: 0.10400000214576721
step: 1472, train loss: nan, train acuracy: 0.109375
step: 1472, val loss: nan, val acuracy: 0.10400000214576721
step: 1473, train loss: nan, train acuracy: 0.0625
step: 1473, val loss: nan, val acuracy: 0.10400000214576721
step: 1474, train loss: nan, train acuracy: 0.140625
step: 1474, val loss: nan, val acuracy: 0.10400000214576721
step: 1475, train loss: nan, train acuracy: 0.140625
step: 1475, val loss: nan, val acuracy: 0.10400000214576721
step: 1476, train loss: nan, train acuracy: 0.109375
step: 1476, val loss: nan, val acuracy: 0.10400000214576721
step: 1477, train loss: nan, train acuracy: 0.15625
step: 1477, val loss: nan, val acuracy: 0.10400000214576721
step: 1478, train loss: nan, train acuracy: 0.125
step: 1478, val loss: nan, val acuracy: 0.10400000214576721
step: 1479, train loss: nan, train acuracy: 0.125
step: 1479, val loss: nan, val acuracy: 0.10400000214576721
step: 1480, train loss: nan, train acuracy: 0.109375
step: 1480, val loss: nan, val acuracy: 0.10400000214576721
step: 1481, train loss: nan, train acuracy: 0.078125
step: 1481, val loss: nan, val acuracy: 0.10400000214576721
step: 1482, train loss: nan, train acuracy: 0.078125
step: 1482, val loss: nan, val acuracy: 0.10400000214576721
step: 1483, train loss: nan, train acuracy: 0.09375
step: 1483, val loss: nan, val acuracy: 0.10400000214576721
step: 1484, train loss: nan, train acuracy: 0.078125
step: 1484, val loss: nan, val acuracy: 0.10400000214576721
step: 1485, train loss: nan, train acuracy: 0.078125
step: 1485, val loss: nan, val acuracy: 0.10400000214576721
step: 1486, train loss: nan, train acuracy: 0.0625
step: 1486, val loss: nan, val acuracy: 0.10400000214576721
step: 1487, train loss: nan, train acuracy: 0.078125
step: 1487, val loss: nan, val acuracy: 0.10400000214576721
step: 1488, train loss: nan, train acuracy: 0.203125
step: 1488, val loss: nan, val acuracy: 0.10400000214576721
step: 1489, train loss: nan, train acuracy: 0.15625
step: 1489, val loss: nan, val acuracy: 0.10400000214576721
step: 1490, train loss: nan, train acuracy: 0.0625
step: 1490, val loss: nan, val acuracy: 0.10400000214576721
step: 1491, train loss: nan, train acuracy: 0.109375
step: 1491, val loss: nan, val acuracy: 0.10400000214576721
step: 1492, train loss: nan, train acuracy: 0.109375
step: 1492, val loss: nan, val acuracy: 0.10400000214576721
step: 1493, train loss: nan, train acuracy: 0.109375
step: 1493, val loss: nan, val acuracy: 0.10400000214576721
step: 1494, train loss: nan, train acuracy: 0.140625
step: 1494, val loss: nan, val acuracy: 0.10400000214576721
step: 1495, train loss: nan, train acuracy: 0.078125
step: 1495, val loss: nan, val acuracy: 0.10400000214576721
step: 1496, train loss: nan, train acuracy: 0.171875
step: 1496, val loss: nan, val acuracy: 0.10400000214576721
step: 1497, train loss: nan, train acuracy: 0.03125
step: 1497, val loss: nan, val acuracy: 0.10400000214576721
step: 1498, train loss: nan, train acuracy: 0.109375
step: 1498, val loss: nan, val acuracy: 0.10400000214576721
step: 1499, train loss: nan, train acuracy: 0.078125
step: 1499, val loss: nan, val acuracy: 0.10400000214576721
step: 1500, train loss: nan, train acuracy: 0.109375
step: 1500, val loss: nan, val acuracy: 0.10400000214576721
step: 1501, train loss: nan, train acuracy: 0.109375
step: 1501, val loss: nan, val acuracy: 0.10400000214576721
step: 1502, train loss: nan, train acuracy: 0.0625
step: 1502, val loss: nan, val acuracy: 0.10400000214576721
step: 1503, train loss: nan, train acuracy: 0.140625
step: 1503, val loss: nan, val acuracy: 0.10400000214576721
step: 1504, train loss: nan, train acuracy: 0.0625
step: 1504, val loss: nan, val acuracy: 0.10400000214576721
step: 1505, train loss: nan, train acuracy: 0.09375
step: 1505, val loss: nan, val acuracy: 0.10400000214576721
step: 1506, train loss: nan, train acuracy: 0.125
step: 1506, val loss: nan, val acuracy: 0.10400000214576721
step: 1507, train loss: nan, train acuracy: 0.09375
step: 1507, val loss: nan, val acuracy: 0.10400000214576721
step: 1508, train loss: nan, train acuracy: 0.125
step: 1508, val loss: nan, val acuracy: 0.10400000214576721
step: 1509, train loss: nan, train acuracy: 0.0625
step: 1509, val loss: nan, val acuracy: 0.10400000214576721
step: 1510, train loss: nan, train acuracy: 0.140625
step: 1510, val loss: nan, val acuracy: 0.10400000214576721
step: 1511, train loss: nan, train acuracy: 0.09375
step: 1511, val loss: nan, val acuracy: 0.10400000214576721
step: 1512, train loss: nan, train acuracy: 0.0625
step: 1512, val loss: nan, val acuracy: 0.10400000214576721
step: 1513, train loss: nan, train acuracy: 0.140625
step: 1513, val loss: nan, val acuracy: 0.10400000214576721
step: 1514, train loss: nan, train acuracy: 0.171875
step: 1514, val loss: nan, val acuracy: 0.10400000214576721
step: 1515, train loss: nan, train acuracy: 0.0625
step: 1515, val loss: nan, val acuracy: 0.10400000214576721
step: 1516, train loss: nan, train acuracy: 0.0625
step: 1516, val loss: nan, val acuracy: 0.10400000214576721
step: 1517, train loss: nan, train acuracy: 0.15625
step: 1517, val loss: nan, val acuracy: 0.10400000214576721
step: 1518, train loss: nan, train acuracy: 0.09375
step: 1518, val loss: nan, val acuracy: 0.10400000214576721
step: 1519, train loss: nan, train acuracy: 0.078125
step: 1519, val loss: nan, val acuracy: 0.10400000214576721
step: 1520, train loss: nan, train acuracy: 0.09375
step: 1520, val loss: nan, val acuracy: 0.10400000214576721
step: 1521, train loss: nan, train acuracy: 0.109375
step: 1521, val loss: nan, val acuracy: 0.10400000214576721
step: 1522, train loss: nan, train acuracy: 0.15625
step: 1522, val loss: nan, val acuracy: 0.10400000214576721
step: 1523, train loss: nan, train acuracy: 0.078125
step: 1523, val loss: nan, val acuracy: 0.10400000214576721
step: 1524, train loss: nan, train acuracy: 0.125
step: 1524, val loss: nan, val acuracy: 0.10400000214576721
step: 1525, train loss: nan, train acuracy: 0.109375
step: 1525, val loss: nan, val acuracy: 0.10400000214576721
step: 1526, train loss: nan, train acuracy: 0.03125
step: 1526, val loss: nan, val acuracy: 0.10400000214576721
step: 1527, train loss: nan, train acuracy: 0.046875
step: 1527, val loss: nan, val acuracy: 0.10400000214576721
step: 1528, train loss: nan, train acuracy: 0.046875
step: 1528, val loss: nan, val acuracy: 0.10400000214576721
step: 1529, train loss: nan, train acuracy: 0.09375
step: 1529, val loss: nan, val acuracy: 0.10400000214576721
step: 1530, train loss: nan, train acuracy: 0.046875
step: 1530, val loss: nan, val acuracy: 0.10400000214576721
step: 1531, train loss: nan, train acuracy: 0.140625
step: 1531, val loss: nan, val acuracy: 0.10400000214576721
step: 1532, train loss: nan, train acuracy: 0.078125
step: 1532, val loss: nan, val acuracy: 0.10400000214576721
step: 1533, train loss: nan, train acuracy: 0.15625
step: 1533, val loss: nan, val acuracy: 0.10400000214576721
step: 1534, train loss: nan, train acuracy: 0.03125
step: 1534, val loss: nan, val acuracy: 0.10400000214576721
step: 1535, train loss: nan, train acuracy: 0.09375
step: 1535, val loss: nan, val acuracy: 0.10400000214576721
step: 1536, train loss: nan, train acuracy: 0.078125
step: 1536, val loss: nan, val acuracy: 0.10400000214576721
step: 1537, train loss: nan, train acuracy: 0.125
step: 1537, val loss: nan, val acuracy: 0.10400000214576721
step: 1538, train loss: nan, train acuracy: 0.171875
step: 1538, val loss: nan, val acuracy: 0.10400000214576721
step: 1539, train loss: nan, train acuracy: 0.109375
step: 1539, val loss: nan, val acuracy: 0.10400000214576721
step: 1540, train loss: nan, train acuracy: 0.0625
step: 1540, val loss: nan, val acuracy: 0.10400000214576721
step: 1541, train loss: nan, train acuracy: 0.09375
step: 1541, val loss: nan, val acuracy: 0.10400000214576721
step: 1542, train loss: nan, train acuracy: 0.078125
step: 1542, val loss: nan, val acuracy: 0.10400000214576721
step: 1543, train loss: nan, train acuracy: 0.109375
step: 1543, val loss: nan, val acuracy: 0.10400000214576721
step: 1544, train loss: nan, train acuracy: 0.09375
step: 1544, val loss: nan, val acuracy: 0.10400000214576721
step: 1545, train loss: nan, train acuracy: 0.0625
step: 1545, val loss: nan, val acuracy: 0.10400000214576721
step: 1546, train loss: nan, train acuracy: 0.109375
step: 1546, val loss: nan, val acuracy: 0.10400000214576721
step: 1547, train loss: nan, train acuracy: 0.078125
step: 1547, val loss: nan, val acuracy: 0.10400000214576721
step: 1548, train loss: nan, train acuracy: 0.09375
step: 1548, val loss: nan, val acuracy: 0.10400000214576721
step: 1549, train loss: nan, train acuracy: 0.109375
step: 1549, val loss: nan, val acuracy: 0.10400000214576721
step: 1550, train loss: nan, train acuracy: 0.109375
step: 1550, val loss: nan, val acuracy: 0.10400000214576721
step: 1551, train loss: nan, train acuracy: 0.125
step: 1551, val loss: nan, val acuracy: 0.10400000214576721
step: 1552, train loss: nan, train acuracy: 0.078125
step: 1552, val loss: nan, val acuracy: 0.10400000214576721
step: 1553, train loss: nan, train acuracy: 0.109375
step: 1553, val loss: nan, val acuracy: 0.10400000214576721
step: 1554, train loss: nan, train acuracy: 0.09375
step: 1554, val loss: nan, val acuracy: 0.10400000214576721
step: 1555, train loss: nan, train acuracy: 0.15625
step: 1555, val loss: nan, val acuracy: 0.10400000214576721
step: 1556, train loss: nan, train acuracy: 0.109375
step: 1556, val loss: nan, val acuracy: 0.10400000214576721
step: 1557, train loss: nan, train acuracy: 0.09375
step: 1557, val loss: nan, val acuracy: 0.10400000214576721
step: 1558, train loss: nan, train acuracy: 0.0625
step: 1558, val loss: nan, val acuracy: 0.10400000214576721
step: 1559, train loss: nan, train acuracy: 0.09375
step: 1559, val loss: nan, val acuracy: 0.10400000214576721
step: 1560, train loss: nan, train acuracy: 0.109375
step: 1560, val loss: nan, val acuracy: 0.10400000214576721
step: 1561, train loss: nan, train acuracy: 0.09375
step: 1561, val loss: nan, val acuracy: 0.10400000214576721
step: 1562, train loss: nan, train acuracy: 0.078125
step: 1562, val loss: nan, val acuracy: 0.10400000214576721
step: 1563, train loss: nan, train acuracy: 0.078125
step: 1563, val loss: nan, val acuracy: 0.10400000214576721
step: 1564, train loss: nan, train acuracy: 0.0625
step: 1564, val loss: nan, val acuracy: 0.10400000214576721
step: 1565, train loss: nan, train acuracy: 0.0625
step: 1565, val loss: nan, val acuracy: 0.10400000214576721
step: 1566, train loss: nan, train acuracy: 0.125
step: 1566, val loss: nan, val acuracy: 0.10400000214576721
step: 1567, train loss: nan, train acuracy: 0.0625
step: 1567, val loss: nan, val acuracy: 0.10400000214576721
step: 1568, train loss: nan, train acuracy: 0.109375
step: 1568, val loss: nan, val acuracy: 0.10400000214576721
step: 1569, train loss: nan, train acuracy: 0.078125
step: 1569, val loss: nan, val acuracy: 0.10400000214576721
step: 1570, train loss: nan, train acuracy: 0.125
step: 1570, val loss: nan, val acuracy: 0.10400000214576721
step: 1571, train loss: nan, train acuracy: 0.0625
step: 1571, val loss: nan, val acuracy: 0.10400000214576721
step: 1572, train loss: nan, train acuracy: 0.09375
step: 1572, val loss: nan, val acuracy: 0.10400000214576721
step: 1573, train loss: nan, train acuracy: 0.125
step: 1573, val loss: nan, val acuracy: 0.10400000214576721
step: 1574, train loss: nan, train acuracy: 0.125
step: 1574, val loss: nan, val acuracy: 0.10400000214576721
step: 1575, train loss: nan, train acuracy: 0.046875
step: 1575, val loss: nan, val acuracy: 0.10400000214576721
step: 1576, train loss: nan, train acuracy: 0.125
step: 1576, val loss: nan, val acuracy: 0.10400000214576721
step: 1577, train loss: nan, train acuracy: 0.109375
step: 1577, val loss: nan, val acuracy: 0.10400000214576721
step: 1578, train loss: nan, train acuracy: 0.140625
step: 1578, val loss: nan, val acuracy: 0.10400000214576721
step: 1579, train loss: nan, train acuracy: 0.125
step: 1579, val loss: nan, val acuracy: 0.10400000214576721
step: 1580, train loss: nan, train acuracy: 0.03125
step: 1580, val loss: nan, val acuracy: 0.10400000214576721
step: 1581, train loss: nan, train acuracy: 0.109375
step: 1581, val loss: nan, val acuracy: 0.10400000214576721
step: 1582, train loss: nan, train acuracy: 0.109375
step: 1582, val loss: nan, val acuracy: 0.10400000214576721
step: 1583, train loss: nan, train acuracy: 0.140625
step: 1583, val loss: nan, val acuracy: 0.10400000214576721
step: 1584, train loss: nan, train acuracy: 0.03125
step: 1584, val loss: nan, val acuracy: 0.10400000214576721
step: 1585, train loss: nan, train acuracy: 0.109375
step: 1585, val loss: nan, val acuracy: 0.10400000214576721
step: 1586, train loss: nan, train acuracy: 0.109375
step: 1586, val loss: nan, val acuracy: 0.10400000214576721
step: 1587, train loss: nan, train acuracy: 0.078125
step: 1587, val loss: nan, val acuracy: 0.10400000214576721
step: 1588, train loss: nan, train acuracy: 0.09375
step: 1588, val loss: nan, val acuracy: 0.10400000214576721
step: 1589, train loss: nan, train acuracy: 0.046875
step: 1589, val loss: nan, val acuracy: 0.10400000214576721
step: 1590, train loss: nan, train acuracy: 0.078125
step: 1590, val loss: nan, val acuracy: 0.10400000214576721
step: 1591, train loss: nan, train acuracy: 0.140625
step: 1591, val loss: nan, val acuracy: 0.10400000214576721
step: 1592, train loss: nan, train acuracy: 0.0625
step: 1592, val loss: nan, val acuracy: 0.10400000214576721
step: 1593, train loss: nan, train acuracy: 0.0625
step: 1593, val loss: nan, val acuracy: 0.10400000214576721
step: 1594, train loss: nan, train acuracy: 0.078125
step: 1594, val loss: nan, val acuracy: 0.10400000214576721
step: 1595, train loss: nan, train acuracy: 0.078125
step: 1595, val loss: nan, val acuracy: 0.10400000214576721
step: 1596, train loss: nan, train acuracy: 0.171875
step: 1596, val loss: nan, val acuracy: 0.10400000214576721
step: 1597, train loss: nan, train acuracy: 0.109375
step: 1597, val loss: nan, val acuracy: 0.10400000214576721
step: 1598, train loss: nan, train acuracy: 0.09375
step: 1598, val loss: nan, val acuracy: 0.10400000214576721
step: 1599, train loss: nan, train acuracy: 0.078125
step: 1599, val loss: nan, val acuracy: 0.10400000214576721
step: 1600, train loss: nan, train acuracy: 0.078125
step: 1600, val loss: nan, val acuracy: 0.10400000214576721
step: 1601, train loss: nan, train acuracy: 0.140625
step: 1601, val loss: nan, val acuracy: 0.10400000214576721
step: 1602, train loss: nan, train acuracy: 0.125
step: 1602, val loss: nan, val acuracy: 0.10400000214576721
step: 1603, train loss: nan, train acuracy: 0.078125
step: 1603, val loss: nan, val acuracy: 0.10400000214576721
step: 1604, train loss: nan, train acuracy: 0.109375
step: 1604, val loss: nan, val acuracy: 0.10400000214576721
step: 1605, train loss: nan, train acuracy: 0.078125
step: 1605, val loss: nan, val acuracy: 0.10400000214576721
step: 1606, train loss: nan, train acuracy: 0.140625
step: 1606, val loss: nan, val acuracy: 0.10400000214576721
step: 1607, train loss: nan, train acuracy: 0.03125
step: 1607, val loss: nan, val acuracy: 0.10400000214576721
step: 1608, train loss: nan, train acuracy: 0.125
step: 1608, val loss: nan, val acuracy: 0.10400000214576721
step: 1609, train loss: nan, train acuracy: 0.078125
step: 1609, val loss: nan, val acuracy: 0.10400000214576721
step: 1610, train loss: nan, train acuracy: 0.125
step: 1610, val loss: nan, val acuracy: 0.10400000214576721
step: 1611, train loss: nan, train acuracy: 0.125
step: 1611, val loss: nan, val acuracy: 0.10400000214576721
step: 1612, train loss: nan, train acuracy: 0.125
step: 1612, val loss: nan, val acuracy: 0.10400000214576721
step: 1613, train loss: nan, train acuracy: 0.046875
step: 1613, val loss: nan, val acuracy: 0.10400000214576721
step: 1614, train loss: nan, train acuracy: 0.140625
step: 1614, val loss: nan, val acuracy: 0.10400000214576721
step: 1615, train loss: nan, train acuracy: 0.109375
step: 1615, val loss: nan, val acuracy: 0.10400000214576721
step: 1616, train loss: nan, train acuracy: 0.0625
step: 1616, val loss: nan, val acuracy: 0.10400000214576721
step: 1617, train loss: nan, train acuracy: 0.171875
step: 1617, val loss: nan, val acuracy: 0.10400000959634781
step: 1618, train loss: nan, train acuracy: 0.109375
step: 1618, val loss: nan, val acuracy: 0.10400000214576721
step: 1619, train loss: nan, train acuracy: 0.109375
step: 1619, val loss: nan, val acuracy: 0.10400000214576721
step: 1620, train loss: nan, train acuracy: 0.0625
step: 1620, val loss: nan, val acuracy: 0.10400000214576721
step: 1621, train loss: nan, train acuracy: 0.0625
step: 1621, val loss: nan, val acuracy: 0.10400000214576721
step: 1622, train loss: nan, train acuracy: 0.09375
step: 1622, val loss: nan, val acuracy: 0.10400000214576721
step: 1623, train loss: nan, train acuracy: 0.125
step: 1623, val loss: nan, val acuracy: 0.10400000214576721
step: 1624, train loss: nan, train acuracy: 0.09375
step: 1624, val loss: nan, val acuracy: 0.10400000214576721
step: 1625, train loss: nan, train acuracy: 0.078125
step: 1625, val loss: nan, val acuracy: 0.10400000214576721
step: 1626, train loss: nan, train acuracy: 0.078125
step: 1626, val loss: nan, val acuracy: 0.10400000214576721
step: 1627, train loss: nan, train acuracy: 0.171875
step: 1627, val loss: nan, val acuracy: 0.10400000214576721
step: 1628, train loss: nan, train acuracy: 0.125
step: 1628, val loss: nan, val acuracy: 0.10400000214576721
step: 1629, train loss: nan, train acuracy: 0.09375
step: 1629, val loss: nan, val acuracy: 0.10400000214576721
step: 1630, train loss: nan, train acuracy: 0.109375
step: 1630, val loss: nan, val acuracy: 0.10400000214576721
step: 1631, train loss: nan, train acuracy: 0.125
step: 1631, val loss: nan, val acuracy: 0.10400000214576721
step: 1632, train loss: nan, train acuracy: 0.125
step: 1632, val loss: nan, val acuracy: 0.10400000214576721
step: 1633, train loss: nan, train acuracy: 0.09375
step: 1633, val loss: nan, val acuracy: 0.10400000214576721
step: 1634, train loss: nan, train acuracy: 0.125
step: 1634, val loss: nan, val acuracy: 0.10400000214576721
step: 1635, train loss: nan, train acuracy: 0.109375
step: 1635, val loss: nan, val acuracy: 0.10400000214576721
step: 1636, train loss: nan, train acuracy: 0.078125
step: 1636, val loss: nan, val acuracy: 0.10400000214576721
step: 1637, train loss: nan, train acuracy: 0.0625
step: 1637, val loss: nan, val acuracy: 0.10400000214576721
step: 1638, train loss: nan, train acuracy: 0.078125
step: 1638, val loss: nan, val acuracy: 0.10400000214576721
step: 1639, train loss: nan, train acuracy: 0.0625
step: 1639, val loss: nan, val acuracy: 0.10400000214576721
step: 1640, train loss: nan, train acuracy: 0.140625
step: 1640, val loss: nan, val acuracy: 0.10400000214576721
step: 1641, train loss: nan, train acuracy: 0.125
step: 1641, val loss: nan, val acuracy: 0.10400000214576721
step: 1642, train loss: nan, train acuracy: 0.109375
step: 1642, val loss: nan, val acuracy: 0.10400000214576721
step: 1643, train loss: nan, train acuracy: 0.0625
step: 1643, val loss: nan, val acuracy: 0.10400000214576721
step: 1644, train loss: nan, train acuracy: 0.078125
step: 1644, val loss: nan, val acuracy: 0.10400000214576721
step: 1645, train loss: nan, train acuracy: 0.09375
step: 1645, val loss: nan, val acuracy: 0.10400000214576721
step: 1646, train loss: nan, train acuracy: 0.125
step: 1646, val loss: nan, val acuracy: 0.10400000214576721
step: 1647, train loss: nan, train acuracy: 0.140625
step: 1647, val loss: nan, val acuracy: 0.10400000214576721
step: 1648, train loss: nan, train acuracy: 0.078125
step: 1648, val loss: nan, val acuracy: 0.10400000214576721
step: 1649, train loss: nan, train acuracy: 0.125
step: 1649, val loss: nan, val acuracy: 0.10400000214576721
step: 1650, train loss: nan, train acuracy: 0.140625
step: 1650, val loss: nan, val acuracy: 0.10400000214576721
step: 1651, train loss: nan, train acuracy: 0.078125
step: 1651, val loss: nan, val acuracy: 0.10400000214576721
step: 1652, train loss: nan, train acuracy: 0.078125
step: 1652, val loss: nan, val acuracy: 0.10400000214576721
step: 1653, train loss: nan, train acuracy: 0.0625
step: 1653, val loss: nan, val acuracy: 0.10400000214576721
step: 1654, train loss: nan, train acuracy: 0.015625
step: 1654, val loss: nan, val acuracy: 0.10400000214576721
step: 1655, train loss: nan, train acuracy: 0.078125
step: 1655, val loss: nan, val acuracy: 0.10400000214576721
step: 1656, train loss: nan, train acuracy: 0.09375
step: 1656, val loss: nan, val acuracy: 0.10400000214576721
step: 1657, train loss: nan, train acuracy: 0.109375
step: 1657, val loss: nan, val acuracy: 0.10400000214576721
step: 1658, train loss: nan, train acuracy: 0.125
step: 1658, val loss: nan, val acuracy: 0.10400000214576721
step: 1659, train loss: nan, train acuracy: 0.21875
step: 1659, val loss: nan, val acuracy: 0.10400000214576721
step: 1660, train loss: nan, train acuracy: 0.046875
step: 1660, val loss: nan, val acuracy: 0.10400000214576721
step: 1661, train loss: nan, train acuracy: 0.0625
step: 1661, val loss: nan, val acuracy: 0.10400000214576721
step: 1662, train loss: nan, train acuracy: 0.109375
step: 1662, val loss: nan, val acuracy: 0.10400000214576721
step: 1663, train loss: nan, train acuracy: 0.109375
step: 1663, val loss: nan, val acuracy: 0.10400000214576721
step: 1664, train loss: nan, train acuracy: 0.125
step: 1664, val loss: nan, val acuracy: 0.10400000214576721
step: 1665, train loss: nan, train acuracy: 0.15625
step: 1665, val loss: nan, val acuracy: 0.10400000214576721
step: 1666, train loss: nan, train acuracy: 0.15625
step: 1666, val loss: nan, val acuracy: 0.10400000214576721
step: 1667, train loss: nan, train acuracy: 0.125
step: 1667, val loss: nan, val acuracy: 0.10400000214576721
step: 1668, train loss: nan, train acuracy: 0.234375
step: 1668, val loss: nan, val acuracy: 0.10400000214576721
step: 1669, train loss: nan, train acuracy: 0.046875
step: 1669, val loss: nan, val acuracy: 0.10400000214576721
step: 1670, train loss: nan, train acuracy: 0.109375
step: 1670, val loss: nan, val acuracy: 0.10400000214576721
step: 1671, train loss: nan, train acuracy: 0.078125
step: 1671, val loss: nan, val acuracy: 0.10400000214576721
step: 1672, train loss: nan, train acuracy: 0.078125
step: 1672, val loss: nan, val acuracy: 0.10400000214576721
step: 1673, train loss: nan, train acuracy: 0.1875
step: 1673, val loss: nan, val acuracy: 0.10400000214576721
step: 1674, train loss: nan, train acuracy: 0.078125
step: 1674, val loss: nan, val acuracy: 0.10400000214576721
step: 1675, train loss: nan, train acuracy: 0.15625
step: 1675, val loss: nan, val acuracy: 0.10400000214576721
step: 1676, train loss: nan, train acuracy: 0.125
step: 1676, val loss: nan, val acuracy: 0.10400000214576721
step: 1677, train loss: nan, train acuracy: 0.09375
step: 1677, val loss: nan, val acuracy: 0.10400000214576721
step: 1678, train loss: nan, train acuracy: 0.109375
step: 1678, val loss: nan, val acuracy: 0.10400000214576721
step: 1679, train loss: nan, train acuracy: 0.09375
step: 1679, val loss: nan, val acuracy: 0.10400000214576721
step: 1680, train loss: nan, train acuracy: 0.09375
step: 1680, val loss: nan, val acuracy: 0.10400000214576721
step: 1681, train loss: nan, train acuracy: 0.046875
step: 1681, val loss: nan, val acuracy: 0.10400000214576721
step: 1682, train loss: nan, train acuracy: 0.109375
step: 1682, val loss: nan, val acuracy: 0.10400000214576721
step: 1683, train loss: nan, train acuracy: 0.125
step: 1683, val loss: nan, val acuracy: 0.10400000214576721
step: 1684, train loss: nan, train acuracy: 0.078125
step: 1684, val loss: nan, val acuracy: 0.10400000214576721
step: 1685, train loss: nan, train acuracy: 0.0625
step: 1685, val loss: nan, val acuracy: 0.10400000214576721
step: 1686, train loss: nan, train acuracy: 0.109375
step: 1686, val loss: nan, val acuracy: 0.10400000214576721
step: 1687, train loss: nan, train acuracy: 0.15625
step: 1687, val loss: nan, val acuracy: 0.10400000214576721
step: 1688, train loss: nan, train acuracy: 0.09375
step: 1688, val loss: nan, val acuracy: 0.10400000214576721
step: 1689, train loss: nan, train acuracy: 0.0625
step: 1689, val loss: nan, val acuracy: 0.10400000214576721
step: 1690, train loss: nan, train acuracy: 0.140625
step: 1690, val loss: nan, val acuracy: 0.10400000214576721
step: 1691, train loss: nan, train acuracy: 0.109375
step: 1691, val loss: nan, val acuracy: 0.10400000214576721
step: 1692, train loss: nan, train acuracy: 0.125
step: 1692, val loss: nan, val acuracy: 0.10400000214576721
step: 1693, train loss: nan, train acuracy: 0.109375
step: 1693, val loss: nan, val acuracy: 0.10400000214576721
step: 1694, train loss: nan, train acuracy: 0.046875
step: 1694, val loss: nan, val acuracy: 0.10400000214576721
step: 1695, train loss: nan, train acuracy: 0.09375
step: 1695, val loss: nan, val acuracy: 0.10400000214576721
step: 1696, train loss: nan, train acuracy: 0.109375
step: 1696, val loss: nan, val acuracy: 0.10400000214576721
step: 1697, train loss: nan, train acuracy: 0.09375
step: 1697, val loss: nan, val acuracy: 0.10400000214576721
step: 1698, train loss: nan, train acuracy: 0.0625
step: 1698, val loss: nan, val acuracy: 0.10400000214576721
step: 1699, train loss: nan, train acuracy: 0.09375
step: 1699, val loss: nan, val acuracy: 0.10400000214576721
step: 1700, train loss: nan, train acuracy: 0.046875
step: 1700, val loss: nan, val acuracy: 0.10400000214576721
step: 1701, train loss: nan, train acuracy: 0.0625
step: 1701, val loss: nan, val acuracy: 0.10400000214576721
step: 1702, train loss: nan, train acuracy: 0.09375
step: 1702, val loss: nan, val acuracy: 0.10400000214576721
step: 1703, train loss: nan, train acuracy: 0.109375
step: 1703, val loss: nan, val acuracy: 0.10400000214576721
step: 1704, train loss: nan, train acuracy: 0.171875
step: 1704, val loss: nan, val acuracy: 0.10400000214576721
step: 1705, train loss: nan, train acuracy: 0.078125
step: 1705, val loss: nan, val acuracy: 0.10400000214576721
step: 1706, train loss: nan, train acuracy: 0.09375
step: 1706, val loss: nan, val acuracy: 0.10400000214576721
step: 1707, train loss: nan, train acuracy: 0.140625
step: 1707, val loss: nan, val acuracy: 0.10400000214576721
step: 1708, train loss: nan, train acuracy: 0.0625
step: 1708, val loss: nan, val acuracy: 0.10400000214576721
step: 1709, train loss: nan, train acuracy: 0.109375
step: 1709, val loss: nan, val acuracy: 0.10400000214576721
step: 1710, train loss: nan, train acuracy: 0.15625
step: 1710, val loss: nan, val acuracy: 0.10400000214576721
step: 1711, train loss: nan, train acuracy: 0.0625
step: 1711, val loss: nan, val acuracy: 0.10400000214576721
step: 1712, train loss: nan, train acuracy: 0.140625
step: 1712, val loss: nan, val acuracy: 0.10400000214576721
step: 1713, train loss: nan, train acuracy: 0.0625
step: 1713, val loss: nan, val acuracy: 0.10400000214576721
step: 1714, train loss: nan, train acuracy: 0.0625
step: 1714, val loss: nan, val acuracy: 0.10400000214576721
step: 1715, train loss: nan, train acuracy: 0.09375
step: 1715, val loss: nan, val acuracy: 0.10400000214576721
step: 1716, train loss: nan, train acuracy: 0.125
step: 1716, val loss: nan, val acuracy: 0.10400000214576721
step: 1717, train loss: nan, train acuracy: 0.078125
step: 1717, val loss: nan, val acuracy: 0.10400000214576721
step: 1718, train loss: nan, train acuracy: 0.09375
step: 1718, val loss: nan, val acuracy: 0.10400000214576721
step: 1719, train loss: nan, train acuracy: 0.09375
step: 1719, val loss: nan, val acuracy: 0.10400000214576721
step: 1720, train loss: nan, train acuracy: 0.09375
step: 1720, val loss: nan, val acuracy: 0.10400000214576721
step: 1721, train loss: nan, train acuracy: 0.0625
step: 1721, val loss: nan, val acuracy: 0.10400000214576721
step: 1722, train loss: nan, train acuracy: 0.109375
step: 1722, val loss: nan, val acuracy: 0.10400000214576721
step: 1723, train loss: nan, train acuracy: 0.046875
step: 1723, val loss: nan, val acuracy: 0.10400000214576721
step: 1724, train loss: nan, train acuracy: 0.078125
step: 1724, val loss: nan, val acuracy: 0.10400000214576721
step: 1725, train loss: nan, train acuracy: 0.0625
step: 1725, val loss: nan, val acuracy: 0.10400000214576721
step: 1726, train loss: nan, train acuracy: 0.09375
step: 1726, val loss: nan, val acuracy: 0.10400000214576721
step: 1727, train loss: nan, train acuracy: 0.0625
step: 1727, val loss: nan, val acuracy: 0.10400000214576721
step: 1728, train loss: nan, train acuracy: 0.078125
step: 1728, val loss: nan, val acuracy: 0.10400000214576721
step: 1729, train loss: nan, train acuracy: 0.0625
step: 1729, val loss: nan, val acuracy: 0.10400000214576721
step: 1730, train loss: nan, train acuracy: 0.0625
step: 1730, val loss: nan, val acuracy: 0.10400000214576721
step: 1731, train loss: nan, train acuracy: 0.140625
step: 1731, val loss: nan, val acuracy: 0.10400000214576721
step: 1732, train loss: nan, train acuracy: 0.109375
step: 1732, val loss: nan, val acuracy: 0.10400000214576721
step: 1733, train loss: nan, train acuracy: 0.09375
step: 1733, val loss: nan, val acuracy: 0.10400000214576721
step: 1734, train loss: nan, train acuracy: 0.0625
step: 1734, val loss: nan, val acuracy: 0.10400000214576721
step: 1735, train loss: nan, train acuracy: 0.109375
step: 1735, val loss: nan, val acuracy: 0.10400000214576721
step: 1736, train loss: nan, train acuracy: 0.078125
step: 1736, val loss: nan, val acuracy: 0.10400000214576721
step: 1737, train loss: nan, train acuracy: 0.09375
step: 1737, val loss: nan, val acuracy: 0.10400000214576721
step: 1738, train loss: nan, train acuracy: 0.078125
step: 1738, val loss: nan, val acuracy: 0.10400000214576721
step: 1739, train loss: nan, train acuracy: 0.109375
step: 1739, val loss: nan, val acuracy: 0.10400000214576721
step: 1740, train loss: nan, train acuracy: 0.078125
step: 1740, val loss: nan, val acuracy: 0.10400000214576721
step: 1741, train loss: nan, train acuracy: 0.09375
step: 1741, val loss: nan, val acuracy: 0.10400000214576721
step: 1742, train loss: nan, train acuracy: 0.125
step: 1742, val loss: nan, val acuracy: 0.10400000214576721
step: 1743, train loss: nan, train acuracy: 0.109375
step: 1743, val loss: nan, val acuracy: 0.10400000214576721
step: 1744, train loss: nan, train acuracy: 0.09375
step: 1744, val loss: nan, val acuracy: 0.10400000214576721
step: 1745, train loss: nan, train acuracy: 0.078125
step: 1745, val loss: nan, val acuracy: 0.10400000214576721
step: 1746, train loss: nan, train acuracy: 0.15625
step: 1746, val loss: nan, val acuracy: 0.10400000214576721
step: 1747, train loss: nan, train acuracy: 0.03125
step: 1747, val loss: nan, val acuracy: 0.10400000214576721
step: 1748, train loss: nan, train acuracy: 0.171875
step: 1748, val loss: nan, val acuracy: 0.10400000214576721
step: 1749, train loss: nan, train acuracy: 0.125
step: 1749, val loss: nan, val acuracy: 0.10400000214576721
step: 1750, train loss: nan, train acuracy: 0.15625
step: 1750, val loss: nan, val acuracy: 0.10400000214576721
step: 1751, train loss: nan, train acuracy: 0.078125
step: 1751, val loss: nan, val acuracy: 0.10400000214576721
step: 1752, train loss: nan, train acuracy: 0.109375
step: 1752, val loss: nan, val acuracy: 0.10400000959634781
step: 1753, train loss: nan, train acuracy: 0.078125
step: 1753, val loss: nan, val acuracy: 0.10400000214576721
step: 1754, train loss: nan, train acuracy: 0.0625
step: 1754, val loss: nan, val acuracy: 0.10400000214576721
step: 1755, train loss: nan, train acuracy: 0.09375
step: 1755, val loss: nan, val acuracy: 0.10400000214576721
step: 1756, train loss: nan, train acuracy: 0.046875
step: 1756, val loss: nan, val acuracy: 0.10400000214576721
step: 1757, train loss: nan, train acuracy: 0.125
step: 1757, val loss: nan, val acuracy: 0.10400000214576721
step: 1758, train loss: nan, train acuracy: 0.125
step: 1758, val loss: nan, val acuracy: 0.10400000214576721
step: 1759, train loss: nan, train acuracy: 0.109375
step: 1759, val loss: nan, val acuracy: 0.10400000214576721
step: 1760, train loss: nan, train acuracy: 0.109375
step: 1760, val loss: nan, val acuracy: 0.10400000214576721
step: 1761, train loss: nan, train acuracy: 0.03125
step: 1761, val loss: nan, val acuracy: 0.10400000214576721
step: 1762, train loss: nan, train acuracy: 0.109375
step: 1762, val loss: nan, val acuracy: 0.10400000214576721
step: 1763, train loss: nan, train acuracy: 0.1875
step: 1763, val loss: nan, val acuracy: 0.10400000214576721
step: 1764, train loss: nan, train acuracy: 0.09375
step: 1764, val loss: nan, val acuracy: 0.10400000214576721
step: 1765, train loss: nan, train acuracy: 0.109375
step: 1765, val loss: nan, val acuracy: 0.10400000214576721
step: 1766, train loss: nan, train acuracy: 0.109375
step: 1766, val loss: nan, val acuracy: 0.10400000214576721
step: 1767, train loss: nan, train acuracy: 0.09375
step: 1767, val loss: nan, val acuracy: 0.10400000214576721
step: 1768, train loss: nan, train acuracy: 0.109375
step: 1768, val loss: nan, val acuracy: 0.10400000214576721
step: 1769, train loss: nan, train acuracy: 0.03125
step: 1769, val loss: nan, val acuracy: 0.10400000214576721
step: 1770, train loss: nan, train acuracy: 0.078125
step: 1770, val loss: nan, val acuracy: 0.10400000214576721
step: 1771, train loss: nan, train acuracy: 0.125
step: 1771, val loss: nan, val acuracy: 0.10400000214576721
step: 1772, train loss: nan, train acuracy: 0.109375
step: 1772, val loss: nan, val acuracy: 0.10400000214576721
step: 1773, train loss: nan, train acuracy: 0.09375
step: 1773, val loss: nan, val acuracy: 0.10400000214576721
step: 1774, train loss: nan, train acuracy: 0.046875
step: 1774, val loss: nan, val acuracy: 0.10400000214576721
step: 1775, train loss: nan, train acuracy: 0.109375
step: 1775, val loss: nan, val acuracy: 0.10400000214576721
step: 1776, train loss: nan, train acuracy: 0.15625
step: 1776, val loss: nan, val acuracy: 0.10400000214576721
step: 1777, train loss: nan, train acuracy: 0.140625
step: 1777, val loss: nan, val acuracy: 0.10400000214576721
step: 1778, train loss: nan, train acuracy: 0.109375
step: 1778, val loss: nan, val acuracy: 0.10400000214576721
step: 1779, train loss: nan, train acuracy: 0.109375
step: 1779, val loss: nan, val acuracy: 0.10400000214576721
step: 1780, train loss: nan, train acuracy: 0.0625
step: 1780, val loss: nan, val acuracy: 0.10400000214576721
step: 1781, train loss: nan, train acuracy: 0.0625
step: 1781, val loss: nan, val acuracy: 0.10400000214576721
step: 1782, train loss: nan, train acuracy: 0.0625
step: 1782, val loss: nan, val acuracy: 0.10400000214576721
step: 1783, train loss: nan, train acuracy: 0.125
step: 1783, val loss: nan, val acuracy: 0.10400000214576721
step: 1784, train loss: nan, train acuracy: 0.078125
step: 1784, val loss: nan, val acuracy: 0.10400000214576721
step: 1785, train loss: nan, train acuracy: 0.125
step: 1785, val loss: nan, val acuracy: 0.10400000214576721
step: 1786, train loss: nan, train acuracy: 0.046875
step: 1786, val loss: nan, val acuracy: 0.10400000214576721
step: 1787, train loss: nan, train acuracy: 0.1875
step: 1787, val loss: nan, val acuracy: 0.10400000214576721
step: 1788, train loss: nan, train acuracy: 0.09375
step: 1788, val loss: nan, val acuracy: 0.10400000214576721
step: 1789, train loss: nan, train acuracy: 0.15625
step: 1789, val loss: nan, val acuracy: 0.10400000214576721
step: 1790, train loss: nan, train acuracy: 0.1875
step: 1790, val loss: nan, val acuracy: 0.10400000214576721
step: 1791, train loss: nan, train acuracy: 0.09375
step: 1791, val loss: nan, val acuracy: 0.10400000214576721
step: 1792, train loss: nan, train acuracy: 0.15625
step: 1792, val loss: nan, val acuracy: 0.10400000214576721
step: 1793, train loss: nan, train acuracy: 0.09375
step: 1793, val loss: nan, val acuracy: 0.10400000214576721
step: 1794, train loss: nan, train acuracy: 0.15625
step: 1794, val loss: nan, val acuracy: 0.10400000214576721
step: 1795, train loss: nan, train acuracy: 0.03125
step: 1795, val loss: nan, val acuracy: 0.10400000214576721
step: 1796, train loss: nan, train acuracy: 0.109375
step: 1796, val loss: nan, val acuracy: 0.10400000214576721
step: 1797, train loss: nan, train acuracy: 0.09375
step: 1797, val loss: nan, val acuracy: 0.10400000214576721
step: 1798, train loss: nan, train acuracy: 0.125
step: 1798, val loss: nan, val acuracy: 0.10400000214576721
step: 1799, train loss: nan, train acuracy: 0.140625
step: 1799, val loss: nan, val acuracy: 0.10400000214576721
step: 1800, train loss: nan, train acuracy: 0.09375
step: 1800, val loss: nan, val acuracy: 0.10400000214576721
step: 1801, train loss: nan, train acuracy: 0.109375
step: 1801, val loss: nan, val acuracy: 0.10400000214576721
step: 1802, train loss: nan, train acuracy: 0.0625
step: 1802, val loss: nan, val acuracy: 0.10400000214576721
step: 1803, train loss: nan, train acuracy: 0.109375
step: 1803, val loss: nan, val acuracy: 0.10400000214576721
step: 1804, train loss: nan, train acuracy: 0.109375
step: 1804, val loss: nan, val acuracy: 0.10400000214576721
step: 1805, train loss: nan, train acuracy: 0.0625
step: 1805, val loss: nan, val acuracy: 0.10400000214576721
step: 1806, train loss: nan, train acuracy: 0.078125
step: 1806, val loss: nan, val acuracy: 0.10400000214576721
step: 1807, train loss: nan, train acuracy: 0.0625
step: 1807, val loss: nan, val acuracy: 0.10400000214576721
step: 1808, train loss: nan, train acuracy: 0.0625
step: 1808, val loss: nan, val acuracy: 0.10400000214576721
step: 1809, train loss: nan, train acuracy: 0.1875
step: 1809, val loss: nan, val acuracy: 0.10400000214576721
step: 1810, train loss: nan, train acuracy: 0.078125
step: 1810, val loss: nan, val acuracy: 0.10400000214576721
step: 1811, train loss: nan, train acuracy: 0.046875
step: 1811, val loss: nan, val acuracy: 0.10400000214576721
step: 1812, train loss: nan, train acuracy: 0.125
step: 1812, val loss: nan, val acuracy: 0.10400000214576721
step: 1813, train loss: nan, train acuracy: 0.046875
step: 1813, val loss: nan, val acuracy: 0.10400000214576721
step: 1814, train loss: nan, train acuracy: 0.109375
step: 1814, val loss: nan, val acuracy: 0.10400000214576721
step: 1815, train loss: nan, train acuracy: 0.078125
step: 1815, val loss: nan, val acuracy: 0.10400000214576721
step: 1816, train loss: nan, train acuracy: 0.15625
step: 1816, val loss: nan, val acuracy: 0.10400000214576721
step: 1817, train loss: nan, train acuracy: 0.140625
step: 1817, val loss: nan, val acuracy: 0.10400000214576721
step: 1818, train loss: nan, train acuracy: 0.09375
step: 1818, val loss: nan, val acuracy: 0.10400000214576721
step: 1819, train loss: nan, train acuracy: 0.15625
step: 1819, val loss: nan, val acuracy: 0.10400000214576721
step: 1820, train loss: nan, train acuracy: 0.09375
step: 1820, val loss: nan, val acuracy: 0.10400000214576721
step: 1821, train loss: nan, train acuracy: 0.0625
step: 1821, val loss: nan, val acuracy: 0.10400000214576721
step: 1822, train loss: nan, train acuracy: 0.109375
step: 1822, val loss: nan, val acuracy: 0.10400000214576721
step: 1823, train loss: nan, train acuracy: 0.125
step: 1823, val loss: nan, val acuracy: 0.10400000214576721
step: 1824, train loss: nan, train acuracy: 0.078125
step: 1824, val loss: nan, val acuracy: 0.10400000214576721
step: 1825, train loss: nan, train acuracy: 0.09375
step: 1825, val loss: nan, val acuracy: 0.10400000214576721
step: 1826, train loss: nan, train acuracy: 0.046875
step: 1826, val loss: nan, val acuracy: 0.10400000214576721
step: 1827, train loss: nan, train acuracy: 0.140625
step: 1827, val loss: nan, val acuracy: 0.10400000214576721
step: 1828, train loss: nan, train acuracy: 0.140625
step: 1828, val loss: nan, val acuracy: 0.10400000214576721
step: 1829, train loss: nan, train acuracy: 0.015625
step: 1829, val loss: nan, val acuracy: 0.10400000214576721
step: 1830, train loss: nan, train acuracy: 0.09375
step: 1830, val loss: nan, val acuracy: 0.10400000214576721
step: 1831, train loss: nan, train acuracy: 0.0625
step: 1831, val loss: nan, val acuracy: 0.10400000214576721
step: 1832, train loss: nan, train acuracy: 0.078125
step: 1832, val loss: nan, val acuracy: 0.10400000214576721
step: 1833, train loss: nan, train acuracy: 0.03125
step: 1833, val loss: nan, val acuracy: 0.10400000214576721
step: 1834, train loss: nan, train acuracy: 0.0625
step: 1834, val loss: nan, val acuracy: 0.10400000214576721
step: 1835, train loss: nan, train acuracy: 0.046875
step: 1835, val loss: nan, val acuracy: 0.10400000214576721
step: 1836, train loss: nan, train acuracy: 0.140625
step: 1836, val loss: nan, val acuracy: 0.10400000214576721
step: 1837, train loss: nan, train acuracy: 0.09375
step: 1837, val loss: nan, val acuracy: 0.10400000214576721
step: 1838, train loss: nan, train acuracy: 0.09375
step: 1838, val loss: nan, val acuracy: 0.10400000214576721
step: 1839, train loss: nan, train acuracy: 0.1875
step: 1839, val loss: nan, val acuracy: 0.10400000214576721
step: 1840, train loss: nan, train acuracy: 0.140625
step: 1840, val loss: nan, val acuracy: 0.10400000214576721
step: 1841, train loss: nan, train acuracy: 0.109375
step: 1841, val loss: nan, val acuracy: 0.10400000214576721
step: 1842, train loss: nan, train acuracy: 0.078125
step: 1842, val loss: nan, val acuracy: 0.10400000214576721
step: 1843, train loss: nan, train acuracy: 0.09375
step: 1843, val loss: nan, val acuracy: 0.10400000214576721
step: 1844, train loss: nan, train acuracy: 0.109375
step: 1844, val loss: nan, val acuracy: 0.10400000214576721
step: 1845, train loss: nan, train acuracy: 0.09375
step: 1845, val loss: nan, val acuracy: 0.10400000214576721
step: 1846, train loss: nan, train acuracy: 0.125
step: 1846, val loss: nan, val acuracy: 0.10400000214576721
step: 1847, train loss: nan, train acuracy: 0.046875
step: 1847, val loss: nan, val acuracy: 0.10400000214576721
step: 1848, train loss: nan, train acuracy: 0.09375
step: 1848, val loss: nan, val acuracy: 0.10400000214576721
step: 1849, train loss: nan, train acuracy: 0.09375
step: 1849, val loss: nan, val acuracy: 0.10400000214576721
step: 1850, train loss: nan, train acuracy: 0.078125
step: 1850, val loss: nan, val acuracy: 0.10400000214576721
step: 1851, train loss: nan, train acuracy: 0.109375
step: 1851, val loss: nan, val acuracy: 0.10400000214576721
step: 1852, train loss: nan, train acuracy: 0.046875
step: 1852, val loss: nan, val acuracy: 0.10400000214576721
step: 1853, train loss: nan, train acuracy: 0.125
step: 1853, val loss: nan, val acuracy: 0.10400000214576721
step: 1854, train loss: nan, train acuracy: 0.078125
step: 1854, val loss: nan, val acuracy: 0.10400000214576721
step: 1855, train loss: nan, train acuracy: 0.046875
step: 1855, val loss: nan, val acuracy: 0.10400000214576721
step: 1856, train loss: nan, train acuracy: 0.046875
step: 1856, val loss: nan, val acuracy: 0.10400000214576721
step: 1857, train loss: nan, train acuracy: 0.171875
step: 1857, val loss: nan, val acuracy: 0.10400000214576721
step: 1858, train loss: nan, train acuracy: 0.09375
step: 1858, val loss: nan, val acuracy: 0.10400000214576721
step: 1859, train loss: nan, train acuracy: 0.078125
step: 1859, val loss: nan, val acuracy: 0.10400000214576721
step: 1860, train loss: nan, train acuracy: 0.0625
step: 1860, val loss: nan, val acuracy: 0.10400000214576721
step: 1861, train loss: nan, train acuracy: 0.09375
step: 1861, val loss: nan, val acuracy: 0.10400000214576721
step: 1862, train loss: nan, train acuracy: 0.0625
step: 1862, val loss: nan, val acuracy: 0.10400000214576721
step: 1863, train loss: nan, train acuracy: 0.09375
step: 1863, val loss: nan, val acuracy: 0.10400000214576721
step: 1864, train loss: nan, train acuracy: 0.140625
step: 1864, val loss: nan, val acuracy: 0.10400000214576721
step: 1865, train loss: nan, train acuracy: 0.109375
step: 1865, val loss: nan, val acuracy: 0.10400000214576721
step: 1866, train loss: nan, train acuracy: 0.0625
step: 1866, val loss: nan, val acuracy: 0.10400000214576721
step: 1867, train loss: nan, train acuracy: 0.09375
step: 1867, val loss: nan, val acuracy: 0.10400000214576721
step: 1868, train loss: nan, train acuracy: 0.046875
step: 1868, val loss: nan, val acuracy: 0.10400000214576721
step: 1869, train loss: nan, train acuracy: 0.078125
step: 1869, val loss: nan, val acuracy: 0.10400000214576721
step: 1870, train loss: nan, train acuracy: 0.0625
step: 1870, val loss: nan, val acuracy: 0.10400000214576721
step: 1871, train loss: nan, train acuracy: 0.09375
step: 1871, val loss: nan, val acuracy: 0.10400000214576721
step: 1872, train loss: nan, train acuracy: 0.078125
step: 1872, val loss: nan, val acuracy: 0.10400000214576721
step: 1873, train loss: nan, train acuracy: 0.109375
step: 1873, val loss: nan, val acuracy: 0.10400000214576721
step: 1874, train loss: nan, train acuracy: 0.0
step: 1874, val loss: nan, val acuracy: 0.10400000214576721
step: 1875, train loss: nan, train acuracy: 0.03125
step: 1875, val loss: nan, val acuracy: 0.10400000214576721
step: 1876, train loss: nan, train acuracy: 0.15625
step: 1876, val loss: nan, val acuracy: 0.10400000214576721
step: 1877, train loss: nan, train acuracy: 0.078125
step: 1877, val loss: nan, val acuracy: 0.10400000214576721
step: 1878, train loss: nan, train acuracy: 0.109375
step: 1878, val loss: nan, val acuracy: 0.10400000214576721
step: 1879, train loss: nan, train acuracy: 0.09375
step: 1879, val loss: nan, val acuracy: 0.10400000214576721
step: 1880, train loss: nan, train acuracy: 0.109375
step: 1880, val loss: nan, val acuracy: 0.10400000214576721
step: 1881, train loss: nan, train acuracy: 0.0625
step: 1881, val loss: nan, val acuracy: 0.10400000214576721
step: 1882, train loss: nan, train acuracy: 0.09375
step: 1882, val loss: nan, val acuracy: 0.10400000214576721
step: 1883, train loss: nan, train acuracy: 0.125
step: 1883, val loss: nan, val acuracy: 0.10400000214576721
step: 1884, train loss: nan, train acuracy: 0.203125
step: 1884, val loss: nan, val acuracy: 0.10400000214576721
step: 1885, train loss: nan, train acuracy: 0.125
step: 1885, val loss: nan, val acuracy: 0.10400000214576721
step: 1886, train loss: nan, train acuracy: 0.109375
step: 1886, val loss: nan, val acuracy: 0.10400000214576721
step: 1887, train loss: nan, train acuracy: 0.125
step: 1887, val loss: nan, val acuracy: 0.10400000214576721
step: 1888, train loss: nan, train acuracy: 0.0625
step: 1888, val loss: nan, val acuracy: 0.10400000214576721
step: 1889, train loss: nan, train acuracy: 0.046875
step: 1889, val loss: nan, val acuracy: 0.10400000214576721
step: 1890, train loss: nan, train acuracy: 0.03125
step: 1890, val loss: nan, val acuracy: 0.10400000214576721
step: 1891, train loss: nan, train acuracy: 0.078125
step: 1891, val loss: nan, val acuracy: 0.10400000214576721
step: 1892, train loss: nan, train acuracy: 0.03125
step: 1892, val loss: nan, val acuracy: 0.10400000214576721
step: 1893, train loss: nan, train acuracy: 0.078125
step: 1893, val loss: nan, val acuracy: 0.10400000214576721
step: 1894, train loss: nan, train acuracy: 0.078125
step: 1894, val loss: nan, val acuracy: 0.10400000214576721
step: 1895, train loss: nan, train acuracy: 0.140625
step: 1895, val loss: nan, val acuracy: 0.10400000214576721
step: 1896, train loss: nan, train acuracy: 0.09375
step: 1896, val loss: nan, val acuracy: 0.10400000214576721
step: 1897, train loss: nan, train acuracy: 0.078125
step: 1897, val loss: nan, val acuracy: 0.10400000214576721
step: 1898, train loss: nan, train acuracy: 0.078125
step: 1898, val loss: nan, val acuracy: 0.10400000214576721
step: 1899, train loss: nan, train acuracy: 0.171875
step: 1899, val loss: nan, val acuracy: 0.10400000214576721
step: 1900, train loss: nan, train acuracy: 0.078125
step: 1900, val loss: nan, val acuracy: 0.10400000214576721
step: 1901, train loss: nan, train acuracy: 0.15625
step: 1901, val loss: nan, val acuracy: 0.10400000214576721
step: 1902, train loss: nan, train acuracy: 0.140625
step: 1902, val loss: nan, val acuracy: 0.10400000214576721
step: 1903, train loss: nan, train acuracy: 0.03125
step: 1903, val loss: nan, val acuracy: 0.10400000214576721
step: 1904, train loss: nan, train acuracy: 0.15625
step: 1904, val loss: nan, val acuracy: 0.10400000214576721
step: 1905, train loss: nan, train acuracy: 0.09375
step: 1905, val loss: nan, val acuracy: 0.10400000214576721
step: 1906, train loss: nan, train acuracy: 0.09375
step: 1906, val loss: nan, val acuracy: 0.10400000214576721
step: 1907, train loss: nan, train acuracy: 0.0625
step: 1907, val loss: nan, val acuracy: 0.10400000214576721
step: 1908, train loss: nan, train acuracy: 0.078125
step: 1908, val loss: nan, val acuracy: 0.10400000214576721
step: 1909, train loss: nan, train acuracy: 0.046875
step: 1909, val loss: nan, val acuracy: 0.10400000214576721
step: 1910, train loss: nan, train acuracy: 0.109375
step: 1910, val loss: nan, val acuracy: 0.10400000214576721
step: 1911, train loss: nan, train acuracy: 0.125
step: 1911, val loss: nan, val acuracy: 0.10400000214576721
step: 1912, train loss: nan, train acuracy: 0.09375
step: 1912, val loss: nan, val acuracy: 0.10400000214576721
step: 1913, train loss: nan, train acuracy: 0.125
step: 1913, val loss: nan, val acuracy: 0.10400000214576721
step: 1914, train loss: nan, train acuracy: 0.046875
step: 1914, val loss: nan, val acuracy: 0.10400000214576721
step: 1915, train loss: nan, train acuracy: 0.125
step: 1915, val loss: nan, val acuracy: 0.10400000214576721
step: 1916, train loss: nan, train acuracy: 0.125
step: 1916, val loss: nan, val acuracy: 0.10400000214576721
step: 1917, train loss: nan, train acuracy: 0.078125
step: 1917, val loss: nan, val acuracy: 0.10400000214576721
step: 1918, train loss: nan, train acuracy: 0.078125
step: 1918, val loss: nan, val acuracy: 0.10400000214576721
step: 1919, train loss: nan, train acuracy: 0.171875
step: 1919, val loss: nan, val acuracy: 0.10400000214576721
step: 1920, train loss: nan, train acuracy: 0.09375
step: 1920, val loss: nan, val acuracy: 0.10400000214576721
step: 1921, train loss: nan, train acuracy: 0.0625
step: 1921, val loss: nan, val acuracy: 0.10400000214576721
step: 1922, train loss: nan, train acuracy: 0.09375
step: 1922, val loss: nan, val acuracy: 0.10400000214576721
step: 1923, train loss: nan, train acuracy: 0.109375
step: 1923, val loss: nan, val acuracy: 0.10400000214576721
step: 1924, train loss: nan, train acuracy: 0.203125
step: 1924, val loss: nan, val acuracy: 0.10400000214576721
step: 1925, train loss: nan, train acuracy: 0.09375
step: 1925, val loss: nan, val acuracy: 0.10400000214576721
step: 1926, train loss: nan, train acuracy: 0.078125
step: 1926, val loss: nan, val acuracy: 0.10400000214576721
step: 1927, train loss: nan, train acuracy: 0.109375
step: 1927, val loss: nan, val acuracy: 0.10400000214576721
step: 1928, train loss: nan, train acuracy: 0.09375
step: 1928, val loss: nan, val acuracy: 0.10400000214576721
step: 1929, train loss: nan, train acuracy: 0.078125
step: 1929, val loss: nan, val acuracy: 0.10400000214576721
step: 1930, train loss: nan, train acuracy: 0.203125
step: 1930, val loss: nan, val acuracy: 0.10400000214576721
step: 1931, train loss: nan, train acuracy: 0.046875
step: 1931, val loss: nan, val acuracy: 0.10400000214576721
step: 1932, train loss: nan, train acuracy: 0.046875
step: 1932, val loss: nan, val acuracy: 0.10400000214576721
step: 1933, train loss: nan, train acuracy: 0.109375
step: 1933, val loss: nan, val acuracy: 0.10400000214576721
step: 1934, train loss: nan, train acuracy: 0.078125
step: 1934, val loss: nan, val acuracy: 0.10400000214576721
step: 1935, train loss: nan, train acuracy: 0.09375
step: 1935, val loss: nan, val acuracy: 0.10400000214576721
step: 1936, train loss: nan, train acuracy: 0.109375
step: 1936, val loss: nan, val acuracy: 0.10400000214576721
step: 1937, train loss: nan, train acuracy: 0.015625
step: 1937, val loss: nan, val acuracy: 0.10400000214576721
step: 1938, train loss: nan, train acuracy: 0.125
step: 1938, val loss: nan, val acuracy: 0.10400000214576721
step: 1939, train loss: nan, train acuracy: 0.0625
step: 1939, val loss: nan, val acuracy: 0.10400000214576721
step: 1940, train loss: nan, train acuracy: 0.09375
step: 1940, val loss: nan, val acuracy: 0.10400000214576721
step: 1941, train loss: nan, train acuracy: 0.046875
step: 1941, val loss: nan, val acuracy: 0.10400000214576721
step: 1942, train loss: nan, train acuracy: 0.1875
step: 1942, val loss: nan, val acuracy: 0.10400000214576721
step: 1943, train loss: nan, train acuracy: 0.046875
step: 1943, val loss: nan, val acuracy: 0.10400000214576721
step: 1944, train loss: nan, train acuracy: 0.09375
step: 1944, val loss: nan, val acuracy: 0.10400000214576721
step: 1945, train loss: nan, train acuracy: 0.109375
step: 1945, val loss: nan, val acuracy: 0.10400000214576721
step: 1946, train loss: nan, train acuracy: 0.171875
step: 1946, val loss: nan, val acuracy: 0.10400000959634781
step: 1947, train loss: nan, train acuracy: 0.078125
step: 1947, val loss: nan, val acuracy: 0.10400000214576721
step: 1948, train loss: nan, train acuracy: 0.0625
step: 1948, val loss: nan, val acuracy: 0.10400000214576721
step: 1949, train loss: nan, train acuracy: 0.109375
step: 1949, val loss: nan, val acuracy: 0.10400000214576721
step: 1950, train loss: nan, train acuracy: 0.125
step: 1950, val loss: nan, val acuracy: 0.10400000214576721
step: 1951, train loss: nan, train acuracy: 0.109375
step: 1951, val loss: nan, val acuracy: 0.10400000214576721
step: 1952, train loss: nan, train acuracy: 0.09375
step: 1952, val loss: nan, val acuracy: 0.10400000214576721
step: 1953, train loss: nan, train acuracy: 0.078125
step: 1953, val loss: nan, val acuracy: 0.10400000214576721
step: 1954, train loss: nan, train acuracy: 0.109375
step: 1954, val loss: nan, val acuracy: 0.10400000214576721
step: 1955, train loss: nan, train acuracy: 0.078125
step: 1955, val loss: nan, val acuracy: 0.10400000214576721
step: 1956, train loss: nan, train acuracy: 0.078125
step: 1956, val loss: nan, val acuracy: 0.10400000214576721
step: 1957, train loss: nan, train acuracy: 0.125
step: 1957, val loss: nan, val acuracy: 0.10400000214576721
step: 1958, train loss: nan, train acuracy: 0.125
step: 1958, val loss: nan, val acuracy: 0.10400000214576721
step: 1959, train loss: nan, train acuracy: 0.125
step: 1959, val loss: nan, val acuracy: 0.10400000214576721
step: 1960, train loss: nan, train acuracy: 0.140625
step: 1960, val loss: nan, val acuracy: 0.10400000214576721
step: 1961, train loss: nan, train acuracy: 0.03125
step: 1961, val loss: nan, val acuracy: 0.10400000214576721
step: 1962, train loss: nan, train acuracy: 0.046875
step: 1962, val loss: nan, val acuracy: 0.10400000214576721
step: 1963, train loss: nan, train acuracy: 0.03125
step: 1963, val loss: nan, val acuracy: 0.10400000214576721
step: 1964, train loss: nan, train acuracy: 0.140625
step: 1964, val loss: nan, val acuracy: 0.10400000214576721
step: 1965, train loss: nan, train acuracy: 0.09375
step: 1965, val loss: nan, val acuracy: 0.10400000214576721
step: 1966, train loss: nan, train acuracy: 0.046875
step: 1966, val loss: nan, val acuracy: 0.10400000214576721
step: 1967, train loss: nan, train acuracy: 0.046875
step: 1967, val loss: nan, val acuracy: 0.10400000214576721
step: 1968, train loss: nan, train acuracy: 0.0625
step: 1968, val loss: nan, val acuracy: 0.10400000214576721
step: 1969, train loss: nan, train acuracy: 0.078125
step: 1969, val loss: nan, val acuracy: 0.10400000214576721
step: 1970, train loss: nan, train acuracy: 0.109375
step: 1970, val loss: nan, val acuracy: 0.10400000214576721
step: 1971, train loss: nan, train acuracy: 0.125
step: 1971, val loss: nan, val acuracy: 0.10400000214576721
step: 1972, train loss: nan, train acuracy: 0.0625
step: 1972, val loss: nan, val acuracy: 0.10400000214576721
step: 1973, train loss: nan, train acuracy: 0.078125
step: 1973, val loss: nan, val acuracy: 0.10400000214576721
step: 1974, train loss: nan, train acuracy: 0.09375
step: 1974, val loss: nan, val acuracy: 0.10400000214576721
step: 1975, train loss: nan, train acuracy: 0.09375
step: 1975, val loss: nan, val acuracy: 0.10400000214576721
step: 1976, train loss: nan, train acuracy: 0.078125
step: 1976, val loss: nan, val acuracy: 0.10400000214576721
step: 1977, train loss: nan, train acuracy: 0.09375
step: 1977, val loss: nan, val acuracy: 0.10400000214576721
step: 1978, train loss: nan, train acuracy: 0.046875
step: 1978, val loss: nan, val acuracy: 0.10400000214576721
step: 1979, train loss: nan, train acuracy: 0.15625
step: 1979, val loss: nan, val acuracy: 0.10400000214576721
step: 1980, train loss: nan, train acuracy: 0.09375
step: 1980, val loss: nan, val acuracy: 0.10400000214576721
step: 1981, train loss: nan, train acuracy: 0.09375
step: 1981, val loss: nan, val acuracy: 0.10400000214576721
step: 1982, train loss: nan, train acuracy: 0.046875
step: 1982, val loss: nan, val acuracy: 0.10400000214576721
step: 1983, train loss: nan, train acuracy: 0.078125
step: 1983, val loss: nan, val acuracy: 0.10400000214576721
step: 1984, train loss: nan, train acuracy: 0.1875
step: 1984, val loss: nan, val acuracy: 0.10400000214576721
step: 1985, train loss: nan, train acuracy: 0.1875
step: 1985, val loss: nan, val acuracy: 0.10400000214576721
step: 1986, train loss: nan, train acuracy: 0.109375
step: 1986, val loss: nan, val acuracy: 0.10400000214576721
step: 1987, train loss: nan, train acuracy: 0.125
step: 1987, val loss: nan, val acuracy: 0.10400000214576721
step: 1988, train loss: nan, train acuracy: 0.078125
step: 1988, val loss: nan, val acuracy: 0.10400000214576721
step: 1989, train loss: nan, train acuracy: 0.125
step: 1989, val loss: nan, val acuracy: 0.10400000214576721
step: 1990, train loss: nan, train acuracy: 0.078125
step: 1990, val loss: nan, val acuracy: 0.10400000214576721
step: 1991, train loss: nan, train acuracy: 0.078125
step: 1991, val loss: nan, val acuracy: 0.10400000214576721
step: 1992, train loss: nan, train acuracy: 0.03125
step: 1992, val loss: nan, val acuracy: 0.10400000214576721
step: 1993, train loss: nan, train acuracy: 0.1875
step: 1993, val loss: nan, val acuracy: 0.10400000214576721
step: 1994, train loss: nan, train acuracy: 0.078125
step: 1994, val loss: nan, val acuracy: 0.10400000214576721
step: 1995, train loss: nan, train acuracy: 0.0625
step: 1995, val loss: nan, val acuracy: 0.10400000214576721
step: 1996, train loss: nan, train acuracy: 0.0625
step: 1996, val loss: nan, val acuracy: 0.10400000214576721
step: 1997, train loss: nan, train acuracy: 0.171875
step: 1997, val loss: nan, val acuracy: 0.10400000214576721
step: 1998, train loss: nan, train acuracy: 0.09375
step: 1998, val loss: nan, val acuracy: 0.10400000214576721
step: 1999, train loss: nan, train acuracy: 0.078125
step: 1999, val loss: nan, val acuracy: 0.10400000214576721
step: 2000, train loss: nan, train acuracy: 0.125
step: 2000, val loss: nan, val acuracy: 0.10400000214576721
step: 2001, train loss: nan, train acuracy: 0.0625
step: 2001, val loss: nan, val acuracy: 0.10400000214576721
step: 2002, train loss: nan, train acuracy: 0.03125
step: 2002, val loss: nan, val acuracy: 0.10400000214576721
step: 2003, train loss: nan, train acuracy: 0.09375
step: 2003, val loss: nan, val acuracy: 0.10400000214576721
step: 2004, train loss: nan, train acuracy: 0.046875
step: 2004, val loss: nan, val acuracy: 0.10400000214576721
step: 2005, train loss: nan, train acuracy: 0.125
step: 2005, val loss: nan, val acuracy: 0.10400000214576721
step: 2006, train loss: nan, train acuracy: 0.109375
step: 2006, val loss: nan, val acuracy: 0.10400000214576721
step: 2007, train loss: nan, train acuracy: 0.125
step: 2007, val loss: nan, val acuracy: 0.10400000214576721
step: 2008, train loss: nan, train acuracy: 0.171875
step: 2008, val loss: nan, val acuracy: 0.10400000214576721
step: 2009, train loss: nan, train acuracy: 0.0625
step: 2009, val loss: nan, val acuracy: 0.10400000214576721
step: 2010, train loss: nan, train acuracy: 0.09375
step: 2010, val loss: nan, val acuracy: 0.10400000214576721
step: 2011, train loss: nan, train acuracy: 0.0625
step: 2011, val loss: nan, val acuracy: 0.10400000214576721
step: 2012, train loss: nan, train acuracy: 0.03125
step: 2012, val loss: nan, val acuracy: 0.10400000214576721
step: 2013, train loss: nan, train acuracy: 0.078125
step: 2013, val loss: nan, val acuracy: 0.10400000214576721
step: 2014, train loss: nan, train acuracy: 0.09375
step: 2014, val loss: nan, val acuracy: 0.10400000214576721
step: 2015, train loss: nan, train acuracy: 0.09375
step: 2015, val loss: nan, val acuracy: 0.10400000214576721
step: 2016, train loss: nan, train acuracy: 0.109375
step: 2016, val loss: nan, val acuracy: 0.10400000214576721
step: 2017, train loss: nan, train acuracy: 0.09375
step: 2017, val loss: nan, val acuracy: 0.10400000214576721
step: 2018, train loss: nan, train acuracy: 0.09375
step: 2018, val loss: nan, val acuracy: 0.10400000214576721
step: 2019, train loss: nan, train acuracy: 0.171875
step: 2019, val loss: nan, val acuracy: 0.10400000214576721
step: 2020, train loss: nan, train acuracy: 0.078125
step: 2020, val loss: nan, val acuracy: 0.10400000214576721
step: 2021, train loss: nan, train acuracy: 0.140625
step: 2021, val loss: nan, val acuracy: 0.10400000214576721
step: 2022, train loss: nan, train acuracy: 0.140625
step: 2022, val loss: nan, val acuracy: 0.10400000214576721
step: 2023, train loss: nan, train acuracy: 0.078125
step: 2023, val loss: nan, val acuracy: 0.10400000214576721
step: 2024, train loss: nan, train acuracy: 0.125
step: 2024, val loss: nan, val acuracy: 0.10400000214576721
step: 2025, train loss: nan, train acuracy: 0.125
step: 2025, val loss: nan, val acuracy: 0.10400000214576721
step: 2026, train loss: nan, train acuracy: 0.140625
step: 2026, val loss: nan, val acuracy: 0.10400000214576721
step: 2027, train loss: nan, train acuracy: 0.171875
step: 2027, val loss: nan, val acuracy: 0.10400000214576721
step: 2028, train loss: nan, train acuracy: 0.109375
step: 2028, val loss: nan, val acuracy: 0.10400000214576721
step: 2029, train loss: nan, train acuracy: 0.078125
step: 2029, val loss: nan, val acuracy: 0.10400000214576721
step: 2030, train loss: nan, train acuracy: 0.09375
step: 2030, val loss: nan, val acuracy: 0.10400000214576721
step: 2031, train loss: nan, train acuracy: 0.078125
step: 2031, val loss: nan, val acuracy: 0.10400000214576721
step: 2032, train loss: nan, train acuracy: 0.078125
step: 2032, val loss: nan, val acuracy: 0.10400000214576721
step: 2033, train loss: nan, train acuracy: 0.109375
step: 2033, val loss: nan, val acuracy: 0.10400000214576721
step: 2034, train loss: nan, train acuracy: 0.046875
step: 2034, val loss: nan, val acuracy: 0.10400000214576721
step: 2035, train loss: nan, train acuracy: 0.078125
step: 2035, val loss: nan, val acuracy: 0.10400000214576721
step: 2036, train loss: nan, train acuracy: 0.0625
step: 2036, val loss: nan, val acuracy: 0.10400000214576721
step: 2037, train loss: nan, train acuracy: 0.078125
step: 2037, val loss: nan, val acuracy: 0.10400000214576721
step: 2038, train loss: nan, train acuracy: 0.09375
step: 2038, val loss: nan, val acuracy: 0.10400000214576721
step: 2039, train loss: nan, train acuracy: 0.109375
step: 2039, val loss: nan, val acuracy: 0.10400000214576721
step: 2040, train loss: nan, train acuracy: 0.09375
step: 2040, val loss: nan, val acuracy: 0.10400000214576721
step: 2041, train loss: nan, train acuracy: 0.125
step: 2041, val loss: nan, val acuracy: 0.10400000214576721
step: 2042, train loss: nan, train acuracy: 0.125
step: 2042, val loss: nan, val acuracy: 0.10400000214576721
step: 2043, train loss: nan, train acuracy: 0.0625
step: 2043, val loss: nan, val acuracy: 0.10400000214576721
step: 2044, train loss: nan, train acuracy: 0.125
step: 2044, val loss: nan, val acuracy: 0.10400000214576721
step: 2045, train loss: nan, train acuracy: 0.078125
step: 2045, val loss: nan, val acuracy: 0.10400000214576721
step: 2046, train loss: nan, train acuracy: 0.09375
step: 2046, val loss: nan, val acuracy: 0.10400000214576721
step: 2047, train loss: nan, train acuracy: 0.171875
step: 2047, val loss: nan, val acuracy: 0.10400000214576721
step: 2048, train loss: nan, train acuracy: 0.078125
step: 2048, val loss: nan, val acuracy: 0.10400000214576721
step: 2049, train loss: nan, train acuracy: 0.125
step: 2049, val loss: nan, val acuracy: 0.10400000214576721
step: 2050, train loss: nan, train acuracy: 0.0625
step: 2050, val loss: nan, val acuracy: 0.10400000214576721
step: 2051, train loss: nan, train acuracy: 0.078125
step: 2051, val loss: nan, val acuracy: 0.10400000214576721
step: 2052, train loss: nan, train acuracy: 0.109375
step: 2052, val loss: nan, val acuracy: 0.10400000214576721
step: 2053, train loss: nan, train acuracy: 0.15625
step: 2053, val loss: nan, val acuracy: 0.10400000214576721
step: 2054, train loss: nan, train acuracy: 0.15625
step: 2054, val loss: nan, val acuracy: 0.10400000214576721
step: 2055, train loss: nan, train acuracy: 0.0625
step: 2055, val loss: nan, val acuracy: 0.10400000214576721
step: 2056, train loss: nan, train acuracy: 0.109375
step: 2056, val loss: nan, val acuracy: 0.10400000214576721
step: 2057, train loss: nan, train acuracy: 0.03125
step: 2057, val loss: nan, val acuracy: 0.10400000214576721
step: 2058, train loss: nan, train acuracy: 0.15625
step: 2058, val loss: nan, val acuracy: 0.10400000214576721
step: 2059, train loss: nan, train acuracy: 0.09375
step: 2059, val loss: nan, val acuracy: 0.10400000214576721
step: 2060, train loss: nan, train acuracy: 0.078125
step: 2060, val loss: nan, val acuracy: 0.10400000214576721
step: 2061, train loss: nan, train acuracy: 0.09375
step: 2061, val loss: nan, val acuracy: 0.10400000214576721
step: 2062, train loss: nan, train acuracy: 0.09375
step: 2062, val loss: nan, val acuracy: 0.10400000214576721
step: 2063, train loss: nan, train acuracy: 0.109375
step: 2063, val loss: nan, val acuracy: 0.10400000214576721
step: 2064, train loss: nan, train acuracy: 0.140625
step: 2064, val loss: nan, val acuracy: 0.10400000214576721
step: 2065, train loss: nan, train acuracy: 0.125
step: 2065, val loss: nan, val acuracy: 0.10400000214576721
step: 2066, train loss: nan, train acuracy: 0.09375
step: 2066, val loss: nan, val acuracy: 0.10400000214576721
step: 2067, train loss: nan, train acuracy: 0.078125
step: 2067, val loss: nan, val acuracy: 0.10400000214576721
step: 2068, train loss: nan, train acuracy: 0.0625
step: 2068, val loss: nan, val acuracy: 0.10400000214576721
step: 2069, train loss: nan, train acuracy: 0.125
step: 2069, val loss: nan, val acuracy: 0.10400000214576721
step: 2070, train loss: nan, train acuracy: 0.125
step: 2070, val loss: nan, val acuracy: 0.10400000214576721
step: 2071, train loss: nan, train acuracy: 0.09375
step: 2071, val loss: nan, val acuracy: 0.10400000214576721
step: 2072, train loss: nan, train acuracy: 0.125
step: 2072, val loss: nan, val acuracy: 0.10400000214576721
step: 2073, train loss: nan, train acuracy: 0.09375
step: 2073, val loss: nan, val acuracy: 0.10400000214576721
step: 2074, train loss: nan, train acuracy: 0.15625
step: 2074, val loss: nan, val acuracy: 0.10400000214576721
step: 2075, train loss: nan, train acuracy: 0.078125
step: 2075, val loss: nan, val acuracy: 0.10400000214576721
step: 2076, train loss: nan, train acuracy: 0.109375
step: 2076, val loss: nan, val acuracy: 0.10400000214576721
step: 2077, train loss: nan, train acuracy: 0.03125
step: 2077, val loss: nan, val acuracy: 0.10400000214576721
step: 2078, train loss: nan, train acuracy: 0.046875
step: 2078, val loss: nan, val acuracy: 0.10400000214576721
step: 2079, train loss: nan, train acuracy: 0.125
step: 2079, val loss: nan, val acuracy: 0.10400000214576721
step: 2080, train loss: nan, train acuracy: 0.09375
step: 2080, val loss: nan, val acuracy: 0.10400000214576721
step: 2081, train loss: nan, train acuracy: 0.140625
step: 2081, val loss: nan, val acuracy: 0.10400000214576721
step: 2082, train loss: nan, train acuracy: 0.0625
step: 2082, val loss: nan, val acuracy: 0.10400000214576721
step: 2083, train loss: nan, train acuracy: 0.125
step: 2083, val loss: nan, val acuracy: 0.10400000214576721
step: 2084, train loss: nan, train acuracy: 0.125
step: 2084, val loss: nan, val acuracy: 0.10400000214576721
step: 2085, train loss: nan, train acuracy: 0.078125
step: 2085, val loss: nan, val acuracy: 0.10400000214576721
step: 2086, train loss: nan, train acuracy: 0.0625
step: 2086, val loss: nan, val acuracy: 0.10400000214576721
step: 2087, train loss: nan, train acuracy: 0.078125
step: 2087, val loss: nan, val acuracy: 0.10400000214576721
step: 2088, train loss: nan, train acuracy: 0.15625
step: 2088, val loss: nan, val acuracy: 0.10400000214576721
step: 2089, train loss: nan, train acuracy: 0.109375
step: 2089, val loss: nan, val acuracy: 0.10400000214576721
step: 2090, train loss: nan, train acuracy: 0.109375
step: 2090, val loss: nan, val acuracy: 0.10400000214576721
step: 2091, train loss: nan, train acuracy: 0.078125
step: 2091, val loss: nan, val acuracy: 0.10400000214576721
step: 2092, train loss: nan, train acuracy: 0.15625
step: 2092, val loss: nan, val acuracy: 0.10400000214576721
step: 2093, train loss: nan, train acuracy: 0.125
step: 2093, val loss: nan, val acuracy: 0.10400000214576721
step: 2094, train loss: nan, train acuracy: 0.09375
step: 2094, val loss: nan, val acuracy: 0.10400000214576721
step: 2095, train loss: nan, train acuracy: 0.078125
step: 2095, val loss: nan, val acuracy: 0.10400000214576721
step: 2096, train loss: nan, train acuracy: 0.140625
step: 2096, val loss: nan, val acuracy: 0.10400000214576721
step: 2097, train loss: nan, train acuracy: 0.0625
step: 2097, val loss: nan, val acuracy: 0.10400000214576721
step: 2098, train loss: nan, train acuracy: 0.109375
step: 2098, val loss: nan, val acuracy: 0.10400000214576721
step: 2099, train loss: nan, train acuracy: 0.125
step: 2099, val loss: nan, val acuracy: 0.10400000214576721
step: 2100, train loss: nan, train acuracy: 0.109375
step: 2100, val loss: nan, val acuracy: 0.10400000214576721
step: 2101, train loss: nan, train acuracy: 0.078125
step: 2101, val loss: nan, val acuracy: 0.10400000214576721
step: 2102, train loss: nan, train acuracy: 0.0625
step: 2102, val loss: nan, val acuracy: 0.10400000214576721
step: 2103, train loss: nan, train acuracy: 0.046875
step: 2103, val loss: nan, val acuracy: 0.10400000214576721
step: 2104, train loss: nan, train acuracy: 0.109375
step: 2104, val loss: nan, val acuracy: 0.10400000214576721
step: 2105, train loss: nan, train acuracy: 0.0625
step: 2105, val loss: nan, val acuracy: 0.10400000214576721
step: 2106, train loss: nan, train acuracy: 0.046875
step: 2106, val loss: nan, val acuracy: 0.10400000214576721
step: 2107, train loss: nan, train acuracy: 0.078125
step: 2107, val loss: nan, val acuracy: 0.10400000214576721
step: 2108, train loss: nan, train acuracy: 0.0625
step: 2108, val loss: nan, val acuracy: 0.10400000214576721
step: 2109, train loss: nan, train acuracy: 0.046875
step: 2109, val loss: nan, val acuracy: 0.10400000214576721
step: 2110, train loss: nan, train acuracy: 0.0625
step: 2110, val loss: nan, val acuracy: 0.10400000214576721
step: 2111, train loss: nan, train acuracy: 0.09375
step: 2111, val loss: nan, val acuracy: 0.10400000214576721
step: 2112, train loss: nan, train acuracy: 0.078125
step: 2112, val loss: nan, val acuracy: 0.10400000214576721
step: 2113, train loss: nan, train acuracy: 0.109375
step: 2113, val loss: nan, val acuracy: 0.10400000214576721
step: 2114, train loss: nan, train acuracy: 0.078125
step: 2114, val loss: nan, val acuracy: 0.10400000214576721
step: 2115, train loss: nan, train acuracy: 0.0625
step: 2115, val loss: nan, val acuracy: 0.10400000214576721
step: 2116, train loss: nan, train acuracy: 0.0625
step: 2116, val loss: nan, val acuracy: 0.10400000214576721
step: 2117, train loss: nan, train acuracy: 0.078125
step: 2117, val loss: nan, val acuracy: 0.10400000214576721
step: 2118, train loss: nan, train acuracy: 0.203125
step: 2118, val loss: nan, val acuracy: 0.10400000214576721
step: 2119, train loss: nan, train acuracy: 0.125
step: 2119, val loss: nan, val acuracy: 0.10400000214576721
step: 2120, train loss: nan, train acuracy: 0.109375
step: 2120, val loss: nan, val acuracy: 0.10400000214576721
step: 2121, train loss: nan, train acuracy: 0.078125
step: 2121, val loss: nan, val acuracy: 0.10400000214576721
step: 2122, train loss: nan, train acuracy: 0.109375
step: 2122, val loss: nan, val acuracy: 0.10400000214576721
step: 2123, train loss: nan, train acuracy: 0.109375
step: 2123, val loss: nan, val acuracy: 0.10400000214576721
step: 2124, train loss: nan, train acuracy: 0.0625
step: 2124, val loss: nan, val acuracy: 0.10400000214576721
step: 2125, train loss: nan, train acuracy: 0.15625
step: 2125, val loss: nan, val acuracy: 0.10400000214576721
step: 2126, train loss: nan, train acuracy: 0.125
step: 2126, val loss: nan, val acuracy: 0.10400000214576721
step: 2127, train loss: nan, train acuracy: 0.09375
step: 2127, val loss: nan, val acuracy: 0.10400000214576721
step: 2128, train loss: nan, train acuracy: 0.140625
step: 2128, val loss: nan, val acuracy: 0.10400000214576721
step: 2129, train loss: nan, train acuracy: 0.140625
step: 2129, val loss: nan, val acuracy: 0.10400000214576721
step: 2130, train loss: nan, train acuracy: 0.078125
step: 2130, val loss: nan, val acuracy: 0.10400000214576721
step: 2131, train loss: nan, train acuracy: 0.09375
step: 2131, val loss: nan, val acuracy: 0.10400000214576721
step: 2132, train loss: nan, train acuracy: 0.140625
step: 2132, val loss: nan, val acuracy: 0.10400000214576721
step: 2133, train loss: nan, train acuracy: 0.15625
step: 2133, val loss: nan, val acuracy: 0.10400000214576721
step: 2134, train loss: nan, train acuracy: 0.140625
step: 2134, val loss: nan, val acuracy: 0.10400000214576721
step: 2135, train loss: nan, train acuracy: 0.109375
step: 2135, val loss: nan, val acuracy: 0.10400000214576721
step: 2136, train loss: nan, train acuracy: 0.09375
step: 2136, val loss: nan, val acuracy: 0.10400000214576721
step: 2137, train loss: nan, train acuracy: 0.078125
step: 2137, val loss: nan, val acuracy: 0.10400000214576721
step: 2138, train loss: nan, train acuracy: 0.109375
step: 2138, val loss: nan, val acuracy: 0.10400000214576721
step: 2139, train loss: nan, train acuracy: 0.078125
step: 2139, val loss: nan, val acuracy: 0.10400000214576721
step: 2140, train loss: nan, train acuracy: 0.09375
step: 2140, val loss: nan, val acuracy: 0.10400000214576721
step: 2141, train loss: nan, train acuracy: 0.046875
step: 2141, val loss: nan, val acuracy: 0.10400000214576721
step: 2142, train loss: nan, train acuracy: 0.125
step: 2142, val loss: nan, val acuracy: 0.10400000214576721
step: 2143, train loss: nan, train acuracy: 0.140625
step: 2143, val loss: nan, val acuracy: 0.10400000214576721
step: 2144, train loss: nan, train acuracy: 0.125
step: 2144, val loss: nan, val acuracy: 0.10400000214576721
step: 2145, train loss: nan, train acuracy: 0.140625
step: 2145, val loss: nan, val acuracy: 0.10400000214576721
step: 2146, train loss: nan, train acuracy: 0.109375
step: 2146, val loss: nan, val acuracy: 0.10400000214576721
step: 2147, train loss: nan, train acuracy: 0.046875
step: 2147, val loss: nan, val acuracy: 0.10400000214576721
step: 2148, train loss: nan, train acuracy: 0.109375
step: 2148, val loss: nan, val acuracy: 0.10400000214576721
step: 2149, train loss: nan, train acuracy: 0.0625
step: 2149, val loss: nan, val acuracy: 0.10400000214576721
step: 2150, train loss: nan, train acuracy: 0.09375
step: 2150, val loss: nan, val acuracy: 0.10400000214576721
step: 2151, train loss: nan, train acuracy: 0.09375
step: 2151, val loss: nan, val acuracy: 0.10400000214576721
step: 2152, train loss: nan, train acuracy: 0.109375
step: 2152, val loss: nan, val acuracy: 0.10400000214576721
step: 2153, train loss: nan, train acuracy: 0.15625
step: 2153, val loss: nan, val acuracy: 0.10400000214576721
step: 2154, train loss: nan, train acuracy: 0.078125
step: 2154, val loss: nan, val acuracy: 0.10400000214576721
step: 2155, train loss: nan, train acuracy: 0.09375
step: 2155, val loss: nan, val acuracy: 0.10400000214576721
step: 2156, train loss: nan, train acuracy: 0.15625
step: 2156, val loss: nan, val acuracy: 0.10400000214576721
step: 2157, train loss: nan, train acuracy: 0.09375
step: 2157, val loss: nan, val acuracy: 0.10400000214576721
step: 2158, train loss: nan, train acuracy: 0.09375
step: 2158, val loss: nan, val acuracy: 0.10400000214576721
step: 2159, train loss: nan, train acuracy: 0.109375
step: 2159, val loss: nan, val acuracy: 0.10400000214576721
step: 2160, train loss: nan, train acuracy: 0.125
step: 2160, val loss: nan, val acuracy: 0.10400000214576721
step: 2161, train loss: nan, train acuracy: 0.125
step: 2161, val loss: nan, val acuracy: 0.10400000214576721
step: 2162, train loss: nan, train acuracy: 0.0625
step: 2162, val loss: nan, val acuracy: 0.10400000214576721
step: 2163, train loss: nan, train acuracy: 0.046875
step: 2163, val loss: nan, val acuracy: 0.10400000214576721
step: 2164, train loss: nan, train acuracy: 0.03125
step: 2164, val loss: nan, val acuracy: 0.10400000214576721
step: 2165, train loss: nan, train acuracy: 0.09375
step: 2165, val loss: nan, val acuracy: 0.10400000214576721
step: 2166, train loss: nan, train acuracy: 0.140625
step: 2166, val loss: nan, val acuracy: 0.10400000214576721
step: 2167, train loss: nan, train acuracy: 0.109375
step: 2167, val loss: nan, val acuracy: 0.10400000214576721
step: 2168, train loss: nan, train acuracy: 0.109375
step: 2168, val loss: nan, val acuracy: 0.10400000214576721
step: 2169, train loss: nan, train acuracy: 0.109375
step: 2169, val loss: nan, val acuracy: 0.10400000214576721
step: 2170, train loss: nan, train acuracy: 0.078125
step: 2170, val loss: nan, val acuracy: 0.10400000214576721
step: 2171, train loss: nan, train acuracy: 0.078125
step: 2171, val loss: nan, val acuracy: 0.10400000214576721
step: 2172, train loss: nan, train acuracy: 0.15625
step: 2172, val loss: nan, val acuracy: 0.10400000214576721
step: 2173, train loss: nan, train acuracy: 0.078125
step: 2173, val loss: nan, val acuracy: 0.10400000214576721
step: 2174, train loss: nan, train acuracy: 0.09375
step: 2174, val loss: nan, val acuracy: 0.10400000214576721
step: 2175, train loss: nan, train acuracy: 0.0625
step: 2175, val loss: nan, val acuracy: 0.10400000214576721
step: 2176, train loss: nan, train acuracy: 0.0625
step: 2176, val loss: nan, val acuracy: 0.10400000214576721
step: 2177, train loss: nan, train acuracy: 0.125
step: 2177, val loss: nan, val acuracy: 0.10400000214576721
step: 2178, train loss: nan, train acuracy: 0.1875
step: 2178, val loss: nan, val acuracy: 0.10400000959634781
step: 2179, train loss: nan, train acuracy: 0.078125
step: 2179, val loss: nan, val acuracy: 0.10400000214576721
step: 2180, train loss: nan, train acuracy: 0.125
step: 2180, val loss: nan, val acuracy: 0.10400000214576721
step: 2181, train loss: nan, train acuracy: 0.125
step: 2181, val loss: nan, val acuracy: 0.10400000214576721
step: 2182, train loss: nan, train acuracy: 0.09375
step: 2182, val loss: nan, val acuracy: 0.10400000214576721
step: 2183, train loss: nan, train acuracy: 0.109375
step: 2183, val loss: nan, val acuracy: 0.10400000214576721
step: 2184, train loss: nan, train acuracy: 0.046875
step: 2184, val loss: nan, val acuracy: 0.10400000214576721
step: 2185, train loss: nan, train acuracy: 0.078125
step: 2185, val loss: nan, val acuracy: 0.10400000214576721
step: 2186, train loss: nan, train acuracy: 0.078125
step: 2186, val loss: nan, val acuracy: 0.10400000214576721
step: 2187, train loss: nan, train acuracy: 0.078125
step: 2187, val loss: nan, val acuracy: 0.10400000214576721
step: 2188, train loss: nan, train acuracy: 0.0625
step: 2188, val loss: nan, val acuracy: 0.10400000214576721
step: 2189, train loss: nan, train acuracy: 0.078125
step: 2189, val loss: nan, val acuracy: 0.10400000214576721
step: 2190, train loss: nan, train acuracy: 0.046875
step: 2190, val loss: nan, val acuracy: 0.10400000214576721
step: 2191, train loss: nan, train acuracy: 0.125
step: 2191, val loss: nan, val acuracy: 0.10400000214576721
step: 2192, train loss: nan, train acuracy: 0.203125
step: 2192, val loss: nan, val acuracy: 0.10400000214576721
step: 2193, train loss: nan, train acuracy: 0.1875
step: 2193, val loss: nan, val acuracy: 0.10400000214576721
step: 2194, train loss: nan, train acuracy: 0.109375
step: 2194, val loss: nan, val acuracy: 0.10400000214576721
step: 2195, train loss: nan, train acuracy: 0.125
step: 2195, val loss: nan, val acuracy: 0.10400000214576721
step: 2196, train loss: nan, train acuracy: 0.046875
step: 2196, val loss: nan, val acuracy: 0.10400000214576721
step: 2197, train loss: nan, train acuracy: 0.109375
step: 2197, val loss: nan, val acuracy: 0.10400000214576721
step: 2198, train loss: nan, train acuracy: 0.109375
step: 2198, val loss: nan, val acuracy: 0.10400000214576721
step: 2199, train loss: nan, train acuracy: 0.140625
step: 2199, val loss: nan, val acuracy: 0.10400000214576721
step: 2200, train loss: nan, train acuracy: 0.09375
step: 2200, val loss: nan, val acuracy: 0.10400000214576721
step: 2201, train loss: nan, train acuracy: 0.15625
step: 2201, val loss: nan, val acuracy: 0.10400000214576721
step: 2202, train loss: nan, train acuracy: 0.0625
step: 2202, val loss: nan, val acuracy: 0.10400000214576721
step: 2203, train loss: nan, train acuracy: 0.09375
step: 2203, val loss: nan, val acuracy: 0.10400000214576721
step: 2204, train loss: nan, train acuracy: 0.09375
step: 2204, val loss: nan, val acuracy: 0.10400000214576721
step: 2205, train loss: nan, train acuracy: 0.03125
step: 2205, val loss: nan, val acuracy: 0.10400000214576721
step: 2206, train loss: nan, train acuracy: 0.09375
step: 2206, val loss: nan, val acuracy: 0.10400000214576721
step: 2207, train loss: nan, train acuracy: 0.046875
step: 2207, val loss: nan, val acuracy: 0.10400000214576721
step: 2208, train loss: nan, train acuracy: 0.15625
step: 2208, val loss: nan, val acuracy: 0.10400000214576721
step: 2209, train loss: nan, train acuracy: 0.09375
step: 2209, val loss: nan, val acuracy: 0.10400000214576721
step: 2210, train loss: nan, train acuracy: 0.125
step: 2210, val loss: nan, val acuracy: 0.10400000214576721
step: 2211, train loss: nan, train acuracy: 0.03125
step: 2211, val loss: nan, val acuracy: 0.10400000214576721
step: 2212, train loss: nan, train acuracy: 0.125
step: 2212, val loss: nan, val acuracy: 0.10400000214576721
step: 2213, train loss: nan, train acuracy: 0.15625
step: 2213, val loss: nan, val acuracy: 0.10400000214576721
step: 2214, train loss: nan, train acuracy: 0.125
step: 2214, val loss: nan, val acuracy: 0.10400000214576721
step: 2215, train loss: nan, train acuracy: 0.078125
step: 2215, val loss: nan, val acuracy: 0.10400000214576721
step: 2216, train loss: nan, train acuracy: 0.078125
step: 2216, val loss: nan, val acuracy: 0.10400000214576721
step: 2217, train loss: nan, train acuracy: 0.109375
step: 2217, val loss: nan, val acuracy: 0.10400000214576721
step: 2218, train loss: nan, train acuracy: 0.09375
step: 2218, val loss: nan, val acuracy: 0.10400000214576721
step: 2219, train loss: nan, train acuracy: 0.046875
step: 2219, val loss: nan, val acuracy: 0.10400000214576721
step: 2220, train loss: nan, train acuracy: 0.09375
step: 2220, val loss: nan, val acuracy: 0.10400000214576721
step: 2221, train loss: nan, train acuracy: 0.046875
step: 2221, val loss: nan, val acuracy: 0.10400000214576721
step: 2222, train loss: nan, train acuracy: 0.125
step: 2222, val loss: nan, val acuracy: 0.10400000214576721
step: 2223, train loss: nan, train acuracy: 0.078125
step: 2223, val loss: nan, val acuracy: 0.10400000214576721
step: 2224, train loss: nan, train acuracy: 0.0625
step: 2224, val loss: nan, val acuracy: 0.10400000214576721
step: 2225, train loss: nan, train acuracy: 0.140625
step: 2225, val loss: nan, val acuracy: 0.10400000214576721
step: 2226, train loss: nan, train acuracy: 0.15625
step: 2226, val loss: nan, val acuracy: 0.10400000214576721
step: 2227, train loss: nan, train acuracy: 0.140625
step: 2227, val loss: nan, val acuracy: 0.10400000214576721
step: 2228, train loss: nan, train acuracy: 0.109375
step: 2228, val loss: nan, val acuracy: 0.10400000214576721
step: 2229, train loss: nan, train acuracy: 0.046875
step: 2229, val loss: nan, val acuracy: 0.10400000214576721
step: 2230, train loss: nan, train acuracy: 0.140625
step: 2230, val loss: nan, val acuracy: 0.10400000214576721
step: 2231, train loss: nan, train acuracy: 0.140625
step: 2231, val loss: nan, val acuracy: 0.10400000214576721
step: 2232, train loss: nan, train acuracy: 0.0625
step: 2232, val loss: nan, val acuracy: 0.10400000214576721
step: 2233, train loss: nan, train acuracy: 0.0625
step: 2233, val loss: nan, val acuracy: 0.10400000214576721
step: 2234, train loss: nan, train acuracy: 0.078125
step: 2234, val loss: nan, val acuracy: 0.10400000214576721
step: 2235, train loss: nan, train acuracy: 0.0625
step: 2235, val loss: nan, val acuracy: 0.10400000214576721
step: 2236, train loss: nan, train acuracy: 0.109375
step: 2236, val loss: nan, val acuracy: 0.10400000214576721
step: 2237, train loss: nan, train acuracy: 0.09375
step: 2237, val loss: nan, val acuracy: 0.10400000214576721
step: 2238, train loss: nan, train acuracy: 0.109375
step: 2238, val loss: nan, val acuracy: 0.10400000214576721
step: 2239, train loss: nan, train acuracy: 0.125
step: 2239, val loss: nan, val acuracy: 0.10400000214576721
step: 2240, train loss: nan, train acuracy: 0.046875
step: 2240, val loss: nan, val acuracy: 0.10400000214576721
step: 2241, train loss: nan, train acuracy: 0.171875
step: 2241, val loss: nan, val acuracy: 0.10400000214576721
step: 2242, train loss: nan, train acuracy: 0.03125
step: 2242, val loss: nan, val acuracy: 0.10400000214576721
step: 2243, train loss: nan, train acuracy: 0.09375
step: 2243, val loss: nan, val acuracy: 0.10400000214576721
step: 2244, train loss: nan, train acuracy: 0.140625
step: 2244, val loss: nan, val acuracy: 0.10400000214576721
step: 2245, train loss: nan, train acuracy: 0.171875
step: 2245, val loss: nan, val acuracy: 0.10400000214576721
step: 2246, train loss: nan, train acuracy: 0.078125
step: 2246, val loss: nan, val acuracy: 0.10400000214576721
step: 2247, train loss: nan, train acuracy: 0.109375
step: 2247, val loss: nan, val acuracy: 0.10400000214576721
step: 2248, train loss: nan, train acuracy: 0.046875
step: 2248, val loss: nan, val acuracy: 0.10400000214576721
step: 2249, train loss: nan, train acuracy: 0.0625
step: 2249, val loss: nan, val acuracy: 0.10400000214576721
step: 2250, train loss: nan, train acuracy: 0.046875
step: 2250, val loss: nan, val acuracy: 0.10400000214576721
step: 2251, train loss: nan, train acuracy: 0.09375
step: 2251, val loss: nan, val acuracy: 0.10400000214576721
step: 2252, train loss: nan, train acuracy: 0.09375
step: 2252, val loss: nan, val acuracy: 0.10400000214576721
step: 2253, train loss: nan, train acuracy: 0.09375
step: 2253, val loss: nan, val acuracy: 0.10400000214576721
step: 2254, train loss: nan, train acuracy: 0.046875
step: 2254, val loss: nan, val acuracy: 0.10400000214576721
step: 2255, train loss: nan, train acuracy: 0.125
step: 2255, val loss: nan, val acuracy: 0.10400000214576721
step: 2256, train loss: nan, train acuracy: 0.125
step: 2256, val loss: nan, val acuracy: 0.10400000214576721
step: 2257, train loss: nan, train acuracy: 0.109375
step: 2257, val loss: nan, val acuracy: 0.10400000214576721
step: 2258, train loss: nan, train acuracy: 0.046875
step: 2258, val loss: nan, val acuracy: 0.10400000214576721
step: 2259, train loss: nan, train acuracy: 0.078125
step: 2259, val loss: nan, val acuracy: 0.10400000214576721
step: 2260, train loss: nan, train acuracy: 0.109375
step: 2260, val loss: nan, val acuracy: 0.10400000214576721
step: 2261, train loss: nan, train acuracy: 0.125
step: 2261, val loss: nan, val acuracy: 0.10400000214576721
step: 2262, train loss: nan, train acuracy: 0.125
step: 2262, val loss: nan, val acuracy: 0.10400000214576721
step: 2263, train loss: nan, train acuracy: 0.0625
step: 2263, val loss: nan, val acuracy: 0.10400000214576721
step: 2264, train loss: nan, train acuracy: 0.140625
step: 2264, val loss: nan, val acuracy: 0.10400000214576721
step: 2265, train loss: nan, train acuracy: 0.078125
step: 2265, val loss: nan, val acuracy: 0.10400000214576721
step: 2266, train loss: nan, train acuracy: 0.015625
step: 2266, val loss: nan, val acuracy: 0.10400000214576721
step: 2267, train loss: nan, train acuracy: 0.046875
step: 2267, val loss: nan, val acuracy: 0.10400000214576721
step: 2268, train loss: nan, train acuracy: 0.109375
step: 2268, val loss: nan, val acuracy: 0.10400000214576721
step: 2269, train loss: nan, train acuracy: 0.0625
step: 2269, val loss: nan, val acuracy: 0.10400000214576721
step: 2270, train loss: nan, train acuracy: 0.0625
step: 2270, val loss: nan, val acuracy: 0.10400000214576721
step: 2271, train loss: nan, train acuracy: 0.078125
step: 2271, val loss: nan, val acuracy: 0.10400000214576721
step: 2272, train loss: nan, train acuracy: 0.046875
step: 2272, val loss: nan, val acuracy: 0.10400000214576721
step: 2273, train loss: nan, train acuracy: 0.0625
step: 2273, val loss: nan, val acuracy: 0.10400000214576721
step: 2274, train loss: nan, train acuracy: 0.09375
step: 2274, val loss: nan, val acuracy: 0.10400000214576721
step: 2275, train loss: nan, train acuracy: 0.140625
step: 2275, val loss: nan, val acuracy: 0.10400000214576721
step: 2276, train loss: nan, train acuracy: 0.09375
step: 2276, val loss: nan, val acuracy: 0.10400000214576721
step: 2277, train loss: nan, train acuracy: 0.078125
step: 2277, val loss: nan, val acuracy: 0.10400000214576721
step: 2278, train loss: nan, train acuracy: 0.078125
step: 2278, val loss: nan, val acuracy: 0.10400000214576721
step: 2279, train loss: nan, train acuracy: 0.09375
step: 2279, val loss: nan, val acuracy: 0.10400000214576721
step: 2280, train loss: nan, train acuracy: 0.109375
step: 2280, val loss: nan, val acuracy: 0.10400000214576721
step: 2281, train loss: nan, train acuracy: 0.140625
step: 2281, val loss: nan, val acuracy: 0.10400000214576721
step: 2282, train loss: nan, train acuracy: 0.0625
step: 2282, val loss: nan, val acuracy: 0.10400000214576721
step: 2283, train loss: nan, train acuracy: 0.109375
step: 2283, val loss: nan, val acuracy: 0.10400000214576721
step: 2284, train loss: nan, train acuracy: 0.09375
step: 2284, val loss: nan, val acuracy: 0.10400000214576721
step: 2285, train loss: nan, train acuracy: 0.078125
step: 2285, val loss: nan, val acuracy: 0.10400000214576721
step: 2286, train loss: nan, train acuracy: 0.0625
step: 2286, val loss: nan, val acuracy: 0.10400000214576721
step: 2287, train loss: nan, train acuracy: 0.125
step: 2287, val loss: nan, val acuracy: 0.10400000214576721
step: 2288, train loss: nan, train acuracy: 0.140625
step: 2288, val loss: nan, val acuracy: 0.10400000214576721
step: 2289, train loss: nan, train acuracy: 0.0625
step: 2289, val loss: nan, val acuracy: 0.10400000214576721
step: 2290, train loss: nan, train acuracy: 0.078125
step: 2290, val loss: nan, val acuracy: 0.10400000214576721
step: 2291, train loss: nan, train acuracy: 0.109375
step: 2291, val loss: nan, val acuracy: 0.10400000214576721
step: 2292, train loss: nan, train acuracy: 0.140625
step: 2292, val loss: nan, val acuracy: 0.10400000214576721
step: 2293, train loss: nan, train acuracy: 0.125
step: 2293, val loss: nan, val acuracy: 0.10400000214576721
step: 2294, train loss: nan, train acuracy: 0.109375
step: 2294, val loss: nan, val acuracy: 0.10400000214576721
step: 2295, train loss: nan, train acuracy: 0.09375
step: 2295, val loss: nan, val acuracy: 0.10400000214576721
step: 2296, train loss: nan, train acuracy: 0.03125
step: 2296, val loss: nan, val acuracy: 0.10400000214576721
step: 2297, train loss: nan, train acuracy: 0.0625
step: 2297, val loss: nan, val acuracy: 0.10400000214576721
step: 2298, train loss: nan, train acuracy: 0.125
step: 2298, val loss: nan, val acuracy: 0.10400000214576721
step: 2299, train loss: nan, train acuracy: 0.109375
step: 2299, val loss: nan, val acuracy: 0.10400000214576721
step: 2300, train loss: nan, train acuracy: 0.203125
step: 2300, val loss: nan, val acuracy: 0.10400000214576721
step: 2301, train loss: nan, train acuracy: 0.125
step: 2301, val loss: nan, val acuracy: 0.10400000214576721
step: 2302, train loss: nan, train acuracy: 0.078125
step: 2302, val loss: nan, val acuracy: 0.10400000214576721
step: 2303, train loss: nan, train acuracy: 0.078125
step: 2303, val loss: nan, val acuracy: 0.10400000214576721
step: 2304, train loss: nan, train acuracy: 0.109375
step: 2304, val loss: nan, val acuracy: 0.10400000214576721
step: 2305, train loss: nan, train acuracy: 0.125
step: 2305, val loss: nan, val acuracy: 0.10400000214576721
step: 2306, train loss: nan, train acuracy: 0.078125
step: 2306, val loss: nan, val acuracy: 0.10400000214576721
step: 2307, train loss: nan, train acuracy: 0.109375
step: 2307, val loss: nan, val acuracy: 0.10400000214576721
step: 2308, train loss: nan, train acuracy: 0.078125
step: 2308, val loss: nan, val acuracy: 0.10400000214576721
step: 2309, train loss: nan, train acuracy: 0.015625
step: 2309, val loss: nan, val acuracy: 0.10400000214576721
step: 2310, train loss: nan, train acuracy: 0.09375
step: 2310, val loss: nan, val acuracy: 0.10400000214576721
step: 2311, train loss: nan, train acuracy: 0.109375
step: 2311, val loss: nan, val acuracy: 0.10400000214576721
step: 2312, train loss: nan, train acuracy: 0.109375
step: 2312, val loss: nan, val acuracy: 0.10400000214576721
step: 2313, train loss: nan, train acuracy: 0.078125
step: 2313, val loss: nan, val acuracy: 0.10400000214576721
step: 2314, train loss: nan, train acuracy: 0.171875
step: 2314, val loss: nan, val acuracy: 0.10400000214576721
step: 2315, train loss: nan, train acuracy: 0.109375
step: 2315, val loss: nan, val acuracy: 0.10400000214576721
step: 2316, train loss: nan, train acuracy: 0.0625
step: 2316, val loss: nan, val acuracy: 0.10400000214576721
step: 2317, train loss: nan, train acuracy: 0.140625
step: 2317, val loss: nan, val acuracy: 0.10400000214576721
step: 2318, train loss: nan, train acuracy: 0.140625
step: 2318, val loss: nan, val acuracy: 0.10400000214576721
step: 2319, train loss: nan, train acuracy: 0.109375
step: 2319, val loss: nan, val acuracy: 0.10400000214576721
step: 2320, train loss: nan, train acuracy: 0.15625
step: 2320, val loss: nan, val acuracy: 0.10400000214576721
step: 2321, train loss: nan, train acuracy: 0.125
step: 2321, val loss: nan, val acuracy: 0.10400000214576721
step: 2322, train loss: nan, train acuracy: 0.125
step: 2322, val loss: nan, val acuracy: 0.10400000214576721
step: 2323, train loss: nan, train acuracy: 0.109375
step: 2323, val loss: nan, val acuracy: 0.10400000214576721
step: 2324, train loss: nan, train acuracy: 0.078125
step: 2324, val loss: nan, val acuracy: 0.10400000214576721
step: 2325, train loss: nan, train acuracy: 0.078125
step: 2325, val loss: nan, val acuracy: 0.10400000214576721
step: 2326, train loss: nan, train acuracy: 0.09375
step: 2326, val loss: nan, val acuracy: 0.10400000214576721
step: 2327, train loss: nan, train acuracy: 0.078125
step: 2327, val loss: nan, val acuracy: 0.10400000214576721
step: 2328, train loss: nan, train acuracy: 0.078125
step: 2328, val loss: nan, val acuracy: 0.10400000214576721
step: 2329, train loss: nan, train acuracy: 0.0625
step: 2329, val loss: nan, val acuracy: 0.10400000214576721
step: 2330, train loss: nan, train acuracy: 0.078125
step: 2330, val loss: nan, val acuracy: 0.10400000214576721
step: 2331, train loss: nan, train acuracy: 0.203125
step: 2331, val loss: nan, val acuracy: 0.10400000214576721
step: 2332, train loss: nan, train acuracy: 0.15625
step: 2332, val loss: nan, val acuracy: 0.10400000214576721
step: 2333, train loss: nan, train acuracy: 0.0625
step: 2333, val loss: nan, val acuracy: 0.10400000214576721
step: 2334, train loss: nan, train acuracy: 0.109375
step: 2334, val loss: nan, val acuracy: 0.10400000214576721
step: 2335, train loss: nan, train acuracy: 0.109375
step: 2335, val loss: nan, val acuracy: 0.10400000214576721
step: 2336, train loss: nan, train acuracy: 0.109375
step: 2336, val loss: nan, val acuracy: 0.10400000214576721
step: 2337, train loss: nan, train acuracy: 0.140625
step: 2337, val loss: nan, val acuracy: 0.10400000214576721
step: 2338, train loss: nan, train acuracy: 0.078125
step: 2338, val loss: nan, val acuracy: 0.10400000214576721
step: 2339, train loss: nan, train acuracy: 0.171875
step: 2339, val loss: nan, val acuracy: 0.10400000214576721
step: 2340, train loss: nan, train acuracy: 0.03125
step: 2340, val loss: nan, val acuracy: 0.10400000214576721
step: 2341, train loss: nan, train acuracy: 0.109375
step: 2341, val loss: nan, val acuracy: 0.10400000214576721
step: 2342, train loss: nan, train acuracy: 0.078125
step: 2342, val loss: nan, val acuracy: 0.10400000214576721
step: 2343, train loss: nan, train acuracy: 0.109375
step: 2343, val loss: nan, val acuracy: 0.10400000214576721
step: 2344, train loss: nan, train acuracy: 0.109375
step: 2344, val loss: nan, val acuracy: 0.10400000214576721
step: 2345, train loss: nan, train acuracy: 0.0625
step: 2345, val loss: nan, val acuracy: 0.10400000214576721
step: 2346, train loss: nan, train acuracy: 0.140625
step: 2346, val loss: nan, val acuracy: 0.10400000214576721
step: 2347, train loss: nan, train acuracy: 0.0625
step: 2347, val loss: nan, val acuracy: 0.10400000214576721
step: 2348, train loss: nan, train acuracy: 0.09375
step: 2348, val loss: nan, val acuracy: 0.10400000214576721
step: 2349, train loss: nan, train acuracy: 0.125
step: 2349, val loss: nan, val acuracy: 0.10400000214576721
step: 2350, train loss: nan, train acuracy: 0.09375
step: 2350, val loss: nan, val acuracy: 0.10400000214576721
step: 2351, train loss: nan, train acuracy: 0.125
step: 2351, val loss: nan, val acuracy: 0.10400000214576721
step: 2352, train loss: nan, train acuracy: 0.0625
step: 2352, val loss: nan, val acuracy: 0.10400000214576721
step: 2353, train loss: nan, train acuracy: 0.140625
step: 2353, val loss: nan, val acuracy: 0.10400000214576721
step: 2354, train loss: nan, train acuracy: 0.09375
step: 2354, val loss: nan, val acuracy: 0.10400000214576721
step: 2355, train loss: nan, train acuracy: 0.0625
step: 2355, val loss: nan, val acuracy: 0.10400000214576721
step: 2356, train loss: nan, train acuracy: 0.140625
step: 2356, val loss: nan, val acuracy: 0.10400000214576721
step: 2357, train loss: nan, train acuracy: 0.171875
step: 2357, val loss: nan, val acuracy: 0.10400000214576721
step: 2358, train loss: nan, train acuracy: 0.0625
step: 2358, val loss: nan, val acuracy: 0.10400000214576721
step: 2359, train loss: nan, train acuracy: 0.0625
step: 2359, val loss: nan, val acuracy: 0.10400000214576721
step: 2360, train loss: nan, train acuracy: 0.15625
step: 2360, val loss: nan, val acuracy: 0.10400000214576721
step: 2361, train loss: nan, train acuracy: 0.09375
step: 2361, val loss: nan, val acuracy: 0.10400000214576721
step: 2362, train loss: nan, train acuracy: 0.078125
step: 2362, val loss: nan, val acuracy: 0.10400000214576721
step: 2363, train loss: nan, train acuracy: 0.09375
step: 2363, val loss: nan, val acuracy: 0.10400000214576721
step: 2364, train loss: nan, train acuracy: 0.109375
step: 2364, val loss: nan, val acuracy: 0.10400000214576721
step: 2365, train loss: nan, train acuracy: 0.15625
step: 2365, val loss: nan, val acuracy: 0.10400000214576721
step: 2366, train loss: nan, train acuracy: 0.078125
step: 2366, val loss: nan, val acuracy: 0.10400000214576721
step: 2367, train loss: nan, train acuracy: 0.125
step: 2367, val loss: nan, val acuracy: 0.10400000214576721
step: 2368, train loss: nan, train acuracy: 0.109375
step: 2368, val loss: nan, val acuracy: 0.10400000214576721
step: 2369, train loss: nan, train acuracy: 0.03125
step: 2369, val loss: nan, val acuracy: 0.10400000214576721
step: 2370, train loss: nan, train acuracy: 0.046875
step: 2370, val loss: nan, val acuracy: 0.10400000214576721
step: 2371, train loss: nan, train acuracy: 0.046875
step: 2371, val loss: nan, val acuracy: 0.10400000214576721
step: 2372, train loss: nan, train acuracy: 0.09375
step: 2372, val loss: nan, val acuracy: 0.10400000214576721
step: 2373, train loss: nan, train acuracy: 0.046875
step: 2373, val loss: nan, val acuracy: 0.10400000214576721
step: 2374, train loss: nan, train acuracy: 0.140625
step: 2374, val loss: nan, val acuracy: 0.10400000214576721
step: 2375, train loss: nan, train acuracy: 0.078125
step: 2375, val loss: nan, val acuracy: 0.10400000214576721
step: 2376, train loss: nan, train acuracy: 0.15625
step: 2376, val loss: nan, val acuracy: 0.10400000214576721
step: 2377, train loss: nan, train acuracy: 0.03125
step: 2377, val loss: nan, val acuracy: 0.10400000214576721
step: 2378, train loss: nan, train acuracy: 0.09375
step: 2378, val loss: nan, val acuracy: 0.10400000214576721
step: 2379, train loss: nan, train acuracy: 0.078125
step: 2379, val loss: nan, val acuracy: 0.10400000214576721
step: 2380, train loss: nan, train acuracy: 0.125
step: 2380, val loss: nan, val acuracy: 0.10400000214576721
step: 2381, train loss: nan, train acuracy: 0.171875
step: 2381, val loss: nan, val acuracy: 0.10400000214576721
step: 2382, train loss: nan, train acuracy: 0.109375
step: 2382, val loss: nan, val acuracy: 0.10400000214576721
step: 2383, train loss: nan, train acuracy: 0.0625
step: 2383, val loss: nan, val acuracy: 0.10400000214576721
step: 2384, train loss: nan, train acuracy: 0.09375
step: 2384, val loss: nan, val acuracy: 0.10400000214576721
step: 2385, train loss: nan, train acuracy: 0.078125
step: 2385, val loss: nan, val acuracy: 0.10400000214576721
step: 2386, train loss: nan, train acuracy: 0.109375
step: 2386, val loss: nan, val acuracy: 0.10400000959634781
step: 2387, train loss: nan, train acuracy: 0.09375
step: 2387, val loss: nan, val acuracy: 0.10400000214576721
step: 2388, train loss: nan, train acuracy: 0.0625
step: 2388, val loss: nan, val acuracy: 0.10400000214576721
step: 2389, train loss: nan, train acuracy: 0.109375
step: 2389, val loss: nan, val acuracy: 0.10400000214576721
step: 2390, train loss: nan, train acuracy: 0.078125
step: 2390, val loss: nan, val acuracy: 0.10400000214576721
step: 2391, train loss: nan, train acuracy: 0.09375
step: 2391, val loss: nan, val acuracy: 0.10400000214576721
step: 2392, train loss: nan, train acuracy: 0.109375
step: 2392, val loss: nan, val acuracy: 0.10400000214576721
step: 2393, train loss: nan, train acuracy: 0.109375
step: 2393, val loss: nan, val acuracy: 0.10400000214576721
step: 2394, train loss: nan, train acuracy: 0.125
step: 2394, val loss: nan, val acuracy: 0.10400000214576721
step: 2395, train loss: nan, train acuracy: 0.078125
step: 2395, val loss: nan, val acuracy: 0.10400000214576721
step: 2396, train loss: nan, train acuracy: 0.109375
step: 2396, val loss: nan, val acuracy: 0.10400000214576721
step: 2397, train loss: nan, train acuracy: 0.09375
step: 2397, val loss: nan, val acuracy: 0.10400000214576721
step: 2398, train loss: nan, train acuracy: 0.15625
step: 2398, val loss: nan, val acuracy: 0.10400000214576721
step: 2399, train loss: nan, train acuracy: 0.109375
step: 2399, val loss: nan, val acuracy: 0.10400000214576721
step: 2400, train loss: nan, train acuracy: 0.09375
step: 2400, val loss: nan, val acuracy: 0.10400000214576721
step: 2401, train loss: nan, train acuracy: 0.0625
step: 2401, val loss: nan, val acuracy: 0.10400000214576721
step: 2402, train loss: nan, train acuracy: 0.09375
step: 2402, val loss: nan, val acuracy: 0.10400000214576721
step: 2403, train loss: nan, train acuracy: 0.109375
step: 2403, val loss: nan, val acuracy: 0.10400000214576721
step: 2404, train loss: nan, train acuracy: 0.09375
step: 2404, val loss: nan, val acuracy: 0.10400000214576721
step: 2405, train loss: nan, train acuracy: 0.078125
step: 2405, val loss: nan, val acuracy: 0.10400000214576721
step: 2406, train loss: nan, train acuracy: 0.078125
step: 2406, val loss: nan, val acuracy: 0.10400000214576721
step: 2407, train loss: nan, train acuracy: 0.0625
step: 2407, val loss: nan, val acuracy: 0.10400000214576721
step: 2408, train loss: nan, train acuracy: 0.0625
step: 2408, val loss: nan, val acuracy: 0.10400000214576721
step: 2409, train loss: nan, train acuracy: 0.125
step: 2409, val loss: nan, val acuracy: 0.10400000214576721
step: 2410, train loss: nan, train acuracy: 0.0625
step: 2410, val loss: nan, val acuracy: 0.10400000214576721
step: 2411, train loss: nan, train acuracy: 0.109375
step: 2411, val loss: nan, val acuracy: 0.10400000214576721
step: 2412, train loss: nan, train acuracy: 0.078125
step: 2412, val loss: nan, val acuracy: 0.10400000214576721
step: 2413, train loss: nan, train acuracy: 0.125
step: 2413, val loss: nan, val acuracy: 0.10400000214576721
step: 2414, train loss: nan, train acuracy: 0.0625
step: 2414, val loss: nan, val acuracy: 0.10400000214576721
step: 2415, train loss: nan, train acuracy: 0.09375
step: 2415, val loss: nan, val acuracy: 0.10400000214576721
step: 2416, train loss: nan, train acuracy: 0.125
step: 2416, val loss: nan, val acuracy: 0.10400000214576721
step: 2417, train loss: nan, train acuracy: 0.125
step: 2417, val loss: nan, val acuracy: 0.10400000214576721
step: 2418, train loss: nan, train acuracy: 0.046875
step: 2418, val loss: nan, val acuracy: 0.10400000214576721
step: 2419, train loss: nan, train acuracy: 0.125
step: 2419, val loss: nan, val acuracy: 0.10400000214576721
step: 2420, train loss: nan, train acuracy: 0.109375
step: 2420, val loss: nan, val acuracy: 0.10400000214576721
step: 2421, train loss: nan, train acuracy: 0.140625
step: 2421, val loss: nan, val acuracy: 0.10400000214576721
step: 2422, train loss: nan, train acuracy: 0.125
step: 2422, val loss: nan, val acuracy: 0.10400000214576721
step: 2423, train loss: nan, train acuracy: 0.03125
step: 2423, val loss: nan, val acuracy: 0.10400000214576721
step: 2424, train loss: nan, train acuracy: 0.109375
step: 2424, val loss: nan, val acuracy: 0.10400000214576721
step: 2425, train loss: nan, train acuracy: 0.109375
step: 2425, val loss: nan, val acuracy: 0.10400000214576721
step: 2426, train loss: nan, train acuracy: 0.140625
step: 2426, val loss: nan, val acuracy: 0.10400000214576721
step: 2427, train loss: nan, train acuracy: 0.03125
step: 2427, val loss: nan, val acuracy: 0.10400000214576721
step: 2428, train loss: nan, train acuracy: 0.109375
step: 2428, val loss: nan, val acuracy: 0.10400000214576721
step: 2429, train loss: nan, train acuracy: 0.109375
step: 2429, val loss: nan, val acuracy: 0.10400000214576721
step: 2430, train loss: nan, train acuracy: 0.078125
step: 2430, val loss: nan, val acuracy: 0.10400000214576721
step: 2431, train loss: nan, train acuracy: 0.09375
step: 2431, val loss: nan, val acuracy: 0.10400000214576721
step: 2432, train loss: nan, train acuracy: 0.046875
step: 2432, val loss: nan, val acuracy: 0.10400000214576721
step: 2433, train loss: nan, train acuracy: 0.078125
step: 2433, val loss: nan, val acuracy: 0.10400000214576721
step: 2434, train loss: nan, train acuracy: 0.140625
step: 2434, val loss: nan, val acuracy: 0.10400000214576721
step: 2435, train loss: nan, train acuracy: 0.0625
step: 2435, val loss: nan, val acuracy: 0.10400000214576721
step: 2436, train loss: nan, train acuracy: 0.0625
step: 2436, val loss: nan, val acuracy: 0.10400000214576721
step: 2437, train loss: nan, train acuracy: 0.078125
step: 2437, val loss: nan, val acuracy: 0.10400000214576721
step: 2438, train loss: nan, train acuracy: 0.078125
step: 2438, val loss: nan, val acuracy: 0.10400000214576721
step: 2439, train loss: nan, train acuracy: 0.171875
step: 2439, val loss: nan, val acuracy: 0.10400000214576721
step: 2440, train loss: nan, train acuracy: 0.109375
step: 2440, val loss: nan, val acuracy: 0.10400000214576721
step: 2441, train loss: nan, train acuracy: 0.09375
step: 2441, val loss: nan, val acuracy: 0.10400000214576721
step: 2442, train loss: nan, train acuracy: 0.078125
step: 2442, val loss: nan, val acuracy: 0.10400000214576721
step: 2443, train loss: nan, train acuracy: 0.078125
step: 2443, val loss: nan, val acuracy: 0.10400000214576721
step: 2444, train loss: nan, train acuracy: 0.140625
step: 2444, val loss: nan, val acuracy: 0.10400000214576721
step: 2445, train loss: nan, train acuracy: 0.125
step: 2445, val loss: nan, val acuracy: 0.10400000214576721
step: 2446, train loss: nan, train acuracy: 0.078125
step: 2446, val loss: nan, val acuracy: 0.10400000214576721
step: 2447, train loss: nan, train acuracy: 0.109375
step: 2447, val loss: nan, val acuracy: 0.10400000214576721
step: 2448, train loss: nan, train acuracy: 0.078125
step: 2448, val loss: nan, val acuracy: 0.10400000214576721
step: 2449, train loss: nan, train acuracy: 0.140625
step: 2449, val loss: nan, val acuracy: 0.10400000214576721
step: 2450, train loss: nan, train acuracy: 0.03125
step: 2450, val loss: nan, val acuracy: 0.10400000214576721
step: 2451, train loss: nan, train acuracy: 0.125
step: 2451, val loss: nan, val acuracy: 0.10400000214576721
step: 2452, train loss: nan, train acuracy: 0.078125
step: 2452, val loss: nan, val acuracy: 0.10400000214576721
step: 2453, train loss: nan, train acuracy: 0.125
step: 2453, val loss: nan, val acuracy: 0.10400000214576721
step: 2454, train loss: nan, train acuracy: 0.125
step: 2454, val loss: nan, val acuracy: 0.10400000214576721
step: 2455, train loss: nan, train acuracy: 0.125
step: 2455, val loss: nan, val acuracy: 0.10400000214576721
step: 2456, train loss: nan, train acuracy: 0.046875
step: 2456, val loss: nan, val acuracy: 0.10400000214576721
step: 2457, train loss: nan, train acuracy: 0.140625
step: 2457, val loss: nan, val acuracy: 0.10400000214576721
step: 2458, train loss: nan, train acuracy: 0.109375
step: 2458, val loss: nan, val acuracy: 0.10400000214576721
step: 2459, train loss: nan, train acuracy: 0.0625
step: 2459, val loss: nan, val acuracy: 0.10400000214576721
step: 2460, train loss: nan, train acuracy: 0.171875
step: 2460, val loss: nan, val acuracy: 0.10400000214576721
step: 2461, train loss: nan, train acuracy: 0.109375
step: 2461, val loss: nan, val acuracy: 0.10400000214576721
step: 2462, train loss: nan, train acuracy: 0.109375
step: 2462, val loss: nan, val acuracy: 0.10400000214576721
step: 2463, train loss: nan, train acuracy: 0.0625
step: 2463, val loss: nan, val acuracy: 0.10400000214576721
step: 2464, train loss: nan, train acuracy: 0.0625
step: 2464, val loss: nan, val acuracy: 0.10400000214576721
step: 2465, train loss: nan, train acuracy: 0.09375
step: 2465, val loss: nan, val acuracy: 0.10400000214576721
step: 2466, train loss: nan, train acuracy: 0.125
step: 2466, val loss: nan, val acuracy: 0.10400000214576721
step: 2467, train loss: nan, train acuracy: 0.09375
step: 2467, val loss: nan, val acuracy: 0.10400000214576721
step: 2468, train loss: nan, train acuracy: 0.078125
step: 2468, val loss: nan, val acuracy: 0.10400000214576721
step: 2469, train loss: nan, train acuracy: 0.078125
step: 2469, val loss: nan, val acuracy: 0.10400000214576721
step: 2470, train loss: nan, train acuracy: 0.171875
step: 2470, val loss: nan, val acuracy: 0.10400000214576721
step: 2471, train loss: nan, train acuracy: 0.125
step: 2471, val loss: nan, val acuracy: 0.10400000214576721
step: 2472, train loss: nan, train acuracy: 0.09375
step: 2472, val loss: nan, val acuracy: 0.10400000214576721
step: 2473, train loss: nan, train acuracy: 0.109375
step: 2473, val loss: nan, val acuracy: 0.10400000214576721
step: 2474, train loss: nan, train acuracy: 0.125
step: 2474, val loss: nan, val acuracy: 0.10400000214576721
step: 2475, train loss: nan, train acuracy: 0.125
step: 2475, val loss: nan, val acuracy: 0.10400000214576721
step: 2476, train loss: nan, train acuracy: 0.09375
step: 2476, val loss: nan, val acuracy: 0.10400000214576721
step: 2477, train loss: nan, train acuracy: 0.125
step: 2477, val loss: nan, val acuracy: 0.10400000214576721
step: 2478, train loss: nan, train acuracy: 0.109375
step: 2478, val loss: nan, val acuracy: 0.10400000214576721
step: 2479, train loss: nan, train acuracy: 0.078125
step: 2479, val loss: nan, val acuracy: 0.10400000214576721
step: 2480, train loss: nan, train acuracy: 0.0625
step: 2480, val loss: nan, val acuracy: 0.10400000214576721
step: 2481, train loss: nan, train acuracy: 0.078125
step: 2481, val loss: nan, val acuracy: 0.10400000214576721
step: 2482, train loss: nan, train acuracy: 0.0625
step: 2482, val loss: nan, val acuracy: 0.10400000214576721
step: 2483, train loss: nan, train acuracy: 0.140625
step: 2483, val loss: nan, val acuracy: 0.10400000214576721
step: 2484, train loss: nan, train acuracy: 0.125
step: 2484, val loss: nan, val acuracy: 0.10400000214576721
step: 2485, train loss: nan, train acuracy: 0.109375
step: 2485, val loss: nan, val acuracy: 0.10400000214576721
step: 2486, train loss: nan, train acuracy: 0.0625
step: 2486, val loss: nan, val acuracy: 0.10400000214576721
step: 2487, train loss: nan, train acuracy: 0.078125
step: 2487, val loss: nan, val acuracy: 0.10400000214576721
step: 2488, train loss: nan, train acuracy: 0.09375
step: 2488, val loss: nan, val acuracy: 0.10400000214576721
step: 2489, train loss: nan, train acuracy: 0.125
step: 2489, val loss: nan, val acuracy: 0.10400000214576721
step: 2490, train loss: nan, train acuracy: 0.140625
step: 2490, val loss: nan, val acuracy: 0.10400000214576721
step: 2491, train loss: nan, train acuracy: 0.078125
step: 2491, val loss: nan, val acuracy: 0.10400000214576721
step: 2492, train loss: nan, train acuracy: 0.125
step: 2492, val loss: nan, val acuracy: 0.10400000214576721
step: 2493, train loss: nan, train acuracy: 0.140625
step: 2493, val loss: nan, val acuracy: 0.10400000214576721
step: 2494, train loss: nan, train acuracy: 0.078125
step: 2494, val loss: nan, val acuracy: 0.10400000214576721
step: 2495, train loss: nan, train acuracy: 0.078125
step: 2495, val loss: nan, val acuracy: 0.10400000214576721
step: 2496, train loss: nan, train acuracy: 0.0625
step: 2496, val loss: nan, val acuracy: 0.10400000214576721
step: 2497, train loss: nan, train acuracy: 0.015625
step: 2497, val loss: nan, val acuracy: 0.10400000214576721
step: 2498, train loss: nan, train acuracy: 0.078125
step: 2498, val loss: nan, val acuracy: 0.10400000214576721
step: 2499, train loss: nan, train acuracy: 0.09375
step: 2499, val loss: nan, val acuracy: 0.10400000214576721
step: 2500, train loss: nan, train acuracy: 0.109375
step: 2500, val loss: nan, val acuracy: 0.10400000214576721
step: 2501, train loss: nan, train acuracy: 0.125
step: 2501, val loss: nan, val acuracy: 0.10400000214576721
step: 2502, train loss: nan, train acuracy: 0.21875
step: 2502, val loss: nan, val acuracy: 0.10400000214576721
step: 2503, train loss: nan, train acuracy: 0.046875
step: 2503, val loss: nan, val acuracy: 0.10400000214576721
step: 2504, train loss: nan, train acuracy: 0.0625
step: 2504, val loss: nan, val acuracy: 0.10400000214576721
step: 2505, train loss: nan, train acuracy: 0.109375
step: 2505, val loss: nan, val acuracy: 0.10400000214576721
step: 2506, train loss: nan, train acuracy: 0.109375
step: 2506, val loss: nan, val acuracy: 0.10400000214576721
step: 2507, train loss: nan, train acuracy: 0.125
step: 2507, val loss: nan, val acuracy: 0.10400000214576721
step: 2508, train loss: nan, train acuracy: 0.15625
step: 2508, val loss: nan, val acuracy: 0.10400000214576721
step: 2509, train loss: nan, train acuracy: 0.15625
step: 2509, val loss: nan, val acuracy: 0.10400000214576721
step: 2510, train loss: nan, train acuracy: 0.125
step: 2510, val loss: nan, val acuracy: 0.10400000214576721
step: 2511, train loss: nan, train acuracy: 0.234375
step: 2511, val loss: nan, val acuracy: 0.10400000214576721
step: 2512, train loss: nan, train acuracy: 0.046875
step: 2512, val loss: nan, val acuracy: 0.10400000214576721
step: 2513, train loss: nan, train acuracy: 0.109375
step: 2513, val loss: nan, val acuracy: 0.10400000214576721
step: 2514, train loss: nan, train acuracy: 0.078125
step: 2514, val loss: nan, val acuracy: 0.10400000214576721
step: 2515, train loss: nan, train acuracy: 0.078125
step: 2515, val loss: nan, val acuracy: 0.10400000214576721
step: 2516, train loss: nan, train acuracy: 0.1875
step: 2516, val loss: nan, val acuracy: 0.10400000214576721
step: 2517, train loss: nan, train acuracy: 0.078125
step: 2517, val loss: nan, val acuracy: 0.10400000214576721
step: 2518, train loss: nan, train acuracy: 0.15625
step: 2518, val loss: nan, val acuracy: 0.10400000214576721
step: 2519, train loss: nan, train acuracy: 0.125
step: 2519, val loss: nan, val acuracy: 0.10400000214576721
step: 2520, train loss: nan, train acuracy: 0.09375
step: 2520, val loss: nan, val acuracy: 0.10400000214576721
step: 2521, train loss: nan, train acuracy: 0.109375
step: 2521, val loss: nan, val acuracy: 0.10400000214576721
step: 2522, train loss: nan, train acuracy: 0.09375
step: 2522, val loss: nan, val acuracy: 0.10400000214576721
step: 2523, train loss: nan, train acuracy: 0.09375
step: 2523, val loss: nan, val acuracy: 0.10400000214576721
step: 2524, train loss: nan, train acuracy: 0.046875
step: 2524, val loss: nan, val acuracy: 0.10400000214576721
step: 2525, train loss: nan, train acuracy: 0.109375
step: 2525, val loss: nan, val acuracy: 0.10400000214576721
step: 2526, train loss: nan, train acuracy: 0.125
step: 2526, val loss: nan, val acuracy: 0.10400000959634781
step: 2527, train loss: nan, train acuracy: 0.078125
step: 2527, val loss: nan, val acuracy: 0.10400000214576721
step: 2528, train loss: nan, train acuracy: 0.0625
step: 2528, val loss: nan, val acuracy: 0.10400000214576721
step: 2529, train loss: nan, train acuracy: 0.109375
step: 2529, val loss: nan, val acuracy: 0.10400000214576721
step: 2530, train loss: nan, train acuracy: 0.15625
step: 2530, val loss: nan, val acuracy: 0.10400000214576721
step: 2531, train loss: nan, train acuracy: 0.09375
step: 2531, val loss: nan, val acuracy: 0.10400000214576721
step: 2532, train loss: nan, train acuracy: 0.0625
step: 2532, val loss: nan, val acuracy: 0.10400000214576721
step: 2533, train loss: nan, train acuracy: 0.140625
step: 2533, val loss: nan, val acuracy: 0.10400000214576721
step: 2534, train loss: nan, train acuracy: 0.109375
step: 2534, val loss: nan, val acuracy: 0.10400000214576721
step: 2535, train loss: nan, train acuracy: 0.125
step: 2535, val loss: nan, val acuracy: 0.10400000214576721
step: 2536, train loss: nan, train acuracy: 0.109375
step: 2536, val loss: nan, val acuracy: 0.10400000214576721
step: 2537, train loss: nan, train acuracy: 0.046875
step: 2537, val loss: nan, val acuracy: 0.10400000214576721
step: 2538, train loss: nan, train acuracy: 0.09375
step: 2538, val loss: nan, val acuracy: 0.10400000214576721
step: 2539, train loss: nan, train acuracy: 0.109375
step: 2539, val loss: nan, val acuracy: 0.10400000214576721
step: 2540, train loss: nan, train acuracy: 0.09375
step: 2540, val loss: nan, val acuracy: 0.10400000214576721
step: 2541, train loss: nan, train acuracy: 0.0625
step: 2541, val loss: nan, val acuracy: 0.10400000214576721
step: 2542, train loss: nan, train acuracy: 0.09375
step: 2542, val loss: nan, val acuracy: 0.10400000214576721
step: 2543, train loss: nan, train acuracy: 0.046875
step: 2543, val loss: nan, val acuracy: 0.10400000214576721
step: 2544, train loss: nan, train acuracy: 0.0625
step: 2544, val loss: nan, val acuracy: 0.10400000214576721
step: 2545, train loss: nan, train acuracy: 0.09375
step: 2545, val loss: nan, val acuracy: 0.10400000214576721
step: 2546, train loss: nan, train acuracy: 0.109375
step: 2546, val loss: nan, val acuracy: 0.10400000214576721
step: 2547, train loss: nan, train acuracy: 0.171875
step: 2547, val loss: nan, val acuracy: 0.10400000214576721
step: 2548, train loss: nan, train acuracy: 0.078125
step: 2548, val loss: nan, val acuracy: 0.10400000214576721
step: 2549, train loss: nan, train acuracy: 0.09375
step: 2549, val loss: nan, val acuracy: 0.10400000214576721
step: 2550, train loss: nan, train acuracy: 0.140625
step: 2550, val loss: nan, val acuracy: 0.10400000214576721
step: 2551, train loss: nan, train acuracy: 0.0625
step: 2551, val loss: nan, val acuracy: 0.10400000214576721
step: 2552, train loss: nan, train acuracy: 0.109375
step: 2552, val loss: nan, val acuracy: 0.10400000214576721
step: 2553, train loss: nan, train acuracy: 0.15625
step: 2553, val loss: nan, val acuracy: 0.10400000214576721
step: 2554, train loss: nan, train acuracy: 0.0625
step: 2554, val loss: nan, val acuracy: 0.10400000214576721
step: 2555, train loss: nan, train acuracy: 0.140625
step: 2555, val loss: nan, val acuracy: 0.10400000214576721
step: 2556, train loss: nan, train acuracy: 0.0625
step: 2556, val loss: nan, val acuracy: 0.10400000214576721
step: 2557, train loss: nan, train acuracy: 0.0625
step: 2557, val loss: nan, val acuracy: 0.10400000214576721
step: 2558, train loss: nan, train acuracy: 0.09375
step: 2558, val loss: nan, val acuracy: 0.10400000214576721
step: 2559, train loss: nan, train acuracy: 0.125
step: 2559, val loss: nan, val acuracy: 0.10400000214576721
step: 2560, train loss: nan, train acuracy: 0.078125
step: 2560, val loss: nan, val acuracy: 0.10400000214576721
step: 2561, train loss: nan, train acuracy: 0.09375
step: 2561, val loss: nan, val acuracy: 0.10400000214576721
step: 2562, train loss: nan, train acuracy: 0.09375
step: 2562, val loss: nan, val acuracy: 0.10400000214576721
step: 2563, train loss: nan, train acuracy: 0.09375
step: 2563, val loss: nan, val acuracy: 0.10400000214576721
step: 2564, train loss: nan, train acuracy: 0.0625
step: 2564, val loss: nan, val acuracy: 0.10400000214576721
step: 2565, train loss: nan, train acuracy: 0.109375
step: 2565, val loss: nan, val acuracy: 0.10400000214576721
step: 2566, train loss: nan, train acuracy: 0.046875
step: 2566, val loss: nan, val acuracy: 0.10400000214576721
step: 2567, train loss: nan, train acuracy: 0.078125
step: 2567, val loss: nan, val acuracy: 0.10400000214576721
step: 2568, train loss: nan, train acuracy: 0.0625
step: 2568, val loss: nan, val acuracy: 0.10400000214576721
step: 2569, train loss: nan, train acuracy: 0.09375
step: 2569, val loss: nan, val acuracy: 0.10400000214576721
step: 2570, train loss: nan, train acuracy: 0.0625
step: 2570, val loss: nan, val acuracy: 0.10400000214576721
step: 2571, train loss: nan, train acuracy: 0.078125
step: 2571, val loss: nan, val acuracy: 0.10400000214576721
step: 2572, train loss: nan, train acuracy: 0.0625
step: 2572, val loss: nan, val acuracy: 0.10400000214576721
step: 2573, train loss: nan, train acuracy: 0.0625
step: 2573, val loss: nan, val acuracy: 0.10400000214576721
step: 2574, train loss: nan, train acuracy: 0.140625
step: 2574, val loss: nan, val acuracy: 0.10400000214576721
step: 2575, train loss: nan, train acuracy: 0.109375
step: 2575, val loss: nan, val acuracy: 0.10400000214576721
step: 2576, train loss: nan, train acuracy: 0.09375
step: 2576, val loss: nan, val acuracy: 0.10400000214576721
step: 2577, train loss: nan, train acuracy: 0.0625
step: 2577, val loss: nan, val acuracy: 0.10400000214576721
step: 2578, train loss: nan, train acuracy: 0.109375
step: 2578, val loss: nan, val acuracy: 0.10400000214576721
step: 2579, train loss: nan, train acuracy: 0.078125
step: 2579, val loss: nan, val acuracy: 0.10400000214576721
step: 2580, train loss: nan, train acuracy: 0.09375
step: 2580, val loss: nan, val acuracy: 0.10400000214576721
step: 2581, train loss: nan, train acuracy: 0.078125
step: 2581, val loss: nan, val acuracy: 0.10400000214576721
step: 2582, train loss: nan, train acuracy: 0.109375
step: 2582, val loss: nan, val acuracy: 0.10400000214576721
step: 2583, train loss: nan, train acuracy: 0.078125
step: 2583, val loss: nan, val acuracy: 0.10400000214576721
step: 2584, train loss: nan, train acuracy: 0.09375
step: 2584, val loss: nan, val acuracy: 0.10400000214576721
step: 2585, train loss: nan, train acuracy: 0.125
step: 2585, val loss: nan, val acuracy: 0.10400000214576721
step: 2586, train loss: nan, train acuracy: 0.109375
step: 2586, val loss: nan, val acuracy: 0.10400000214576721
step: 2587, train loss: nan, train acuracy: 0.09375
step: 2587, val loss: nan, val acuracy: 0.10400000214576721
step: 2588, train loss: nan, train acuracy: 0.078125
step: 2588, val loss: nan, val acuracy: 0.10400000214576721
step: 2589, train loss: nan, train acuracy: 0.15625
step: 2589, val loss: nan, val acuracy: 0.10400000214576721
step: 2590, train loss: nan, train acuracy: 0.03125
step: 2590, val loss: nan, val acuracy: 0.10400000214576721
step: 2591, train loss: nan, train acuracy: 0.171875
step: 2591, val loss: nan, val acuracy: 0.10400000214576721
step: 2592, train loss: nan, train acuracy: 0.125
step: 2592, val loss: nan, val acuracy: 0.10400000214576721
step: 2593, train loss: nan, train acuracy: 0.15625
step: 2593, val loss: nan, val acuracy: 0.10400000214576721
step: 2594, train loss: nan, train acuracy: 0.078125
step: 2594, val loss: nan, val acuracy: 0.10400000214576721
step: 2595, train loss: nan, train acuracy: 0.109375
step: 2595, val loss: nan, val acuracy: 0.10400000214576721
step: 2596, train loss: nan, train acuracy: 0.078125
step: 2596, val loss: nan, val acuracy: 0.10400000214576721
step: 2597, train loss: nan, train acuracy: 0.0625
step: 2597, val loss: nan, val acuracy: 0.10400000214576721
step: 2598, train loss: nan, train acuracy: 0.09375
step: 2598, val loss: nan, val acuracy: 0.10400000214576721
step: 2599, train loss: nan, train acuracy: 0.046875
step: 2599, val loss: nan, val acuracy: 0.10400000214576721
step: 2600, train loss: nan, train acuracy: 0.125
step: 2600, val loss: nan, val acuracy: 0.10400000214576721
step: 2601, train loss: nan, train acuracy: 0.125
step: 2601, val loss: nan, val acuracy: 0.10400000214576721
step: 2602, train loss: nan, train acuracy: 0.109375
step: 2602, val loss: nan, val acuracy: 0.10400000214576721
step: 2603, train loss: nan, train acuracy: 0.109375
step: 2603, val loss: nan, val acuracy: 0.10400000214576721
step: 2604, train loss: nan, train acuracy: 0.03125
step: 2604, val loss: nan, val acuracy: 0.10400000214576721
step: 2605, train loss: nan, train acuracy: 0.109375
step: 2605, val loss: nan, val acuracy: 0.10400000214576721
step: 2606, train loss: nan, train acuracy: 0.1875
step: 2606, val loss: nan, val acuracy: 0.10400000214576721
step: 2607, train loss: nan, train acuracy: 0.09375
step: 2607, val loss: nan, val acuracy: 0.10400000214576721
step: 2608, train loss: nan, train acuracy: 0.109375
step: 2608, val loss: nan, val acuracy: 0.10400000214576721
step: 2609, train loss: nan, train acuracy: 0.109375
step: 2609, val loss: nan, val acuracy: 0.10400000214576721
step: 2610, train loss: nan, train acuracy: 0.09375
step: 2610, val loss: nan, val acuracy: 0.10400000214576721
step: 2611, train loss: nan, train acuracy: 0.109375
step: 2611, val loss: nan, val acuracy: 0.10400000214576721
step: 2612, train loss: nan, train acuracy: 0.03125
step: 2612, val loss: nan, val acuracy: 0.10400000214576721
step: 2613, train loss: nan, train acuracy: 0.078125
step: 2613, val loss: nan, val acuracy: 0.10400000214576721
step: 2614, train loss: nan, train acuracy: 0.125
step: 2614, val loss: nan, val acuracy: 0.10400000214576721
step: 2615, train loss: nan, train acuracy: 0.109375
step: 2615, val loss: nan, val acuracy: 0.10400000214576721
step: 2616, train loss: nan, train acuracy: 0.09375
step: 2616, val loss: nan, val acuracy: 0.10400000214576721
step: 2617, train loss: nan, train acuracy: 0.046875
step: 2617, val loss: nan, val acuracy: 0.10400000214576721
step: 2618, train loss: nan, train acuracy: 0.109375
step: 2618, val loss: nan, val acuracy: 0.10400000214576721
step: 2619, train loss: nan, train acuracy: 0.15625
step: 2619, val loss: nan, val acuracy: 0.10400000214576721
step: 2620, train loss: nan, train acuracy: 0.140625
step: 2620, val loss: nan, val acuracy: 0.10400000214576721
step: 2621, train loss: nan, train acuracy: 0.109375
step: 2621, val loss: nan, val acuracy: 0.10400000214576721
step: 2622, train loss: nan, train acuracy: 0.109375
step: 2622, val loss: nan, val acuracy: 0.10400000214576721
step: 2623, train loss: nan, train acuracy: 0.0625
step: 2623, val loss: nan, val acuracy: 0.10400000214576721
step: 2624, train loss: nan, train acuracy: 0.0625
step: 2624, val loss: nan, val acuracy: 0.10400000214576721
step: 2625, train loss: nan, train acuracy: 0.0625
step: 2625, val loss: nan, val acuracy: 0.10400000214576721
step: 2626, train loss: nan, train acuracy: 0.125
step: 2626, val loss: nan, val acuracy: 0.10400000214576721
step: 2627, train loss: nan, train acuracy: 0.078125
step: 2627, val loss: nan, val acuracy: 0.10400000214576721
step: 2628, train loss: nan, train acuracy: 0.125
step: 2628, val loss: nan, val acuracy: 0.10400000214576721
step: 2629, train loss: nan, train acuracy: 0.046875
step: 2629, val loss: nan, val acuracy: 0.10400000214576721
step: 2630, train loss: nan, train acuracy: 0.1875
step: 2630, val loss: nan, val acuracy: 0.10400000214576721
step: 2631, train loss: nan, train acuracy: 0.09375
step: 2631, val loss: nan, val acuracy: 0.10400000214576721
step: 2632, train loss: nan, train acuracy: 0.15625
step: 2632, val loss: nan, val acuracy: 0.10400000214576721
step: 2633, train loss: nan, train acuracy: 0.1875
step: 2633, val loss: nan, val acuracy: 0.10400000214576721
step: 2634, train loss: nan, train acuracy: 0.09375
step: 2634, val loss: nan, val acuracy: 0.10400000214576721
step: 2635, train loss: nan, train acuracy: 0.15625
step: 2635, val loss: nan, val acuracy: 0.10400000214576721
step: 2636, train loss: nan, train acuracy: 0.09375
step: 2636, val loss: nan, val acuracy: 0.10400000214576721
step: 2637, train loss: nan, train acuracy: 0.15625
step: 2637, val loss: nan, val acuracy: 0.10400000214576721
step: 2638, train loss: nan, train acuracy: 0.03125
step: 2638, val loss: nan, val acuracy: 0.10400000214576721
step: 2639, train loss: nan, train acuracy: 0.109375
step: 2639, val loss: nan, val acuracy: 0.10400000214576721
step: 2640, train loss: nan, train acuracy: 0.09375
step: 2640, val loss: nan, val acuracy: 0.10400000214576721
step: 2641, train loss: nan, train acuracy: 0.125
step: 2641, val loss: nan, val acuracy: 0.10400000214576721
step: 2642, train loss: nan, train acuracy: 0.140625
step: 2642, val loss: nan, val acuracy: 0.10400000214576721
step: 2643, train loss: nan, train acuracy: 0.09375
step: 2643, val loss: nan, val acuracy: 0.10400000214576721
step: 2644, train loss: nan, train acuracy: 0.109375
step: 2644, val loss: nan, val acuracy: 0.10400000214576721
step: 2645, train loss: nan, train acuracy: 0.0625
step: 2645, val loss: nan, val acuracy: 0.10400000214576721
step: 2646, train loss: nan, train acuracy: 0.109375
step: 2646, val loss: nan, val acuracy: 0.10400000214576721
step: 2647, train loss: nan, train acuracy: 0.109375
step: 2647, val loss: nan, val acuracy: 0.10400000214576721
step: 2648, train loss: nan, train acuracy: 0.0625
step: 2648, val loss: nan, val acuracy: 0.10400000214576721
step: 2649, train loss: nan, train acuracy: 0.078125
step: 2649, val loss: nan, val acuracy: 0.10400000214576721
step: 2650, train loss: nan, train acuracy: 0.0625
step: 2650, val loss: nan, val acuracy: 0.10400000214576721
step: 2651, train loss: nan, train acuracy: 0.0625
step: 2651, val loss: nan, val acuracy: 0.10400000214576721
step: 2652, train loss: nan, train acuracy: 0.1875
step: 2652, val loss: nan, val acuracy: 0.10400000214576721
step: 2653, train loss: nan, train acuracy: 0.078125
step: 2653, val loss: nan, val acuracy: 0.10400000214576721
step: 2654, train loss: nan, train acuracy: 0.046875
step: 2654, val loss: nan, val acuracy: 0.10400000214576721
step: 2655, train loss: nan, train acuracy: 0.125
step: 2655, val loss: nan, val acuracy: 0.10400000214576721
step: 2656, train loss: nan, train acuracy: 0.046875
step: 2656, val loss: nan, val acuracy: 0.10400000214576721
step: 2657, train loss: nan, train acuracy: 0.109375
step: 2657, val loss: nan, val acuracy: 0.10400000214576721
step: 2658, train loss: nan, train acuracy: 0.078125
step: 2658, val loss: nan, val acuracy: 0.10400000214576721
step: 2659, train loss: nan, train acuracy: 0.15625
step: 2659, val loss: nan, val acuracy: 0.10400000214576721
step: 2660, train loss: nan, train acuracy: 0.140625
step: 2660, val loss: nan, val acuracy: 0.10400000214576721
step: 2661, train loss: nan, train acuracy: 0.09375
step: 2661, val loss: nan, val acuracy: 0.10400000214576721
step: 2662, train loss: nan, train acuracy: 0.15625
step: 2662, val loss: nan, val acuracy: 0.10400000214576721
step: 2663, train loss: nan, train acuracy: 0.09375
step: 2663, val loss: nan, val acuracy: 0.10400000214576721
step: 2664, train loss: nan, train acuracy: 0.0625
step: 2664, val loss: nan, val acuracy: 0.10400000214576721
step: 2665, train loss: nan, train acuracy: 0.109375
step: 2665, val loss: nan, val acuracy: 0.10400000214576721
step: 2666, train loss: nan, train acuracy: 0.125
step: 2666, val loss: nan, val acuracy: 0.10400000214576721
step: 2667, train loss: nan, train acuracy: 0.078125
step: 2667, val loss: nan, val acuracy: 0.10400000214576721
step: 2668, train loss: nan, train acuracy: 0.09375
step: 2668, val loss: nan, val acuracy: 0.10400000214576721
step: 2669, train loss: nan, train acuracy: 0.046875
step: 2669, val loss: nan, val acuracy: 0.10400000214576721
step: 2670, train loss: nan, train acuracy: 0.140625
step: 2670, val loss: nan, val acuracy: 0.10400000214576721
step: 2671, train loss: nan, train acuracy: 0.140625
step: 2671, val loss: nan, val acuracy: 0.10400000214576721
step: 2672, train loss: nan, train acuracy: 0.015625
step: 2672, val loss: nan, val acuracy: 0.10400000214576721
step: 2673, train loss: nan, train acuracy: 0.09375
step: 2673, val loss: nan, val acuracy: 0.10400000214576721
step: 2674, train loss: nan, train acuracy: 0.0625
step: 2674, val loss: nan, val acuracy: 0.10400000214576721
step: 2675, train loss: nan, train acuracy: 0.078125
step: 2675, val loss: nan, val acuracy: 0.10400000214576721
step: 2676, train loss: nan, train acuracy: 0.03125
step: 2676, val loss: nan, val acuracy: 0.10400000214576721
step: 2677, train loss: nan, train acuracy: 0.0625
step: 2677, val loss: nan, val acuracy: 0.10400000214576721
step: 2678, train loss: nan, train acuracy: 0.046875
step: 2678, val loss: nan, val acuracy: 0.10400000214576721
step: 2679, train loss: nan, train acuracy: 0.140625
step: 2679, val loss: nan, val acuracy: 0.10400000214576721
step: 2680, train loss: nan, train acuracy: 0.09375
step: 2680, val loss: nan, val acuracy: 0.10400000214576721
step: 2681, train loss: nan, train acuracy: 0.09375
step: 2681, val loss: nan, val acuracy: 0.10400000214576721
step: 2682, train loss: nan, train acuracy: 0.1875
step: 2682, val loss: nan, val acuracy: 0.10400000214576721
step: 2683, train loss: nan, train acuracy: 0.140625
step: 2683, val loss: nan, val acuracy: 0.10400000214576721
step: 2684, train loss: nan, train acuracy: 0.109375
step: 2684, val loss: nan, val acuracy: 0.10400000214576721
step: 2685, train loss: nan, train acuracy: 0.078125
step: 2685, val loss: nan, val acuracy: 0.10400000214576721
step: 2686, train loss: nan, train acuracy: 0.09375
step: 2686, val loss: nan, val acuracy: 0.10400000214576721
step: 2687, train loss: nan, train acuracy: 0.109375
step: 2687, val loss: nan, val acuracy: 0.10400000214576721
step: 2688, train loss: nan, train acuracy: 0.09375
step: 2688, val loss: nan, val acuracy: 0.10400000214576721
step: 2689, train loss: nan, train acuracy: 0.125
step: 2689, val loss: nan, val acuracy: 0.10400000214576721
step: 2690, train loss: nan, train acuracy: 0.046875
step: 2690, val loss: nan, val acuracy: 0.10400000214576721
step: 2691, train loss: nan, train acuracy: 0.09375
step: 2691, val loss: nan, val acuracy: 0.10400000214576721
step: 2692, train loss: nan, train acuracy: 0.09375
step: 2692, val loss: nan, val acuracy: 0.10400000214576721
step: 2693, train loss: nan, train acuracy: 0.078125
step: 2693, val loss: nan, val acuracy: 0.10400000214576721
step: 2694, train loss: nan, train acuracy: 0.109375
step: 2694, val loss: nan, val acuracy: 0.10400000214576721
step: 2695, train loss: nan, train acuracy: 0.046875
step: 2695, val loss: nan, val acuracy: 0.10400000214576721
step: 2696, train loss: nan, train acuracy: 0.125
step: 2696, val loss: nan, val acuracy: 0.10400000214576721
step: 2697, train loss: nan, train acuracy: 0.078125
step: 2697, val loss: nan, val acuracy: 0.10400000214576721
step: 2698, train loss: nan, train acuracy: 0.046875
step: 2698, val loss: nan, val acuracy: 0.10400000214576721
step: 2699, train loss: nan, train acuracy: 0.046875
step: 2699, val loss: nan, val acuracy: 0.10400000214576721
step: 2700, train loss: nan, train acuracy: 0.171875
step: 2700, val loss: nan, val acuracy: 0.10400000214576721
step: 2701, train loss: nan, train acuracy: 0.09375
step: 2701, val loss: nan, val acuracy: 0.10400000214576721
step: 2702, train loss: nan, train acuracy: 0.078125
step: 2702, val loss: nan, val acuracy: 0.10400000214576721
step: 2703, train loss: nan, train acuracy: 0.0625
step: 2703, val loss: nan, val acuracy: 0.10400000214576721
step: 2704, train loss: nan, train acuracy: 0.09375
step: 2704, val loss: nan, val acuracy: 0.10400000214576721
step: 2705, train loss: nan, train acuracy: 0.0625
step: 2705, val loss: nan, val acuracy: 0.10400000214576721
step: 2706, train loss: nan, train acuracy: 0.09375
step: 2706, val loss: nan, val acuracy: 0.10400000214576721
step: 2707, train loss: nan, train acuracy: 0.140625
step: 2707, val loss: nan, val acuracy: 0.10400000214576721
step: 2708, train loss: nan, train acuracy: 0.109375
step: 2708, val loss: nan, val acuracy: 0.10400000214576721
step: 2709, train loss: nan, train acuracy: 0.0625
step: 2709, val loss: nan, val acuracy: 0.10400000214576721
step: 2710, train loss: nan, train acuracy: 0.09375
step: 2710, val loss: nan, val acuracy: 0.10400000214576721
step: 2711, train loss: nan, train acuracy: 0.046875
step: 2711, val loss: nan, val acuracy: 0.10400000214576721
step: 2712, train loss: nan, train acuracy: 0.078125
step: 2712, val loss: nan, val acuracy: 0.10400000214576721
step: 2713, train loss: nan, train acuracy: 0.0625
step: 2713, val loss: nan, val acuracy: 0.10400000214576721
step: 2714, train loss: nan, train acuracy: 0.09375
step: 2714, val loss: nan, val acuracy: 0.10400000214576721
step: 2715, train loss: nan, train acuracy: 0.078125
step: 2715, val loss: nan, val acuracy: 0.10400000214576721
step: 2716, train loss: nan, train acuracy: 0.109375
step: 2716, val loss: nan, val acuracy: 0.10400000214576721
step: 2717, train loss: nan, train acuracy: 0.0
step: 2717, val loss: nan, val acuracy: 0.10400000214576721
step: 2718, train loss: nan, train acuracy: 0.03125
step: 2718, val loss: nan, val acuracy: 0.10400000214576721
step: 2719, train loss: nan, train acuracy: 0.15625
step: 2719, val loss: nan, val acuracy: 0.10400000214576721
step: 2720, train loss: nan, train acuracy: 0.078125
step: 2720, val loss: nan, val acuracy: 0.10400000214576721
step: 2721, train loss: nan, train acuracy: 0.109375
step: 2721, val loss: nan, val acuracy: 0.10400000214576721
step: 2722, train loss: nan, train acuracy: 0.09375
step: 2722, val loss: nan, val acuracy: 0.10400000214576721
step: 2723, train loss: nan, train acuracy: 0.109375
step: 2723, val loss: nan, val acuracy: 0.10400000214576721
step: 2724, train loss: nan, train acuracy: 0.0625
step: 2724, val loss: nan, val acuracy: 0.10400000214576721
step: 2725, train loss: nan, train acuracy: 0.09375
step: 2725, val loss: nan, val acuracy: 0.10400000214576721
step: 2726, train loss: nan, train acuracy: 0.125
step: 2726, val loss: nan, val acuracy: 0.10400000214576721
step: 2727, train loss: nan, train acuracy: 0.203125
step: 2727, val loss: nan, val acuracy: 0.10400000214576721
step: 2728, train loss: nan, train acuracy: 0.125
step: 2728, val loss: nan, val acuracy: 0.10400000214576721
step: 2729, train loss: nan, train acuracy: 0.109375
step: 2729, val loss: nan, val acuracy: 0.10400000214576721
step: 2730, train loss: nan, train acuracy: 0.125
step: 2730, val loss: nan, val acuracy: 0.10400000214576721
step: 2731, train loss: nan, train acuracy: 0.0625
step: 2731, val loss: nan, val acuracy: 0.10400000214576721
step: 2732, train loss: nan, train acuracy: 0.046875
step: 2732, val loss: nan, val acuracy: 0.10400000214576721
step: 2733, train loss: nan, train acuracy: 0.03125
step: 2733, val loss: nan, val acuracy: 0.10400000214576721
step: 2734, train loss: nan, train acuracy: 0.078125
step: 2734, val loss: nan, val acuracy: 0.10400000214576721
step: 2735, train loss: nan, train acuracy: 0.03125
step: 2735, val loss: nan, val acuracy: 0.10400000214576721
step: 2736, train loss: nan, train acuracy: 0.078125
step: 2736, val loss: nan, val acuracy: 0.10400000214576721
step: 2737, train loss: nan, train acuracy: 0.078125
step: 2737, val loss: nan, val acuracy: 0.10400000214576721
step: 2738, train loss: nan, train acuracy: 0.140625
step: 2738, val loss: nan, val acuracy: 0.10400000959634781
step: 2739, train loss: nan, train acuracy: 0.09375
step: 2739, val loss: nan, val acuracy: 0.10400000214576721
step: 2740, train loss: nan, train acuracy: 0.078125
step: 2740, val loss: nan, val acuracy: 0.10400000214576721
step: 2741, train loss: nan, train acuracy: 0.078125
step: 2741, val loss: nan, val acuracy: 0.10400000214576721
step: 2742, train loss: nan, train acuracy: 0.171875
step: 2742, val loss: nan, val acuracy: 0.10400000214576721
step: 2743, train loss: nan, train acuracy: 0.078125
step: 2743, val loss: nan, val acuracy: 0.10400000214576721
step: 2744, train loss: nan, train acuracy: 0.15625
step: 2744, val loss: nan, val acuracy: 0.10400000214576721
step: 2745, train loss: nan, train acuracy: 0.140625
step: 2745, val loss: nan, val acuracy: 0.10400000214576721
step: 2746, train loss: nan, train acuracy: 0.03125
step: 2746, val loss: nan, val acuracy: 0.10400000214576721
step: 2747, train loss: nan, train acuracy: 0.15625
step: 2747, val loss: nan, val acuracy: 0.10400000214576721
step: 2748, train loss: nan, train acuracy: 0.09375
step: 2748, val loss: nan, val acuracy: 0.10400000214576721
step: 2749, train loss: nan, train acuracy: 0.09375
step: 2749, val loss: nan, val acuracy: 0.10400000214576721
step: 2750, train loss: nan, train acuracy: 0.0625
step: 2750, val loss: nan, val acuracy: 0.10400000214576721
step: 2751, train loss: nan, train acuracy: 0.078125
step: 2751, val loss: nan, val acuracy: 0.10400000214576721
step: 2752, train loss: nan, train acuracy: 0.046875
step: 2752, val loss: nan, val acuracy: 0.10400000214576721
step: 2753, train loss: nan, train acuracy: 0.109375
step: 2753, val loss: nan, val acuracy: 0.10400000214576721
step: 2754, train loss: nan, train acuracy: 0.125
step: 2754, val loss: nan, val acuracy: 0.10400000214576721
step: 2755, train loss: nan, train acuracy: 0.09375
step: 2755, val loss: nan, val acuracy: 0.10400000214576721
step: 2756, train loss: nan, train acuracy: 0.125
step: 2756, val loss: nan, val acuracy: 0.10400000214576721
step: 2757, train loss: nan, train acuracy: 0.046875
step: 2757, val loss: nan, val acuracy: 0.10400000214576721
step: 2758, train loss: nan, train acuracy: 0.125
step: 2758, val loss: nan, val acuracy: 0.10400000214576721
step: 2759, train loss: nan, train acuracy: 0.125
step: 2759, val loss: nan, val acuracy: 0.10400000214576721
step: 2760, train loss: nan, train acuracy: 0.078125
step: 2760, val loss: nan, val acuracy: 0.10400000214576721
step: 2761, train loss: nan, train acuracy: 0.078125
step: 2761, val loss: nan, val acuracy: 0.10400000214576721
step: 2762, train loss: nan, train acuracy: 0.171875
step: 2762, val loss: nan, val acuracy: 0.10400000214576721
step: 2763, train loss: nan, train acuracy: 0.09375
step: 2763, val loss: nan, val acuracy: 0.10400000214576721
step: 2764, train loss: nan, train acuracy: 0.0625
step: 2764, val loss: nan, val acuracy: 0.10400000214576721
step: 2765, train loss: nan, train acuracy: 0.09375
step: 2765, val loss: nan, val acuracy: 0.10400000214576721
step: 2766, train loss: nan, train acuracy: 0.109375
step: 2766, val loss: nan, val acuracy: 0.10400000214576721
step: 2767, train loss: nan, train acuracy: 0.203125
step: 2767, val loss: nan, val acuracy: 0.10400000214576721
step: 2768, train loss: nan, train acuracy: 0.09375
step: 2768, val loss: nan, val acuracy: 0.10400000214576721
step: 2769, train loss: nan, train acuracy: 0.078125
step: 2769, val loss: nan, val acuracy: 0.10400000214576721
step: 2770, train loss: nan, train acuracy: 0.109375
step: 2770, val loss: nan, val acuracy: 0.10400000214576721
step: 2771, train loss: nan, train acuracy: 0.09375
step: 2771, val loss: nan, val acuracy: 0.10400000214576721
step: 2772, train loss: nan, train acuracy: 0.078125
step: 2772, val loss: nan, val acuracy: 0.10400000214576721
step: 2773, train loss: nan, train acuracy: 0.203125
step: 2773, val loss: nan, val acuracy: 0.10400000959634781
step: 2774, train loss: nan, train acuracy: 0.046875
step: 2774, val loss: nan, val acuracy: 0.10400000214576721
step: 2775, train loss: nan, train acuracy: 0.046875
step: 2775, val loss: nan, val acuracy: 0.10400000214576721
step: 2776, train loss: nan, train acuracy: 0.109375
step: 2776, val loss: nan, val acuracy: 0.10400000214576721
step: 2777, train loss: nan, train acuracy: 0.078125
step: 2777, val loss: nan, val acuracy: 0.10400000214576721
step: 2778, train loss: nan, train acuracy: 0.09375
step: 2778, val loss: nan, val acuracy: 0.10400000214576721
step: 2779, train loss: nan, train acuracy: 0.109375
step: 2779, val loss: nan, val acuracy: 0.10400000214576721
step: 2780, train loss: nan, train acuracy: 0.015625
step: 2780, val loss: nan, val acuracy: 0.10400000214576721
step: 2781, train loss: nan, train acuracy: 0.125
step: 2781, val loss: nan, val acuracy: 0.10400000214576721
step: 2782, train loss: nan, train acuracy: 0.0625
step: 2782, val loss: nan, val acuracy: 0.10400000214576721
step: 2783, train loss: nan, train acuracy: 0.09375
step: 2783, val loss: nan, val acuracy: 0.10400000214576721
step: 2784, train loss: nan, train acuracy: 0.046875
step: 2784, val loss: nan, val acuracy: 0.10400000214576721
step: 2785, train loss: nan, train acuracy: 0.1875
step: 2785, val loss: nan, val acuracy: 0.10400000214576721
step: 2786, train loss: nan, train acuracy: 0.046875
step: 2786, val loss: nan, val acuracy: 0.10400000214576721
step: 2787, train loss: nan, train acuracy: 0.09375
step: 2787, val loss: nan, val acuracy: 0.10400000214576721
step: 2788, train loss: nan, train acuracy: 0.109375
step: 2788, val loss: nan, val acuracy: 0.10400000214576721
step: 2789, train loss: nan, train acuracy: 0.171875
step: 2789, val loss: nan, val acuracy: 0.10400000214576721
step: 2790, train loss: nan, train acuracy: 0.078125
step: 2790, val loss: nan, val acuracy: 0.10400000214576721
step: 2791, train loss: nan, train acuracy: 0.0625
step: 2791, val loss: nan, val acuracy: 0.10400000214576721
step: 2792, train loss: nan, train acuracy: 0.109375
step: 2792, val loss: nan, val acuracy: 0.10400000214576721
step: 2793, train loss: nan, train acuracy: 0.125
step: 2793, val loss: nan, val acuracy: 0.10400000214576721
step: 2794, train loss: nan, train acuracy: 0.109375
step: 2794, val loss: nan, val acuracy: 0.10400000214576721
step: 2795, train loss: nan, train acuracy: 0.09375
step: 2795, val loss: nan, val acuracy: 0.10400000214576721
step: 2796, train loss: nan, train acuracy: 0.078125
step: 2796, val loss: nan, val acuracy: 0.10400000214576721
step: 2797, train loss: nan, train acuracy: 0.109375
step: 2797, val loss: nan, val acuracy: 0.10400000214576721
step: 2798, train loss: nan, train acuracy: 0.078125
step: 2798, val loss: nan, val acuracy: 0.10400000214576721
step: 2799, train loss: nan, train acuracy: 0.078125
step: 2799, val loss: nan, val acuracy: 0.10400000214576721
step: 2800, train loss: nan, train acuracy: 0.125
step: 2800, val loss: nan, val acuracy: 0.10400000214576721
step: 2801, train loss: nan, train acuracy: 0.125
step: 2801, val loss: nan, val acuracy: 0.10400000214576721
step: 2802, train loss: nan, train acuracy: 0.125
step: 2802, val loss: nan, val acuracy: 0.10400000214576721
step: 2803, train loss: nan, train acuracy: 0.140625
step: 2803, val loss: nan, val acuracy: 0.10400000214576721
step: 2804, train loss: nan, train acuracy: 0.03125
step: 2804, val loss: nan, val acuracy: 0.10400000214576721
step: 2805, train loss: nan, train acuracy: 0.046875
step: 2805, val loss: nan, val acuracy: 0.10400000214576721
step: 2806, train loss: nan, train acuracy: 0.03125
step: 2806, val loss: nan, val acuracy: 0.10400000214576721
step: 2807, train loss: nan, train acuracy: 0.140625
step: 2807, val loss: nan, val acuracy: 0.10400000214576721
step: 2808, train loss: nan, train acuracy: 0.09375
step: 2808, val loss: nan, val acuracy: 0.10400000214576721
step: 2809, train loss: nan, train acuracy: 0.046875
step: 2809, val loss: nan, val acuracy: 0.10400000214576721
step: 2810, train loss: nan, train acuracy: 0.046875
step: 2810, val loss: nan, val acuracy: 0.10400000214576721
step: 2811, train loss: nan, train acuracy: 0.0625
step: 2811, val loss: nan, val acuracy: 0.10400000214576721
step: 2812, train loss: nan, train acuracy: 0.078125
step: 2812, val loss: nan, val acuracy: 0.10400000214576721
step: 2813, train loss: nan, train acuracy: 0.109375
step: 2813, val loss: nan, val acuracy: 0.10400000214576721
step: 2814, train loss: nan, train acuracy: 0.125
step: 2814, val loss: nan, val acuracy: 0.10400000214576721
step: 2815, train loss: nan, train acuracy: 0.0625
step: 2815, val loss: nan, val acuracy: 0.10400000214576721
step: 2816, train loss: nan, train acuracy: 0.078125
step: 2816, val loss: nan, val acuracy: 0.10400000214576721
step: 2817, train loss: nan, train acuracy: 0.09375
step: 2817, val loss: nan, val acuracy: 0.10400000214576721
step: 2818, train loss: nan, train acuracy: 0.09375
step: 2818, val loss: nan, val acuracy: 0.10400000214576721
step: 2819, train loss: nan, train acuracy: 0.078125
step: 2819, val loss: nan, val acuracy: 0.10400000214576721
step: 2820, train loss: nan, train acuracy: 0.09375
step: 2820, val loss: nan, val acuracy: 0.10400000214576721
step: 2821, train loss: nan, train acuracy: 0.046875
step: 2821, val loss: nan, val acuracy: 0.10400000214576721
step: 2822, train loss: nan, train acuracy: 0.15625
step: 2822, val loss: nan, val acuracy: 0.10400000214576721
step: 2823, train loss: nan, train acuracy: 0.09375
step: 2823, val loss: nan, val acuracy: 0.10400000214576721
step: 2824, train loss: nan, train acuracy: 0.09375
step: 2824, val loss: nan, val acuracy: 0.10400000214576721
step: 2825, train loss: nan, train acuracy: 0.046875
step: 2825, val loss: nan, val acuracy: 0.10400000214576721
step: 2826, train loss: nan, train acuracy: 0.078125
step: 2826, val loss: nan, val acuracy: 0.10400000214576721
step: 2827, train loss: nan, train acuracy: 0.1875
step: 2827, val loss: nan, val acuracy: 0.10400000214576721
step: 2828, train loss: nan, train acuracy: 0.1875
step: 2828, val loss: nan, val acuracy: 0.10400000214576721
step: 2829, train loss: nan, train acuracy: 0.109375
step: 2829, val loss: nan, val acuracy: 0.10400000214576721
step: 2830, train loss: nan, train acuracy: 0.125
step: 2830, val loss: nan, val acuracy: 0.10400000214576721
step: 2831, train loss: nan, train acuracy: 0.078125
step: 2831, val loss: nan, val acuracy: 0.10400000214576721
step: 2832, train loss: nan, train acuracy: 0.125
step: 2832, val loss: nan, val acuracy: 0.10400000214576721
step: 2833, train loss: nan, train acuracy: 0.078125
step: 2833, val loss: nan, val acuracy: 0.10400000214576721
step: 2834, train loss: nan, train acuracy: 0.078125
step: 2834, val loss: nan, val acuracy: 0.10400000214576721
step: 2835, train loss: nan, train acuracy: 0.03125
step: 2835, val loss: nan, val acuracy: 0.10400000214576721
step: 2836, train loss: nan, train acuracy: 0.1875
step: 2836, val loss: nan, val acuracy: 0.10400000214576721
step: 2837, train loss: nan, train acuracy: 0.078125
step: 2837, val loss: nan, val acuracy: 0.10400000214576721
step: 2838, train loss: nan, train acuracy: 0.0625
step: 2838, val loss: nan, val acuracy: 0.10400000214576721
step: 2839, train loss: nan, train acuracy: 0.0625
step: 2839, val loss: nan, val acuracy: 0.10400000214576721
step: 2840, train loss: nan, train acuracy: 0.171875
step: 2840, val loss: nan, val acuracy: 0.10400000214576721
step: 2841, train loss: nan, train acuracy: 0.09375
step: 2841, val loss: nan, val acuracy: 0.10400000214576721
step: 2842, train loss: nan, train acuracy: 0.078125
step: 2842, val loss: nan, val acuracy: 0.10400000214576721
step: 2843, train loss: nan, train acuracy: 0.125
step: 2843, val loss: nan, val acuracy: 0.10400000214576721
step: 2844, train loss: nan, train acuracy: 0.0625
step: 2844, val loss: nan, val acuracy: 0.10400000214576721
step: 2845, train loss: nan, train acuracy: 0.03125
step: 2845, val loss: nan, val acuracy: 0.10400000214576721
step: 2846, train loss: nan, train acuracy: 0.09375
step: 2846, val loss: nan, val acuracy: 0.10400000214576721
step: 2847, train loss: nan, train acuracy: 0.046875
step: 2847, val loss: nan, val acuracy: 0.10400000214576721
step: 2848, train loss: nan, train acuracy: 0.125
step: 2848, val loss: nan, val acuracy: 0.10400000214576721
step: 2849, train loss: nan, train acuracy: 0.109375
step: 2849, val loss: nan, val acuracy: 0.10400000214576721
step: 2850, train loss: nan, train acuracy: 0.125
step: 2850, val loss: nan, val acuracy: 0.10400000214576721
step: 2851, train loss: nan, train acuracy: 0.171875
step: 2851, val loss: nan, val acuracy: 0.10400000214576721
step: 2852, train loss: nan, train acuracy: 0.0625
step: 2852, val loss: nan, val acuracy: 0.10400000214576721
step: 2853, train loss: nan, train acuracy: 0.09375
step: 2853, val loss: nan, val acuracy: 0.10400000214576721
step: 2854, train loss: nan, train acuracy: 0.0625
step: 2854, val loss: nan, val acuracy: 0.10400000214576721
step: 2855, train loss: nan, train acuracy: 0.03125
step: 2855, val loss: nan, val acuracy: 0.10400000214576721
step: 2856, train loss: nan, train acuracy: 0.078125
step: 2856, val loss: nan, val acuracy: 0.10400000214576721
step: 2857, train loss: nan, train acuracy: 0.09375
step: 2857, val loss: nan, val acuracy: 0.10400000214576721
step: 2858, train loss: nan, train acuracy: 0.09375
step: 2858, val loss: nan, val acuracy: 0.10400000214576721
step: 2859, train loss: nan, train acuracy: 0.109375
step: 2859, val loss: nan, val acuracy: 0.10400000214576721
step: 2860, train loss: nan, train acuracy: 0.09375
step: 2860, val loss: nan, val acuracy: 0.10400000214576721
step: 2861, train loss: nan, train acuracy: 0.09375
step: 2861, val loss: nan, val acuracy: 0.10400000214576721
step: 2862, train loss: nan, train acuracy: 0.171875
step: 2862, val loss: nan, val acuracy: 0.10400000214576721
step: 2863, train loss: nan, train acuracy: 0.078125
step: 2863, val loss: nan, val acuracy: 0.10400000214576721
step: 2864, train loss: nan, train acuracy: 0.140625
step: 2864, val loss: nan, val acuracy: 0.10400000214576721
step: 2865, train loss: nan, train acuracy: 0.140625
step: 2865, val loss: nan, val acuracy: 0.10400000214576721
step: 2866, train loss: nan, train acuracy: 0.078125
step: 2866, val loss: nan, val acuracy: 0.10400000214576721
step: 2867, train loss: nan, train acuracy: 0.125
step: 2867, val loss: nan, val acuracy: 0.10400000214576721
step: 2868, train loss: nan, train acuracy: 0.125
step: 2868, val loss: nan, val acuracy: 0.10400000214576721
step: 2869, train loss: nan, train acuracy: 0.140625
step: 2869, val loss: nan, val acuracy: 0.10400000214576721
step: 2870, train loss: nan, train acuracy: 0.171875
step: 2870, val loss: nan, val acuracy: 0.10400000214576721
step: 2871, train loss: nan, train acuracy: 0.109375
step: 2871, val loss: nan, val acuracy: 0.10400000214576721
step: 2872, train loss: nan, train acuracy: 0.078125
step: 2872, val loss: nan, val acuracy: 0.10400000214576721
step: 2873, train loss: nan, train acuracy: 0.09375
step: 2873, val loss: nan, val acuracy: 0.10400000214576721
step: 2874, train loss: nan, train acuracy: 0.078125
step: 2874, val loss: nan, val acuracy: 0.10400000214576721
step: 2875, train loss: nan, train acuracy: 0.078125
step: 2875, val loss: nan, val acuracy: 0.10400000214576721
step: 2876, train loss: nan, train acuracy: 0.109375
step: 2876, val loss: nan, val acuracy: 0.10400000214576721
step: 2877, train loss: nan, train acuracy: 0.046875
step: 2877, val loss: nan, val acuracy: 0.10400000214576721
step: 2878, train loss: nan, train acuracy: 0.078125
step: 2878, val loss: nan, val acuracy: 0.10400000214576721
step: 2879, train loss: nan, train acuracy: 0.0625
step: 2879, val loss: nan, val acuracy: 0.10400000214576721
step: 2880, train loss: nan, train acuracy: 0.078125
step: 2880, val loss: nan, val acuracy: 0.10400000214576721
step: 2881, train loss: nan, train acuracy: 0.09375
step: 2881, val loss: nan, val acuracy: 0.10400000214576721
step: 2882, train loss: nan, train acuracy: 0.109375
step: 2882, val loss: nan, val acuracy: 0.10400000214576721
step: 2883, train loss: nan, train acuracy: 0.09375
step: 2883, val loss: nan, val acuracy: 0.10400000214576721
step: 2884, train loss: nan, train acuracy: 0.125
step: 2884, val loss: nan, val acuracy: 0.10400000214576721
step: 2885, train loss: nan, train acuracy: 0.125
step: 2885, val loss: nan, val acuracy: 0.10400000214576721
step: 2886, train loss: nan, train acuracy: 0.0625
step: 2886, val loss: nan, val acuracy: 0.10400000214576721
step: 2887, train loss: nan, train acuracy: 0.125
step: 2887, val loss: nan, val acuracy: 0.10400000214576721
step: 2888, train loss: nan, train acuracy: 0.078125
step: 2888, val loss: nan, val acuracy: 0.10400000214576721
step: 2889, train loss: nan, train acuracy: 0.09375
step: 2889, val loss: nan, val acuracy: 0.10400000214576721
step: 2890, train loss: nan, train acuracy: 0.171875
step: 2890, val loss: nan, val acuracy: 0.10400000214576721
step: 2891, train loss: nan, train acuracy: 0.078125
step: 2891, val loss: nan, val acuracy: 0.10400000214576721
step: 2892, train loss: nan, train acuracy: 0.125
step: 2892, val loss: nan, val acuracy: 0.10400000214576721
step: 2893, train loss: nan, train acuracy: 0.0625
step: 2893, val loss: nan, val acuracy: 0.10400000214576721
step: 2894, train loss: nan, train acuracy: 0.078125
step: 2894, val loss: nan, val acuracy: 0.10400000214576721
step: 2895, train loss: nan, train acuracy: 0.109375
step: 2895, val loss: nan, val acuracy: 0.10400000214576721
step: 2896, train loss: nan, train acuracy: 0.15625
step: 2896, val loss: nan, val acuracy: 0.10400000214576721
step: 2897, train loss: nan, train acuracy: 0.15625
step: 2897, val loss: nan, val acuracy: 0.10400000214576721
step: 2898, train loss: nan, train acuracy: 0.0625
step: 2898, val loss: nan, val acuracy: 0.10400000214576721
step: 2899, train loss: nan, train acuracy: 0.109375
step: 2899, val loss: nan, val acuracy: 0.10400000214576721
step: 2900, train loss: nan, train acuracy: 0.03125
step: 2900, val loss: nan, val acuracy: 0.10400000214576721
step: 2901, train loss: nan, train acuracy: 0.15625
step: 2901, val loss: nan, val acuracy: 0.10400000214576721
step: 2902, train loss: nan, train acuracy: 0.09375
step: 2902, val loss: nan, val acuracy: 0.10400000214576721
step: 2903, train loss: nan, train acuracy: 0.078125
step: 2903, val loss: nan, val acuracy: 0.10400000214576721
step: 2904, train loss: nan, train acuracy: 0.09375
step: 2904, val loss: nan, val acuracy: 0.10400000214576721
step: 2905, train loss: nan, train acuracy: 0.09375
step: 2905, val loss: nan, val acuracy: 0.10400000214576721
step: 2906, train loss: nan, train acuracy: 0.109375
step: 2906, val loss: nan, val acuracy: 0.10400000214576721
step: 2907, train loss: nan, train acuracy: 0.140625
step: 2907, val loss: nan, val acuracy: 0.10400000214576721
step: 2908, train loss: nan, train acuracy: 0.125
step: 2908, val loss: nan, val acuracy: 0.10400000214576721
step: 2909, train loss: nan, train acuracy: 0.09375
step: 2909, val loss: nan, val acuracy: 0.10400000214576721
step: 2910, train loss: nan, train acuracy: 0.078125
step: 2910, val loss: nan, val acuracy: 0.10400000214576721
step: 2911, train loss: nan, train acuracy: 0.0625
step: 2911, val loss: nan, val acuracy: 0.10400000214576721
step: 2912, train loss: nan, train acuracy: 0.125
step: 2912, val loss: nan, val acuracy: 0.10400000214576721
step: 2913, train loss: nan, train acuracy: 0.125
step: 2913, val loss: nan, val acuracy: 0.10400000214576721
step: 2914, train loss: nan, train acuracy: 0.09375
step: 2914, val loss: nan, val acuracy: 0.10400000214576721
step: 2915, train loss: nan, train acuracy: 0.125
step: 2915, val loss: nan, val acuracy: 0.10400000214576721
step: 2916, train loss: nan, train acuracy: 0.09375
step: 2916, val loss: nan, val acuracy: 0.10400000214576721
step: 2917, train loss: nan, train acuracy: 0.15625
step: 2917, val loss: nan, val acuracy: 0.10400000214576721
step: 2918, train loss: nan, train acuracy: 0.078125
step: 2918, val loss: nan, val acuracy: 0.10400000214576721
step: 2919, train loss: nan, train acuracy: 0.109375
step: 2919, val loss: nan, val acuracy: 0.10400000214576721
step: 2920, train loss: nan, train acuracy: 0.03125
step: 2920, val loss: nan, val acuracy: 0.10400000214576721
step: 2921, train loss: nan, train acuracy: 0.046875
step: 2921, val loss: nan, val acuracy: 0.10400000214576721
step: 2922, train loss: nan, train acuracy: 0.125
step: 2922, val loss: nan, val acuracy: 0.10400000214576721
step: 2923, train loss: nan, train acuracy: 0.09375
step: 2923, val loss: nan, val acuracy: 0.10400000214576721
step: 2924, train loss: nan, train acuracy: 0.140625
step: 2924, val loss: nan, val acuracy: 0.10400000214576721
step: 2925, train loss: nan, train acuracy: 0.0625
step: 2925, val loss: nan, val acuracy: 0.10400000214576721
step: 2926, train loss: nan, train acuracy: 0.125
step: 2926, val loss: nan, val acuracy: 0.10400000214576721
step: 2927, train loss: nan, train acuracy: 0.125
step: 2927, val loss: nan, val acuracy: 0.10400000214576721
step: 2928, train loss: nan, train acuracy: 0.078125
step: 2928, val loss: nan, val acuracy: 0.10400000214576721
step: 2929, train loss: nan, train acuracy: 0.0625
step: 2929, val loss: nan, val acuracy: 0.10400000214576721
step: 2930, train loss: nan, train acuracy: 0.078125
step: 2930, val loss: nan, val acuracy: 0.10400000214576721
step: 2931, train loss: nan, train acuracy: 0.15625
step: 2931, val loss: nan, val acuracy: 0.10400000214576721
step: 2932, train loss: nan, train acuracy: 0.109375
step: 2932, val loss: nan, val acuracy: 0.10400000214576721
step: 2933, train loss: nan, train acuracy: 0.109375
step: 2933, val loss: nan, val acuracy: 0.10400000214576721
step: 2934, train loss: nan, train acuracy: 0.078125
step: 2934, val loss: nan, val acuracy: 0.10400000214576721
step: 2935, train loss: nan, train acuracy: 0.15625
step: 2935, val loss: nan, val acuracy: 0.10400000214576721
step: 2936, train loss: nan, train acuracy: 0.125
step: 2936, val loss: nan, val acuracy: 0.10400000214576721
step: 2937, train loss: nan, train acuracy: 0.09375
step: 2937, val loss: nan, val acuracy: 0.10400000214576721
step: 2938, train loss: nan, train acuracy: 0.078125
step: 2938, val loss: nan, val acuracy: 0.10400000214576721
step: 2939, train loss: nan, train acuracy: 0.140625
step: 2939, val loss: nan, val acuracy: 0.10400000214576721
step: 2940, train loss: nan, train acuracy: 0.0625
step: 2940, val loss: nan, val acuracy: 0.10400000214576721
step: 2941, train loss: nan, train acuracy: 0.109375
step: 2941, val loss: nan, val acuracy: 0.10400000214576721
step: 2942, train loss: nan, train acuracy: 0.125
step: 2942, val loss: nan, val acuracy: 0.10400000214576721
step: 2943, train loss: nan, train acuracy: 0.109375
step: 2943, val loss: nan, val acuracy: 0.10400000214576721
step: 2944, train loss: nan, train acuracy: 0.078125
step: 2944, val loss: nan, val acuracy: 0.10400000214576721
step: 2945, train loss: nan, train acuracy: 0.0625
step: 2945, val loss: nan, val acuracy: 0.10400000214576721
step: 2946, train loss: nan, train acuracy: 0.046875
step: 2946, val loss: nan, val acuracy: 0.10400000214576721
step: 2947, train loss: nan, train acuracy: 0.109375
step: 2947, val loss: nan, val acuracy: 0.10400000214576721
step: 2948, train loss: nan, train acuracy: 0.0625
step: 2948, val loss: nan, val acuracy: 0.10400000214576721
step: 2949, train loss: nan, train acuracy: 0.046875
step: 2949, val loss: nan, val acuracy: 0.10400000214576721
step: 2950, train loss: nan, train acuracy: 0.078125
step: 2950, val loss: nan, val acuracy: 0.10400000214576721
step: 2951, train loss: nan, train acuracy: 0.0625
step: 2951, val loss: nan, val acuracy: 0.10400000214576721
step: 2952, train loss: nan, train acuracy: 0.046875
step: 2952, val loss: nan, val acuracy: 0.10400000214576721
step: 2953, train loss: nan, train acuracy: 0.0625
step: 2953, val loss: nan, val acuracy: 0.10400000214576721
step: 2954, train loss: nan, train acuracy: 0.09375
step: 2954, val loss: nan, val acuracy: 0.10400000214576721
step: 2955, train loss: nan, train acuracy: 0.078125
step: 2955, val loss: nan, val acuracy: 0.10400000214576721
step: 2956, train loss: nan, train acuracy: 0.109375
step: 2956, val loss: nan, val acuracy: 0.10400000214576721
step: 2957, train loss: nan, train acuracy: 0.078125
step: 2957, val loss: nan, val acuracy: 0.10400000214576721
step: 2958, train loss: nan, train acuracy: 0.0625
step: 2958, val loss: nan, val acuracy: 0.10400000214576721
step: 2959, train loss: nan, train acuracy: 0.0625
step: 2959, val loss: nan, val acuracy: 0.10400000214576721
step: 2960, train loss: nan, train acuracy: 0.078125
step: 2960, val loss: nan, val acuracy: 0.10400000214576721
step: 2961, train loss: nan, train acuracy: 0.203125
step: 2961, val loss: nan, val acuracy: 0.10400000214576721
step: 2962, train loss: nan, train acuracy: 0.125
step: 2962, val loss: nan, val acuracy: 0.10400000214576721
step: 2963, train loss: nan, train acuracy: 0.109375
step: 2963, val loss: nan, val acuracy: 0.10400000214576721
step: 2964, train loss: nan, train acuracy: 0.078125
step: 2964, val loss: nan, val acuracy: 0.10400000214576721
step: 2965, train loss: nan, train acuracy: 0.109375
step: 2965, val loss: nan, val acuracy: 0.10400000214576721
step: 2966, train loss: nan, train acuracy: 0.109375
step: 2966, val loss: nan, val acuracy: 0.10400000214576721
step: 2967, train loss: nan, train acuracy: 0.0625
step: 2967, val loss: nan, val acuracy: 0.10400000214576721
step: 2968, train loss: nan, train acuracy: 0.15625
step: 2968, val loss: nan, val acuracy: 0.10400000214576721
step: 2969, train loss: nan, train acuracy: 0.125
step: 2969, val loss: nan, val acuracy: 0.10400000214576721
step: 2970, train loss: nan, train acuracy: 0.09375
step: 2970, val loss: nan, val acuracy: 0.10400000214576721
step: 2971, train loss: nan, train acuracy: 0.140625
step: 2971, val loss: nan, val acuracy: 0.10400000214576721
step: 2972, train loss: nan, train acuracy: 0.140625
step: 2972, val loss: nan, val acuracy: 0.10400000214576721
step: 2973, train loss: nan, train acuracy: 0.078125
step: 2973, val loss: nan, val acuracy: 0.10400000214576721
step: 2974, train loss: nan, train acuracy: 0.09375
step: 2974, val loss: nan, val acuracy: 0.10400000214576721
step: 2975, train loss: nan, train acuracy: 0.140625
step: 2975, val loss: nan, val acuracy: 0.10400000214576721
step: 2976, train loss: nan, train acuracy: 0.15625
step: 2976, val loss: nan, val acuracy: 0.10400000214576721
step: 2977, train loss: nan, train acuracy: 0.140625
step: 2977, val loss: nan, val acuracy: 0.10400000214576721
step: 2978, train loss: nan, train acuracy: 0.109375
step: 2978, val loss: nan, val acuracy: 0.10400000214576721
step: 2979, train loss: nan, train acuracy: 0.09375
step: 2979, val loss: nan, val acuracy: 0.10400000214576721
step: 2980, train loss: nan, train acuracy: 0.078125
step: 2980, val loss: nan, val acuracy: 0.10400000214576721
step: 2981, train loss: nan, train acuracy: 0.109375
step: 2981, val loss: nan, val acuracy: 0.10400000214576721
step: 2982, train loss: nan, train acuracy: 0.078125
step: 2982, val loss: nan, val acuracy: 0.10400000214576721
step: 2983, train loss: nan, train acuracy: 0.09375
step: 2983, val loss: nan, val acuracy: 0.10400000214576721
step: 2984, train loss: nan, train acuracy: 0.046875
step: 2984, val loss: nan, val acuracy: 0.10400000214576721
step: 2985, train loss: nan, train acuracy: 0.125
step: 2985, val loss: nan, val acuracy: 0.10400000214576721
step: 2986, train loss: nan, train acuracy: 0.140625
step: 2986, val loss: nan, val acuracy: 0.10400000214576721
step: 2987, train loss: nan, train acuracy: 0.125
step: 2987, val loss: nan, val acuracy: 0.10400000214576721
step: 2988, train loss: nan, train acuracy: 0.140625
step: 2988, val loss: nan, val acuracy: 0.10400000214576721
step: 2989, train loss: nan, train acuracy: 0.109375
step: 2989, val loss: nan, val acuracy: 0.10400000214576721
step: 2990, train loss: nan, train acuracy: 0.046875
step: 2990, val loss: nan, val acuracy: 0.10400000214576721
step: 2991, train loss: nan, train acuracy: 0.109375
step: 2991, val loss: nan, val acuracy: 0.10400000214576721
step: 2992, train loss: nan, train acuracy: 0.0625
step: 2992, val loss: nan, val acuracy: 0.10400000214576721
step: 2993, train loss: nan, train acuracy: 0.09375
step: 2993, val loss: nan, val acuracy: 0.10400000214576721
step: 2994, train loss: nan, train acuracy: 0.09375
step: 2994, val loss: nan, val acuracy: 0.10400000214576721
step: 2995, train loss: nan, train acuracy: 0.109375
step: 2995, val loss: nan, val acuracy: 0.10400000214576721
step: 2996, train loss: nan, train acuracy: 0.15625
step: 2996, val loss: nan, val acuracy: 0.10400000214576721
step: 2997, train loss: nan, train acuracy: 0.078125
step: 2997, val loss: nan, val acuracy: 0.10400000214576721
step: 2998, train loss: nan, train acuracy: 0.09375
step: 2998, val loss: nan, val acuracy: 0.10400000214576721
step: 2999, train loss: nan, train acuracy: 0.15625
step: 2999, val loss: nan, val acuracy: 0.10400000214576721
step: 3000, train loss: nan, train acuracy: 0.09375
step: 3000, val loss: nan, val acuracy: 0.10400000214576721
step: 3001, train loss: nan, train acuracy: 0.09375
step: 3001, val loss: nan, val acuracy: 0.10400000214576721
step: 3002, train loss: nan, train acuracy: 0.109375
step: 3002, val loss: nan, val acuracy: 0.10400000214576721
step: 3003, train loss: nan, train acuracy: 0.125
step: 3003, val loss: nan, val acuracy: 0.10400000214576721
step: 3004, train loss: nan, train acuracy: 0.125
step: 3004, val loss: nan, val acuracy: 0.10400000214576721
step: 3005, train loss: nan, train acuracy: 0.0625
step: 3005, val loss: nan, val acuracy: 0.10400000214576721
step: 3006, train loss: nan, train acuracy: 0.046875
step: 3006, val loss: nan, val acuracy: 0.10400000214576721
step: 3007, train loss: nan, train acuracy: 0.03125
step: 3007, val loss: nan, val acuracy: 0.10400000214576721
step: 3008, train loss: nan, train acuracy: 0.09375
step: 3008, val loss: nan, val acuracy: 0.10400000214576721
step: 3009, train loss: nan, train acuracy: 0.140625
step: 3009, val loss: nan, val acuracy: 0.10400000214576721
step: 3010, train loss: nan, train acuracy: 0.109375
step: 3010, val loss: nan, val acuracy: 0.10400000214576721
step: 3011, train loss: nan, train acuracy: 0.109375
step: 3011, val loss: nan, val acuracy: 0.10400000214576721
step: 3012, train loss: nan, train acuracy: 0.109375
step: 3012, val loss: nan, val acuracy: 0.10400000214576721
step: 3013, train loss: nan, train acuracy: 0.078125
step: 3013, val loss: nan, val acuracy: 0.10400000214576721
step: 3014, train loss: nan, train acuracy: 0.078125
step: 3014, val loss: nan, val acuracy: 0.10400000214576721
step: 3015, train loss: nan, train acuracy: 0.15625
step: 3015, val loss: nan, val acuracy: 0.10400000214576721
step: 3016, train loss: nan, train acuracy: 0.078125
step: 3016, val loss: nan, val acuracy: 0.10400000214576721
step: 3017, train loss: nan, train acuracy: 0.09375
step: 3017, val loss: nan, val acuracy: 0.10400000214576721
step: 3018, train loss: nan, train acuracy: 0.0625
step: 3018, val loss: nan, val acuracy: 0.10400000214576721
step: 3019, train loss: nan, train acuracy: 0.0625
step: 3019, val loss: nan, val acuracy: 0.10400000214576721
step: 3020, train loss: nan, train acuracy: 0.125
step: 3020, val loss: nan, val acuracy: 0.10400000214576721
step: 3021, train loss: nan, train acuracy: 0.1875
step: 3021, val loss: nan, val acuracy: 0.10400000214576721
step: 3022, train loss: nan, train acuracy: 0.078125
step: 3022, val loss: nan, val acuracy: 0.10400000214576721
step: 3023, train loss: nan, train acuracy: 0.125
step: 3023, val loss: nan, val acuracy: 0.10400000214576721
step: 3024, train loss: nan, train acuracy: 0.125
step: 3024, val loss: nan, val acuracy: 0.10400000214576721
step: 3025, train loss: nan, train acuracy: 0.09375
step: 3025, val loss: nan, val acuracy: 0.10400000214576721
step: 3026, train loss: nan, train acuracy: 0.109375
step: 3026, val loss: nan, val acuracy: 0.10400000214576721
step: 3027, train loss: nan, train acuracy: 0.046875
step: 3027, val loss: nan, val acuracy: 0.10400000214576721
step: 3028, train loss: nan, train acuracy: 0.078125
step: 3028, val loss: nan, val acuracy: 0.10400000214576721
step: 3029, train loss: nan, train acuracy: 0.078125
step: 3029, val loss: nan, val acuracy: 0.10400000214576721
step: 3030, train loss: nan, train acuracy: 0.078125
step: 3030, val loss: nan, val acuracy: 0.10400000214576721
step: 3031, train loss: nan, train acuracy: 0.0625
step: 3031, val loss: nan, val acuracy: 0.10400000214576721
step: 3032, train loss: nan, train acuracy: 0.078125
step: 3032, val loss: nan, val acuracy: 0.10400000214576721
step: 3033, train loss: nan, train acuracy: 0.046875
step: 3033, val loss: nan, val acuracy: 0.10400000214576721
step: 3034, train loss: nan, train acuracy: 0.125
step: 3034, val loss: nan, val acuracy: 0.10400000214576721
step: 3035, train loss: nan, train acuracy: 0.203125
step: 3035, val loss: nan, val acuracy: 0.10400000214576721
step: 3036, train loss: nan, train acuracy: 0.1875
step: 3036, val loss: nan, val acuracy: 0.10400000214576721
step: 3037, train loss: nan, train acuracy: 0.109375
step: 3037, val loss: nan, val acuracy: 0.10400000214576721
step: 3038, train loss: nan, train acuracy: 0.125
step: 3038, val loss: nan, val acuracy: 0.10400000214576721
step: 3039, train loss: nan, train acuracy: 0.046875
step: 3039, val loss: nan, val acuracy: 0.10400000214576721
step: 3040, train loss: nan, train acuracy: 0.109375
step: 3040, val loss: nan, val acuracy: 0.10400000214576721
step: 3041, train loss: nan, train acuracy: 0.109375
step: 3041, val loss: nan, val acuracy: 0.10400000214576721
step: 3042, train loss: nan, train acuracy: 0.140625
step: 3042, val loss: nan, val acuracy: 0.10400000214576721
step: 3043, train loss: nan, train acuracy: 0.09375
step: 3043, val loss: nan, val acuracy: 0.10400000214576721
step: 3044, train loss: nan, train acuracy: 0.15625
step: 3044, val loss: nan, val acuracy: 0.10400000214576721
step: 3045, train loss: nan, train acuracy: 0.0625
step: 3045, val loss: nan, val acuracy: 0.10400000214576721
step: 3046, train loss: nan, train acuracy: 0.09375
step: 3046, val loss: nan, val acuracy: 0.10400000214576721
step: 3047, train loss: nan, train acuracy: 0.09375
step: 3047, val loss: nan, val acuracy: 0.10400000214576721
step: 3048, train loss: nan, train acuracy: 0.03125
step: 3048, val loss: nan, val acuracy: 0.10400000214576721
step: 3049, train loss: nan, train acuracy: 0.09375
step: 3049, val loss: nan, val acuracy: 0.10400000214576721
step: 3050, train loss: nan, train acuracy: 0.046875
step: 3050, val loss: nan, val acuracy: 0.10400000214576721
step: 3051, train loss: nan, train acuracy: 0.15625
step: 3051, val loss: nan, val acuracy: 0.10400000214576721
step: 3052, train loss: nan, train acuracy: 0.09375
step: 3052, val loss: nan, val acuracy: 0.10400000214576721
step: 3053, train loss: nan, train acuracy: 0.125
step: 3053, val loss: nan, val acuracy: 0.10400000214576721
step: 3054, train loss: nan, train acuracy: 0.03125
step: 3054, val loss: nan, val acuracy: 0.10400000214576721
step: 3055, train loss: nan, train acuracy: 0.125
step: 3055, val loss: nan, val acuracy: 0.10400000214576721
step: 3056, train loss: nan, train acuracy: 0.15625
step: 3056, val loss: nan, val acuracy: 0.10400000214576721
step: 3057, train loss: nan, train acuracy: 0.125
step: 3057, val loss: nan, val acuracy: 0.10400000214576721
step: 3058, train loss: nan, train acuracy: 0.078125
step: 3058, val loss: nan, val acuracy: 0.10400000214576721
step: 3059, train loss: nan, train acuracy: 0.078125
step: 3059, val loss: nan, val acuracy: 0.10400000214576721
step: 3060, train loss: nan, train acuracy: 0.109375
step: 3060, val loss: nan, val acuracy: 0.10400000214576721
step: 3061, train loss: nan, train acuracy: 0.09375
step: 3061, val loss: nan, val acuracy: 0.10400000214576721
step: 3062, train loss: nan, train acuracy: 0.046875
step: 3062, val loss: nan, val acuracy: 0.10400000214576721
step: 3063, train loss: nan, train acuracy: 0.09375
step: 3063, val loss: nan, val acuracy: 0.10400000214576721
step: 3064, train loss: nan, train acuracy: 0.046875
step: 3064, val loss: nan, val acuracy: 0.10400000214576721
step: 3065, train loss: nan, train acuracy: 0.125
step: 3065, val loss: nan, val acuracy: 0.10400000214576721
step: 3066, train loss: nan, train acuracy: 0.078125
step: 3066, val loss: nan, val acuracy: 0.10400000214576721
step: 3067, train loss: nan, train acuracy: 0.0625
step: 3067, val loss: nan, val acuracy: 0.10400000214576721
step: 3068, train loss: nan, train acuracy: 0.140625
step: 3068, val loss: nan, val acuracy: 0.10400000214576721
step: 3069, train loss: nan, train acuracy: 0.15625
step: 3069, val loss: nan, val acuracy: 0.10400000214576721
step: 3070, train loss: nan, train acuracy: 0.140625
step: 3070, val loss: nan, val acuracy: 0.10400000214576721
step: 3071, train loss: nan, train acuracy: 0.109375
step: 3071, val loss: nan, val acuracy: 0.10400000214576721
step: 3072, train loss: nan, train acuracy: 0.046875
step: 3072, val loss: nan, val acuracy: 0.10400000214576721
step: 3073, train loss: nan, train acuracy: 0.140625
step: 3073, val loss: nan, val acuracy: 0.10400000214576721
step: 3074, train loss: nan, train acuracy: 0.140625
step: 3074, val loss: nan, val acuracy: 0.10400000214576721
step: 3075, train loss: nan, train acuracy: 0.0625
step: 3075, val loss: nan, val acuracy: 0.10400000214576721
step: 3076, train loss: nan, train acuracy: 0.0625
step: 3076, val loss: nan, val acuracy: 0.10400000214576721
step: 3077, train loss: nan, train acuracy: 0.078125
step: 3077, val loss: nan, val acuracy: 0.10400000214576721
step: 3078, train loss: nan, train acuracy: 0.0625
step: 3078, val loss: nan, val acuracy: 0.10400000214576721
step: 3079, train loss: nan, train acuracy: 0.109375
step: 3079, val loss: nan, val acuracy: 0.10400000214576721
step: 3080, train loss: nan, train acuracy: 0.09375
step: 3080, val loss: nan, val acuracy: 0.10400000214576721
step: 3081, train loss: nan, train acuracy: 0.109375
step: 3081, val loss: nan, val acuracy: 0.10400000214576721
step: 3082, train loss: nan, train acuracy: 0.125
step: 3082, val loss: nan, val acuracy: 0.10400000214576721
step: 3083, train loss: nan, train acuracy: 0.046875
step: 3083, val loss: nan, val acuracy: 0.10400000214576721
step: 3084, train loss: nan, train acuracy: 0.171875
step: 3084, val loss: nan, val acuracy: 0.10400000214576721
step: 3085, train loss: nan, train acuracy: 0.03125
step: 3085, val loss: nan, val acuracy: 0.10400000214576721
step: 3086, train loss: nan, train acuracy: 0.09375
step: 3086, val loss: nan, val acuracy: 0.10400000214576721
step: 3087, train loss: nan, train acuracy: 0.140625
step: 3087, val loss: nan, val acuracy: 0.10400000214576721
step: 3088, train loss: nan, train acuracy: 0.171875
step: 3088, val loss: nan, val acuracy: 0.10400000214576721
step: 3089, train loss: nan, train acuracy: 0.078125
step: 3089, val loss: nan, val acuracy: 0.10400000214576721
step: 3090, train loss: nan, train acuracy: 0.109375
step: 3090, val loss: nan, val acuracy: 0.10400000214576721
step: 3091, train loss: nan, train acuracy: 0.046875
step: 3091, val loss: nan, val acuracy: 0.10400000214576721
step: 3092, train loss: nan, train acuracy: 0.0625
step: 3092, val loss: nan, val acuracy: 0.10400000214576721
step: 3093, train loss: nan, train acuracy: 0.046875
step: 3093, val loss: nan, val acuracy: 0.10400000214576721
step: 3094, train loss: nan, train acuracy: 0.09375
step: 3094, val loss: nan, val acuracy: 0.10400000214576721
step: 3095, train loss: nan, train acuracy: 0.09375
step: 3095, val loss: nan, val acuracy: 0.10400000214576721
step: 3096, train loss: nan, train acuracy: 0.09375
step: 3096, val loss: nan, val acuracy: 0.10400000214576721
step: 3097, train loss: nan, train acuracy: 0.046875
step: 3097, val loss: nan, val acuracy: 0.10400000214576721
step: 3098, train loss: nan, train acuracy: 0.125
step: 3098, val loss: nan, val acuracy: 0.10400000214576721
step: 3099, train loss: nan, train acuracy: 0.125
step: 3099, val loss: nan, val acuracy: 0.10400000214576721
step: 3100, train loss: nan, train acuracy: 0.109375
step: 3100, val loss: nan, val acuracy: 0.10400000214576721
step: 3101, train loss: nan, train acuracy: 0.046875
step: 3101, val loss: nan, val acuracy: 0.10400000214576721
step: 3102, train loss: nan, train acuracy: 0.078125
step: 3102, val loss: nan, val acuracy: 0.10400000214576721
step: 3103, train loss: nan, train acuracy: 0.109375
step: 3103, val loss: nan, val acuracy: 0.10400000214576721
step: 3104, train loss: nan, train acuracy: 0.125
step: 3104, val loss: nan, val acuracy: 0.10400000214576721
step: 3105, train loss: nan, train acuracy: 0.125
step: 3105, val loss: nan, val acuracy: 0.10400000214576721
step: 3106, train loss: nan, train acuracy: 0.0625
step: 3106, val loss: nan, val acuracy: 0.10400000214576721
step: 3107, train loss: nan, train acuracy: 0.140625
step: 3107, val loss: nan, val acuracy: 0.10400000214576721
step: 3108, train loss: nan, train acuracy: 0.078125
step: 3108, val loss: nan, val acuracy: 0.10400000214576721
step: 3109, train loss: nan, train acuracy: 0.015625
step: 3109, val loss: nan, val acuracy: 0.10400000214576721
step: 3110, train loss: nan, train acuracy: 0.046875
step: 3110, val loss: nan, val acuracy: 0.10400000214576721
step: 3111, train loss: nan, train acuracy: 0.109375
step: 3111, val loss: nan, val acuracy: 0.10400000214576721
step: 3112, train loss: nan, train acuracy: 0.0625
step: 3112, val loss: nan, val acuracy: 0.10400000214576721
step: 3113, train loss: nan, train acuracy: 0.0625
step: 3113, val loss: nan, val acuracy: 0.10400000214576721
step: 3114, train loss: nan, train acuracy: 0.078125
step: 3114, val loss: nan, val acuracy: 0.10400000214576721
step: 3115, train loss: nan, train acuracy: 0.046875
step: 3115, val loss: nan, val acuracy: 0.10400000214576721
step: 3116, train loss: nan, train acuracy: 0.0625
step: 3116, val loss: nan, val acuracy: 0.10400000214576721
step: 3117, train loss: nan, train acuracy: 0.09375
step: 3117, val loss: nan, val acuracy: 0.10400000214576721
step: 3118, train loss: nan, train acuracy: 0.140625
step: 3118, val loss: nan, val acuracy: 0.10400000214576721
step: 3119, train loss: nan, train acuracy: 0.09375
step: 3119, val loss: nan, val acuracy: 0.10400000214576721
step: 3120, train loss: nan, train acuracy: 0.078125
step: 3120, val loss: nan, val acuracy: 0.10400000214576721
step: 3121, train loss: nan, train acuracy: 0.078125
step: 3121, val loss: nan, val acuracy: 0.10400000214576721
step: 3122, train loss: nan, train acuracy: 0.09375
step: 3122, val loss: nan, val acuracy: 0.10400000214576721
step: 3123, train loss: nan, train acuracy: 0.109375
step: 3123, val loss: nan, val acuracy: 0.10400000214576721
step: 3124, train loss: nan, train acuracy: 0.140625
step: 3124, val loss: nan, val acuracy: 0.10400000214576721
step: 3125, train loss: nan, train acuracy: 0.0625
step: 3125, val loss: nan, val acuracy: 0.10400000214576721
step: 3126, train loss: nan, train acuracy: 0.109375
step: 3126, val loss: nan, val acuracy: 0.10400000214576721
step: 3127, train loss: nan, train acuracy: 0.09375
step: 3127, val loss: nan, val acuracy: 0.10400000214576721
step: 3128, train loss: nan, train acuracy: 0.078125
step: 3128, val loss: nan, val acuracy: 0.10400000214576721
step: 3129, train loss: nan, train acuracy: 0.0625
step: 3129, val loss: nan, val acuracy: 0.10400000214576721
step: 3130, train loss: nan, train acuracy: 0.125
step: 3130, val loss: nan, val acuracy: 0.10400000214576721
step: 3131, train loss: nan, train acuracy: 0.140625
step: 3131, val loss: nan, val acuracy: 0.10400000214576721
step: 3132, train loss: nan, train acuracy: 0.0625
step: 3132, val loss: nan, val acuracy: 0.10400000214576721
step: 3133, train loss: nan, train acuracy: 0.078125
step: 3133, val loss: nan, val acuracy: 0.10400000214576721
step: 3134, train loss: nan, train acuracy: 0.109375
step: 3134, val loss: nan, val acuracy: 0.10400000214576721
step: 3135, train loss: nan, train acuracy: 0.140625
step: 3135, val loss: nan, val acuracy: 0.10400000214576721
step: 3136, train loss: nan, train acuracy: 0.125
step: 3136, val loss: nan, val acuracy: 0.10400000214576721
step: 3137, train loss: nan, train acuracy: 0.109375
step: 3137, val loss: nan, val acuracy: 0.10400000214576721
step: 3138, train loss: nan, train acuracy: 0.09375
step: 3138, val loss: nan, val acuracy: 0.10400000214576721
step: 3139, train loss: nan, train acuracy: 0.03125
step: 3139, val loss: nan, val acuracy: 0.10400000214576721
step: 3140, train loss: nan, train acuracy: 0.0625
step: 3140, val loss: nan, val acuracy: 0.10400000214576721
step: 3141, train loss: nan, train acuracy: 0.125
step: 3141, val loss: nan, val acuracy: 0.10400000214576721
step: 3142, train loss: nan, train acuracy: 0.109375
step: 3142, val loss: nan, val acuracy: 0.10400000214576721
step: 3143, train loss: nan, train acuracy: 0.203125
step: 3143, val loss: nan, val acuracy: 0.10400000214576721
step: 3144, train loss: nan, train acuracy: 0.125
step: 3144, val loss: nan, val acuracy: 0.10400000214576721
step: 3145, train loss: nan, train acuracy: 0.078125
step: 3145, val loss: nan, val acuracy: 0.10400000214576721
step: 3146, train loss: nan, train acuracy: 0.078125
step: 3146, val loss: nan, val acuracy: 0.10400000214576721
step: 3147, train loss: nan, train acuracy: 0.109375
step: 3147, val loss: nan, val acuracy: 0.10400000214576721
step: 3148, train loss: nan, train acuracy: 0.125
step: 3148, val loss: nan, val acuracy: 0.10400000214576721
step: 3149, train loss: nan, train acuracy: 0.078125
step: 3149, val loss: nan, val acuracy: 0.10400000214576721
step: 3150, train loss: nan, train acuracy: 0.109375
step: 3150, val loss: nan, val acuracy: 0.10400000214576721
step: 3151, train loss: nan, train acuracy: 0.078125
step: 3151, val loss: nan, val acuracy: 0.10400000214576721
step: 3152, train loss: nan, train acuracy: 0.015625
step: 3152, val loss: nan, val acuracy: 0.10400000214576721
step: 3153, train loss: nan, train acuracy: 0.09375
step: 3153, val loss: nan, val acuracy: 0.10400000214576721
step: 3154, train loss: nan, train acuracy: 0.109375
step: 3154, val loss: nan, val acuracy: 0.10400000214576721
step: 3155, train loss: nan, train acuracy: 0.109375
step: 3155, val loss: nan, val acuracy: 0.10400000214576721
step: 3156, train loss: nan, train acuracy: 0.078125
step: 3156, val loss: nan, val acuracy: 0.10400000214576721
step: 3157, train loss: nan, train acuracy: 0.171875
step: 3157, val loss: nan, val acuracy: 0.10400000214576721
step: 3158, train loss: nan, train acuracy: 0.109375
step: 3158, val loss: nan, val acuracy: 0.10400000214576721
step: 3159, train loss: nan, train acuracy: 0.0625
step: 3159, val loss: nan, val acuracy: 0.10400000214576721
step: 3160, train loss: nan, train acuracy: 0.140625
step: 3160, val loss: nan, val acuracy: 0.10400000214576721
step: 3161, train loss: nan, train acuracy: 0.140625
step: 3161, val loss: nan, val acuracy: 0.10400000214576721
step: 3162, train loss: nan, train acuracy: 0.109375
step: 3162, val loss: nan, val acuracy: 0.10400000214576721
step: 3163, train loss: nan, train acuracy: 0.15625
step: 3163, val loss: nan, val acuracy: 0.10400000214576721
step: 3164, train loss: nan, train acuracy: 0.125
step: 3164, val loss: nan, val acuracy: 0.10400000214576721
step: 3165, train loss: nan, train acuracy: 0.125
step: 3165, val loss: nan, val acuracy: 0.10400000214576721
step: 3166, train loss: nan, train acuracy: 0.109375
step: 3166, val loss: nan, val acuracy: 0.10400000214576721
step: 3167, train loss: nan, train acuracy: 0.078125
step: 3167, val loss: nan, val acuracy: 0.10400000214576721
step: 3168, train loss: nan, train acuracy: 0.078125
step: 3168, val loss: nan, val acuracy: 0.10400000214576721
step: 3169, train loss: nan, train acuracy: 0.09375
step: 3169, val loss: nan, val acuracy: 0.10400000214576721
step: 3170, train loss: nan, train acuracy: 0.078125
step: 3170, val loss: nan, val acuracy: 0.10400000214576721
step: 3171, train loss: nan, train acuracy: 0.078125
step: 3171, val loss: nan, val acuracy: 0.10400000214576721
step: 3172, train loss: nan, train acuracy: 0.0625
step: 3172, val loss: nan, val acuracy: 0.10400000214576721
step: 3173, train loss: nan, train acuracy: 0.078125
step: 3173, val loss: nan, val acuracy: 0.10400000214576721
step: 3174, train loss: nan, train acuracy: 0.203125
step: 3174, val loss: nan, val acuracy: 0.10400000214576721
step: 3175, train loss: nan, train acuracy: 0.15625
step: 3175, val loss: nan, val acuracy: 0.10400000214576721
step: 3176, train loss: nan, train acuracy: 0.0625
step: 3176, val loss: nan, val acuracy: 0.10400000214576721
step: 3177, train loss: nan, train acuracy: 0.109375
step: 3177, val loss: nan, val acuracy: 0.10400000214576721
step: 3178, train loss: nan, train acuracy: 0.109375
step: 3178, val loss: nan, val acuracy: 0.10400000214576721
step: 3179, train loss: nan, train acuracy: 0.109375
step: 3179, val loss: nan, val acuracy: 0.10400000214576721
step: 3180, train loss: nan, train acuracy: 0.140625
step: 3180, val loss: nan, val acuracy: 0.10400000214576721
step: 3181, train loss: nan, train acuracy: 0.078125
step: 3181, val loss: nan, val acuracy: 0.10400000214576721
step: 3182, train loss: nan, train acuracy: 0.171875
step: 3182, val loss: nan, val acuracy: 0.10400000214576721
step: 3183, train loss: nan, train acuracy: 0.03125
step: 3183, val loss: nan, val acuracy: 0.10400000214576721
step: 3184, train loss: nan, train acuracy: 0.109375
step: 3184, val loss: nan, val acuracy: 0.10400000214576721
step: 3185, train loss: nan, train acuracy: 0.078125
step: 3185, val loss: nan, val acuracy: 0.10400000214576721
step: 3186, train loss: nan, train acuracy: 0.109375
step: 3186, val loss: nan, val acuracy: 0.10400000214576721
step: 3187, train loss: nan, train acuracy: 0.109375
step: 3187, val loss: nan, val acuracy: 0.10400000214576721
step: 3188, train loss: nan, train acuracy: 0.0625
step: 3188, val loss: nan, val acuracy: 0.10400000214576721
step: 3189, train loss: nan, train acuracy: 0.140625
step: 3189, val loss: nan, val acuracy: 0.10400000214576721
step: 3190, train loss: nan, train acuracy: 0.0625
step: 3190, val loss: nan, val acuracy: 0.10400000214576721
step: 3191, train loss: nan, train acuracy: 0.09375
step: 3191, val loss: nan, val acuracy: 0.10400000214576721
step: 3192, train loss: nan, train acuracy: 0.125
step: 3192, val loss: nan, val acuracy: 0.10400000214576721
step: 3193, train loss: nan, train acuracy: 0.09375
step: 3193, val loss: nan, val acuracy: 0.10400000214576721
step: 3194, train loss: nan, train acuracy: 0.125
step: 3194, val loss: nan, val acuracy: 0.10400000214576721
step: 3195, train loss: nan, train acuracy: 0.0625
step: 3195, val loss: nan, val acuracy: 0.10400000214576721
step: 3196, train loss: nan, train acuracy: 0.140625
step: 3196, val loss: nan, val acuracy: 0.10400000214576721
step: 3197, train loss: nan, train acuracy: 0.09375
step: 3197, val loss: nan, val acuracy: 0.10400000214576721
step: 3198, train loss: nan, train acuracy: 0.0625
step: 3198, val loss: nan, val acuracy: 0.10400000214576721
step: 3199, train loss: nan, train acuracy: 0.140625
step: 3199, val loss: nan, val acuracy: 0.10400000214576721
step: 3200, train loss: nan, train acuracy: 0.171875
step: 3200, val loss: nan, val acuracy: 0.10400000214576721
step: 3201, train loss: nan, train acuracy: 0.0625
step: 3201, val loss: nan, val acuracy: 0.10400000214576721
step: 3202, train loss: nan, train acuracy: 0.0625
step: 3202, val loss: nan, val acuracy: 0.10400000214576721
step: 3203, train loss: nan, train acuracy: 0.15625
step: 3203, val loss: nan, val acuracy: 0.10400000214576721
step: 3204, train loss: nan, train acuracy: 0.09375
step: 3204, val loss: nan, val acuracy: 0.10400000214576721
step: 3205, train loss: nan, train acuracy: 0.078125
step: 3205, val loss: nan, val acuracy: 0.10400000214576721
step: 3206, train loss: nan, train acuracy: 0.09375
step: 3206, val loss: nan, val acuracy: 0.10400000214576721
step: 3207, train loss: nan, train acuracy: 0.109375
step: 3207, val loss: nan, val acuracy: 0.10400000214576721
step: 3208, train loss: nan, train acuracy: 0.15625
step: 3208, val loss: nan, val acuracy: 0.10400000214576721
step: 3209, train loss: nan, train acuracy: 0.078125
step: 3209, val loss: nan, val acuracy: 0.10400000214576721
step: 3210, train loss: nan, train acuracy: 0.125
step: 3210, val loss: nan, val acuracy: 0.10400000214576721
step: 3211, train loss: nan, train acuracy: 0.109375
step: 3211, val loss: nan, val acuracy: 0.10400000214576721
step: 3212, train loss: nan, train acuracy: 0.03125
step: 3212, val loss: nan, val acuracy: 0.10400000214576721
step: 3213, train loss: nan, train acuracy: 0.046875
step: 3213, val loss: nan, val acuracy: 0.10400000214576721
step: 3214, train loss: nan, train acuracy: 0.046875
step: 3214, val loss: nan, val acuracy: 0.10400000214576721
step: 3215, train loss: nan, train acuracy: 0.09375
step: 3215, val loss: nan, val acuracy: 0.10400000214576721
step: 3216, train loss: nan, train acuracy: 0.046875
step: 3216, val loss: nan, val acuracy: 0.10400000214576721
step: 3217, train loss: nan, train acuracy: 0.140625
step: 3217, val loss: nan, val acuracy: 0.10400000214576721
step: 3218, train loss: nan, train acuracy: 0.078125
step: 3218, val loss: nan, val acuracy: 0.10400000214576721
step: 3219, train loss: nan, train acuracy: 0.15625
step: 3219, val loss: nan, val acuracy: 0.10400000214576721
step: 3220, train loss: nan, train acuracy: 0.03125
step: 3220, val loss: nan, val acuracy: 0.10400000214576721
step: 3221, train loss: nan, train acuracy: 0.09375
step: 3221, val loss: nan, val acuracy: 0.10400000214576721
step: 3222, train loss: nan, train acuracy: 0.078125
step: 3222, val loss: nan, val acuracy: 0.10400000214576721
step: 3223, train loss: nan, train acuracy: 0.125
step: 3223, val loss: nan, val acuracy: 0.10400000214576721
step: 3224, train loss: nan, train acuracy: 0.171875
step: 3224, val loss: nan, val acuracy: 0.10400000214576721
step: 3225, train loss: nan, train acuracy: 0.109375
step: 3225, val loss: nan, val acuracy: 0.10400000214576721
step: 3226, train loss: nan, train acuracy: 0.0625
step: 3226, val loss: nan, val acuracy: 0.10400000214576721
step: 3227, train loss: nan, train acuracy: 0.09375
step: 3227, val loss: nan, val acuracy: 0.10400000214576721
step: 3228, train loss: nan, train acuracy: 0.078125
step: 3228, val loss: nan, val acuracy: 0.10400000214576721
step: 3229, train loss: nan, train acuracy: 0.109375
step: 3229, val loss: nan, val acuracy: 0.10400000214576721
step: 3230, train loss: nan, train acuracy: 0.09375
step: 3230, val loss: nan, val acuracy: 0.10400000214576721
step: 3231, train loss: nan, train acuracy: 0.0625
step: 3231, val loss: nan, val acuracy: 0.10400000214576721
step: 3232, train loss: nan, train acuracy: 0.109375
step: 3232, val loss: nan, val acuracy: 0.10400000214576721
step: 3233, train loss: nan, train acuracy: 0.078125
step: 3233, val loss: nan, val acuracy: 0.10400000214576721
step: 3234, train loss: nan, train acuracy: 0.09375
step: 3234, val loss: nan, val acuracy: 0.10400000214576721
step: 3235, train loss: nan, train acuracy: 0.109375
step: 3235, val loss: nan, val acuracy: 0.10400000214576721
step: 3236, train loss: nan, train acuracy: 0.109375
step: 3236, val loss: nan, val acuracy: 0.10400000214576721
step: 3237, train loss: nan, train acuracy: 0.125
step: 3237, val loss: nan, val acuracy: 0.10400000214576721
step: 3238, train loss: nan, train acuracy: 0.078125
step: 3238, val loss: nan, val acuracy: 0.10400000214576721
step: 3239, train loss: nan, train acuracy: 0.109375
step: 3239, val loss: nan, val acuracy: 0.10400000214576721
step: 3240, train loss: nan, train acuracy: 0.09375
step: 3240, val loss: nan, val acuracy: 0.10400000214576721
step: 3241, train loss: nan, train acuracy: 0.15625
step: 3241, val loss: nan, val acuracy: 0.10400000214576721
step: 3242, train loss: nan, train acuracy: 0.109375
step: 3242, val loss: nan, val acuracy: 0.10400000214576721
step: 3243, train loss: nan, train acuracy: 0.09375
step: 3243, val loss: nan, val acuracy: 0.10400000214576721
step: 3244, train loss: nan, train acuracy: 0.0625
step: 3244, val loss: nan, val acuracy: 0.10400000214576721
step: 3245, train loss: nan, train acuracy: 0.09375
step: 3245, val loss: nan, val acuracy: 0.10400000214576721
step: 3246, train loss: nan, train acuracy: 0.109375
step: 3246, val loss: nan, val acuracy: 0.10400000214576721
step: 3247, train loss: nan, train acuracy: 0.09375
step: 3247, val loss: nan, val acuracy: 0.10400000214576721
step: 3248, train loss: nan, train acuracy: 0.078125
step: 3248, val loss: nan, val acuracy: 0.10400000214576721
step: 3249, train loss: nan, train acuracy: 0.078125
step: 3249, val loss: nan, val acuracy: 0.10400000214576721
step: 3250, train loss: nan, train acuracy: 0.0625
step: 3250, val loss: nan, val acuracy: 0.10400000214576721
step: 3251, train loss: nan, train acuracy: 0.0625
step: 3251, val loss: nan, val acuracy: 0.10400000214576721
step: 3252, train loss: nan, train acuracy: 0.125
step: 3252, val loss: nan, val acuracy: 0.10400000214576721
step: 3253, train loss: nan, train acuracy: 0.0625
step: 3253, val loss: nan, val acuracy: 0.10400000959634781
step: 3254, train loss: nan, train acuracy: 0.109375
step: 3254, val loss: nan, val acuracy: 0.10400000214576721
step: 3255, train loss: nan, train acuracy: 0.078125
step: 3255, val loss: nan, val acuracy: 0.10400000214576721
step: 3256, train loss: nan, train acuracy: 0.125
step: 3256, val loss: nan, val acuracy: 0.10400000214576721
step: 3257, train loss: nan, train acuracy: 0.0625
step: 3257, val loss: nan, val acuracy: 0.10400000214576721
step: 3258, train loss: nan, train acuracy: 0.09375
step: 3258, val loss: nan, val acuracy: 0.10400000214576721
step: 3259, train loss: nan, train acuracy: 0.125
step: 3259, val loss: nan, val acuracy: 0.10400000214576721
step: 3260, train loss: nan, train acuracy: 0.125
step: 3260, val loss: nan, val acuracy: 0.10400000214576721
step: 3261, train loss: nan, train acuracy: 0.046875
step: 3261, val loss: nan, val acuracy: 0.10400000214576721
step: 3262, train loss: nan, train acuracy: 0.125
step: 3262, val loss: nan, val acuracy: 0.10400000214576721
step: 3263, train loss: nan, train acuracy: 0.109375
step: 3263, val loss: nan, val acuracy: 0.10400000214576721
step: 3264, train loss: nan, train acuracy: 0.140625
step: 3264, val loss: nan, val acuracy: 0.10400000214576721
step: 3265, train loss: nan, train acuracy: 0.125
step: 3265, val loss: nan, val acuracy: 0.10400000214576721
step: 3266, train loss: nan, train acuracy: 0.03125
step: 3266, val loss: nan, val acuracy: 0.10400000214576721
step: 3267, train loss: nan, train acuracy: 0.109375
step: 3267, val loss: nan, val acuracy: 0.10400000214576721
step: 3268, train loss: nan, train acuracy: 0.109375
step: 3268, val loss: nan, val acuracy: 0.10400000214576721
step: 3269, train loss: nan, train acuracy: 0.140625
step: 3269, val loss: nan, val acuracy: 0.10400000214576721
step: 3270, train loss: nan, train acuracy: 0.03125
step: 3270, val loss: nan, val acuracy: 0.10400000214576721
step: 3271, train loss: nan, train acuracy: 0.109375
step: 3271, val loss: nan, val acuracy: 0.10400000214576721
step: 3272, train loss: nan, train acuracy: 0.109375
step: 3272, val loss: nan, val acuracy: 0.10400000214576721
step: 3273, train loss: nan, train acuracy: 0.078125
step: 3273, val loss: nan, val acuracy: 0.10400000214576721
step: 3274, train loss: nan, train acuracy: 0.09375
step: 3274, val loss: nan, val acuracy: 0.10400000214576721
step: 3275, train loss: nan, train acuracy: 0.046875
step: 3275, val loss: nan, val acuracy: 0.10400000214576721
step: 3276, train loss: nan, train acuracy: 0.078125
step: 3276, val loss: nan, val acuracy: 0.10400000214576721
step: 3277, train loss: nan, train acuracy: 0.140625
step: 3277, val loss: nan, val acuracy: 0.10400000214576721
step: 3278, train loss: nan, train acuracy: 0.0625
step: 3278, val loss: nan, val acuracy: 0.10400000214576721
step: 3279, train loss: nan, train acuracy: 0.0625
step: 3279, val loss: nan, val acuracy: 0.10400000214576721
step: 3280, train loss: nan, train acuracy: 0.078125
step: 3280, val loss: nan, val acuracy: 0.10400000214576721
step: 3281, train loss: nan, train acuracy: 0.078125
step: 3281, val loss: nan, val acuracy: 0.10400000214576721
step: 3282, train loss: nan, train acuracy: 0.171875
step: 3282, val loss: nan, val acuracy: 0.10400000214576721
step: 3283, train loss: nan, train acuracy: 0.109375
step: 3283, val loss: nan, val acuracy: 0.10400000214576721
step: 3284, train loss: nan, train acuracy: 0.09375
step: 3284, val loss: nan, val acuracy: 0.10400000214576721
step: 3285, train loss: nan, train acuracy: 0.078125
step: 3285, val loss: nan, val acuracy: 0.10400000214576721
step: 3286, train loss: nan, train acuracy: 0.078125
step: 3286, val loss: nan, val acuracy: 0.10400000214576721
step: 3287, train loss: nan, train acuracy: 0.140625
step: 3287, val loss: nan, val acuracy: 0.10400000214576721
step: 3288, train loss: nan, train acuracy: 0.125
step: 3288, val loss: nan, val acuracy: 0.10400000214576721
step: 3289, train loss: nan, train acuracy: 0.078125
step: 3289, val loss: nan, val acuracy: 0.10400000214576721
step: 3290, train loss: nan, train acuracy: 0.109375
step: 3290, val loss: nan, val acuracy: 0.10400000214576721
step: 3291, train loss: nan, train acuracy: 0.078125
step: 3291, val loss: nan, val acuracy: 0.10400000214576721
step: 3292, train loss: nan, train acuracy: 0.140625
step: 3292, val loss: nan, val acuracy: 0.10400000214576721
step: 3293, train loss: nan, train acuracy: 0.03125
step: 3293, val loss: nan, val acuracy: 0.10400000214576721
step: 3294, train loss: nan, train acuracy: 0.125
step: 3294, val loss: nan, val acuracy: 0.10400000214576721
step: 3295, train loss: nan, train acuracy: 0.078125
step: 3295, val loss: nan, val acuracy: 0.10400000214576721
step: 3296, train loss: nan, train acuracy: 0.125
step: 3296, val loss: nan, val acuracy: 0.10400000214576721
step: 3297, train loss: nan, train acuracy: 0.125
step: 3297, val loss: nan, val acuracy: 0.10400000214576721
step: 3298, train loss: nan, train acuracy: 0.125
step: 3298, val loss: nan, val acuracy: 0.10400000214576721
step: 3299, train loss: nan, train acuracy: 0.046875
step: 3299, val loss: nan, val acuracy: 0.10400000214576721
step: 3300, train loss: nan, train acuracy: 0.140625
step: 3300, val loss: nan, val acuracy: 0.10400000214576721
step: 3301, train loss: nan, train acuracy: 0.109375
step: 3301, val loss: nan, val acuracy: 0.10400000214576721
step: 3302, train loss: nan, train acuracy: 0.0625
step: 3302, val loss: nan, val acuracy: 0.10400000214576721
step: 3303, train loss: nan, train acuracy: 0.171875
step: 3303, val loss: nan, val acuracy: 0.10400000214576721
step: 3304, train loss: nan, train acuracy: 0.109375
step: 3304, val loss: nan, val acuracy: 0.10400000214576721
step: 3305, train loss: nan, train acuracy: 0.109375
step: 3305, val loss: nan, val acuracy: 0.10400000214576721
step: 3306, train loss: nan, train acuracy: 0.0625
step: 3306, val loss: nan, val acuracy: 0.10400000214576721
step: 3307, train loss: nan, train acuracy: 0.0625
step: 3307, val loss: nan, val acuracy: 0.10400000214576721
step: 3308, train loss: nan, train acuracy: 0.09375
step: 3308, val loss: nan, val acuracy: 0.10400000214576721
step: 3309, train loss: nan, train acuracy: 0.125
step: 3309, val loss: nan, val acuracy: 0.10400000214576721
step: 3310, train loss: nan, train acuracy: 0.09375
step: 3310, val loss: nan, val acuracy: 0.10400000214576721
step: 3311, train loss: nan, train acuracy: 0.078125
step: 3311, val loss: nan, val acuracy: 0.10400000214576721
step: 3312, train loss: nan, train acuracy: 0.078125
step: 3312, val loss: nan, val acuracy: 0.10400000214576721
step: 3313, train loss: nan, train acuracy: 0.171875
step: 3313, val loss: nan, val acuracy: 0.10400000214576721
step: 3314, train loss: nan, train acuracy: 0.125
step: 3314, val loss: nan, val acuracy: 0.10400000214576721
step: 3315, train loss: nan, train acuracy: 0.09375
step: 3315, val loss: nan, val acuracy: 0.10400000214576721
step: 3316, train loss: nan, train acuracy: 0.109375
step: 3316, val loss: nan, val acuracy: 0.10400000214576721
step: 3317, train loss: nan, train acuracy: 0.125
step: 3317, val loss: nan, val acuracy: 0.10400000214576721
step: 3318, train loss: nan, train acuracy: 0.125
step: 3318, val loss: nan, val acuracy: 0.10400000214576721
step: 3319, train loss: nan, train acuracy: 0.09375
step: 3319, val loss: nan, val acuracy: 0.10400000214576721
step: 3320, train loss: nan, train acuracy: 0.125
step: 3320, val loss: nan, val acuracy: 0.10400000214576721
step: 3321, train loss: nan, train acuracy: 0.109375
step: 3321, val loss: nan, val acuracy: 0.10400000214576721
step: 3322, train loss: nan, train acuracy: 0.078125
step: 3322, val loss: nan, val acuracy: 0.10400000214576721
step: 3323, train loss: nan, train acuracy: 0.0625
step: 3323, val loss: nan, val acuracy: 0.10400000214576721
step: 3324, train loss: nan, train acuracy: 0.078125
step: 3324, val loss: nan, val acuracy: 0.10400000214576721
step: 3325, train loss: nan, train acuracy: 0.0625
step: 3325, val loss: nan, val acuracy: 0.10400000214576721
step: 3326, train loss: nan, train acuracy: 0.140625
step: 3326, val loss: nan, val acuracy: 0.10400000214576721
step: 3327, train loss: nan, train acuracy: 0.125
step: 3327, val loss: nan, val acuracy: 0.10400000214576721
step: 3328, train loss: nan, train acuracy: 0.109375
step: 3328, val loss: nan, val acuracy: 0.10400000214576721
step: 3329, train loss: nan, train acuracy: 0.0625
step: 3329, val loss: nan, val acuracy: 0.10400000214576721
step: 3330, train loss: nan, train acuracy: 0.078125
step: 3330, val loss: nan, val acuracy: 0.10400000214576721
step: 3331, train loss: nan, train acuracy: 0.09375
step: 3331, val loss: nan, val acuracy: 0.10400000214576721
step: 3332, train loss: nan, train acuracy: 0.125
step: 3332, val loss: nan, val acuracy: 0.10400000214576721
step: 3333, train loss: nan, train acuracy: 0.140625
step: 3333, val loss: nan, val acuracy: 0.10400000214576721
step: 3334, train loss: nan, train acuracy: 0.078125
step: 3334, val loss: nan, val acuracy: 0.10400000214576721
step: 3335, train loss: nan, train acuracy: 0.125
step: 3335, val loss: nan, val acuracy: 0.10400000214576721
step: 3336, train loss: nan, train acuracy: 0.140625
step: 3336, val loss: nan, val acuracy: 0.10400000214576721
step: 3337, train loss: nan, train acuracy: 0.078125
step: 3337, val loss: nan, val acuracy: 0.10400000214576721
step: 3338, train loss: nan, train acuracy: 0.078125
step: 3338, val loss: nan, val acuracy: 0.10400000214576721
step: 3339, train loss: nan, train acuracy: 0.0625
step: 3339, val loss: nan, val acuracy: 0.10400000214576721
step: 3340, train loss: nan, train acuracy: 0.015625
step: 3340, val loss: nan, val acuracy: 0.10400000214576721
step: 3341, train loss: nan, train acuracy: 0.078125
step: 3341, val loss: nan, val acuracy: 0.10400000214576721
step: 3342, train loss: nan, train acuracy: 0.09375
step: 3342, val loss: nan, val acuracy: 0.10400000214576721
step: 3343, train loss: nan, train acuracy: 0.109375
step: 3343, val loss: nan, val acuracy: 0.10400000214576721
step: 3344, train loss: nan, train acuracy: 0.125
step: 3344, val loss: nan, val acuracy: 0.10400000214576721
step: 3345, train loss: nan, train acuracy: 0.21875
step: 3345, val loss: nan, val acuracy: 0.10400000214576721
step: 3346, train loss: nan, train acuracy: 0.046875
step: 3346, val loss: nan, val acuracy: 0.10400000214576721
step: 3347, train loss: nan, train acuracy: 0.0625
step: 3347, val loss: nan, val acuracy: 0.10400000214576721
step: 3348, train loss: nan, train acuracy: 0.109375
step: 3348, val loss: nan, val acuracy: 0.10400000214576721
step: 3349, train loss: nan, train acuracy: 0.109375
step: 3349, val loss: nan, val acuracy: 0.10400000214576721
step: 3350, train loss: nan, train acuracy: 0.125
step: 3350, val loss: nan, val acuracy: 0.10400000214576721
step: 3351, train loss: nan, train acuracy: 0.15625
step: 3351, val loss: nan, val acuracy: 0.10400000214576721
step: 3352, train loss: nan, train acuracy: 0.15625
step: 3352, val loss: nan, val acuracy: 0.10400000214576721
step: 3353, train loss: nan, train acuracy: 0.125
step: 3353, val loss: nan, val acuracy: 0.10400000214576721
step: 3354, train loss: nan, train acuracy: 0.234375
step: 3354, val loss: nan, val acuracy: 0.10400000214576721
step: 3355, train loss: nan, train acuracy: 0.046875
step: 3355, val loss: nan, val acuracy: 0.10400000214576721
step: 3356, train loss: nan, train acuracy: 0.109375
step: 3356, val loss: nan, val acuracy: 0.10400000214576721
step: 3357, train loss: nan, train acuracy: 0.078125
step: 3357, val loss: nan, val acuracy: 0.10400000214576721
step: 3358, train loss: nan, train acuracy: 0.078125
step: 3358, val loss: nan, val acuracy: 0.10400000214576721
step: 3359, train loss: nan, train acuracy: 0.1875
step: 3359, val loss: nan, val acuracy: 0.10400000214576721
step: 3360, train loss: nan, train acuracy: 0.078125
step: 3360, val loss: nan, val acuracy: 0.10400000214576721
step: 3361, train loss: nan, train acuracy: 0.15625
step: 3361, val loss: nan, val acuracy: 0.10400000214576721
step: 3362, train loss: nan, train acuracy: 0.125
step: 3362, val loss: nan, val acuracy: 0.10400000214576721
step: 3363, train loss: nan, train acuracy: 0.09375
step: 3363, val loss: nan, val acuracy: 0.10400000214576721
step: 3364, train loss: nan, train acuracy: 0.109375
step: 3364, val loss: nan, val acuracy: 0.10400000214576721
step: 3365, train loss: nan, train acuracy: 0.09375
step: 3365, val loss: nan, val acuracy: 0.10400000214576721
step: 3366, train loss: nan, train acuracy: 0.09375
step: 3366, val loss: nan, val acuracy: 0.10400000214576721
step: 3367, train loss: nan, train acuracy: 0.046875
step: 3367, val loss: nan, val acuracy: 0.10400000214576721
step: 3368, train loss: nan, train acuracy: 0.109375
step: 3368, val loss: nan, val acuracy: 0.10400000214576721
step: 3369, train loss: nan, train acuracy: 0.125
step: 3369, val loss: nan, val acuracy: 0.10400000214576721
step: 3370, train loss: nan, train acuracy: 0.078125
step: 3370, val loss: nan, val acuracy: 0.10400000214576721
step: 3371, train loss: nan, train acuracy: 0.0625
step: 3371, val loss: nan, val acuracy: 0.10400000214576721
step: 3372, train loss: nan, train acuracy: 0.109375
step: 3372, val loss: nan, val acuracy: 0.10400000214576721
step: 3373, train loss: nan, train acuracy: 0.15625
step: 3373, val loss: nan, val acuracy: 0.10400000214576721
step: 3374, train loss: nan, train acuracy: 0.09375
step: 3374, val loss: nan, val acuracy: 0.10400000214576721
step: 3375, train loss: nan, train acuracy: 0.0625
step: 3375, val loss: nan, val acuracy: 0.10400000214576721
step: 3376, train loss: nan, train acuracy: 0.140625
step: 3376, val loss: nan, val acuracy: 0.10400000214576721
step: 3377, train loss: nan, train acuracy: 0.109375
step: 3377, val loss: nan, val acuracy: 0.10400000214576721
step: 3378, train loss: nan, train acuracy: 0.125
step: 3378, val loss: nan, val acuracy: 0.10400000214576721
step: 3379, train loss: nan, train acuracy: 0.109375
step: 3379, val loss: nan, val acuracy: 0.10400000214576721
step: 3380, train loss: nan, train acuracy: 0.046875
step: 3380, val loss: nan, val acuracy: 0.10400000214576721
step: 3381, train loss: nan, train acuracy: 0.09375
step: 3381, val loss: nan, val acuracy: 0.10400000214576721
step: 3382, train loss: nan, train acuracy: 0.109375
step: 3382, val loss: nan, val acuracy: 0.10400000214576721
step: 3383, train loss: nan, train acuracy: 0.09375
step: 3383, val loss: nan, val acuracy: 0.10400000214576721
step: 3384, train loss: nan, train acuracy: 0.0625
step: 3384, val loss: nan, val acuracy: 0.10400000959634781
step: 3385, train loss: nan, train acuracy: 0.09375
step: 3385, val loss: nan, val acuracy: 0.10400000214576721
step: 3386, train loss: nan, train acuracy: 0.046875
step: 3386, val loss: nan, val acuracy: 0.10400000214576721
step: 3387, train loss: nan, train acuracy: 0.0625
step: 3387, val loss: nan, val acuracy: 0.10400000214576721
step: 3388, train loss: nan, train acuracy: 0.09375
step: 3388, val loss: nan, val acuracy: 0.10400000214576721
step: 3389, train loss: nan, train acuracy: 0.109375
step: 3389, val loss: nan, val acuracy: 0.10400000214576721
step: 3390, train loss: nan, train acuracy: 0.171875
step: 3390, val loss: nan, val acuracy: 0.10400000214576721
step: 3391, train loss: nan, train acuracy: 0.078125
step: 3391, val loss: nan, val acuracy: 0.10400000214576721
step: 3392, train loss: nan, train acuracy: 0.09375
step: 3392, val loss: nan, val acuracy: 0.10400000214576721
step: 3393, train loss: nan, train acuracy: 0.140625
step: 3393, val loss: nan, val acuracy: 0.10400000214576721
step: 3394, train loss: nan, train acuracy: 0.0625
step: 3394, val loss: nan, val acuracy: 0.10400000214576721
step: 3395, train loss: nan, train acuracy: 0.109375
step: 3395, val loss: nan, val acuracy: 0.10400000214576721
step: 3396, train loss: nan, train acuracy: 0.15625
step: 3396, val loss: nan, val acuracy: 0.10400000214576721
step: 3397, train loss: nan, train acuracy: 0.0625
step: 3397, val loss: nan, val acuracy: 0.10400000214576721
step: 3398, train loss: nan, train acuracy: 0.140625
step: 3398, val loss: nan, val acuracy: 0.10400000214576721
step: 3399, train loss: nan, train acuracy: 0.0625
step: 3399, val loss: nan, val acuracy: 0.10400000214576721
step: 3400, train loss: nan, train acuracy: 0.0625
step: 3400, val loss: nan, val acuracy: 0.10400000214576721
step: 3401, train loss: nan, train acuracy: 0.09375
step: 3401, val loss: nan, val acuracy: 0.10400000214576721
step: 3402, train loss: nan, train acuracy: 0.125
step: 3402, val loss: nan, val acuracy: 0.10400000214576721
step: 3403, train loss: nan, train acuracy: 0.078125
step: 3403, val loss: nan, val acuracy: 0.10400000214576721
step: 3404, train loss: nan, train acuracy: 0.09375
step: 3404, val loss: nan, val acuracy: 0.10400000214576721
step: 3405, train loss: nan, train acuracy: 0.09375
step: 3405, val loss: nan, val acuracy: 0.10400000214576721
step: 3406, train loss: nan, train acuracy: 0.09375
step: 3406, val loss: nan, val acuracy: 0.10400000214576721
step: 3407, train loss: nan, train acuracy: 0.0625
step: 3407, val loss: nan, val acuracy: 0.10400000214576721
step: 3408, train loss: nan, train acuracy: 0.109375
step: 3408, val loss: nan, val acuracy: 0.10400000214576721
step: 3409, train loss: nan, train acuracy: 0.046875
step: 3409, val loss: nan, val acuracy: 0.10400000214576721
step: 3410, train loss: nan, train acuracy: 0.078125
step: 3410, val loss: nan, val acuracy: 0.10400000214576721
step: 3411, train loss: nan, train acuracy: 0.0625
step: 3411, val loss: nan, val acuracy: 0.10400000214576721
step: 3412, train loss: nan, train acuracy: 0.09375
step: 3412, val loss: nan, val acuracy: 0.10400000214576721
step: 3413, train loss: nan, train acuracy: 0.0625
step: 3413, val loss: nan, val acuracy: 0.10400000214576721
step: 3414, train loss: nan, train acuracy: 0.078125
step: 3414, val loss: nan, val acuracy: 0.10400000214576721
step: 3415, train loss: nan, train acuracy: 0.0625
step: 3415, val loss: nan, val acuracy: 0.10400000214576721
step: 3416, train loss: nan, train acuracy: 0.0625
step: 3416, val loss: nan, val acuracy: 0.10400000214576721
step: 3417, train loss: nan, train acuracy: 0.140625
step: 3417, val loss: nan, val acuracy: 0.10400000214576721
step: 3418, train loss: nan, train acuracy: 0.109375
step: 3418, val loss: nan, val acuracy: 0.10400000214576721
step: 3419, train loss: nan, train acuracy: 0.09375
step: 3419, val loss: nan, val acuracy: 0.10400000214576721
step: 3420, train loss: nan, train acuracy: 0.0625
step: 3420, val loss: nan, val acuracy: 0.10400000214576721
step: 3421, train loss: nan, train acuracy: 0.109375
step: 3421, val loss: nan, val acuracy: 0.10400000214576721
step: 3422, train loss: nan, train acuracy: 0.078125
step: 3422, val loss: nan, val acuracy: 0.10400000214576721
step: 3423, train loss: nan, train acuracy: 0.09375
step: 3423, val loss: nan, val acuracy: 0.10400000214576721
step: 3424, train loss: nan, train acuracy: 0.078125
step: 3424, val loss: nan, val acuracy: 0.10400000959634781
step: 3425, train loss: nan, train acuracy: 0.109375
step: 3425, val loss: nan, val acuracy: 0.10400000214576721
step: 3426, train loss: nan, train acuracy: 0.078125
step: 3426, val loss: nan, val acuracy: 0.10400000214576721
step: 3427, train loss: nan, train acuracy: 0.09375
step: 3427, val loss: nan, val acuracy: 0.10400000214576721
step: 3428, train loss: nan, train acuracy: 0.125
step: 3428, val loss: nan, val acuracy: 0.10400000214576721
step: 3429, train loss: nan, train acuracy: 0.109375
step: 3429, val loss: nan, val acuracy: 0.10400000214576721
step: 3430, train loss: nan, train acuracy: 0.09375
step: 3430, val loss: nan, val acuracy: 0.10400000214576721
step: 3431, train loss: nan, train acuracy: 0.078125
step: 3431, val loss: nan, val acuracy: 0.10400000214576721
step: 3432, train loss: nan, train acuracy: 0.15625
step: 3432, val loss: nan, val acuracy: 0.10400000214576721
step: 3433, train loss: nan, train acuracy: 0.03125
step: 3433, val loss: nan, val acuracy: 0.10400000214576721
step: 3434, train loss: nan, train acuracy: 0.171875
step: 3434, val loss: nan, val acuracy: 0.10400000214576721
step: 3435, train loss: nan, train acuracy: 0.125
step: 3435, val loss: nan, val acuracy: 0.10400000214576721
step: 3436, train loss: nan, train acuracy: 0.15625
step: 3436, val loss: nan, val acuracy: 0.10400000214576721
step: 3437, train loss: nan, train acuracy: 0.078125
step: 3437, val loss: nan, val acuracy: 0.10400000214576721
step: 3438, train loss: nan, train acuracy: 0.109375
step: 3438, val loss: nan, val acuracy: 0.10400000214576721
step: 3439, train loss: nan, train acuracy: 0.078125
step: 3439, val loss: nan, val acuracy: 0.10400000214576721
step: 3440, train loss: nan, train acuracy: 0.0625
step: 3440, val loss: nan, val acuracy: 0.10400000214576721
step: 3441, train loss: nan, train acuracy: 0.09375
step: 3441, val loss: nan, val acuracy: 0.10400000214576721
step: 3442, train loss: nan, train acuracy: 0.046875
step: 3442, val loss: nan, val acuracy: 0.10400000214576721
step: 3443, train loss: nan, train acuracy: 0.125
step: 3443, val loss: nan, val acuracy: 0.10400000214576721
step: 3444, train loss: nan, train acuracy: 0.125
step: 3444, val loss: nan, val acuracy: 0.10400000214576721
step: 3445, train loss: nan, train acuracy: 0.109375
step: 3445, val loss: nan, val acuracy: 0.10400000214576721
step: 3446, train loss: nan, train acuracy: 0.109375
step: 3446, val loss: nan, val acuracy: 0.10400000214576721
step: 3447, train loss: nan, train acuracy: 0.03125
step: 3447, val loss: nan, val acuracy: 0.10400000214576721
step: 3448, train loss: nan, train acuracy: 0.109375
step: 3448, val loss: nan, val acuracy: 0.10400000214576721
step: 3449, train loss: nan, train acuracy: 0.1875
step: 3449, val loss: nan, val acuracy: 0.10400000214576721
step: 3450, train loss: nan, train acuracy: 0.09375
step: 3450, val loss: nan, val acuracy: 0.10400000214576721
step: 3451, train loss: nan, train acuracy: 0.109375
step: 3451, val loss: nan, val acuracy: 0.10400000214576721
step: 3452, train loss: nan, train acuracy: 0.109375
step: 3452, val loss: nan, val acuracy: 0.10400000214576721
step: 3453, train loss: nan, train acuracy: 0.09375
step: 3453, val loss: nan, val acuracy: 0.10400000214576721
step: 3454, train loss: nan, train acuracy: 0.109375
step: 3454, val loss: nan, val acuracy: 0.10400000214576721
step: 3455, train loss: nan, train acuracy: 0.03125
step: 3455, val loss: nan, val acuracy: 0.10400000214576721
step: 3456, train loss: nan, train acuracy: 0.078125
step: 3456, val loss: nan, val acuracy: 0.10400000214576721
step: 3457, train loss: nan, train acuracy: 0.125
step: 3457, val loss: nan, val acuracy: 0.10400000214576721
step: 3458, train loss: nan, train acuracy: 0.109375
step: 3458, val loss: nan, val acuracy: 0.10400000214576721
step: 3459, train loss: nan, train acuracy: 0.09375
step: 3459, val loss: nan, val acuracy: 0.10400000214576721
step: 3460, train loss: nan, train acuracy: 0.046875
step: 3460, val loss: nan, val acuracy: 0.10400000214576721
step: 3461, train loss: nan, train acuracy: 0.109375
step: 3461, val loss: nan, val acuracy: 0.10400000214576721
step: 3462, train loss: nan, train acuracy: 0.15625
step: 3462, val loss: nan, val acuracy: 0.10400000214576721
step: 3463, train loss: nan, train acuracy: 0.140625
step: 3463, val loss: nan, val acuracy: 0.10400000214576721
step: 3464, train loss: nan, train acuracy: 0.109375
step: 3464, val loss: nan, val acuracy: 0.10400000214576721
step: 3465, train loss: nan, train acuracy: 0.109375
step: 3465, val loss: nan, val acuracy: 0.10400000214576721
step: 3466, train loss: nan, train acuracy: 0.0625
step: 3466, val loss: nan, val acuracy: 0.10400000214576721
step: 3467, train loss: nan, train acuracy: 0.0625
step: 3467, val loss: nan, val acuracy: 0.10400000214576721
step: 3468, train loss: nan, train acuracy: 0.0625
step: 3468, val loss: nan, val acuracy: 0.10400000214576721
step: 3469, train loss: nan, train acuracy: 0.125
step: 3469, val loss: nan, val acuracy: 0.10400000214576721
step: 3470, train loss: nan, train acuracy: 0.078125
step: 3470, val loss: nan, val acuracy: 0.10400000214576721
step: 3471, train loss: nan, train acuracy: 0.125
step: 3471, val loss: nan, val acuracy: 0.10400000214576721
step: 3472, train loss: nan, train acuracy: 0.046875
step: 3472, val loss: nan, val acuracy: 0.10400000214576721
step: 3473, train loss: nan, train acuracy: 0.1875
step: 3473, val loss: nan, val acuracy: 0.10400000214576721
step: 3474, train loss: nan, train acuracy: 0.09375
step: 3474, val loss: nan, val acuracy: 0.10400000214576721
step: 3475, train loss: nan, train acuracy: 0.15625
step: 3475, val loss: nan, val acuracy: 0.10400000214576721
step: 3476, train loss: nan, train acuracy: 0.1875
step: 3476, val loss: nan, val acuracy: 0.10400000214576721
step: 3477, train loss: nan, train acuracy: 0.09375
step: 3477, val loss: nan, val acuracy: 0.10400000214576721
step: 3478, train loss: nan, train acuracy: 0.15625
step: 3478, val loss: nan, val acuracy: 0.10400000214576721
step: 3479, train loss: nan, train acuracy: 0.09375
step: 3479, val loss: nan, val acuracy: 0.10400000214576721
step: 3480, train loss: nan, train acuracy: 0.15625
step: 3480, val loss: nan, val acuracy: 0.10400000214576721
step: 3481, train loss: nan, train acuracy: 0.03125
step: 3481, val loss: nan, val acuracy: 0.10400000214576721
step: 3482, train loss: nan, train acuracy: 0.109375
step: 3482, val loss: nan, val acuracy: 0.10400000214576721
step: 3483, train loss: nan, train acuracy: 0.09375
step: 3483, val loss: nan, val acuracy: 0.10400000214576721
step: 3484, train loss: nan, train acuracy: 0.125
step: 3484, val loss: nan, val acuracy: 0.10400000214576721
step: 3485, train loss: nan, train acuracy: 0.140625
step: 3485, val loss: nan, val acuracy: 0.10400000214576721
step: 3486, train loss: nan, train acuracy: 0.09375
step: 3486, val loss: nan, val acuracy: 0.10400000214576721
step: 3487, train loss: nan, train acuracy: 0.109375
step: 3487, val loss: nan, val acuracy: 0.10400000214576721
step: 3488, train loss: nan, train acuracy: 0.0625
step: 3488, val loss: nan, val acuracy: 0.10400000214576721
step: 3489, train loss: nan, train acuracy: 0.109375
step: 3489, val loss: nan, val acuracy: 0.10400000214576721
step: 3490, train loss: nan, train acuracy: 0.109375
step: 3490, val loss: nan, val acuracy: 0.10400000214576721
step: 3491, train loss: nan, train acuracy: 0.0625
step: 3491, val loss: nan, val acuracy: 0.10400000214576721
step: 3492, train loss: nan, train acuracy: 0.078125
step: 3492, val loss: nan, val acuracy: 0.10400000214576721
step: 3493, train loss: nan, train acuracy: 0.0625
step: 3493, val loss: nan, val acuracy: 0.10400000214576721
step: 3494, train loss: nan, train acuracy: 0.0625
step: 3494, val loss: nan, val acuracy: 0.10400000214576721
step: 3495, train loss: nan, train acuracy: 0.1875
step: 3495, val loss: nan, val acuracy: 0.10400000214576721
step: 3496, train loss: nan, train acuracy: 0.078125
step: 3496, val loss: nan, val acuracy: 0.10400000214576721
step: 3497, train loss: nan, train acuracy: 0.046875
step: 3497, val loss: nan, val acuracy: 0.10400000214576721
step: 3498, train loss: nan, train acuracy: 0.125
step: 3498, val loss: nan, val acuracy: 0.10400000214576721
step: 3499, train loss: nan, train acuracy: 0.046875
step: 3499, val loss: nan, val acuracy: 0.10400000214576721
step: 3500, train loss: nan, train acuracy: 0.109375
step: 3500, val loss: nan, val acuracy: 0.10400000214576721
step: 3501, train loss: nan, train acuracy: 0.078125
step: 3501, val loss: nan, val acuracy: 0.10400000214576721
step: 3502, train loss: nan, train acuracy: 0.15625
step: 3502, val loss: nan, val acuracy: 0.10400000214576721
step: 3503, train loss: nan, train acuracy: 0.140625
step: 3503, val loss: nan, val acuracy: 0.10400000214576721
step: 3504, train loss: nan, train acuracy: 0.09375
step: 3504, val loss: nan, val acuracy: 0.10400000214576721
step: 3505, train loss: nan, train acuracy: 0.15625
step: 3505, val loss: nan, val acuracy: 0.10400000214576721
step: 3506, train loss: nan, train acuracy: 0.09375
step: 3506, val loss: nan, val acuracy: 0.10400000214576721
step: 3507, train loss: nan, train acuracy: 0.0625
step: 3507, val loss: nan, val acuracy: 0.10400000214576721
step: 3508, train loss: nan, train acuracy: 0.109375
step: 3508, val loss: nan, val acuracy: 0.10400000214576721
step: 3509, train loss: nan, train acuracy: 0.125
step: 3509, val loss: nan, val acuracy: 0.10400000214576721
step: 3510, train loss: nan, train acuracy: 0.078125
step: 3510, val loss: nan, val acuracy: 0.10400000214576721
step: 3511, train loss: nan, train acuracy: 0.09375
step: 3511, val loss: nan, val acuracy: 0.10400000214576721
step: 3512, train loss: nan, train acuracy: 0.046875
step: 3512, val loss: nan, val acuracy: 0.10400000214576721
step: 3513, train loss: nan, train acuracy: 0.140625
step: 3513, val loss: nan, val acuracy: 0.10400000214576721
step: 3514, train loss: nan, train acuracy: 0.140625
step: 3514, val loss: nan, val acuracy: 0.10400000214576721
step: 3515, train loss: nan, train acuracy: 0.015625
step: 3515, val loss: nan, val acuracy: 0.10400000214576721
step: 3516, train loss: nan, train acuracy: 0.09375
step: 3516, val loss: nan, val acuracy: 0.10400000214576721
step: 3517, train loss: nan, train acuracy: 0.0625
step: 3517, val loss: nan, val acuracy: 0.10400000214576721
step: 3518, train loss: nan, train acuracy: 0.078125
step: 3518, val loss: nan, val acuracy: 0.10400000214576721
step: 3519, train loss: nan, train acuracy: 0.03125
step: 3519, val loss: nan, val acuracy: 0.10400000214576721
step: 3520, train loss: nan, train acuracy: 0.0625
step: 3520, val loss: nan, val acuracy: 0.10400000214576721
step: 3521, train loss: nan, train acuracy: 0.046875
step: 3521, val loss: nan, val acuracy: 0.10400000214576721
step: 3522, train loss: nan, train acuracy: 0.140625
step: 3522, val loss: nan, val acuracy: 0.10400000214576721
step: 3523, train loss: nan, train acuracy: 0.09375
step: 3523, val loss: nan, val acuracy: 0.10400000214576721
step: 3524, train loss: nan, train acuracy: 0.09375
step: 3524, val loss: nan, val acuracy: 0.10400000214576721
step: 3525, train loss: nan, train acuracy: 0.1875
step: 3525, val loss: nan, val acuracy: 0.10400000214576721
step: 3526, train loss: nan, train acuracy: 0.140625
step: 3526, val loss: nan, val acuracy: 0.10400000214576721
step: 3527, train loss: nan, train acuracy: 0.109375
step: 3527, val loss: nan, val acuracy: 0.10400000214576721
step: 3528, train loss: nan, train acuracy: 0.078125
step: 3528, val loss: nan, val acuracy: 0.10400000214576721
step: 3529, train loss: nan, train acuracy: 0.09375
step: 3529, val loss: nan, val acuracy: 0.10400000214576721
step: 3530, train loss: nan, train acuracy: 0.109375
step: 3530, val loss: nan, val acuracy: 0.10400000214576721
step: 3531, train loss: nan, train acuracy: 0.09375
step: 3531, val loss: nan, val acuracy: 0.10400000214576721
step: 3532, train loss: nan, train acuracy: 0.125
step: 3532, val loss: nan, val acuracy: 0.10400000214576721
step: 3533, train loss: nan, train acuracy: 0.046875
step: 3533, val loss: nan, val acuracy: 0.10400000214576721
step: 3534, train loss: nan, train acuracy: 0.09375
step: 3534, val loss: nan, val acuracy: 0.10400000214576721
step: 3535, train loss: nan, train acuracy: 0.09375
step: 3535, val loss: nan, val acuracy: 0.10400000959634781
step: 3536, train loss: nan, train acuracy: 0.078125
step: 3536, val loss: nan, val acuracy: 0.10400000214576721
step: 3537, train loss: nan, train acuracy: 0.109375
step: 3537, val loss: nan, val acuracy: 0.10400000214576721
step: 3538, train loss: nan, train acuracy: 0.046875
step: 3538, val loss: nan, val acuracy: 0.10400000214576721
step: 3539, train loss: nan, train acuracy: 0.125
step: 3539, val loss: nan, val acuracy: 0.10400000214576721
step: 3540, train loss: nan, train acuracy: 0.078125
step: 3540, val loss: nan, val acuracy: 0.10400000214576721
step: 3541, train loss: nan, train acuracy: 0.046875
step: 3541, val loss: nan, val acuracy: 0.10400000214576721
step: 3542, train loss: nan, train acuracy: 0.046875
step: 3542, val loss: nan, val acuracy: 0.10400000214576721
step: 3543, train loss: nan, train acuracy: 0.171875
step: 3543, val loss: nan, val acuracy: 0.10400000214576721
step: 3544, train loss: nan, train acuracy: 0.09375
step: 3544, val loss: nan, val acuracy: 0.10400000214576721
step: 3545, train loss: nan, train acuracy: 0.078125
step: 3545, val loss: nan, val acuracy: 0.10400000214576721
step: 3546, train loss: nan, train acuracy: 0.0625
step: 3546, val loss: nan, val acuracy: 0.10400000214576721
step: 3547, train loss: nan, train acuracy: 0.09375
step: 3547, val loss: nan, val acuracy: 0.10400000214576721
step: 3548, train loss: nan, train acuracy: 0.0625
step: 3548, val loss: nan, val acuracy: 0.10400000214576721
step: 3549, train loss: nan, train acuracy: 0.09375
step: 3549, val loss: nan, val acuracy: 0.10400000214576721
step: 3550, train loss: nan, train acuracy: 0.140625
step: 3550, val loss: nan, val acuracy: 0.10400000214576721
step: 3551, train loss: nan, train acuracy: 0.109375
step: 3551, val loss: nan, val acuracy: 0.10400000214576721
step: 3552, train loss: nan, train acuracy: 0.0625
step: 3552, val loss: nan, val acuracy: 0.10400000214576721
step: 3553, train loss: nan, train acuracy: 0.09375
step: 3553, val loss: nan, val acuracy: 0.10400000214576721
step: 3554, train loss: nan, train acuracy: 0.046875
step: 3554, val loss: nan, val acuracy: 0.10400000214576721
step: 3555, train loss: nan, train acuracy: 0.078125
step: 3555, val loss: nan, val acuracy: 0.10400000214576721
step: 3556, train loss: nan, train acuracy: 0.0625
step: 3556, val loss: nan, val acuracy: 0.10400000214576721
step: 3557, train loss: nan, train acuracy: 0.09375
step: 3557, val loss: nan, val acuracy: 0.10400000214576721
step: 3558, train loss: nan, train acuracy: 0.078125
step: 3558, val loss: nan, val acuracy: 0.10400000214576721
step: 3559, train loss: nan, train acuracy: 0.109375
step: 3559, val loss: nan, val acuracy: 0.10400000214576721
step: 3560, train loss: nan, train acuracy: 0.0
step: 3560, val loss: nan, val acuracy: 0.10400000214576721
step: 3561, train loss: nan, train acuracy: 0.03125
step: 3561, val loss: nan, val acuracy: 0.10400000214576721
step: 3562, train loss: nan, train acuracy: 0.15625
step: 3562, val loss: nan, val acuracy: 0.10400000214576721
step: 3563, train loss: nan, train acuracy: 0.078125
step: 3563, val loss: nan, val acuracy: 0.10400000214576721
step: 3564, train loss: nan, train acuracy: 0.109375
step: 3564, val loss: nan, val acuracy: 0.10400000214576721
step: 3565, train loss: nan, train acuracy: 0.09375
step: 3565, val loss: nan, val acuracy: 0.10400000214576721
step: 3566, train loss: nan, train acuracy: 0.109375
step: 3566, val loss: nan, val acuracy: 0.10400000214576721
step: 3567, train loss: nan, train acuracy: 0.0625
step: 3567, val loss: nan, val acuracy: 0.10400000214576721
step: 3568, train loss: nan, train acuracy: 0.09375
step: 3568, val loss: nan, val acuracy: 0.10400000214576721
step: 3569, train loss: nan, train acuracy: 0.125
step: 3569, val loss: nan, val acuracy: 0.10400000214576721
step: 3570, train loss: nan, train acuracy: 0.203125
step: 3570, val loss: nan, val acuracy: 0.10400000214576721
step: 3571, train loss: nan, train acuracy: 0.125
step: 3571, val loss: nan, val acuracy: 0.10400000214576721
step: 3572, train loss: nan, train acuracy: 0.109375
step: 3572, val loss: nan, val acuracy: 0.10400000214576721
step: 3573, train loss: nan, train acuracy: 0.125
step: 3573, val loss: nan, val acuracy: 0.10400000214576721
step: 3574, train loss: nan, train acuracy: 0.0625
step: 3574, val loss: nan, val acuracy: 0.10400000214576721
step: 3575, train loss: nan, train acuracy: 0.046875
step: 3575, val loss: nan, val acuracy: 0.10400000214576721
step: 3576, train loss: nan, train acuracy: 0.03125
step: 3576, val loss: nan, val acuracy: 0.10400000214576721
step: 3577, train loss: nan, train acuracy: 0.078125
step: 3577, val loss: nan, val acuracy: 0.10400000214576721
step: 3578, train loss: nan, train acuracy: 0.03125
step: 3578, val loss: nan, val acuracy: 0.10400000214576721
step: 3579, train loss: nan, train acuracy: 0.078125
step: 3579, val loss: nan, val acuracy: 0.10400000214576721
step: 3580, train loss: nan, train acuracy: 0.078125
step: 3580, val loss: nan, val acuracy: 0.10400000214576721
step: 3581, train loss: nan, train acuracy: 0.140625
step: 3581, val loss: nan, val acuracy: 0.10400000214576721
step: 3582, train loss: nan, train acuracy: 0.09375
step: 3582, val loss: nan, val acuracy: 0.10400000214576721
step: 3583, train loss: nan, train acuracy: 0.078125
step: 3583, val loss: nan, val acuracy: 0.10400000214576721
step: 3584, train loss: nan, train acuracy: 0.078125
step: 3584, val loss: nan, val acuracy: 0.10400000214576721
step: 3585, train loss: nan, train acuracy: 0.171875
step: 3585, val loss: nan, val acuracy: 0.10400000214576721
step: 3586, train loss: nan, train acuracy: 0.078125
step: 3586, val loss: nan, val acuracy: 0.10400000214576721
step: 3587, train loss: nan, train acuracy: 0.15625
step: 3587, val loss: nan, val acuracy: 0.10400000214576721
step: 3588, train loss: nan, train acuracy: 0.140625
step: 3588, val loss: nan, val acuracy: 0.10400000214576721
step: 3589, train loss: nan, train acuracy: 0.03125
step: 3589, val loss: nan, val acuracy: 0.10400000214576721
step: 3590, train loss: nan, train acuracy: 0.15625
step: 3590, val loss: nan, val acuracy: 0.10400000214576721
step: 3591, train loss: nan, train acuracy: 0.09375
step: 3591, val loss: nan, val acuracy: 0.10400000214576721
step: 3592, train loss: nan, train acuracy: 0.09375
step: 3592, val loss: nan, val acuracy: 0.10400000214576721
step: 3593, train loss: nan, train acuracy: 0.0625
step: 3593, val loss: nan, val acuracy: 0.10400000214576721
step: 3594, train loss: nan, train acuracy: 0.078125
step: 3594, val loss: nan, val acuracy: 0.10400000214576721
step: 3595, train loss: nan, train acuracy: 0.046875
step: 3595, val loss: nan, val acuracy: 0.10400000214576721
step: 3596, train loss: nan, train acuracy: 0.109375
step: 3596, val loss: nan, val acuracy: 0.10400000214576721
step: 3597, train loss: nan, train acuracy: 0.125
step: 3597, val loss: nan, val acuracy: 0.10400000214576721
step: 3598, train loss: nan, train acuracy: 0.09375
step: 3598, val loss: nan, val acuracy: 0.10400000214576721
step: 3599, train loss: nan, train acuracy: 0.125
step: 3599, val loss: nan, val acuracy: 0.10400000214576721
step: 3600, train loss: nan, train acuracy: 0.046875
step: 3600, val loss: nan, val acuracy: 0.10400000214576721
step: 3601, train loss: nan, train acuracy: 0.125
step: 3601, val loss: nan, val acuracy: 0.10400000214576721
step: 3602, train loss: nan, train acuracy: 0.125
step: 3602, val loss: nan, val acuracy: 0.10400000214576721
step: 3603, train loss: nan, train acuracy: 0.078125
step: 3603, val loss: nan, val acuracy: 0.10400000214576721
step: 3604, train loss: nan, train acuracy: 0.078125
step: 3604, val loss: nan, val acuracy: 0.10400000214576721
step: 3605, train loss: nan, train acuracy: 0.171875
step: 3605, val loss: nan, val acuracy: 0.10400000214576721
step: 3606, train loss: nan, train acuracy: 0.09375
step: 3606, val loss: nan, val acuracy: 0.10400000214576721
step: 3607, train loss: nan, train acuracy: 0.0625
step: 3607, val loss: nan, val acuracy: 0.10400000214576721
step: 3608, train loss: nan, train acuracy: 0.09375
step: 3608, val loss: nan, val acuracy: 0.10400000214576721
step: 3609, train loss: nan, train acuracy: 0.109375
step: 3609, val loss: nan, val acuracy: 0.10400000214576721
step: 3610, train loss: nan, train acuracy: 0.203125
step: 3610, val loss: nan, val acuracy: 0.10400000214576721
step: 3611, train loss: nan, train acuracy: 0.09375
step: 3611, val loss: nan, val acuracy: 0.10400000214576721
step: 3612, train loss: nan, train acuracy: 0.078125
step: 3612, val loss: nan, val acuracy: 0.10400000214576721
step: 3613, train loss: nan, train acuracy: 0.109375
step: 3613, val loss: nan, val acuracy: 0.10400000214576721
step: 3614, train loss: nan, train acuracy: 0.09375
step: 3614, val loss: nan, val acuracy: 0.10400000214576721
step: 3615, train loss: nan, train acuracy: 0.078125
step: 3615, val loss: nan, val acuracy: 0.10400000214576721
step: 3616, train loss: nan, train acuracy: 0.203125
step: 3616, val loss: nan, val acuracy: 0.10400000214576721
step: 3617, train loss: nan, train acuracy: 0.046875
step: 3617, val loss: nan, val acuracy: 0.10400000214576721
step: 3618, train loss: nan, train acuracy: 0.046875
step: 3618, val loss: nan, val acuracy: 0.10400000214576721
step: 3619, train loss: nan, train acuracy: 0.109375
step: 3619, val loss: nan, val acuracy: 0.10400000214576721
step: 3620, train loss: nan, train acuracy: 0.078125
step: 3620, val loss: nan, val acuracy: 0.10400000214576721
step: 3621, train loss: nan, train acuracy: 0.09375
step: 3621, val loss: nan, val acuracy: 0.10400000214576721
step: 3622, train loss: nan, train acuracy: 0.109375
step: 3622, val loss: nan, val acuracy: 0.10400000214576721
step: 3623, train loss: nan, train acuracy: 0.015625
step: 3623, val loss: nan, val acuracy: 0.10400000214576721
step: 3624, train loss: nan, train acuracy: 0.125
step: 3624, val loss: nan, val acuracy: 0.10400000214576721
step: 3625, train loss: nan, train acuracy: 0.0625
step: 3625, val loss: nan, val acuracy: 0.10400000214576721
step: 3626, train loss: nan, train acuracy: 0.09375
step: 3626, val loss: nan, val acuracy: 0.10400000214576721
step: 3627, train loss: nan, train acuracy: 0.046875
step: 3627, val loss: nan, val acuracy: 0.10400000214576721
step: 3628, train loss: nan, train acuracy: 0.1875
step: 3628, val loss: nan, val acuracy: 0.10400000214576721
step: 3629, train loss: nan, train acuracy: 0.046875
step: 3629, val loss: nan, val acuracy: 0.10400000214576721
step: 3630, train loss: nan, train acuracy: 0.09375
step: 3630, val loss: nan, val acuracy: 0.10400000214576721
step: 3631, train loss: nan, train acuracy: 0.109375
step: 3631, val loss: nan, val acuracy: 0.10400000214576721
step: 3632, train loss: nan, train acuracy: 0.171875
step: 3632, val loss: nan, val acuracy: 0.10400000214576721
step: 3633, train loss: nan, train acuracy: 0.078125
step: 3633, val loss: nan, val acuracy: 0.10400000214576721
step: 3634, train loss: nan, train acuracy: 0.0625
step: 3634, val loss: nan, val acuracy: 0.10400000214576721
step: 3635, train loss: nan, train acuracy: 0.109375
step: 3635, val loss: nan, val acuracy: 0.10400000214576721
step: 3636, train loss: nan, train acuracy: 0.125
step: 3636, val loss: nan, val acuracy: 0.10400000214576721
step: 3637, train loss: nan, train acuracy: 0.109375
step: 3637, val loss: nan, val acuracy: 0.10400000214576721
step: 3638, train loss: nan, train acuracy: 0.09375
step: 3638, val loss: nan, val acuracy: 0.10400000214576721
step: 3639, train loss: nan, train acuracy: 0.078125
step: 3639, val loss: nan, val acuracy: 0.10400000214576721
step: 3640, train loss: nan, train acuracy: 0.109375
step: 3640, val loss: nan, val acuracy: 0.10400000214576721
step: 3641, train loss: nan, train acuracy: 0.078125
step: 3641, val loss: nan, val acuracy: 0.10400000214576721
step: 3642, train loss: nan, train acuracy: 0.078125
step: 3642, val loss: nan, val acuracy: 0.10400000214576721
step: 3643, train loss: nan, train acuracy: 0.125
step: 3643, val loss: nan, val acuracy: 0.10400000214576721
step: 3644, train loss: nan, train acuracy: 0.125
step: 3644, val loss: nan, val acuracy: 0.10400000214576721
step: 3645, train loss: nan, train acuracy: 0.125
step: 3645, val loss: nan, val acuracy: 0.10400000214576721
step: 3646, train loss: nan, train acuracy: 0.140625
step: 3646, val loss: nan, val acuracy: 0.10400000214576721
step: 3647, train loss: nan, train acuracy: 0.03125
step: 3647, val loss: nan, val acuracy: 0.10400000214576721
step: 3648, train loss: nan, train acuracy: 0.046875
step: 3648, val loss: nan, val acuracy: 0.10400000214576721
step: 3649, train loss: nan, train acuracy: 0.03125
step: 3649, val loss: nan, val acuracy: 0.10400000214576721
step: 3650, train loss: nan, train acuracy: 0.140625
step: 3650, val loss: nan, val acuracy: 0.10400000214576721
step: 3651, train loss: nan, train acuracy: 0.09375
step: 3651, val loss: nan, val acuracy: 0.10400000214576721
step: 3652, train loss: nan, train acuracy: 0.046875
step: 3652, val loss: nan, val acuracy: 0.10400000214576721
step: 3653, train loss: nan, train acuracy: 0.046875
step: 3653, val loss: nan, val acuracy: 0.10400000214576721
step: 3654, train loss: nan, train acuracy: 0.0625
step: 3654, val loss: nan, val acuracy: 0.10400000214576721
step: 3655, train loss: nan, train acuracy: 0.078125
step: 3655, val loss: nan, val acuracy: 0.10400000214576721
step: 3656, train loss: nan, train acuracy: 0.109375
step: 3656, val loss: nan, val acuracy: 0.10400000214576721
step: 3657, train loss: nan, train acuracy: 0.125
step: 3657, val loss: nan, val acuracy: 0.10400000214576721
step: 3658, train loss: nan, train acuracy: 0.0625
step: 3658, val loss: nan, val acuracy: 0.10400000214576721
step: 3659, train loss: nan, train acuracy: 0.078125
step: 3659, val loss: nan, val acuracy: 0.10400000214576721
step: 3660, train loss: nan, train acuracy: 0.09375
step: 3660, val loss: nan, val acuracy: 0.10400000214576721
step: 3661, train loss: nan, train acuracy: 0.09375
step: 3661, val loss: nan, val acuracy: 0.10400000214576721
step: 3662, train loss: nan, train acuracy: 0.078125
step: 3662, val loss: nan, val acuracy: 0.10400000214576721
step: 3663, train loss: nan, train acuracy: 0.09375
step: 3663, val loss: nan, val acuracy: 0.10400000214576721
step: 3664, train loss: nan, train acuracy: 0.046875
step: 3664, val loss: nan, val acuracy: 0.10400000214576721
step: 3665, train loss: nan, train acuracy: 0.15625
step: 3665, val loss: nan, val acuracy: 0.10400000214576721
step: 3666, train loss: nan, train acuracy: 0.09375
step: 3666, val loss: nan, val acuracy: 0.10400000214576721
step: 3667, train loss: nan, train acuracy: 0.09375
step: 3667, val loss: nan, val acuracy: 0.10400000214576721
step: 3668, train loss: nan, train acuracy: 0.046875
step: 3668, val loss: nan, val acuracy: 0.10400000214576721
step: 3669, train loss: nan, train acuracy: 0.078125
step: 3669, val loss: nan, val acuracy: 0.10400000214576721
step: 3670, train loss: nan, train acuracy: 0.1875
step: 3670, val loss: nan, val acuracy: 0.10400000214576721
step: 3671, train loss: nan, train acuracy: 0.1875
step: 3671, val loss: nan, val acuracy: 0.10400000214576721
step: 3672, train loss: nan, train acuracy: 0.109375
step: 3672, val loss: nan, val acuracy: 0.10400000214576721
step: 3673, train loss: nan, train acuracy: 0.125
step: 3673, val loss: nan, val acuracy: 0.10400000214576721
step: 3674, train loss: nan, train acuracy: 0.078125
step: 3674, val loss: nan, val acuracy: 0.10400000214576721
step: 3675, train loss: nan, train acuracy: 0.125
step: 3675, val loss: nan, val acuracy: 0.10400000214576721
step: 3676, train loss: nan, train acuracy: 0.078125
step: 3676, val loss: nan, val acuracy: 0.10400000214576721
step: 3677, train loss: nan, train acuracy: 0.078125
step: 3677, val loss: nan, val acuracy: 0.10400000214576721
step: 3678, train loss: nan, train acuracy: 0.03125
step: 3678, val loss: nan, val acuracy: 0.10400000214576721
step: 3679, train loss: nan, train acuracy: 0.1875
step: 3679, val loss: nan, val acuracy: 0.10400000214576721
step: 3680, train loss: nan, train acuracy: 0.078125
step: 3680, val loss: nan, val acuracy: 0.10400000214576721
step: 3681, train loss: nan, train acuracy: 0.0625
step: 3681, val loss: nan, val acuracy: 0.10400000214576721
step: 3682, train loss: nan, train acuracy: 0.0625
step: 3682, val loss: nan, val acuracy: 0.10400000214576721
step: 3683, train loss: nan, train acuracy: 0.171875
step: 3683, val loss: nan, val acuracy: 0.10400000214576721
step: 3684, train loss: nan, train acuracy: 0.09375
step: 3684, val loss: nan, val acuracy: 0.10400000214576721
step: 3685, train loss: nan, train acuracy: 0.078125
step: 3685, val loss: nan, val acuracy: 0.10400000214576721
step: 3686, train loss: nan, train acuracy: 0.125
step: 3686, val loss: nan, val acuracy: 0.10400000214576721
step: 3687, train loss: nan, train acuracy: 0.0625
step: 3687, val loss: nan, val acuracy: 0.10400000214576721
step: 3688, train loss: nan, train acuracy: 0.03125
step: 3688, val loss: nan, val acuracy: 0.10400000214576721
step: 3689, train loss: nan, train acuracy: 0.09375
step: 3689, val loss: nan, val acuracy: 0.10400000214576721
step: 3690, train loss: nan, train acuracy: 0.046875
step: 3690, val loss: nan, val acuracy: 0.10400000214576721
step: 3691, train loss: nan, train acuracy: 0.125
step: 3691, val loss: nan, val acuracy: 0.10400000214576721
step: 3692, train loss: nan, train acuracy: 0.109375
step: 3692, val loss: nan, val acuracy: 0.10400000214576721
step: 3693, train loss: nan, train acuracy: 0.125
step: 3693, val loss: nan, val acuracy: 0.10400000214576721
step: 3694, train loss: nan, train acuracy: 0.171875
step: 3694, val loss: nan, val acuracy: 0.10400000214576721
step: 3695, train loss: nan, train acuracy: 0.0625
step: 3695, val loss: nan, val acuracy: 0.10400000214576721
step: 3696, train loss: nan, train acuracy: 0.09375
step: 3696, val loss: nan, val acuracy: 0.10400000214576721
step: 3697, train loss: nan, train acuracy: 0.0625
step: 3697, val loss: nan, val acuracy: 0.10400000214576721
step: 3698, train loss: nan, train acuracy: 0.03125
step: 3698, val loss: nan, val acuracy: 0.10400000214576721
step: 3699, train loss: nan, train acuracy: 0.078125
step: 3699, val loss: nan, val acuracy: 0.10400000214576721
step: 3700, train loss: nan, train acuracy: 0.09375
step: 3700, val loss: nan, val acuracy: 0.10400000214576721
step: 3701, train loss: nan, train acuracy: 0.09375
step: 3701, val loss: nan, val acuracy: 0.10400000214576721
step: 3702, train loss: nan, train acuracy: 0.109375
step: 3702, val loss: nan, val acuracy: 0.10400000214576721
step: 3703, train loss: nan, train acuracy: 0.09375
step: 3703, val loss: nan, val acuracy: 0.10400000214576721
step: 3704, train loss: nan, train acuracy: 0.09375
step: 3704, val loss: nan, val acuracy: 0.10400000214576721
step: 3705, train loss: nan, train acuracy: 0.171875
step: 3705, val loss: nan, val acuracy: 0.10400000214576721
step: 3706, train loss: nan, train acuracy: 0.078125
step: 3706, val loss: nan, val acuracy: 0.10400000214576721
step: 3707, train loss: nan, train acuracy: 0.140625
step: 3707, val loss: nan, val acuracy: 0.10400000214576721
step: 3708, train loss: nan, train acuracy: 0.140625
step: 3708, val loss: nan, val acuracy: 0.10400000214576721
step: 3709, train loss: nan, train acuracy: 0.078125
step: 3709, val loss: nan, val acuracy: 0.10400000214576721
step: 3710, train loss: nan, train acuracy: 0.125
step: 3710, val loss: nan, val acuracy: 0.10400000214576721
step: 3711, train loss: nan, train acuracy: 0.125
step: 3711, val loss: nan, val acuracy: 0.10400000214576721
step: 3712, train loss: nan, train acuracy: 0.140625
step: 3712, val loss: nan, val acuracy: 0.10400000214576721
step: 3713, train loss: nan, train acuracy: 0.171875
step: 3713, val loss: nan, val acuracy: 0.10400000214576721
step: 3714, train loss: nan, train acuracy: 0.109375
step: 3714, val loss: nan, val acuracy: 0.10400000214576721
step: 3715, train loss: nan, train acuracy: 0.078125
step: 3715, val loss: nan, val acuracy: 0.10400000214576721
step: 3716, train loss: nan, train acuracy: 0.09375
step: 3716, val loss: nan, val acuracy: 0.10400000214576721
step: 3717, train loss: nan, train acuracy: 0.078125
step: 3717, val loss: nan, val acuracy: 0.10400000214576721
step: 3718, train loss: nan, train acuracy: 0.078125
step: 3718, val loss: nan, val acuracy: 0.10400000214576721
step: 3719, train loss: nan, train acuracy: 0.109375
step: 3719, val loss: nan, val acuracy: 0.10400000214576721
step: 3720, train loss: nan, train acuracy: 0.046875
step: 3720, val loss: nan, val acuracy: 0.10400000214576721
step: 3721, train loss: nan, train acuracy: 0.078125
step: 3721, val loss: nan, val acuracy: 0.10400000214576721
step: 3722, train loss: nan, train acuracy: 0.0625
step: 3722, val loss: nan, val acuracy: 0.10400000214576721
step: 3723, train loss: nan, train acuracy: 0.078125
step: 3723, val loss: nan, val acuracy: 0.10400000214576721
step: 3724, train loss: nan, train acuracy: 0.09375
step: 3724, val loss: nan, val acuracy: 0.10400000214576721
step: 3725, train loss: nan, train acuracy: 0.109375
step: 3725, val loss: nan, val acuracy: 0.10400000214576721
step: 3726, train loss: nan, train acuracy: 0.09375
step: 3726, val loss: nan, val acuracy: 0.10400000214576721
step: 3727, train loss: nan, train acuracy: 0.125
step: 3727, val loss: nan, val acuracy: 0.10400000214576721
step: 3728, train loss: nan, train acuracy: 0.125
step: 3728, val loss: nan, val acuracy: 0.10400000214576721
step: 3729, train loss: nan, train acuracy: 0.0625
step: 3729, val loss: nan, val acuracy: 0.10400000214576721
step: 3730, train loss: nan, train acuracy: 0.125
step: 3730, val loss: nan, val acuracy: 0.10400000214576721
step: 3731, train loss: nan, train acuracy: 0.078125
step: 3731, val loss: nan, val acuracy: 0.10400000214576721
step: 3732, train loss: nan, train acuracy: 0.09375
step: 3732, val loss: nan, val acuracy: 0.10400000214576721
step: 3733, train loss: nan, train acuracy: 0.171875
step: 3733, val loss: nan, val acuracy: 0.10400000214576721
step: 3734, train loss: nan, train acuracy: 0.078125
step: 3734, val loss: nan, val acuracy: 0.10400000214576721
step: 3735, train loss: nan, train acuracy: 0.125
step: 3735, val loss: nan, val acuracy: 0.10400000214576721
step: 3736, train loss: nan, train acuracy: 0.0625
step: 3736, val loss: nan, val acuracy: 0.10400000214576721
step: 3737, train loss: nan, train acuracy: 0.078125
step: 3737, val loss: nan, val acuracy: 0.10400000214576721
step: 3738, train loss: nan, train acuracy: 0.109375
step: 3738, val loss: nan, val acuracy: 0.10400000214576721
step: 3739, train loss: nan, train acuracy: 0.15625
step: 3739, val loss: nan, val acuracy: 0.10400000214576721
step: 3740, train loss: nan, train acuracy: 0.15625
step: 3740, val loss: nan, val acuracy: 0.10400000214576721
step: 3741, train loss: nan, train acuracy: 0.0625
step: 3741, val loss: nan, val acuracy: 0.10400000214576721
step: 3742, train loss: nan, train acuracy: 0.109375
step: 3742, val loss: nan, val acuracy: 0.10400000214576721
step: 3743, train loss: nan, train acuracy: 0.03125
step: 3743, val loss: nan, val acuracy: 0.10400000214576721
step: 3744, train loss: nan, train acuracy: 0.15625
step: 3744, val loss: nan, val acuracy: 0.10400000214576721
step: 3745, train loss: nan, train acuracy: 0.09375
step: 3745, val loss: nan, val acuracy: 0.10400000214576721
step: 3746, train loss: nan, train acuracy: 0.078125
step: 3746, val loss: nan, val acuracy: 0.10400000214576721
step: 3747, train loss: nan, train acuracy: 0.09375
step: 3747, val loss: nan, val acuracy: 0.10400000214576721
step: 3748, train loss: nan, train acuracy: 0.09375
step: 3748, val loss: nan, val acuracy: 0.10400000214576721
step: 3749, train loss: nan, train acuracy: 0.109375
step: 3749, val loss: nan, val acuracy: 0.10400000214576721
step: 3750, train loss: nan, train acuracy: 0.140625
step: 3750, val loss: nan, val acuracy: 0.10400000214576721
step: 3751, train loss: nan, train acuracy: 0.125
step: 3751, val loss: nan, val acuracy: 0.10400000214576721
step: 3752, train loss: nan, train acuracy: 0.09375
step: 3752, val loss: nan, val acuracy: 0.10400000214576721
step: 3753, train loss: nan, train acuracy: 0.078125
step: 3753, val loss: nan, val acuracy: 0.10400000214576721
step: 3754, train loss: nan, train acuracy: 0.0625
step: 3754, val loss: nan, val acuracy: 0.10400000214576721
step: 3755, train loss: nan, train acuracy: 0.125
step: 3755, val loss: nan, val acuracy: 0.10400000214576721
step: 3756, train loss: nan, train acuracy: 0.125
step: 3756, val loss: nan, val acuracy: 0.10400000214576721
step: 3757, train loss: nan, train acuracy: 0.09375
step: 3757, val loss: nan, val acuracy: 0.10400000214576721
step: 3758, train loss: nan, train acuracy: 0.125
step: 3758, val loss: nan, val acuracy: 0.10400000214576721
step: 3759, train loss: nan, train acuracy: 0.09375
step: 3759, val loss: nan, val acuracy: 0.10400000214576721
step: 3760, train loss: nan, train acuracy: 0.15625
step: 3760, val loss: nan, val acuracy: 0.10400000214576721
step: 3761, train loss: nan, train acuracy: 0.078125
step: 3761, val loss: nan, val acuracy: 0.10400000214576721
step: 3762, train loss: nan, train acuracy: 0.109375
step: 3762, val loss: nan, val acuracy: 0.10400000214576721
step: 3763, train loss: nan, train acuracy: 0.03125
step: 3763, val loss: nan, val acuracy: 0.10400000214576721
step: 3764, train loss: nan, train acuracy: 0.046875
step: 3764, val loss: nan, val acuracy: 0.10400000214576721
step: 3765, train loss: nan, train acuracy: 0.125
step: 3765, val loss: nan, val acuracy: 0.10400000214576721
step: 3766, train loss: nan, train acuracy: 0.09375
step: 3766, val loss: nan, val acuracy: 0.10400000214576721
step: 3767, train loss: nan, train acuracy: 0.140625
step: 3767, val loss: nan, val acuracy: 0.10400000214576721
step: 3768, train loss: nan, train acuracy: 0.0625
step: 3768, val loss: nan, val acuracy: 0.10400000214576721
step: 3769, train loss: nan, train acuracy: 0.125
step: 3769, val loss: nan, val acuracy: 0.10400000214576721
step: 3770, train loss: nan, train acuracy: 0.125
step: 3770, val loss: nan, val acuracy: 0.10400000214576721
step: 3771, train loss: nan, train acuracy: 0.078125
step: 3771, val loss: nan, val acuracy: 0.10400000214576721
step: 3772, train loss: nan, train acuracy: 0.0625
step: 3772, val loss: nan, val acuracy: 0.10400000214576721
step: 3773, train loss: nan, train acuracy: 0.078125
step: 3773, val loss: nan, val acuracy: 0.10400000214576721
step: 3774, train loss: nan, train acuracy: 0.15625
step: 3774, val loss: nan, val acuracy: 0.10400000214576721
step: 3775, train loss: nan, train acuracy: 0.109375
step: 3775, val loss: nan, val acuracy: 0.10400000214576721
step: 3776, train loss: nan, train acuracy: 0.109375
step: 3776, val loss: nan, val acuracy: 0.10400000214576721
step: 3777, train loss: nan, train acuracy: 0.078125
step: 3777, val loss: nan, val acuracy: 0.10400000214576721
step: 3778, train loss: nan, train acuracy: 0.15625
step: 3778, val loss: nan, val acuracy: 0.10400000214576721
step: 3779, train loss: nan, train acuracy: 0.125
step: 3779, val loss: nan, val acuracy: 0.10400000214576721
step: 3780, train loss: nan, train acuracy: 0.09375
step: 3780, val loss: nan, val acuracy: 0.10400000214576721
step: 3781, train loss: nan, train acuracy: 0.078125
step: 3781, val loss: nan, val acuracy: 0.10400000214576721
step: 3782, train loss: nan, train acuracy: 0.140625
step: 3782, val loss: nan, val acuracy: 0.10400000214576721
step: 3783, train loss: nan, train acuracy: 0.0625
step: 3783, val loss: nan, val acuracy: 0.10400000214576721
step: 3784, train loss: nan, train acuracy: 0.109375
step: 3784, val loss: nan, val acuracy: 0.10400000214576721
step: 3785, train loss: nan, train acuracy: 0.125
step: 3785, val loss: nan, val acuracy: 0.10400000214576721
step: 3786, train loss: nan, train acuracy: 0.109375
step: 3786, val loss: nan, val acuracy: 0.10400000214576721
step: 3787, train loss: nan, train acuracy: 0.078125
step: 3787, val loss: nan, val acuracy: 0.10400000214576721
step: 3788, train loss: nan, train acuracy: 0.0625
step: 3788, val loss: nan, val acuracy: 0.10400000214576721
step: 3789, train loss: nan, train acuracy: 0.046875
step: 3789, val loss: nan, val acuracy: 0.10400000214576721
step: 3790, train loss: nan, train acuracy: 0.109375
step: 3790, val loss: nan, val acuracy: 0.10400000214576721
step: 3791, train loss: nan, train acuracy: 0.0625
step: 3791, val loss: nan, val acuracy: 0.10400000214576721
step: 3792, train loss: nan, train acuracy: 0.046875
step: 3792, val loss: nan, val acuracy: 0.10400000214576721
step: 3793, train loss: nan, train acuracy: 0.078125
step: 3793, val loss: nan, val acuracy: 0.10400000214576721
step: 3794, train loss: nan, train acuracy: 0.0625
step: 3794, val loss: nan, val acuracy: 0.10400000214576721
step: 3795, train loss: nan, train acuracy: 0.046875
step: 3795, val loss: nan, val acuracy: 0.10400000214576721
step: 3796, train loss: nan, train acuracy: 0.0625
step: 3796, val loss: nan, val acuracy: 0.10400000214576721
step: 3797, train loss: nan, train acuracy: 0.09375
step: 3797, val loss: nan, val acuracy: 0.10400000214576721
step: 3798, train loss: nan, train acuracy: 0.078125
step: 3798, val loss: nan, val acuracy: 0.10400000214576721
step: 3799, train loss: nan, train acuracy: 0.109375
step: 3799, val loss: nan, val acuracy: 0.10400000214576721
step: 3800, train loss: nan, train acuracy: 0.078125
step: 3800, val loss: nan, val acuracy: 0.10400000214576721
step: 3801, train loss: nan, train acuracy: 0.0625
step: 3801, val loss: nan, val acuracy: 0.10400000214576721
step: 3802, train loss: nan, train acuracy: 0.0625
step: 3802, val loss: nan, val acuracy: 0.10400000214576721
step: 3803, train loss: nan, train acuracy: 0.078125
step: 3803, val loss: nan, val acuracy: 0.10400000214576721
step: 3804, train loss: nan, train acuracy: 0.203125
step: 3804, val loss: nan, val acuracy: 0.10400000214576721
step: 3805, train loss: nan, train acuracy: 0.125
step: 3805, val loss: nan, val acuracy: 0.10400000214576721
step: 3806, train loss: nan, train acuracy: 0.109375
step: 3806, val loss: nan, val acuracy: 0.10400000214576721
step: 3807, train loss: nan, train acuracy: 0.078125
step: 3807, val loss: nan, val acuracy: 0.10400000214576721
step: 3808, train loss: nan, train acuracy: 0.109375
step: 3808, val loss: nan, val acuracy: 0.10400000214576721
step: 3809, train loss: nan, train acuracy: 0.109375
step: 3809, val loss: nan, val acuracy: 0.10400000214576721
step: 3810, train loss: nan, train acuracy: 0.0625
step: 3810, val loss: nan, val acuracy: 0.10400000214576721
step: 3811, train loss: nan, train acuracy: 0.15625
step: 3811, val loss: nan, val acuracy: 0.10400000214576721
step: 3812, train loss: nan, train acuracy: 0.125
step: 3812, val loss: nan, val acuracy: 0.10400000214576721
step: 3813, train loss: nan, train acuracy: 0.09375
step: 3813, val loss: nan, val acuracy: 0.10400000214576721
step: 3814, train loss: nan, train acuracy: 0.140625
step: 3814, val loss: nan, val acuracy: 0.10400000214576721
step: 3815, train loss: nan, train acuracy: 0.140625
step: 3815, val loss: nan, val acuracy: 0.10400000214576721
step: 3816, train loss: nan, train acuracy: 0.078125
step: 3816, val loss: nan, val acuracy: 0.10400000214576721
step: 3817, train loss: nan, train acuracy: 0.09375
step: 3817, val loss: nan, val acuracy: 0.10400000214576721
step: 3818, train loss: nan, train acuracy: 0.140625
step: 3818, val loss: nan, val acuracy: 0.10400000214576721
step: 3819, train loss: nan, train acuracy: 0.15625
step: 3819, val loss: nan, val acuracy: 0.10400000214576721
step: 3820, train loss: nan, train acuracy: 0.140625
step: 3820, val loss: nan, val acuracy: 0.10400000214576721
step: 3821, train loss: nan, train acuracy: 0.109375
step: 3821, val loss: nan, val acuracy: 0.10400000214576721
step: 3822, train loss: nan, train acuracy: 0.09375
step: 3822, val loss: nan, val acuracy: 0.10400000214576721
step: 3823, train loss: nan, train acuracy: 0.078125
step: 3823, val loss: nan, val acuracy: 0.10400000214576721
step: 3824, train loss: nan, train acuracy: 0.109375
step: 3824, val loss: nan, val acuracy: 0.10400000214576721
step: 3825, train loss: nan, train acuracy: 0.078125
step: 3825, val loss: nan, val acuracy: 0.10400000214576721
step: 3826, train loss: nan, train acuracy: 0.09375
step: 3826, val loss: nan, val acuracy: 0.10400000214576721
step: 3827, train loss: nan, train acuracy: 0.046875
step: 3827, val loss: nan, val acuracy: 0.10400000214576721
step: 3828, train loss: nan, train acuracy: 0.125
step: 3828, val loss: nan, val acuracy: 0.10400000214576721
step: 3829, train loss: nan, train acuracy: 0.140625
step: 3829, val loss: nan, val acuracy: 0.10400000214576721
step: 3830, train loss: nan, train acuracy: 0.125
step: 3830, val loss: nan, val acuracy: 0.10400000214576721
step: 3831, train loss: nan, train acuracy: 0.140625
step: 3831, val loss: nan, val acuracy: 0.10400000214576721
step: 3832, train loss: nan, train acuracy: 0.109375
step: 3832, val loss: nan, val acuracy: 0.10400000214576721
step: 3833, train loss: nan, train acuracy: 0.046875
step: 3833, val loss: nan, val acuracy: 0.10400000214576721
step: 3834, train loss: nan, train acuracy: 0.109375
step: 3834, val loss: nan, val acuracy: 0.10400000214576721
step: 3835, train loss: nan, train acuracy: 0.0625
step: 3835, val loss: nan, val acuracy: 0.10400000214576721
step: 3836, train loss: nan, train acuracy: 0.09375
step: 3836, val loss: nan, val acuracy: 0.10400000214576721
step: 3837, train loss: nan, train acuracy: 0.09375
step: 3837, val loss: nan, val acuracy: 0.10400000214576721
step: 3838, train loss: nan, train acuracy: 0.109375
step: 3838, val loss: nan, val acuracy: 0.10400000214576721
step: 3839, train loss: nan, train acuracy: 0.15625
step: 3839, val loss: nan, val acuracy: 0.10400000214576721
step: 3840, train loss: nan, train acuracy: 0.078125
step: 3840, val loss: nan, val acuracy: 0.10400000214576721
step: 3841, train loss: nan, train acuracy: 0.09375
step: 3841, val loss: nan, val acuracy: 0.10400000214576721
step: 3842, train loss: nan, train acuracy: 0.15625
step: 3842, val loss: nan, val acuracy: 0.10400000214576721
step: 3843, train loss: nan, train acuracy: 0.09375
step: 3843, val loss: nan, val acuracy: 0.10400000214576721
step: 3844, train loss: nan, train acuracy: 0.09375
step: 3844, val loss: nan, val acuracy: 0.10400000214576721
step: 3845, train loss: nan, train acuracy: 0.109375
step: 3845, val loss: nan, val acuracy: 0.10400000214576721
step: 3846, train loss: nan, train acuracy: 0.125
step: 3846, val loss: nan, val acuracy: 0.10400000214576721
step: 3847, train loss: nan, train acuracy: 0.125
step: 3847, val loss: nan, val acuracy: 0.10400000214576721
step: 3848, train loss: nan, train acuracy: 0.0625
step: 3848, val loss: nan, val acuracy: 0.10400000214576721
step: 3849, train loss: nan, train acuracy: 0.046875
step: 3849, val loss: nan, val acuracy: 0.10400000214576721
step: 3850, train loss: nan, train acuracy: 0.03125
step: 3850, val loss: nan, val acuracy: 0.10400000214576721
step: 3851, train loss: nan, train acuracy: 0.09375
step: 3851, val loss: nan, val acuracy: 0.10400000214576721
step: 3852, train loss: nan, train acuracy: 0.140625
step: 3852, val loss: nan, val acuracy: 0.10400000214576721
step: 3853, train loss: nan, train acuracy: 0.109375
step: 3853, val loss: nan, val acuracy: 0.10400000214576721
step: 3854, train loss: nan, train acuracy: 0.109375
step: 3854, val loss: nan, val acuracy: 0.10400000214576721
step: 3855, train loss: nan, train acuracy: 0.109375
step: 3855, val loss: nan, val acuracy: 0.10400000214576721
step: 3856, train loss: nan, train acuracy: 0.078125
step: 3856, val loss: nan, val acuracy: 0.10400000214576721
step: 3857, train loss: nan, train acuracy: 0.078125
step: 3857, val loss: nan, val acuracy: 0.10400000214576721
step: 3858, train loss: nan, train acuracy: 0.15625
step: 3858, val loss: nan, val acuracy: 0.10400000214576721
step: 3859, train loss: nan, train acuracy: 0.078125
step: 3859, val loss: nan, val acuracy: 0.10400000214576721
step: 3860, train loss: nan, train acuracy: 0.09375
step: 3860, val loss: nan, val acuracy: 0.10400000214576721
step: 3861, train loss: nan, train acuracy: 0.0625
step: 3861, val loss: nan, val acuracy: 0.10400000214576721
step: 3862, train loss: nan, train acuracy: 0.0625
step: 3862, val loss: nan, val acuracy: 0.10400000214576721
step: 3863, train loss: nan, train acuracy: 0.125
step: 3863, val loss: nan, val acuracy: 0.10400000214576721
step: 3864, train loss: nan, train acuracy: 0.1875
step: 3864, val loss: nan, val acuracy: 0.10400000214576721
step: 3865, train loss: nan, train acuracy: 0.078125
step: 3865, val loss: nan, val acuracy: 0.10400000214576721
step: 3866, train loss: nan, train acuracy: 0.125
step: 3866, val loss: nan, val acuracy: 0.10400000214576721
step: 3867, train loss: nan, train acuracy: 0.125
step: 3867, val loss: nan, val acuracy: 0.10400000214576721
step: 3868, train loss: nan, train acuracy: 0.09375
step: 3868, val loss: nan, val acuracy: 0.10400000214576721
step: 3869, train loss: nan, train acuracy: 0.109375
step: 3869, val loss: nan, val acuracy: 0.10400000214576721
step: 3870, train loss: nan, train acuracy: 0.046875
step: 3870, val loss: nan, val acuracy: 0.10400000214576721
step: 3871, train loss: nan, train acuracy: 0.078125
step: 3871, val loss: nan, val acuracy: 0.10400000214576721
step: 3872, train loss: nan, train acuracy: 0.078125
step: 3872, val loss: nan, val acuracy: 0.10400000214576721
step: 3873, train loss: nan, train acuracy: 0.078125
step: 3873, val loss: nan, val acuracy: 0.10400000214576721
step: 3874, train loss: nan, train acuracy: 0.0625
step: 3874, val loss: nan, val acuracy: 0.10400000214576721
step: 3875, train loss: nan, train acuracy: 0.078125
step: 3875, val loss: nan, val acuracy: 0.10400000214576721
step: 3876, train loss: nan, train acuracy: 0.046875
step: 3876, val loss: nan, val acuracy: 0.10400000214576721
step: 3877, train loss: nan, train acuracy: 0.125
step: 3877, val loss: nan, val acuracy: 0.10400000214576721
step: 3878, train loss: nan, train acuracy: 0.203125
step: 3878, val loss: nan, val acuracy: 0.10400000214576721
step: 3879, train loss: nan, train acuracy: 0.1875
step: 3879, val loss: nan, val acuracy: 0.10400000214576721
step: 3880, train loss: nan, train acuracy: 0.109375
step: 3880, val loss: nan, val acuracy: 0.10400000214576721
step: 3881, train loss: nan, train acuracy: 0.125
step: 3881, val loss: nan, val acuracy: 0.10400000214576721
step: 3882, train loss: nan, train acuracy: 0.046875
step: 3882, val loss: nan, val acuracy: 0.10400000214576721
step: 3883, train loss: nan, train acuracy: 0.109375
step: 3883, val loss: nan, val acuracy: 0.10400000214576721
step: 3884, train loss: nan, train acuracy: 0.109375
step: 3884, val loss: nan, val acuracy: 0.10400000214576721
step: 3885, train loss: nan, train acuracy: 0.140625
step: 3885, val loss: nan, val acuracy: 0.10400000214576721
step: 3886, train loss: nan, train acuracy: 0.09375
step: 3886, val loss: nan, val acuracy: 0.10400000214576721
step: 3887, train loss: nan, train acuracy: 0.15625
step: 3887, val loss: nan, val acuracy: 0.10400000214576721
step: 3888, train loss: nan, train acuracy: 0.0625
step: 3888, val loss: nan, val acuracy: 0.10400000214576721
step: 3889, train loss: nan, train acuracy: 0.09375
step: 3889, val loss: nan, val acuracy: 0.10400000214576721
step: 3890, train loss: nan, train acuracy: 0.09375
step: 3890, val loss: nan, val acuracy: 0.10400000214576721
step: 3891, train loss: nan, train acuracy: 0.03125
step: 3891, val loss: nan, val acuracy: 0.10400000214576721
step: 3892, train loss: nan, train acuracy: 0.09375
step: 3892, val loss: nan, val acuracy: 0.10400000214576721
step: 3893, train loss: nan, train acuracy: 0.046875
step: 3893, val loss: nan, val acuracy: 0.10400000214576721
step: 3894, train loss: nan, train acuracy: 0.15625
step: 3894, val loss: nan, val acuracy: 0.10400000214576721
step: 3895, train loss: nan, train acuracy: 0.09375
step: 3895, val loss: nan, val acuracy: 0.10400000214576721
step: 3896, train loss: nan, train acuracy: 0.125
step: 3896, val loss: nan, val acuracy: 0.10400000214576721
step: 3897, train loss: nan, train acuracy: 0.03125
step: 3897, val loss: nan, val acuracy: 0.10400000214576721
step: 3898, train loss: nan, train acuracy: 0.125
step: 3898, val loss: nan, val acuracy: 0.10400000214576721
step: 3899, train loss: nan, train acuracy: 0.15625
step: 3899, val loss: nan, val acuracy: 0.10400000214576721
step: 3900, train loss: nan, train acuracy: 0.125
step: 3900, val loss: nan, val acuracy: 0.10400000214576721
step: 3901, train loss: nan, train acuracy: 0.078125
step: 3901, val loss: nan, val acuracy: 0.10400000214576721
step: 3902, train loss: nan, train acuracy: 0.078125
step: 3902, val loss: nan, val acuracy: 0.10400000214576721
step: 3903, train loss: nan, train acuracy: 0.109375
step: 3903, val loss: nan, val acuracy: 0.10400000214576721
step: 3904, train loss: nan, train acuracy: 0.09375
step: 3904, val loss: nan, val acuracy: 0.10400000214576721
step: 3905, train loss: nan, train acuracy: 0.046875
step: 3905, val loss: nan, val acuracy: 0.10400000214576721
step: 3906, train loss: nan, train acuracy: 0.09375
step: 3906, val loss: nan, val acuracy: 0.10400000214576721
step: 3907, train loss: nan, train acuracy: 0.046875
step: 3907, val loss: nan, val acuracy: 0.10400000214576721
step: 3908, train loss: nan, train acuracy: 0.125
step: 3908, val loss: nan, val acuracy: 0.10400000214576721
step: 3909, train loss: nan, train acuracy: 0.078125
step: 3909, val loss: nan, val acuracy: 0.10400000214576721
step: 3910, train loss: nan, train acuracy: 0.0625
step: 3910, val loss: nan, val acuracy: 0.10400000214576721
step: 3911, train loss: nan, train acuracy: 0.140625
step: 3911, val loss: nan, val acuracy: 0.10400000214576721
step: 3912, train loss: nan, train acuracy: 0.15625
step: 3912, val loss: nan, val acuracy: 0.10400000214576721
step: 3913, train loss: nan, train acuracy: 0.140625
step: 3913, val loss: nan, val acuracy: 0.10400000214576721
step: 3914, train loss: nan, train acuracy: 0.109375
step: 3914, val loss: nan, val acuracy: 0.10400000214576721
step: 3915, train loss: nan, train acuracy: 0.046875
step: 3915, val loss: nan, val acuracy: 0.10400000214576721
step: 3916, train loss: nan, train acuracy: 0.140625
step: 3916, val loss: nan, val acuracy: 0.10400000214576721
step: 3917, train loss: nan, train acuracy: 0.140625
step: 3917, val loss: nan, val acuracy: 0.10400000214576721
step: 3918, train loss: nan, train acuracy: 0.0625
step: 3918, val loss: nan, val acuracy: 0.10400000214576721
step: 3919, train loss: nan, train acuracy: 0.0625
step: 3919, val loss: nan, val acuracy: 0.10400000214576721
step: 3920, train loss: nan, train acuracy: 0.078125
step: 3920, val loss: nan, val acuracy: 0.10400000214576721
step: 3921, train loss: nan, train acuracy: 0.0625
step: 3921, val loss: nan, val acuracy: 0.10400000214576721
step: 3922, train loss: nan, train acuracy: 0.109375
step: 3922, val loss: nan, val acuracy: 0.10400000214576721
step: 3923, train loss: nan, train acuracy: 0.09375
step: 3923, val loss: nan, val acuracy: 0.10400000214576721
step: 3924, train loss: nan, train acuracy: 0.109375
step: 3924, val loss: nan, val acuracy: 0.10400000214576721
step: 3925, train loss: nan, train acuracy: 0.125
step: 3925, val loss: nan, val acuracy: 0.10400000214576721
step: 3926, train loss: nan, train acuracy: 0.046875
step: 3926, val loss: nan, val acuracy: 0.10400000214576721
step: 3927, train loss: nan, train acuracy: 0.171875
step: 3927, val loss: nan, val acuracy: 0.10400000214576721
step: 3928, train loss: nan, train acuracy: 0.03125
step: 3928, val loss: nan, val acuracy: 0.10400000214576721
step: 3929, train loss: nan, train acuracy: 0.09375
step: 3929, val loss: nan, val acuracy: 0.10400000214576721
step: 3930, train loss: nan, train acuracy: 0.140625
step: 3930, val loss: nan, val acuracy: 0.10400000214576721
step: 3931, train loss: nan, train acuracy: 0.171875
step: 3931, val loss: nan, val acuracy: 0.10400000214576721
step: 3932, train loss: nan, train acuracy: 0.078125
step: 3932, val loss: nan, val acuracy: 0.10400000214576721
step: 3933, train loss: nan, train acuracy: 0.109375
step: 3933, val loss: nan, val acuracy: 0.10400000214576721
step: 3934, train loss: nan, train acuracy: 0.046875
step: 3934, val loss: nan, val acuracy: 0.10400000214576721
step: 3935, train loss: nan, train acuracy: 0.0625
step: 3935, val loss: nan, val acuracy: 0.10400000214576721
step: 3936, train loss: nan, train acuracy: 0.046875
step: 3936, val loss: nan, val acuracy: 0.10400000214576721
step: 3937, train loss: nan, train acuracy: 0.09375
step: 3937, val loss: nan, val acuracy: 0.10400000214576721
step: 3938, train loss: nan, train acuracy: 0.09375
step: 3938, val loss: nan, val acuracy: 0.10400000214576721
step: 3939, train loss: nan, train acuracy: 0.09375
step: 3939, val loss: nan, val acuracy: 0.10400000214576721
step: 3940, train loss: nan, train acuracy: 0.046875
step: 3940, val loss: nan, val acuracy: 0.10400000214576721
step: 3941, train loss: nan, train acuracy: 0.125
step: 3941, val loss: nan, val acuracy: 0.10400000214576721
step: 3942, train loss: nan, train acuracy: 0.125
step: 3942, val loss: nan, val acuracy: 0.10400000214576721
step: 3943, train loss: nan, train acuracy: 0.109375
step: 3943, val loss: nan, val acuracy: 0.10400000214576721
step: 3944, train loss: nan, train acuracy: 0.046875
step: 3944, val loss: nan, val acuracy: 0.10400000214576721
step: 3945, train loss: nan, train acuracy: 0.078125
step: 3945, val loss: nan, val acuracy: 0.10400000214576721
step: 3946, train loss: nan, train acuracy: 0.109375
step: 3946, val loss: nan, val acuracy: 0.10400000214576721
step: 3947, train loss: nan, train acuracy: 0.125
step: 3947, val loss: nan, val acuracy: 0.10400000214576721
step: 3948, train loss: nan, train acuracy: 0.125
step: 3948, val loss: nan, val acuracy: 0.10400000214576721
step: 3949, train loss: nan, train acuracy: 0.0625
step: 3949, val loss: nan, val acuracy: 0.10400000214576721
step: 3950, train loss: nan, train acuracy: 0.140625
step: 3950, val loss: nan, val acuracy: 0.10400000214576721
step: 3951, train loss: nan, train acuracy: 0.078125
step: 3951, val loss: nan, val acuracy: 0.10400000214576721
step: 3952, train loss: nan, train acuracy: 0.015625
step: 3952, val loss: nan, val acuracy: 0.10400000214576721
step: 3953, train loss: nan, train acuracy: 0.046875
step: 3953, val loss: nan, val acuracy: 0.10400000214576721
step: 3954, train loss: nan, train acuracy: 0.109375
step: 3954, val loss: nan, val acuracy: 0.10400000214576721
step: 3955, train loss: nan, train acuracy: 0.0625
step: 3955, val loss: nan, val acuracy: 0.10400000214576721
step: 3956, train loss: nan, train acuracy: 0.0625
step: 3956, val loss: nan, val acuracy: 0.10400000214576721
step: 3957, train loss: nan, train acuracy: 0.078125
step: 3957, val loss: nan, val acuracy: 0.10400000214576721
step: 3958, train loss: nan, train acuracy: 0.046875
step: 3958, val loss: nan, val acuracy: 0.10400000214576721
step: 3959, train loss: nan, train acuracy: 0.0625
step: 3959, val loss: nan, val acuracy: 0.10400000214576721
step: 3960, train loss: nan, train acuracy: 0.09375
step: 3960, val loss: nan, val acuracy: 0.10400000214576721
step: 3961, train loss: nan, train acuracy: 0.140625
step: 3961, val loss: nan, val acuracy: 0.10400000214576721
step: 3962, train loss: nan, train acuracy: 0.09375
step: 3962, val loss: nan, val acuracy: 0.10400000214576721
step: 3963, train loss: nan, train acuracy: 0.078125
step: 3963, val loss: nan, val acuracy: 0.10400000214576721
step: 3964, train loss: nan, train acuracy: 0.078125
step: 3964, val loss: nan, val acuracy: 0.10400000214576721
step: 3965, train loss: nan, train acuracy: 0.09375
step: 3965, val loss: nan, val acuracy: 0.10400000214576721
step: 3966, train loss: nan, train acuracy: 0.109375
step: 3966, val loss: nan, val acuracy: 0.10400000214576721
step: 3967, train loss: nan, train acuracy: 0.140625
step: 3967, val loss: nan, val acuracy: 0.10400000214576721
step: 3968, train loss: nan, train acuracy: 0.0625
step: 3968, val loss: nan, val acuracy: 0.10400000214576721
step: 3969, train loss: nan, train acuracy: 0.109375
step: 3969, val loss: nan, val acuracy: 0.10400000214576721
step: 3970, train loss: nan, train acuracy: 0.09375
step: 3970, val loss: nan, val acuracy: 0.10400000214576721
step: 3971, train loss: nan, train acuracy: 0.078125
step: 3971, val loss: nan, val acuracy: 0.10400000214576721
step: 3972, train loss: nan, train acuracy: 0.0625
step: 3972, val loss: nan, val acuracy: 0.10400000214576721
step: 3973, train loss: nan, train acuracy: 0.125
step: 3973, val loss: nan, val acuracy: 0.10400000214576721
step: 3974, train loss: nan, train acuracy: 0.140625
step: 3974, val loss: nan, val acuracy: 0.10400000214576721
step: 3975, train loss: nan, train acuracy: 0.0625
step: 3975, val loss: nan, val acuracy: 0.10400000214576721
step: 3976, train loss: nan, train acuracy: 0.078125
step: 3976, val loss: nan, val acuracy: 0.10400000214576721
step: 3977, train loss: nan, train acuracy: 0.109375
step: 3977, val loss: nan, val acuracy: 0.10400000214576721
step: 3978, train loss: nan, train acuracy: 0.140625
step: 3978, val loss: nan, val acuracy: 0.10400000214576721
step: 3979, train loss: nan, train acuracy: 0.125
step: 3979, val loss: nan, val acuracy: 0.10400000214576721
step: 3980, train loss: nan, train acuracy: 0.109375
step: 3980, val loss: nan, val acuracy: 0.10400000214576721
step: 3981, train loss: nan, train acuracy: 0.09375
step: 3981, val loss: nan, val acuracy: 0.10400000214576721
step: 3982, train loss: nan, train acuracy: 0.03125
step: 3982, val loss: nan, val acuracy: 0.10400000214576721
step: 3983, train loss: nan, train acuracy: 0.0625
step: 3983, val loss: nan, val acuracy: 0.10400000214576721
step: 3984, train loss: nan, train acuracy: 0.125
step: 3984, val loss: nan, val acuracy: 0.10400000214576721
step: 3985, train loss: nan, train acuracy: 0.109375
step: 3985, val loss: nan, val acuracy: 0.10400000214576721
step: 3986, train loss: nan, train acuracy: 0.203125
step: 3986, val loss: nan, val acuracy: 0.10400000214576721
step: 3987, train loss: nan, train acuracy: 0.125
step: 3987, val loss: nan, val acuracy: 0.10400000214576721
step: 3988, train loss: nan, train acuracy: 0.078125
step: 3988, val loss: nan, val acuracy: 0.10400000214576721
step: 3989, train loss: nan, train acuracy: 0.078125
step: 3989, val loss: nan, val acuracy: 0.10400000214576721
step: 3990, train loss: nan, train acuracy: 0.109375
step: 3990, val loss: nan, val acuracy: 0.10400000214576721
step: 3991, train loss: nan, train acuracy: 0.125
step: 3991, val loss: nan, val acuracy: 0.10400000214576721
step: 3992, train loss: nan, train acuracy: 0.078125
step: 3992, val loss: nan, val acuracy: 0.10400000214576721
step: 3993, train loss: nan, train acuracy: 0.109375
step: 3993, val loss: nan, val acuracy: 0.10400000214576721
step: 3994, train loss: nan, train acuracy: 0.078125
step: 3994, val loss: nan, val acuracy: 0.10400000214576721
step: 3995, train loss: nan, train acuracy: 0.015625
step: 3995, val loss: nan, val acuracy: 0.10400000214576721
step: 3996, train loss: nan, train acuracy: 0.09375
step: 3996, val loss: nan, val acuracy: 0.10400000214576721
step: 3997, train loss: nan, train acuracy: 0.109375
step: 3997, val loss: nan, val acuracy: 0.10400000214576721
step: 3998, train loss: nan, train acuracy: 0.109375
step: 3998, val loss: nan, val acuracy: 0.10400000214576721
step: 3999, train loss: nan, train acuracy: 0.078125
step: 3999, val loss: nan, val acuracy: 0.10400000214576721
2017-12-04 14:46:35.382714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 14:46:35.637114: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x59c5cf0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 14:46:35.637941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 14:46:35.919430: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x59ca1a0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 14:46:35.920316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:82:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 14:46:36.211172: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x59ce650 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 14:46:36.212159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:83:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 14:46:36.212481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 2
2017-12-04 14:46:36.212506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 3
2017-12-04 14:46:36.212540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 2
2017-12-04 14:46:36.212554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 3
2017-12-04 14:46:36.212568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 0
2017-12-04 14:46:36.212581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 1
2017-12-04 14:46:36.212844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 0
2017-12-04 14:46:36.212865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 1
2017-12-04 14:46:36.212979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3 
2017-12-04 14:46:36.212994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y N N 
2017-12-04 14:46:36.213002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y N N 
2017-12-04 14:46:36.213009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   N N Y Y 
2017-12-04 14:46:36.213016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   N N Y Y 
2017-12-04 14:46:36.213031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 14:46:36.213040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
2017-12-04 14:46:36.213048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K20m, pci bus id: 0000:82:00.0)
2017-12-04 14:46:36.213055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K20m, pci bus id: 0000:83:00.0)
2017-12-04 14:53:39.556034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 14:53:39.805369: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x6a45550 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 14:53:39.806401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 14:53:39.806761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 14:53:39.806783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 14:53:39.806794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 14:53:39.806811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 14:53:39.806822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.3694047927856445, train acuracy: 0.125
step: 0, val loss: 2.5884249210357666, val acuracy: 0.09183333069086075
step: 1, train loss: 2.2395968437194824, train acuracy: 0.15625
step: 1, val loss: 2.3572897911071777, val acuracy: 0.09866666793823242
step: 2, train loss: 2.3143177032470703, train acuracy: 0.125
step: 2, val loss: 2.3192028999328613, val acuracy: 0.09883332997560501
step: 3, train loss: 2.210944652557373, train acuracy: 0.2578125
step: 3, val loss: 2.354560136795044, val acuracy: 0.19850000739097595
step: 4, train loss: 2.355620861053467, train acuracy: 0.0625
step: 4, val loss: 2.3154022693634033, val acuracy: 0.09816667437553406
step: 5, train loss: 2.2575230598449707, train acuracy: 0.1328125
step: 5, val loss: 2.315105438232422, val acuracy: 0.09816665947437286
step: 6, train loss: 2.3267271518707275, train acuracy: 0.0546875
step: 6, val loss: 2.3138434886932373, val acuracy: 0.09816665947437286
step: 7, train loss: 2.273155689239502, train acuracy: 0.140625
step: 7, val loss: 2.3135335445404053, val acuracy: 0.09816665947437286
step: 8, train loss: 2.298901319503784, train acuracy: 0.1171875
step: 8, val loss: 2.313278913497925, val acuracy: 0.09816667437553406
step: 9, train loss: 2.3069334030151367, train acuracy: 0.078125
step: 9, val loss: 2.313079833984375, val acuracy: 0.09816665947437286
step: 10, train loss: 2.3450546264648438, train acuracy: 0.09375
step: 10, val loss: 2.3127739429473877, val acuracy: 0.09816665947437286
step: 11, train loss: 2.3200936317443848, train acuracy: 0.09375
step: 11, val loss: 2.312659978866577, val acuracy: 0.09816665947437286
step: 12, train loss: 2.3177475929260254, train acuracy: 0.1171875
step: 12, val loss: 2.3124337196350098, val acuracy: 0.09816667437553406
step: 13, train loss: 2.3307793140411377, train acuracy: 0.0703125
step: 13, val loss: 2.3123116493225098, val acuracy: 0.09816665947437286
step: 14, train loss: 2.27290678024292, train acuracy: 0.1328125
step: 14, val loss: 2.313826084136963, val acuracy: 0.09816665947437286
step: 15, train loss: 2.289154529571533, train acuracy: 0.0859375
step: 15, val loss: 2.3110525608062744, val acuracy: 0.09816665947437286
step: 16, train loss: 2.3045096397399902, train acuracy: 0.09375
step: 16, val loss: 2.311678886413574, val acuracy: 0.09816666692495346
step: 17, train loss: 2.326032876968384, train acuracy: 0.0625
step: 17, val loss: 2.310922145843506, val acuracy: 0.09816665947437286
step: 18, train loss: 2.306307315826416, train acuracy: 0.0859375
step: 18, val loss: 2.3329038619995117, val acuracy: 0.09816665947437286
step: 19, train loss: 2.274869680404663, train acuracy: 0.203125
step: 19, val loss: 2.2930495738983154, val acuracy: 0.1548333317041397
step: 20, train loss: 2.285125255584717, train acuracy: 0.203125
step: 20, val loss: 2.3203470706939697, val acuracy: 0.23849999904632568
step: 21, train loss: 2.2892556190490723, train acuracy: 0.3046875
step: 21, val loss: 2.3134965896606445, val acuracy: 0.2698333263397217
step: 22, train loss: 2.2887606620788574, train acuracy: 0.28125
step: 22, val loss: 2.3126819133758545, val acuracy: 0.25999999046325684
step: 23, train loss: 2.2881717681884766, train acuracy: 0.3203125
step: 23, val loss: 2.3113179206848145, val acuracy: 0.2538333535194397
step: 24, train loss: 2.28509259223938, train acuracy: 0.234375
step: 24, val loss: 2.3110361099243164, val acuracy: 0.24700000882148743
step: 25, train loss: 2.301608085632324, train acuracy: 0.2890625
step: 25, val loss: 2.310511350631714, val acuracy: 0.23500001430511475
step: 26, train loss: 2.3148365020751953, train acuracy: 0.2578125
step: 26, val loss: 2.3098604679107666, val acuracy: 0.24816669523715973
step: 27, train loss: 2.303992748260498, train acuracy: 0.2265625
step: 27, val loss: 2.309769630432129, val acuracy: 0.24950000643730164
step: 28, train loss: 2.3207664489746094, train acuracy: 0.1328125
step: 28, val loss: 2.3343546390533447, val acuracy: 0.09666665643453598
step: 29, train loss: 2.3494224548339844, train acuracy: 0.125
step: 29, val loss: 2.4306743144989014, val acuracy: 0.11433333158493042
step: 30, train loss: 2.4146158695220947, train acuracy: 0.1015625
step: 30, val loss: 2.440294027328491, val acuracy: 0.09749999642372131
step: 31, train loss: 2.41127872467041, train acuracy: 0.109375
step: 31, val loss: 2.496321678161621, val acuracy: 0.10916666686534882
step: 32, train loss: 2.2745137214660645, train acuracy: 0.2734375
step: 32, val loss: 2.313920497894287, val acuracy: 0.18333333730697632
step: 33, train loss: 2.283555030822754, train acuracy: 0.125
step: 33, val loss: 2.3400955200195312, val acuracy: 0.09666667133569717
step: 34, train loss: 2.3546719551086426, train acuracy: 0.0390625
step: 34, val loss: 2.3638250827789307, val acuracy: 0.04516666382551193
step: 35, train loss: 2.3993730545043945, train acuracy: 0.0546875
step: 35, val loss: 2.3519418239593506, val acuracy: 0.04800000041723251
step: 36, train loss: 2.3558006286621094, train acuracy: 0.09375
step: 36, val loss: 2.396181583404541, val acuracy: 0.09183333069086075
step: 37, train loss: 2.3960676193237305, train acuracy: 0.078125
step: 37, val loss: 2.4348578453063965, val acuracy: 0.1053333431482315
step: 38, train loss: 2.294090509414673, train acuracy: 0.109375
step: 38, val loss: 2.3278071880340576, val acuracy: 0.11083333194255829
step: 39, train loss: 2.2573890686035156, train acuracy: 0.140625
step: 39, val loss: 2.3200032711029053, val acuracy: 0.10899998992681503
step: 40, train loss: 2.3153839111328125, train acuracy: 0.1015625
step: 40, val loss: 2.3175268173217773, val acuracy: 0.10899998992681503
step: 41, train loss: 2.3548741340637207, train acuracy: 0.0546875
step: 41, val loss: 2.3177106380462646, val acuracy: 0.10899999737739563
step: 42, train loss: 2.3504562377929688, train acuracy: 0.1875
step: 42, val loss: 2.491412401199341, val acuracy: 0.12916666269302368
step: 43, train loss: 2.2736101150512695, train acuracy: 0.1953125
step: 43, val loss: 2.3295602798461914, val acuracy: 0.17616666853427887
step: 44, train loss: 2.2688941955566406, train acuracy: 0.1640625
step: 44, val loss: 2.3034772872924805, val acuracy: 0.12700000405311584
step: 45, train loss: 2.178229808807373, train acuracy: 0.203125
step: 45, val loss: 2.301722526550293, val acuracy: 0.14350000023841858
step: 46, train loss: 2.2471070289611816, train acuracy: 0.1015625
step: 46, val loss: 2.377319812774658, val acuracy: 0.1054999977350235
step: 47, train loss: 2.3143808841705322, train acuracy: 0.1953125
step: 47, val loss: 2.3290467262268066, val acuracy: 0.17550000548362732
step: 48, train loss: 2.2520527839660645, train acuracy: 0.2109375
step: 48, val loss: 2.2954530715942383, val acuracy: 0.18250000476837158
step: 49, train loss: 2.2393674850463867, train acuracy: 0.34375
step: 49, val loss: 2.2295055389404297, val acuracy: 0.31050002574920654
step: 50, train loss: 2.1055476665496826, train acuracy: 0.234375
step: 50, val loss: 2.1343493461608887, val acuracy: 0.24500000476837158
step: 51, train loss: 1.7274932861328125, train acuracy: 0.453125
step: 51, val loss: 1.877376675605774, val acuracy: 0.38466668128967285
step: 52, train loss: 1.7837457656860352, train acuracy: 0.453125
step: 52, val loss: 1.8025267124176025, val acuracy: 0.3946666717529297
step: 53, train loss: 1.9272513389587402, train acuracy: 0.3515625
step: 53, val loss: 1.7695127725601196, val acuracy: 0.4073333442211151
step: 54, train loss: 1.6826295852661133, train acuracy: 0.40625
step: 54, val loss: 1.628016471862793, val acuracy: 0.460500031709671
step: 55, train loss: 1.2927124500274658, train acuracy: 0.5625
step: 55, val loss: 1.4806267023086548, val acuracy: 0.47466668486595154
step: 56, train loss: 1.2644805908203125, train acuracy: 0.546875
step: 56, val loss: 1.3029346466064453, val acuracy: 0.5485000610351562
step: 57, train loss: 1.2823539972305298, train acuracy: 0.5703125
step: 57, val loss: 1.506168246269226, val acuracy: 0.5466666221618652
step: 58, train loss: 1.2312135696411133, train acuracy: 0.734375
step: 58, val loss: 1.5896943807601929, val acuracy: 0.6143333315849304
step: 59, train loss: 1.312814712524414, train acuracy: 0.609375
step: 59, val loss: 1.3716022968292236, val acuracy: 0.5961666703224182
step: 60, train loss: 0.9802002906799316, train acuracy: 0.6875
step: 60, val loss: 1.1060142517089844, val acuracy: 0.6328334212303162
step: 61, train loss: 0.8446565270423889, train acuracy: 0.734375
step: 61, val loss: 1.0950133800506592, val acuracy: 0.6350000500679016
step: 62, train loss: 1.1269783973693848, train acuracy: 0.6484375
step: 62, val loss: 1.0905237197875977, val acuracy: 0.6265000700950623
step: 63, train loss: 1.14125657081604, train acuracy: 0.609375
step: 63, val loss: 1.1145519018173218, val acuracy: 0.6263334155082703
step: 64, train loss: 1.0928425788879395, train acuracy: 0.6171875
step: 64, val loss: 1.1003140211105347, val acuracy: 0.6301667094230652
step: 65, train loss: 1.0787298679351807, train acuracy: 0.625
step: 65, val loss: 1.215582251548767, val acuracy: 0.5943333506584167
step: 66, train loss: 1.1207354068756104, train acuracy: 0.6328125
step: 66, val loss: 1.1519920825958252, val acuracy: 0.6221666932106018
step: 67, train loss: 1.0655537843704224, train acuracy: 0.671875
step: 67, val loss: 1.132584810256958, val acuracy: 0.6413333415985107
step: 68, train loss: 1.7754862308502197, train acuracy: 0.5
step: 68, val loss: 1.5716688632965088, val acuracy: 0.53083336353302
step: 69, train loss: 1.6603368520736694, train acuracy: 0.5234375
step: 69, val loss: 1.511646032333374, val acuracy: 0.5381667017936707
step: 70, train loss: 1.2171380519866943, train acuracy: 0.6484375
step: 70, val loss: 1.5083972215652466, val acuracy: 0.5393333435058594
step: 71, train loss: 1.5495808124542236, train acuracy: 0.5078125
step: 71, val loss: 1.5072458982467651, val acuracy: 0.5403333306312561
step: 72, train loss: 1.3026366233825684, train acuracy: 0.59375
step: 72, val loss: 1.5956286191940308, val acuracy: 0.5355000495910645
step: 73, train loss: 9.088593482971191, train acuracy: 0.4296875
step: 73, val loss: 9.454961776733398, val acuracy: 0.47350001335144043
step: 74, train loss: 2.961073875427246, train acuracy: 0.3828125
step: 74, val loss: 3.0463266372680664, val acuracy: 0.38833335041999817
step: 75, train loss: 5.189970016479492, train acuracy: 0.0859375
step: 75, val loss: 5.038586139678955, val acuracy: 0.10899999737739563
step: 76, train loss: 2.593496799468994, train acuracy: 0.09375
step: 76, val loss: 2.6322712898254395, val acuracy: 0.09016666561365128
step: 77, train loss: 2.3860044479370117, train acuracy: 0.109375
step: 77, val loss: 2.376760244369507, val acuracy: 0.10899998992681503
step: 78, train loss: 2.2842366695404053, train acuracy: 0.1796875
step: 78, val loss: 2.375781297683716, val acuracy: 0.17399998009204865
step: 79, train loss: 2.2006044387817383, train acuracy: 0.3046875
step: 79, val loss: 2.2432804107666016, val acuracy: 0.24833333492279053
step: 80, train loss: 2.2224302291870117, train acuracy: 0.25
step: 80, val loss: 2.2381489276885986, val acuracy: 0.23649999499320984
step: 81, train loss: 1.9679176807403564, train acuracy: 0.4375
step: 81, val loss: 1.993957757949829, val acuracy: 0.4176666736602783
step: 82, train loss: 1.9497941732406616, train acuracy: 0.296875
step: 82, val loss: 1.8846131563186646, val acuracy: 0.34550002217292786
step: 83, train loss: 1.5412436723709106, train acuracy: 0.4921875
step: 83, val loss: 1.6709274053573608, val acuracy: 0.41966667771339417
step: 84, train loss: 1.6854010820388794, train acuracy: 0.3671875
step: 84, val loss: 1.6591370105743408, val acuracy: 0.4281666874885559
step: 85, train loss: 1.7001850605010986, train acuracy: 0.3828125
step: 85, val loss: 1.7075634002685547, val acuracy: 0.40799999237060547
step: 86, train loss: 1.6561646461486816, train acuracy: 0.3984375
step: 86, val loss: 1.6866188049316406, val acuracy: 0.42133334279060364
step: 87, train loss: 1.6688141822814941, train acuracy: 0.4296875
step: 87, val loss: 1.684836745262146, val acuracy: 0.4205000400543213
step: 88, train loss: 1.6492797136306763, train acuracy: 0.3984375
step: 88, val loss: 1.6845701932907104, val acuracy: 0.41733333468437195
step: 89, train loss: 1.744305968284607, train acuracy: 0.4375
step: 89, val loss: 1.6837393045425415, val acuracy: 0.4186667203903198
step: 90, train loss: 1.595005989074707, train acuracy: 0.4609375
step: 90, val loss: 1.7004384994506836, val acuracy: 0.4073333442211151
step: 91, train loss: 9.612955093383789, train acuracy: 0.0703125
step: 91, val loss: 9.270891189575195, val acuracy: 0.09816665947437286
step: 92, train loss: 2.485398292541504, train acuracy: 0.1171875
step: 92, val loss: 2.4585230350494385, val acuracy: 0.10899998992681503
step: 93, train loss: 2.3256640434265137, train acuracy: 0.0859375
step: 93, val loss: 2.338411808013916, val acuracy: 0.109499990940094
step: 94, train loss: 2.289163589477539, train acuracy: 0.1484375
step: 94, val loss: 2.3166396617889404, val acuracy: 0.10899998992681503
step: 95, train loss: 2.2713990211486816, train acuracy: 0.140625
step: 95, val loss: 2.3013622760772705, val acuracy: 0.10899999737739563
step: 96, train loss: 2.232778787612915, train acuracy: 0.1484375
step: 96, val loss: 2.287261724472046, val acuracy: 0.10899999737739563
step: 97, train loss: 2.2557930946350098, train acuracy: 0.125
step: 97, val loss: 2.2463555335998535, val acuracy: 0.10899998992681503
step: 98, train loss: 2.1492621898651123, train acuracy: 0.1875
step: 98, val loss: 2.158714771270752, val acuracy: 0.1730000078678131
step: 99, train loss: 2.131162643432617, train acuracy: 0.3046875
step: 99, val loss: 2.142352819442749, val acuracy: 0.3100000023841858
step: 100, train loss: 1.6860040426254272, train acuracy: 0.4375
step: 100, val loss: 1.7801432609558105, val acuracy: 0.4475000500679016
step: 101, train loss: 1.6035327911376953, train acuracy: 0.5234375
step: 101, val loss: 1.6155203580856323, val acuracy: 0.5526667237281799
step: 102, train loss: 1.6155847311019897, train acuracy: 0.5078125
step: 102, val loss: 1.5595847368240356, val acuracy: 0.4751667380332947
step: 103, train loss: 1.2898170948028564, train acuracy: 0.625
step: 103, val loss: 1.263556957244873, val acuracy: 0.6080000996589661
step: 104, train loss: 1.2283961772918701, train acuracy: 0.6484375
step: 104, val loss: 1.248315453529358, val acuracy: 0.6021667122840881
step: 105, train loss: 1.2936925888061523, train acuracy: 0.6171875
step: 105, val loss: 1.2468451261520386, val acuracy: 0.6104999780654907
step: 106, train loss: 1.5257023572921753, train acuracy: 0.5546875
step: 106, val loss: 1.2417042255401611, val acuracy: 0.6118334531784058
step: 107, train loss: 1.179761528968811, train acuracy: 0.6015625
step: 107, val loss: 1.2380759716033936, val acuracy: 0.6143333911895752
step: 108, train loss: 1.147962212562561, train acuracy: 0.6640625
step: 108, val loss: 1.2360726594924927, val acuracy: 0.6140000224113464
step: 109, train loss: 1.3114351034164429, train acuracy: 0.546875
step: 109, val loss: 1.2351772785186768, val acuracy: 0.6145000457763672
step: 110, train loss: 1.431694746017456, train acuracy: 0.5625
step: 110, val loss: 1.2349247932434082, val acuracy: 0.6153333187103271
step: 111, train loss: 1.2300171852111816, train acuracy: 0.65625
step: 111, val loss: 1.233507752418518, val acuracy: 0.6166667342185974
step: 112, train loss: 1.0397993326187134, train acuracy: 0.6796875
step: 112, val loss: 1.2319955825805664, val acuracy: 0.6158334016799927
step: 113, train loss: 1.136535882949829, train acuracy: 0.7109375
step: 113, val loss: 1.2316629886627197, val acuracy: 0.6153333783149719
step: 114, train loss: 1.3385367393493652, train acuracy: 0.609375
step: 114, val loss: 1.231163740158081, val acuracy: 0.6153333783149719
step: 115, train loss: 1.2441996335983276, train acuracy: 0.671875
step: 115, val loss: 1.229706048965454, val acuracy: 0.6160000562667847
step: 116, train loss: 1.0869786739349365, train acuracy: 0.703125
step: 116, val loss: 1.229371190071106, val acuracy: 0.6170001029968262
step: 117, train loss: 1.222494125366211, train acuracy: 0.625
step: 117, val loss: 1.2297710180282593, val acuracy: 0.6175000071525574
step: 118, train loss: 1.159615397453308, train acuracy: 0.6640625
step: 118, val loss: 1.2289249897003174, val acuracy: 0.6165000796318054
step: 119, train loss: 1.2644680738449097, train acuracy: 0.65625
step: 119, val loss: 1.227953553199768, val acuracy: 0.6186666488647461
step: 120, train loss: 1.3078926801681519, train acuracy: 0.625
step: 120, val loss: 1.2270467281341553, val acuracy: 0.6185000538825989
step: 121, train loss: 1.190462589263916, train acuracy: 0.6015625
step: 121, val loss: 1.2715373039245605, val acuracy: 0.5901666879653931
step: 122, train loss: 1.3384371995925903, train acuracy: 0.6171875
step: 122, val loss: 1.260406732559204, val acuracy: 0.5958333611488342
step: 123, train loss: 1.439388632774353, train acuracy: 0.5546875
step: 123, val loss: 1.2817810773849487, val acuracy: 0.5858334302902222
step: 124, train loss: 1.1952263116836548, train acuracy: 0.6015625
step: 124, val loss: 1.275960922241211, val acuracy: 0.5893333554267883
step: 125, train loss: 1.2468900680541992, train acuracy: 0.625
step: 125, val loss: 1.2664788961410522, val acuracy: 0.6101666688919067
step: 126, train loss: 1.3001604080200195, train acuracy: 0.578125
step: 126, val loss: 1.2582401037216187, val acuracy: 0.6031666994094849
step: 127, train loss: 1.227034330368042, train acuracy: 0.640625
step: 127, val loss: 1.2296113967895508, val acuracy: 0.6128333806991577
step: 128, train loss: 1.1362684965133667, train acuracy: 0.640625
step: 128, val loss: 1.2541249990463257, val acuracy: 0.6126667261123657
step: 129, train loss: 1.2173713445663452, train acuracy: 0.609375
step: 129, val loss: 1.2483313083648682, val acuracy: 0.6121666431427002
step: 130, train loss: 1.4265835285186768, train acuracy: 0.59375
step: 130, val loss: 1.247499942779541, val acuracy: 0.6096667051315308
step: 131, train loss: 1.3652307987213135, train acuracy: 0.625
step: 131, val loss: 1.2470064163208008, val acuracy: 0.6113333702087402
step: 132, train loss: 1.201296329498291, train acuracy: 0.6328125
step: 132, val loss: 1.2459824085235596, val acuracy: 0.6110000610351562
step: 133, train loss: 1.2689011096954346, train acuracy: 0.6328125
step: 133, val loss: 1.2445425987243652, val acuracy: 0.6128333210945129
step: 134, train loss: 1.2149988412857056, train acuracy: 0.5703125
step: 134, val loss: 1.2439804077148438, val acuracy: 0.6145000457763672
step: 135, train loss: 1.2208356857299805, train acuracy: 0.6171875
step: 135, val loss: 1.3581552505493164, val acuracy: 0.6019999980926514
step: 136, train loss: 1.2205400466918945, train acuracy: 0.625
step: 136, val loss: 1.2761025428771973, val acuracy: 0.6008333563804626
step: 137, train loss: 1.2472368478775024, train acuracy: 0.609375
step: 137, val loss: 1.272437334060669, val acuracy: 0.6021666526794434
step: 138, train loss: 1.230698585510254, train acuracy: 0.5703125
step: 138, val loss: 1.2707194089889526, val acuracy: 0.6025000810623169
step: 139, train loss: 1.0863903760910034, train acuracy: 0.6640625
step: 139, val loss: 1.2686034440994263, val acuracy: 0.6043334007263184
step: 140, train loss: 1.2555729150772095, train acuracy: 0.5859375
step: 140, val loss: 1.2681405544281006, val acuracy: 0.6035000085830688
step: 141, train loss: 1.3180875778198242, train acuracy: 0.578125
step: 141, val loss: 1.3368277549743652, val acuracy: 0.5758333802223206
step: 142, train loss: 1.171851396560669, train acuracy: 0.6328125
step: 142, val loss: 1.2948417663574219, val acuracy: 0.592666745185852
step: 143, train loss: 1.3076952695846558, train acuracy: 0.5859375
step: 143, val loss: 1.3004841804504395, val acuracy: 0.6040000319480896
step: 144, train loss: 1.464587688446045, train acuracy: 0.578125
step: 144, val loss: 1.3900783061981201, val acuracy: 0.5538333654403687
step: 145, train loss: 1.018829584121704, train acuracy: 0.7265625
step: 145, val loss: 1.4010107517242432, val acuracy: 0.5830000042915344
step: 146, train loss: 1.2882952690124512, train acuracy: 0.578125
step: 146, val loss: 1.3030647039413452, val acuracy: 0.5743333697319031
step: 147, train loss: 1.1783983707427979, train acuracy: 0.5859375
step: 147, val loss: 1.2285043001174927, val acuracy: 0.6261667609214783
step: 148, train loss: 3.3276708126068115, train acuracy: 0.3359375
step: 148, val loss: 3.6530094146728516, val acuracy: 0.320166677236557
step: 149, train loss: 1.9352920055389404, train acuracy: 0.25
step: 149, val loss: 1.9067505598068237, val acuracy: 0.2695000171661377
step: 150, train loss: 1.5968167781829834, train acuracy: 0.4921875
step: 150, val loss: 1.8159379959106445, val acuracy: 0.43516668677330017
step: 151, train loss: 1.6016764640808105, train acuracy: 0.3828125
step: 151, val loss: 1.8078659772872925, val acuracy: 0.3141666650772095
step: 152, train loss: 1.997511386871338, train acuracy: 0.2734375
step: 152, val loss: 1.7816623449325562, val acuracy: 0.32116666436195374
step: 153, train loss: 1.7887866497039795, train acuracy: 0.3046875
step: 153, val loss: 1.8286223411560059, val acuracy: 0.3095000088214874
step: 154, train loss: 1.7844899892807007, train acuracy: 0.4375
step: 154, val loss: 1.8928208351135254, val acuracy: 0.366833359003067
step: 155, train loss: 1.8148462772369385, train acuracy: 0.28125
step: 155, val loss: 1.8449825048446655, val acuracy: 0.33016666769981384
step: 156, train loss: 1.806994915008545, train acuracy: 0.3046875
step: 156, val loss: 1.7760813236236572, val acuracy: 0.3269999921321869
step: 157, train loss: 1.8575353622436523, train acuracy: 0.3125
step: 157, val loss: 1.7901033163070679, val acuracy: 0.3370000123977661
step: 158, train loss: 6.415927886962891, train acuracy: 0.265625
step: 158, val loss: 6.681910991668701, val acuracy: 0.2473333328962326
step: 159, train loss: 6.595760345458984, train acuracy: 0.1796875
step: 159, val loss: 5.8706955909729, val acuracy: 0.2553333640098572
step: 160, train loss: 6.607391834259033, train acuracy: 0.1953125
step: 160, val loss: 5.913847923278809, val acuracy: 0.2565000057220459
step: 161, train loss: 5.556137561798096, train acuracy: 0.3515625
step: 161, val loss: 5.901102066040039, val acuracy: 0.257833331823349
step: 162, train loss: 5.413642883300781, train acuracy: 0.265625
step: 162, val loss: 5.887884140014648, val acuracy: 0.257999986410141
step: 163, train loss: 5.130683422088623, train acuracy: 0.265625
step: 163, val loss: 5.880010604858398, val acuracy: 0.2601666748523712
step: 164, train loss: 5.821239471435547, train acuracy: 0.234375
step: 164, val loss: 5.946223258972168, val acuracy: 0.21799999475479126
step: 165, train loss: 156.455810546875, train acuracy: 0.125
step: 165, val loss: 151.7368927001953, val acuracy: 0.11349999904632568
step: 166, train loss: 236.91452026367188, train acuracy: 0.0234375
step: 166, val loss: 252.04998779296875, val acuracy: 0.02383333258330822
step: 167, train loss: 209.94187927246094, train acuracy: 0.125
step: 167, val loss: 215.44134521484375, val acuracy: 0.1054999977350235
step: 168, train loss: 23.354278564453125, train acuracy: 0.1875
step: 168, val loss: 28.842063903808594, val acuracy: 0.12466666102409363
step: 169, train loss: 31.440296173095703, train acuracy: 0.0859375
step: 169, val loss: 33.180328369140625, val acuracy: 0.09566666185855865
step: 170, train loss: 54.692832946777344, train acuracy: 0.1328125
step: 170, val loss: 49.964691162109375, val acuracy: 0.13349999487400055
step: 171, train loss: 51.02066421508789, train acuracy: 0.109375
step: 171, val loss: 54.696807861328125, val acuracy: 0.10899999737739563
step: 172, train loss: 42.60419464111328, train acuracy: 0.140625
step: 172, val loss: 45.614864349365234, val acuracy: 0.1054999977350235
step: 173, train loss: 294.6439208984375, train acuracy: 0.0859375
step: 173, val loss: 317.6459045410156, val acuracy: 0.09533333778381348
step: 174, train loss: 1628.0546875, train acuracy: 0.09375
step: 174, val loss: 1430.728759765625, val acuracy: 0.09666666388511658
step: 175, train loss: 1054.4703369140625, train acuracy: 0.1171875
step: 175, val loss: 982.853515625, val acuracy: 0.101666659116745
step: 176, train loss: 3246.957275390625, train acuracy: 0.1015625
step: 176, val loss: 3401.17041015625, val acuracy: 0.10400000214576721
step: 177, train loss: 2695.34423828125, train acuracy: 0.1328125
step: 177, val loss: 2819.62451171875, val acuracy: 0.10599999874830246
step: 178, train loss: 668601.0625, train acuracy: 0.1015625
step: 178, val loss: 591693.625, val acuracy: 0.10799999535083771
step: 179, train loss: 2827344674816.0, train acuracy: 0.1171875
step: 179, val loss: 2980914921472.0, val acuracy: 0.09183333069086075
step: 180, train loss: 1.963788192504167e+32, train acuracy: 0.046875
step: 180, val loss: 1.9522718684324526e+32, val acuracy: 0.09749999642372131
step: 181, train loss: nan, train acuracy: 0.1015625
step: 181, val loss: nan, val acuracy: 0.10400000214576721
step: 182, train loss: nan, train acuracy: 0.0703125
step: 182, val loss: nan, val acuracy: 0.10400000214576721
step: 183, train loss: nan, train acuracy: 0.1328125
step: 183, val loss: nan, val acuracy: 0.10400000214576721
step: 184, train loss: nan, train acuracy: 0.109375
step: 184, val loss: nan, val acuracy: 0.10400000214576721
step: 185, train loss: nan, train acuracy: 0.0703125
step: 185, val loss: nan, val acuracy: 0.10400000214576721
step: 186, train loss: nan, train acuracy: 0.125
step: 186, val loss: nan, val acuracy: 0.10400000214576721
step: 187, train loss: nan, train acuracy: 0.0859375
step: 187, val loss: nan, val acuracy: 0.10400000214576721
step: 188, train loss: nan, train acuracy: 0.1015625
step: 188, val loss: nan, val acuracy: 0.10400000214576721
step: 189, train loss: nan, train acuracy: 0.1328125
step: 189, val loss: nan, val acuracy: 0.10400000214576721
step: 190, train loss: nan, train acuracy: 0.0859375
step: 190, val loss: nan, val acuracy: 0.10400000214576721
step: 191, train loss: nan, train acuracy: 0.09375
step: 191, val loss: nan, val acuracy: 0.10400000214576721
step: 192, train loss: nan, train acuracy: 0.109375
step: 192, val loss: nan, val acuracy: 0.10400000214576721
step: 193, train loss: nan, train acuracy: 0.109375
step: 193, val loss: nan, val acuracy: 0.10400000214576721
step: 194, train loss: nan, train acuracy: 0.1171875
step: 194, val loss: nan, val acuracy: 0.10400000214576721
step: 195, train loss: nan, train acuracy: 0.0703125
step: 195, val loss: nan, val acuracy: 0.10400000214576721
step: 196, train loss: nan, train acuracy: 0.0859375
step: 196, val loss: nan, val acuracy: 0.10400000214576721
step: 197, train loss: nan, train acuracy: 0.1171875
step: 197, val loss: nan, val acuracy: 0.10400000214576721
step: 198, train loss: nan, train acuracy: 0.09375
step: 198, val loss: nan, val acuracy: 0.10400000214576721
step: 199, train loss: nan, train acuracy: 0.1015625
step: 199, val loss: nan, val acuracy: 0.10400000214576721
step: 200, train loss: nan, train acuracy: 0.0703125
step: 200, val loss: nan, val acuracy: 0.10400000214576721
step: 201, train loss: nan, train acuracy: 0.1328125
step: 201, val loss: nan, val acuracy: 0.10400000214576721
step: 202, train loss: nan, train acuracy: 0.09375
step: 202, val loss: nan, val acuracy: 0.10400000214576721
step: 203, train loss: nan, train acuracy: 0.140625
step: 203, val loss: nan, val acuracy: 0.10400000214576721
step: 204, train loss: nan, train acuracy: 0.0859375
step: 204, val loss: nan, val acuracy: 0.10400000214576721
step: 205, train loss: nan, train acuracy: 0.1015625
step: 205, val loss: nan, val acuracy: 0.10400000214576721
step: 206, train loss: nan, train acuracy: 0.1171875
step: 206, val loss: nan, val acuracy: 0.10400000214576721
step: 207, train loss: nan, train acuracy: 0.09375
step: 207, val loss: nan, val acuracy: 0.10400000214576721
step: 208, train loss: nan, train acuracy: 0.0546875
step: 208, val loss: nan, val acuracy: 0.10400000214576721
step: 209, train loss: nan, train acuracy: 0.0859375
step: 209, val loss: nan, val acuracy: 0.10400000214576721
step: 210, train loss: nan, train acuracy: 0.0625
step: 210, val loss: nan, val acuracy: 0.10400000214576721
step: 211, train loss: nan, train acuracy: 0.0546875
step: 211, val loss: nan, val acuracy: 0.10400000214576721
step: 212, train loss: nan, train acuracy: 0.078125
step: 212, val loss: nan, val acuracy: 0.10400000214576721
step: 213, train loss: nan, train acuracy: 0.09375
step: 213, val loss: nan, val acuracy: 0.10400000214576721
step: 214, train loss: nan, train acuracy: 0.0703125
step: 214, val loss: nan, val acuracy: 0.10400000214576721
step: 215, train loss: nan, train acuracy: 0.0703125
step: 215, val loss: nan, val acuracy: 0.10400000214576721
step: 216, train loss: nan, train acuracy: 0.1640625
step: 216, val loss: nan, val acuracy: 0.10400000214576721
step: 217, train loss: nan, train acuracy: 0.09375
step: 217, val loss: nan, val acuracy: 0.10400000214576721
step: 218, train loss: nan, train acuracy: 0.109375
step: 218, val loss: nan, val acuracy: 0.10400000214576721
step: 219, train loss: nan, train acuracy: 0.109375
step: 219, val loss: nan, val acuracy: 0.10400000214576721
step: 220, train loss: nan, train acuracy: 0.109375
step: 220, val loss: nan, val acuracy: 0.10400000214576721
step: 221, train loss: nan, train acuracy: 0.140625
step: 221, val loss: nan, val acuracy: 0.10400000214576721
step: 222, train loss: nan, train acuracy: 0.0859375
step: 222, val loss: nan, val acuracy: 0.10400000214576721
step: 223, train loss: nan, train acuracy: 0.1484375
step: 223, val loss: nan, val acuracy: 0.10400000214576721
step: 224, train loss: nan, train acuracy: 0.125
step: 224, val loss: nan, val acuracy: 0.10400000214576721
step: 225, train loss: nan, train acuracy: 0.0859375
step: 225, val loss: nan, val acuracy: 0.10400000214576721
step: 226, train loss: nan, train acuracy: 0.09375
step: 226, val loss: nan, val acuracy: 0.10400000214576721
step: 227, train loss: nan, train acuracy: 0.0703125
step: 227, val loss: nan, val acuracy: 0.10400000214576721
step: 228, train loss: nan, train acuracy: 0.1328125
step: 228, val loss: nan, val acuracy: 0.10400000214576721
step: 229, train loss: nan, train acuracy: 0.1328125
step: 229, val loss: nan, val acuracy: 0.10400000214576721
step: 230, train loss: nan, train acuracy: 0.078125
step: 230, val loss: nan, val acuracy: 0.10400000214576721
step: 231, train loss: nan, train acuracy: 0.0859375
step: 231, val loss: nan, val acuracy: 0.10400000214576721
step: 232, train loss: nan, train acuracy: 0.09375
step: 232, val loss: nan, val acuracy: 0.10400000214576721
step: 233, train loss: nan, train acuracy: 0.1328125
step: 233, val loss: nan, val acuracy: 0.10400000214576721
step: 234, train loss: nan, train acuracy: 0.0859375
step: 234, val loss: nan, val acuracy: 0.10400000214576721
step: 235, train loss: nan, train acuracy: 0.125
step: 235, val loss: nan, val acuracy: 0.10400000214576721
step: 236, train loss: nan, train acuracy: 0.1015625
step: 236, val loss: nan, val acuracy: 0.10400000214576721
step: 237, train loss: nan, train acuracy: 0.125
step: 237, val loss: nan, val acuracy: 0.10400000214576721
step: 238, train loss: nan, train acuracy: 0.0546875
step: 238, val loss: nan, val acuracy: 0.10400000214576721
step: 239, train loss: nan, train acuracy: 0.0625
step: 239, val loss: nan, val acuracy: 0.10400000214576721
step: 240, train loss: nan, train acuracy: 0.125
step: 240, val loss: nan, val acuracy: 0.10400000214576721
step: 241, train loss: nan, train acuracy: 0.109375
step: 241, val loss: nan, val acuracy: 0.10400000214576721
step: 242, train loss: nan, train acuracy: 0.078125
step: 242, val loss: nan, val acuracy: 0.10400000214576721
step: 243, train loss: nan, train acuracy: 0.1171875
step: 243, val loss: nan, val acuracy: 0.10400000214576721
step: 244, train loss: nan, train acuracy: 0.078125
step: 244, val loss: nan, val acuracy: 0.10400000214576721
step: 245, train loss: nan, train acuracy: 0.09375
step: 245, val loss: nan, val acuracy: 0.10400000214576721
step: 246, train loss: nan, train acuracy: 0.1328125
step: 246, val loss: nan, val acuracy: 0.10400000214576721
step: 247, train loss: nan, train acuracy: 0.125
step: 247, val loss: nan, val acuracy: 0.10400000214576721
step: 248, train loss: nan, train acuracy: 0.1015625
step: 248, val loss: nan, val acuracy: 0.10400000214576721
step: 249, train loss: nan, train acuracy: 0.0625
step: 249, val loss: nan, val acuracy: 0.10400000214576721
step: 250, train loss: nan, train acuracy: 0.078125
step: 250, val loss: nan, val acuracy: 0.10400000214576721
step: 251, train loss: nan, train acuracy: 0.0703125
step: 251, val loss: nan, val acuracy: 0.10400000214576721
step: 252, train loss: nan, train acuracy: 0.0859375
step: 252, val loss: nan, val acuracy: 0.10400000214576721
step: 253, train loss: nan, train acuracy: 0.1953125
step: 253, val loss: nan, val acuracy: 0.10400000214576721
step: 254, train loss: nan, train acuracy: 0.1171875
step: 254, val loss: nan, val acuracy: 0.10400000214576721
step: 255, train loss: nan, train acuracy: 0.078125
step: 255, val loss: nan, val acuracy: 0.10400000214576721
step: 256, train loss: nan, train acuracy: 0.125
step: 256, val loss: nan, val acuracy: 0.10400000214576721
step: 257, train loss: nan, train acuracy: 0.125
step: 257, val loss: nan, val acuracy: 0.10400000214576721
step: 258, train loss: nan, train acuracy: 0.078125
step: 258, val loss: nan, val acuracy: 0.10400000214576721
step: 259, train loss: nan, train acuracy: 0.0625
step: 259, val loss: nan, val acuracy: 0.10400000214576721
step: 260, train loss: nan, train acuracy: 0.0703125
step: 260, val loss: nan, val acuracy: 0.10400000214576721
step: 261, train loss: nan, train acuracy: 0.125
step: 261, val loss: nan, val acuracy: 0.10400000214576721
step: 262, train loss: nan, train acuracy: 0.078125
step: 262, val loss: nan, val acuracy: 0.10400000214576721
step: 263, train loss: nan, train acuracy: 0.140625
step: 263, val loss: nan, val acuracy: 0.10400000214576721
step: 264, train loss: nan, train acuracy: 0.1015625
step: 264, val loss: nan, val acuracy: 0.10400000214576721
step: 265, train loss: nan, train acuracy: 0.09375
step: 265, val loss: nan, val acuracy: 0.10400000214576721
step: 266, train loss: nan, train acuracy: 0.0703125
step: 266, val loss: nan, val acuracy: 0.10400000214576721
step: 267, train loss: nan, train acuracy: 0.0703125
step: 267, val loss: nan, val acuracy: 0.10400000214576721
step: 268, train loss: nan, train acuracy: 0.1015625
step: 268, val loss: nan, val acuracy: 0.10400000214576721
step: 269, train loss: nan, train acuracy: 0.1015625
step: 269, val loss: nan, val acuracy: 0.10400000214576721
step: 270, train loss: nan, train acuracy: 0.1484375
step: 270, val loss: nan, val acuracy: 0.10400000959634781
step: 271, train loss: nan, train acuracy: 0.078125
step: 271, val loss: nan, val acuracy: 0.10400000214576721
step: 272, train loss: nan, train acuracy: 0.140625
step: 272, val loss: nan, val acuracy: 0.10400000214576721
step: 273, train loss: nan, train acuracy: 0.0625
step: 273, val loss: nan, val acuracy: 0.10400000214576721
step: 274, train loss: nan, train acuracy: 0.0703125
step: 274, val loss: nan, val acuracy: 0.10400000214576721
step: 275, train loss: nan, train acuracy: 0.1015625
step: 275, val loss: nan, val acuracy: 0.10400000214576721
step: 276, train loss: nan, train acuracy: 0.1171875
step: 276, val loss: nan, val acuracy: 0.10400000214576721
step: 277, train loss: nan, train acuracy: 0.109375
step: 277, val loss: nan, val acuracy: 0.10400000214576721
step: 278, train loss: nan, train acuracy: 0.0625
step: 278, val loss: nan, val acuracy: 0.10400000214576721
step: 279, train loss: nan, train acuracy: 0.15625
step: 279, val loss: nan, val acuracy: 0.10400000214576721
step: 280, train loss: nan, train acuracy: 0.09375
step: 280, val loss: nan, val acuracy: 0.10400000214576721
step: 281, train loss: nan, train acuracy: 0.0546875
step: 281, val loss: nan, val acuracy: 0.10400000214576721
step: 282, train loss: nan, train acuracy: 0.0703125
step: 282, val loss: nan, val acuracy: 0.10400000214576721
step: 283, train loss: nan, train acuracy: 0.09375
step: 283, val loss: nan, val acuracy: 0.10400000214576721
step: 284, train loss: nan, train acuracy: 0.0859375
step: 284, val loss: nan, val acuracy: 0.10400000214576721
step: 285, train loss: nan, train acuracy: 0.1171875
step: 285, val loss: nan, val acuracy: 0.10400000214576721
step: 286, train loss: nan, train acuracy: 0.0625
step: 286, val loss: nan, val acuracy: 0.10400000214576721
step: 287, train loss: nan, train acuracy: 0.1171875
step: 287, val loss: nan, val acuracy: 0.10400000214576721
step: 288, train loss: nan, train acuracy: 0.09375
step: 288, val loss: nan, val acuracy: 0.10400000214576721
step: 289, train loss: nan, train acuracy: 0.109375
step: 289, val loss: nan, val acuracy: 0.10400000214576721
step: 290, train loss: nan, train acuracy: 0.03125
step: 290, val loss: nan, val acuracy: 0.10400000214576721
step: 291, train loss: nan, train acuracy: 0.0859375
step: 291, val loss: nan, val acuracy: 0.10400000214576721
step: 292, train loss: nan, train acuracy: 0.0703125
step: 292, val loss: nan, val acuracy: 0.10400000214576721
step: 293, train loss: nan, train acuracy: 0.0546875
step: 293, val loss: nan, val acuracy: 0.10400000214576721
step: 294, train loss: nan, train acuracy: 0.1171875
step: 294, val loss: nan, val acuracy: 0.10400000214576721
step: 295, train loss: nan, train acuracy: 0.0859375
step: 295, val loss: nan, val acuracy: 0.10400000214576721
step: 296, train loss: nan, train acuracy: 0.0859375
step: 296, val loss: nan, val acuracy: 0.10400000214576721
step: 297, train loss: nan, train acuracy: 0.125
step: 297, val loss: nan, val acuracy: 0.10400000214576721
step: 298, train loss: nan, train acuracy: 0.0859375
step: 298, val loss: nan, val acuracy: 0.10400000214576721
step: 299, train loss: nan, train acuracy: 0.0859375
step: 299, val loss: nan, val acuracy: 0.10400000214576721
step: 300, train loss: nan, train acuracy: 0.09375
step: 300, val loss: nan, val acuracy: 0.10400000214576721
step: 301, train loss: nan, train acuracy: 0.1015625
step: 301, val loss: nan, val acuracy: 0.10400000214576721
step: 302, train loss: nan, train acuracy: 0.09375
step: 302, val loss: nan, val acuracy: 0.10400000214576721
step: 303, train loss: nan, train acuracy: 0.1328125
step: 303, val loss: nan, val acuracy: 0.10400000214576721
step: 304, train loss: nan, train acuracy: 0.1015625
step: 304, val loss: nan, val acuracy: 0.10400000214576721
step: 305, train loss: nan, train acuracy: 0.046875
step: 305, val loss: nan, val acuracy: 0.10400000214576721
step: 306, train loss: nan, train acuracy: 0.1171875
step: 306, val loss: nan, val acuracy: 0.10400000214576721
step: 307, train loss: nan, train acuracy: 0.1640625
step: 307, val loss: nan, val acuracy: 0.10400000214576721
step: 308, train loss: nan, train acuracy: 0.078125
step: 308, val loss: nan, val acuracy: 0.10400000214576721
step: 309, train loss: nan, train acuracy: 0.1171875
step: 309, val loss: nan, val acuracy: 0.10400000214576721
step: 310, train loss: nan, train acuracy: 0.09375
step: 310, val loss: nan, val acuracy: 0.10400000214576721
step: 311, train loss: nan, train acuracy: 0.046875
step: 311, val loss: nan, val acuracy: 0.10400000214576721
step: 312, train loss: nan, train acuracy: 0.1015625
step: 312, val loss: nan, val acuracy: 0.10400000214576721
step: 313, train loss: nan, train acuracy: 0.09375
step: 313, val loss: nan, val acuracy: 0.10400000214576721
step: 314, train loss: nan, train acuracy: 0.140625
step: 314, val loss: nan, val acuracy: 0.10400000214576721
step: 315, train loss: nan, train acuracy: 0.1015625
step: 315, val loss: nan, val acuracy: 0.10400000214576721
step: 316, train loss: nan, train acuracy: 0.125
step: 316, val loss: nan, val acuracy: 0.10400000214576721
step: 317, train loss: nan, train acuracy: 0.140625
step: 317, val loss: nan, val acuracy: 0.10400000214576721
step: 318, train loss: nan, train acuracy: 0.1171875
step: 318, val loss: nan, val acuracy: 0.10400000214576721
step: 319, train loss: nan, train acuracy: 0.078125
step: 319, val loss: nan, val acuracy: 0.10400000214576721
step: 320, train loss: nan, train acuracy: 0.0859375
step: 320, val loss: nan, val acuracy: 0.10400000214576721
step: 321, train loss: nan, train acuracy: 0.0703125
step: 321, val loss: nan, val acuracy: 0.10400000214576721
step: 322, train loss: nan, train acuracy: 0.140625
step: 322, val loss: nan, val acuracy: 0.10400000214576721
step: 323, train loss: nan, train acuracy: 0.109375
step: 323, val loss: nan, val acuracy: 0.10400000214576721
step: 324, train loss: nan, train acuracy: 0.109375
step: 324, val loss: nan, val acuracy: 0.10400000214576721
step: 325, train loss: nan, train acuracy: 0.125
step: 325, val loss: nan, val acuracy: 0.10400000214576721
step: 326, train loss: nan, train acuracy: 0.125
step: 326, val loss: nan, val acuracy: 0.10400000214576721
step: 327, train loss: nan, train acuracy: 0.0703125
step: 327, val loss: nan, val acuracy: 0.10400000214576721
step: 328, train loss: nan, train acuracy: 0.09375
step: 328, val loss: nan, val acuracy: 0.10400000214576721
step: 329, train loss: nan, train acuracy: 0.0859375
step: 329, val loss: nan, val acuracy: 0.10400000214576721
step: 330, train loss: nan, train acuracy: 0.1015625
step: 330, val loss: nan, val acuracy: 0.10400000214576721
step: 331, train loss: nan, train acuracy: 0.109375
step: 331, val loss: nan, val acuracy: 0.10400000214576721
step: 332, train loss: nan, train acuracy: 0.109375
step: 332, val loss: nan, val acuracy: 0.10400000214576721
step: 333, train loss: nan, train acuracy: 0.1015625
step: 333, val loss: nan, val acuracy: 0.10400000214576721
step: 334, train loss: nan, train acuracy: 0.078125
step: 334, val loss: nan, val acuracy: 0.10400000214576721
step: 335, train loss: nan, train acuracy: 0.15625
step: 335, val loss: nan, val acuracy: 0.10400000214576721
step: 336, train loss: nan, train acuracy: 0.0625
step: 336, val loss: nan, val acuracy: 0.10400000214576721
step: 337, train loss: nan, train acuracy: 0.125
step: 337, val loss: nan, val acuracy: 0.10400000214576721
step: 338, train loss: nan, train acuracy: 0.0859375
step: 338, val loss: nan, val acuracy: 0.10400000214576721
step: 339, train loss: nan, train acuracy: 0.1328125
step: 339, val loss: nan, val acuracy: 0.10400000214576721
step: 340, train loss: nan, train acuracy: 0.1015625
step: 340, val loss: nan, val acuracy: 0.10400000214576721
step: 341, train loss: nan, train acuracy: 0.0703125
step: 341, val loss: nan, val acuracy: 0.10400000214576721
step: 342, train loss: nan, train acuracy: 0.046875
step: 342, val loss: nan, val acuracy: 0.10400000214576721
step: 343, train loss: nan, train acuracy: 0.0703125
step: 343, val loss: nan, val acuracy: 0.10400000214576721
step: 344, train loss: nan, train acuracy: 0.109375
step: 344, val loss: nan, val acuracy: 0.10400000214576721
step: 345, train loss: nan, train acuracy: 0.09375
step: 345, val loss: nan, val acuracy: 0.10400000214576721
step: 346, train loss: nan, train acuracy: 0.0859375
step: 346, val loss: nan, val acuracy: 0.10400000214576721
step: 347, train loss: nan, train acuracy: 0.1484375
step: 347, val loss: nan, val acuracy: 0.10400000214576721
step: 348, train loss: nan, train acuracy: 0.0859375
step: 348, val loss: nan, val acuracy: 0.10400000214576721
step: 349, train loss: nan, train acuracy: 0.0859375
step: 349, val loss: nan, val acuracy: 0.10400000214576721
step: 350, train loss: nan, train acuracy: 0.1015625
step: 350, val loss: nan, val acuracy: 0.10400000214576721
step: 351, train loss: nan, train acuracy: 0.0859375
step: 351, val loss: nan, val acuracy: 0.10400000214576721
step: 352, train loss: nan, train acuracy: 0.0859375
step: 352, val loss: nan, val acuracy: 0.10400000214576721
step: 353, train loss: nan, train acuracy: 0.109375
step: 353, val loss: nan, val acuracy: 0.10400000214576721
step: 354, train loss: nan, train acuracy: 0.1015625
step: 354, val loss: nan, val acuracy: 0.10400000214576721
step: 355, train loss: nan, train acuracy: 0.1015625
step: 355, val loss: nan, val acuracy: 0.10400000214576721
step: 356, train loss: nan, train acuracy: 0.1328125
step: 356, val loss: nan, val acuracy: 0.10400000214576721
step: 357, train loss: nan, train acuracy: 0.078125
step: 357, val loss: nan, val acuracy: 0.10400000214576721
step: 358, train loss: nan, train acuracy: 0.1015625
step: 358, val loss: nan, val acuracy: 0.10400000214576721
step: 359, train loss: nan, train acuracy: 0.0859375
step: 359, val loss: nan, val acuracy: 0.10400000214576721
step: 360, train loss: nan, train acuracy: 0.0703125
step: 360, val loss: nan, val acuracy: 0.10400000214576721
step: 361, train loss: nan, train acuracy: 0.09375
step: 361, val loss: nan, val acuracy: 0.10400000214576721
step: 362, train loss: nan, train acuracy: 0.0859375
step: 362, val loss: nan, val acuracy: 0.10400000214576721
step: 363, train loss: nan, train acuracy: 0.1015625
step: 363, val loss: nan, val acuracy: 0.10400000214576721
step: 364, train loss: nan, train acuracy: 0.078125
step: 364, val loss: nan, val acuracy: 0.10400000214576721
step: 365, train loss: nan, train acuracy: 0.125
step: 365, val loss: nan, val acuracy: 0.10400000214576721
step: 366, train loss: nan, train acuracy: 0.0859375
step: 366, val loss: nan, val acuracy: 0.10400000214576721
step: 367, train loss: nan, train acuracy: 0.125
step: 367, val loss: nan, val acuracy: 0.10400000214576721
step: 368, train loss: nan, train acuracy: 0.078125
step: 368, val loss: nan, val acuracy: 0.10400000214576721
step: 369, train loss: nan, train acuracy: 0.109375
step: 369, val loss: nan, val acuracy: 0.10400000214576721
step: 370, train loss: nan, train acuracy: 0.0859375
step: 370, val loss: nan, val acuracy: 0.10400000214576721
step: 371, train loss: nan, train acuracy: 0.109375
step: 371, val loss: nan, val acuracy: 0.10400000214576721
step: 372, train loss: nan, train acuracy: 0.0859375
step: 372, val loss: nan, val acuracy: 0.10400000214576721
step: 373, train loss: nan, train acuracy: 0.0625
step: 373, val loss: nan, val acuracy: 0.10400000214576721
step: 374, train loss: nan, train acuracy: 0.1015625
step: 374, val loss: nan, val acuracy: 0.10400000214576721
step: 375, train loss: nan, train acuracy: 0.0703125
step: 375, val loss: nan, val acuracy: 0.10400000214576721
step: 376, train loss: nan, train acuracy: 0.125
step: 376, val loss: nan, val acuracy: 0.10400000214576721
step: 377, train loss: nan, train acuracy: 0.1015625
step: 377, val loss: nan, val acuracy: 0.10400000214576721
step: 378, train loss: nan, train acuracy: 0.078125
step: 378, val loss: nan, val acuracy: 0.10400000214576721
step: 379, train loss: nan, train acuracy: 0.1328125
step: 379, val loss: nan, val acuracy: 0.10400000214576721
step: 380, train loss: nan, train acuracy: 0.09375
step: 380, val loss: nan, val acuracy: 0.10400000214576721
step: 381, train loss: nan, train acuracy: 0.109375
step: 381, val loss: nan, val acuracy: 0.10400000214576721
step: 382, train loss: nan, train acuracy: 0.078125
step: 382, val loss: nan, val acuracy: 0.10400000214576721
step: 383, train loss: nan, train acuracy: 0.1015625
step: 383, val loss: nan, val acuracy: 0.10400000214576721
step: 384, train loss: nan, train acuracy: 0.125
step: 384, val loss: nan, val acuracy: 0.10400000214576721
step: 385, train loss: nan, train acuracy: 0.09375
step: 385, val loss: nan, val acuracy: 0.10400000214576721
step: 386, train loss: nan, train acuracy: 0.0859375
step: 386, val loss: nan, val acuracy: 0.10400000214576721
step: 387, train loss: nan, train acuracy: 0.140625
step: 387, val loss: nan, val acuracy: 0.10400000214576721
step: 388, train loss: nan, train acuracy: 0.0859375
step: 388, val loss: nan, val acuracy: 0.10400000214576721
step: 389, train loss: nan, train acuracy: 0.078125
step: 389, val loss: nan, val acuracy: 0.10400000214576721
step: 390, train loss: nan, train acuracy: 0.109375
step: 390, val loss: nan, val acuracy: 0.10400000214576721
step: 391, train loss: nan, train acuracy: 0.078125
step: 391, val loss: nan, val acuracy: 0.10400000214576721
step: 392, train loss: nan, train acuracy: 0.1484375
step: 392, val loss: nan, val acuracy: 0.10400000214576721
step: 393, train loss: nan, train acuracy: 0.1015625
step: 393, val loss: nan, val acuracy: 0.10400000214576721
step: 394, train loss: nan, train acuracy: 0.125
step: 394, val loss: nan, val acuracy: 0.10400000214576721
step: 395, train loss: nan, train acuracy: 0.109375
step: 395, val loss: nan, val acuracy: 0.10400000214576721
step: 396, train loss: nan, train acuracy: 0.09375
step: 396, val loss: nan, val acuracy: 0.10400000214576721
step: 397, train loss: nan, train acuracy: 0.0703125
step: 397, val loss: nan, val acuracy: 0.10400000214576721
step: 398, train loss: nan, train acuracy: 0.1015625
step: 398, val loss: nan, val acuracy: 0.10400000214576721
step: 399, train loss: nan, train acuracy: 0.1171875
step: 399, val loss: nan, val acuracy: 0.10400000214576721
2017-12-04 14:58:24.879807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 14:58:25.147088: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x6667990 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 14:58:25.147917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 14:58:25.148221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 14:58:25.148240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 14:58:25.148248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 14:58:25.148263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 14:58:25.148272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.33060359954834, train acuracy: 0.125
step: 0, val loss: 2.4361464977264404, val acuracy: 0.09666665643453598
step: 1, train loss: 2.211441993713379, train acuracy: 0.27734375
step: 1, val loss: 2.261535167694092, val acuracy: 0.2251666784286499
step: 2, train loss: 2.2614996433258057, train acuracy: 0.12890625
step: 2, val loss: 2.2823829650878906, val acuracy: 0.09666666388511658
step: 3, train loss: 2.1489510536193848, train acuracy: 0.2734375
step: 3, val loss: 2.1993608474731445, val acuracy: 0.2224999964237213
step: 4, train loss: 2.0781021118164062, train acuracy: 0.4140625
step: 4, val loss: 2.0887482166290283, val acuracy: 0.4103333652019501
step: 5, train loss: 1.8976860046386719, train acuracy: 0.34765625
step: 5, val loss: 1.8532812595367432, val acuracy: 0.3684999942779541
step: 6, train loss: 1.7780144214630127, train acuracy: 0.42578125
step: 6, val loss: 1.8269002437591553, val acuracy: 0.4103333353996277
step: 7, train loss: 1.7291960716247559, train acuracy: 0.4140625
step: 7, val loss: 1.7778077125549316, val acuracy: 0.41333335638046265
step: 8, train loss: 1.741071105003357, train acuracy: 0.3984375
step: 8, val loss: 1.8027493953704834, val acuracy: 0.366666704416275
step: 9, train loss: 1.7083239555358887, train acuracy: 0.3984375
step: 9, val loss: 1.787114143371582, val acuracy: 0.38600003719329834
step: 10, train loss: 1.693930983543396, train acuracy: 0.39453125
step: 10, val loss: 1.8316214084625244, val acuracy: 0.3516666889190674
step: 11, train loss: 1.6903762817382812, train acuracy: 0.42578125
step: 11, val loss: 1.7866318225860596, val acuracy: 0.39416664838790894
step: 12, train loss: 1.7134850025177002, train acuracy: 0.4296875
step: 12, val loss: 1.7958298921585083, val acuracy: 0.38833335041999817
step: 13, train loss: 1.7704154253005981, train acuracy: 0.4296875
step: 13, val loss: 1.817455530166626, val acuracy: 0.38883334398269653
step: 14, train loss: 1.7757060527801514, train acuracy: 0.40234375
step: 14, val loss: 1.8050440549850464, val acuracy: 0.40050002932548523
step: 15, train loss: 1.7914037704467773, train acuracy: 0.390625
step: 15, val loss: 1.8573381900787354, val acuracy: 0.37033334374427795
step: 16, train loss: 1.8977456092834473, train acuracy: 0.3984375
step: 16, val loss: 1.8548046350479126, val acuracy: 0.4321666359901428
step: 17, train loss: 1.7549920082092285, train acuracy: 0.37890625
step: 17, val loss: 1.8545300960540771, val acuracy: 0.3396666944026947
step: 18, train loss: 1.7854143381118774, train acuracy: 0.4609375
step: 18, val loss: 1.8546156883239746, val acuracy: 0.4423333406448364
step: 19, train loss: 1.9703365564346313, train acuracy: 0.3203125
step: 19, val loss: 1.9386470317840576, val acuracy: 0.30233335494995117
step: 20, train loss: 1.9299957752227783, train acuracy: 0.3515625
step: 20, val loss: 2.002699136734009, val acuracy: 0.36866670846939087
step: 21, train loss: 1.936155080795288, train acuracy: 0.34375
step: 21, val loss: 1.9763084650039673, val acuracy: 0.37933334708213806
step: 22, train loss: 2.0501370429992676, train acuracy: 0.28125
step: 22, val loss: 2.0324206352233887, val acuracy: 0.28050002455711365
step: 23, train loss: 1.8799244165420532, train acuracy: 0.4609375
step: 23, val loss: 2.0197577476501465, val acuracy: 0.41600000858306885
step: 24, train loss: 2.0162196159362793, train acuracy: 0.3359375
step: 24, val loss: 2.0942416191101074, val acuracy: 0.2721666991710663
step: 25, train loss: 2.097111940383911, train acuracy: 0.41796875
step: 25, val loss: 2.085850715637207, val acuracy: 0.39116668701171875
step: 26, train loss: 2.0186567306518555, train acuracy: 0.18359375
step: 26, val loss: 2.0216026306152344, val acuracy: 0.21700000762939453
step: 27, train loss: 2.0240108966827393, train acuracy: 0.33203125
step: 27, val loss: 2.0138065814971924, val acuracy: 0.3251667022705078
step: 28, train loss: 2.071082830429077, train acuracy: 0.24609375
step: 28, val loss: 2.117764711380005, val acuracy: 0.26233333349227905
step: 29, train loss: 2.09186053276062, train acuracy: 0.3828125
step: 29, val loss: 2.2176241874694824, val acuracy: 0.3264999985694885
step: 30, train loss: 2.0939218997955322, train acuracy: 0.2734375
step: 30, val loss: 2.075819253921509, val acuracy: 0.28866666555404663
step: 31, train loss: 1.9887927770614624, train acuracy: 0.328125
step: 31, val loss: 2.0721840858459473, val acuracy: 0.3199999928474426
step: 32, train loss: 2.1127076148986816, train acuracy: 0.26171875
step: 32, val loss: 2.157977819442749, val acuracy: 0.2746666669845581
step: 33, train loss: 2.260622501373291, train acuracy: 0.20703125
step: 33, val loss: 2.2629857063293457, val acuracy: 0.19583332538604736
step: 34, train loss: 2.0441184043884277, train acuracy: 0.3046875
step: 34, val loss: 2.0938210487365723, val acuracy: 0.3426666855812073
step: 35, train loss: 2.0023465156555176, train acuracy: 0.36328125
step: 35, val loss: 2.07499623298645, val acuracy: 0.3426666855812073
step: 36, train loss: 2.0214014053344727, train acuracy: 0.328125
step: 36, val loss: 2.1128900051116943, val acuracy: 0.31983333826065063
step: 37, train loss: 2.0482938289642334, train acuracy: 0.30078125
step: 37, val loss: 2.1642355918884277, val acuracy: 0.27900001406669617
step: 38, train loss: 2.067807197570801, train acuracy: 0.3125
step: 38, val loss: 2.0738906860351562, val acuracy: 0.3230000138282776
step: 39, train loss: 1.885491967201233, train acuracy: 0.38671875
step: 39, val loss: 2.0715997219085693, val acuracy: 0.32350003719329834
step: 40, train loss: 2.0929830074310303, train acuracy: 0.3203125
step: 40, val loss: 2.075723648071289, val acuracy: 0.3281666934490204
step: 41, train loss: 2.0705437660217285, train acuracy: 0.28515625
step: 41, val loss: 2.0860989093780518, val acuracy: 0.27516669034957886
step: 42, train loss: 2.002117395401001, train acuracy: 0.3125
step: 42, val loss: 2.0427515506744385, val acuracy: 0.31450003385543823
step: 43, train loss: 3.49212384223938, train acuracy: 0.2109375
step: 43, val loss: 3.461679458618164, val acuracy: 0.21933333575725555
step: 44, train loss: 3.253690719604492, train acuracy: 0.1796875
step: 44, val loss: 3.305756092071533, val acuracy: 0.21016669273376465
step: 45, train loss: 2.412932872772217, train acuracy: 0.1796875
step: 45, val loss: 2.295961380004883, val acuracy: 0.18416666984558105
step: 46, train loss: 2.3472177982330322, train acuracy: 0.16015625
step: 46, val loss: 2.2841737270355225, val acuracy: 0.18833333253860474
step: 47, train loss: 2.2109830379486084, train acuracy: 0.21875
step: 47, val loss: 2.2739458084106445, val acuracy: 0.195333331823349
step: 48, train loss: 2.20863938331604, train acuracy: 0.21484375
step: 48, val loss: 2.2741031646728516, val acuracy: 0.195333331823349
step: 49, train loss: 2.2736434936523438, train acuracy: 0.16796875
step: 49, val loss: 2.2732036113739014, val acuracy: 0.19500000774860382
step: 50, train loss: 2.2386975288391113, train acuracy: 0.1953125
step: 50, val loss: 2.273958206176758, val acuracy: 0.19483333826065063
step: 51, train loss: 2.313664436340332, train acuracy: 0.16015625
step: 51, val loss: 2.2732696533203125, val acuracy: 0.19349998235702515
step: 52, train loss: 2.3322298526763916, train acuracy: 0.14453125
step: 52, val loss: 2.2732183933258057, val acuracy: 0.19366665184497833
step: 53, train loss: 2.2789039611816406, train acuracy: 0.171875
step: 53, val loss: 2.2731974124908447, val acuracy: 0.18533332645893097
step: 54, train loss: 2.2526538372039795, train acuracy: 0.1796875
step: 54, val loss: 2.276001214981079, val acuracy: 0.2058333456516266
step: 55, train loss: 2.2623398303985596, train acuracy: 0.234375
step: 55, val loss: 2.287083148956299, val acuracy: 0.22216665744781494
step: 56, train loss: 2.256915330886841, train acuracy: 0.1640625
step: 56, val loss: 2.2779881954193115, val acuracy: 0.1848333328962326
step: 57, train loss: 2.425173044204712, train acuracy: 0.1484375
step: 57, val loss: 2.300832748413086, val acuracy: 0.1848333477973938
step: 58, train loss: 2.344804525375366, train acuracy: 0.15234375
step: 58, val loss: 2.3302500247955322, val acuracy: 0.14100000262260437
step: 59, train loss: 2.2884461879730225, train acuracy: 0.1484375
step: 59, val loss: 2.3229448795318604, val acuracy: 0.14816665649414062
step: 60, train loss: 2.281843900680542, train acuracy: 0.1875
step: 60, val loss: 2.3169093132019043, val acuracy: 0.1848333328962326
step: 61, train loss: 2.360056161880493, train acuracy: 0.1484375
step: 61, val loss: 2.316030979156494, val acuracy: 0.18433332443237305
step: 62, train loss: 2.2849082946777344, train acuracy: 0.1953125
step: 62, val loss: 2.315023422241211, val acuracy: 0.19200000166893005
step: 63, train loss: 2.261906147003174, train acuracy: 0.203125
step: 63, val loss: 2.318601369857788, val acuracy: 0.18383333086967468
step: 64, train loss: 2.3510191440582275, train acuracy: 0.18359375
step: 64, val loss: 2.32723069190979, val acuracy: 0.21016666293144226
step: 65, train loss: 2.267711877822876, train acuracy: 0.2109375
step: 65, val loss: 2.3193109035491943, val acuracy: 0.1926666647195816
step: 66, train loss: 2.289074420928955, train acuracy: 0.1875
step: 66, val loss: 2.320142984390259, val acuracy: 0.18133333325386047
step: 67, train loss: 2.294420003890991, train acuracy: 0.19140625
step: 67, val loss: 2.3091816902160645, val acuracy: 0.203166663646698
step: 68, train loss: 2.24416446685791, train acuracy: 0.18359375
step: 68, val loss: 2.2988829612731934, val acuracy: 0.1679999977350235
step: 69, train loss: 2.2301430702209473, train acuracy: 0.1484375
step: 69, val loss: 2.2666707038879395, val acuracy: 0.16116666793823242
step: 70, train loss: 2.3305575847625732, train acuracy: 0.125
step: 70, val loss: 2.263765335083008, val acuracy: 0.16300000250339508
step: 71, train loss: 2.2848706245422363, train acuracy: 0.21875
step: 71, val loss: 2.2631659507751465, val acuracy: 0.2198333442211151
step: 72, train loss: 2.049853563308716, train acuracy: 0.41015625
step: 72, val loss: 2.093496322631836, val acuracy: 0.3956666588783264
step: 73, train loss: 1.941529631614685, train acuracy: 0.37109375
step: 73, val loss: 1.9866962432861328, val acuracy: 0.37683334946632385
step: 74, train loss: 2.008667230606079, train acuracy: 0.34765625
step: 74, val loss: 1.963179588317871, val acuracy: 0.38833335041999817
step: 75, train loss: 1.7872588634490967, train acuracy: 0.40625
step: 75, val loss: 1.9496549367904663, val acuracy: 0.35500001907348633
step: 76, train loss: 2.0229296684265137, train acuracy: 0.33984375
step: 76, val loss: 1.9451779127120972, val acuracy: 0.3851666748523712
step: 77, train loss: 1.8197518587112427, train acuracy: 0.38671875
step: 77, val loss: 1.9448938369750977, val acuracy: 0.36783337593078613
step: 78, train loss: 1.9847962856292725, train acuracy: 0.359375
step: 78, val loss: 1.9784797430038452, val acuracy: 0.35766667127609253
step: 79, train loss: 1.9056916236877441, train acuracy: 0.36328125
step: 79, val loss: 1.9405131340026855, val acuracy: 0.36633333563804626
step: 80, train loss: 1.9874191284179688, train acuracy: 0.3828125
step: 80, val loss: 1.9720414876937866, val acuracy: 0.3706666827201843
step: 81, train loss: 1.9509965181350708, train acuracy: 0.3203125
step: 81, val loss: 1.8745224475860596, val acuracy: 0.36900001764297485
step: 82, train loss: 1.8300844430923462, train acuracy: 0.359375
step: 82, val loss: 1.8137173652648926, val acuracy: 0.359000027179718
step: 83, train loss: 1.5923657417297363, train acuracy: 0.46875
step: 83, val loss: 1.6892896890640259, val acuracy: 0.4554999768733978
step: 84, train loss: 1.9152216911315918, train acuracy: 0.4609375
step: 84, val loss: 2.097043514251709, val acuracy: 0.4429999887943268
step: 85, train loss: 1.4739019870758057, train acuracy: 0.55859375
step: 85, val loss: 1.4536614418029785, val acuracy: 0.54666668176651
step: 86, train loss: 1.3730289936065674, train acuracy: 0.60546875
step: 86, val loss: 1.4397432804107666, val acuracy: 0.5590000152587891
step: 87, train loss: 1.5700008869171143, train acuracy: 0.5078125
step: 87, val loss: 1.4318844079971313, val acuracy: 0.562166690826416
step: 88, train loss: 1.4522504806518555, train acuracy: 0.5546875
step: 88, val loss: 1.4308607578277588, val acuracy: 0.5628333687782288
step: 89, train loss: 1.4344786405563354, train acuracy: 0.5703125
step: 89, val loss: 1.4304143190383911, val acuracy: 0.562000036239624
step: 90, train loss: 1.4270389080047607, train acuracy: 0.56640625
step: 90, val loss: 1.429748296737671, val acuracy: 0.562166690826416
step: 91, train loss: 1.4750044345855713, train acuracy: 0.5859375
step: 91, val loss: 1.4294562339782715, val acuracy: 0.5630000829696655
step: 92, train loss: 1.4907231330871582, train acuracy: 0.51953125
step: 92, val loss: 1.4294308423995972, val acuracy: 0.5633333921432495
step: 93, train loss: 1.4904627799987793, train acuracy: 0.53125
step: 93, val loss: 1.4562711715698242, val acuracy: 0.5146666765213013
step: 94, train loss: 1.410606026649475, train acuracy: 0.62890625
step: 94, val loss: 1.4326915740966797, val acuracy: 0.5821667313575745
step: 95, train loss: 1.719847559928894, train acuracy: 0.34765625
step: 95, val loss: 1.7236201763153076, val acuracy: 0.3163333237171173
step: 96, train loss: 1.8693231344223022, train acuracy: 0.36328125
step: 96, val loss: 1.7348883152008057, val acuracy: 0.4051666557788849
step: 97, train loss: 1.598106861114502, train acuracy: 0.53515625
step: 97, val loss: 1.6079095602035522, val acuracy: 0.5210000276565552
step: 98, train loss: 1.6206802129745483, train acuracy: 0.4609375
step: 98, val loss: 1.589311122894287, val acuracy: 0.45633333921432495
step: 99, train loss: 1.589813470840454, train acuracy: 0.45703125
step: 99, val loss: 1.5806372165679932, val acuracy: 0.4583333432674408
step: 100, train loss: 1.6177654266357422, train acuracy: 0.4453125
step: 100, val loss: 1.5808091163635254, val acuracy: 0.4595000445842743
step: 101, train loss: 1.5601545572280884, train acuracy: 0.48046875
step: 101, val loss: 1.5808407068252563, val acuracy: 0.45750001072883606
step: 102, train loss: 1.632132887840271, train acuracy: 0.453125
step: 102, val loss: 1.5808039903640747, val acuracy: 0.4580000340938568
step: 103, train loss: 1.5991672277450562, train acuracy: 0.453125
step: 103, val loss: 1.5805975198745728, val acuracy: 0.45866668224334717
step: 104, train loss: 1.5450592041015625, train acuracy: 0.4765625
step: 104, val loss: 1.5928624868392944, val acuracy: 0.453000009059906
step: 105, train loss: 1.652296781539917, train acuracy: 0.43359375
step: 105, val loss: 1.6092100143432617, val acuracy: 0.45216667652130127
step: 106, train loss: 1.70099675655365, train acuracy: 0.39453125
step: 106, val loss: 1.6449209451675415, val acuracy: 0.4113333523273468
step: 107, train loss: 1.5449981689453125, train acuracy: 0.4921875
step: 107, val loss: 1.6081585884094238, val acuracy: 0.4656667113304138
step: 108, train loss: 1.551570177078247, train acuracy: 0.4765625
step: 108, val loss: 1.605773687362671, val acuracy: 0.4633334279060364
step: 109, train loss: 1.5944640636444092, train acuracy: 0.44140625
step: 109, val loss: 1.6252641677856445, val acuracy: 0.4256666898727417
step: 110, train loss: 1.4847278594970703, train acuracy: 0.51171875
step: 110, val loss: 1.6362069845199585, val acuracy: 0.4765000343322754
step: 111, train loss: 1.5481078624725342, train acuracy: 0.50390625
step: 111, val loss: 1.6231026649475098, val acuracy: 0.45133334398269653
step: 112, train loss: 1.6278276443481445, train acuracy: 0.4765625
step: 112, val loss: 1.6304470300674438, val acuracy: 0.4818333387374878
step: 113, train loss: 1.6659331321716309, train acuracy: 0.42578125
step: 113, val loss: 1.6139137744903564, val acuracy: 0.4583333432674408
step: 114, train loss: 1.5963058471679688, train acuracy: 0.4921875
step: 114, val loss: 1.6107399463653564, val acuracy: 0.45750001072883606
step: 115, train loss: 1.604762315750122, train acuracy: 0.44921875
step: 115, val loss: 1.6455743312835693, val acuracy: 0.4386667013168335
step: 116, train loss: 1.6605441570281982, train acuracy: 0.40234375
step: 116, val loss: 1.6403952836990356, val acuracy: 0.4396667182445526
step: 117, train loss: 1.4602817296981812, train acuracy: 0.5078125
step: 117, val loss: 1.639868974685669, val acuracy: 0.4389999806880951
step: 118, train loss: 1.6760966777801514, train acuracy: 0.4375
step: 118, val loss: 1.639878749847412, val acuracy: 0.43933334946632385
step: 119, train loss: 1.6929988861083984, train acuracy: 0.40234375
step: 119, val loss: 1.6401273012161255, val acuracy: 0.43933334946632385
step: 120, train loss: 1.5793647766113281, train acuracy: 0.47265625
step: 120, val loss: 1.642077088356018, val acuracy: 0.4398333728313446
step: 121, train loss: 1.671641230583191, train acuracy: 0.421875
step: 121, val loss: 1.638548493385315, val acuracy: 0.44416671991348267
step: 122, train loss: 1.6190719604492188, train acuracy: 0.421875
step: 122, val loss: 1.6464945077896118, val acuracy: 0.43833333253860474
step: 123, train loss: 1.5692415237426758, train acuracy: 0.50390625
step: 123, val loss: 1.650248408317566, val acuracy: 0.43933331966400146
step: 124, train loss: 1.790727138519287, train acuracy: 0.390625
step: 124, val loss: 1.6851413249969482, val acuracy: 0.4320000112056732
step: 125, train loss: 1.728674054145813, train acuracy: 0.421875
step: 125, val loss: 1.6814892292022705, val acuracy: 0.43299999833106995
step: 126, train loss: 1.706507921218872, train acuracy: 0.41796875
step: 126, val loss: 1.6803593635559082, val acuracy: 0.4326666593551636
step: 127, train loss: 1.645772099494934, train acuracy: 0.44921875
step: 127, val loss: 1.6802966594696045, val acuracy: 0.43550002574920654
step: 128, train loss: 1.6444905996322632, train acuracy: 0.4453125
step: 128, val loss: 1.6769639253616333, val acuracy: 0.4321666359901428
step: 129, train loss: 1.7663242816925049, train acuracy: 0.41015625
step: 129, val loss: 1.7303673028945923, val acuracy: 0.4246666729450226
step: 130, train loss: 1.6643868684768677, train acuracy: 0.4453125
step: 130, val loss: 1.6968016624450684, val acuracy: 0.42483338713645935
step: 131, train loss: 1.7380279302597046, train acuracy: 0.40234375
step: 131, val loss: 1.695504903793335, val acuracy: 0.4306666851043701
step: 132, train loss: 1.6840094327926636, train acuracy: 0.4453125
step: 132, val loss: 1.7058424949645996, val acuracy: 0.4268333315849304
step: 133, train loss: 1.6624281406402588, train acuracy: 0.44140625
step: 133, val loss: 1.7033146619796753, val acuracy: 0.42633333802223206
step: 134, train loss: 1.7254003286361694, train acuracy: 0.4375
step: 134, val loss: 1.7199307680130005, val acuracy: 0.4306666851043701
step: 135, train loss: 1.683171033859253, train acuracy: 0.43359375
step: 135, val loss: 1.7452447414398193, val acuracy: 0.406333327293396
step: 136, train loss: 1.7331498861312866, train acuracy: 0.4296875
step: 136, val loss: 1.7499409914016724, val acuracy: 0.4153333306312561
step: 137, train loss: 1.7249644994735718, train acuracy: 0.39453125
step: 137, val loss: 1.7132141590118408, val acuracy: 0.4150000214576721
step: 138, train loss: 1.6812981367111206, train acuracy: 0.41796875
step: 138, val loss: 1.7098191976547241, val acuracy: 0.41833335161209106
step: 139, train loss: 1.6494594812393188, train acuracy: 0.46875
step: 139, val loss: 1.7368415594100952, val acuracy: 0.4318333566188812
step: 140, train loss: 1.800078272819519, train acuracy: 0.3828125
step: 140, val loss: 1.761734127998352, val acuracy: 0.40183335542678833
step: 141, train loss: 1.7436540126800537, train acuracy: 0.41796875
step: 141, val loss: 1.718301773071289, val acuracy: 0.3998333215713501
step: 142, train loss: 1.7237050533294678, train acuracy: 0.390625
step: 142, val loss: 1.7252622842788696, val acuracy: 0.3973333239555359
step: 143, train loss: 1.8377989530563354, train acuracy: 0.32421875
step: 143, val loss: 1.721810221672058, val acuracy: 0.398333340883255
step: 144, train loss: 1.7151037454605103, train acuracy: 0.3828125
step: 144, val loss: 1.7193061113357544, val acuracy: 0.3918333649635315
step: 145, train loss: 1.8311783075332642, train acuracy: 0.3515625
step: 145, val loss: 1.7637684345245361, val acuracy: 0.3843333423137665
step: 146, train loss: 1.7417395114898682, train acuracy: 0.3671875
step: 146, val loss: 1.7594681978225708, val acuracy: 0.38600003719329834
step: 147, train loss: 1.8026432991027832, train acuracy: 0.390625
step: 147, val loss: 1.7684142589569092, val acuracy: 0.4051666855812073
step: 148, train loss: 1.8181655406951904, train acuracy: 0.3671875
step: 148, val loss: 1.7604494094848633, val acuracy: 0.39149999618530273
step: 149, train loss: 1.8130581378936768, train acuracy: 0.3515625
step: 149, val loss: 1.7506227493286133, val acuracy: 0.3995000123977661
step: 150, train loss: 26.376880645751953, train acuracy: 0.1640625
step: 150, val loss: 26.990694046020508, val acuracy: 0.14433331787586212
step: 151, train loss: 14.197296142578125, train acuracy: 0.08203125
step: 151, val loss: 13.622756958007812, val acuracy: 0.09849999099969864
step: 152, train loss: 12.84046745300293, train acuracy: 0.078125
step: 152, val loss: 12.465896606445312, val acuracy: 0.08116666227579117
step: 153, train loss: 5.678657054901123, train acuracy: 0.16796875
step: 153, val loss: 5.915000915527344, val acuracy: 0.16766667366027832
step: 154, train loss: 5.555215835571289, train acuracy: 0.11328125
step: 154, val loss: 5.9755096435546875, val acuracy: 0.10449999570846558
step: 155, train loss: 6.112844467163086, train acuracy: 0.08984375
step: 155, val loss: 5.801939487457275, val acuracy: 0.10599999874830246
step: 156, train loss: 5.695514678955078, train acuracy: 0.08984375
step: 156, val loss: 5.646660327911377, val acuracy: 0.10400000214576721
step: 157, train loss: 5.1996049880981445, train acuracy: 0.16015625
step: 157, val loss: 5.2621026039123535, val acuracy: 0.17783333361148834
step: 158, train loss: 3.600148916244507, train acuracy: 0.1171875
step: 158, val loss: 3.7006030082702637, val acuracy: 0.08966667205095291
step: 159, train loss: 3.3350777626037598, train acuracy: 0.1171875
step: 159, val loss: 3.2875607013702393, val acuracy: 0.13099998235702515
step: 160, train loss: 2.7741918563842773, train acuracy: 0.1953125
step: 160, val loss: 2.854666233062744, val acuracy: 0.19316667318344116
step: 161, train loss: 2.3179383277893066, train acuracy: 0.21875
step: 161, val loss: 2.3200509548187256, val acuracy: 0.23849999904632568
step: 162, train loss: 2.2127866744995117, train acuracy: 0.22265625
step: 162, val loss: 2.221379041671753, val acuracy: 0.19616664946079254
step: 163, train loss: 1.7994012832641602, train acuracy: 0.4296875
step: 163, val loss: 1.847790241241455, val acuracy: 0.45600003004074097
step: 164, train loss: 1.706146240234375, train acuracy: 0.44140625
step: 164, val loss: 1.7362874746322632, val acuracy: 0.4000000059604645
step: 165, train loss: 1.6446309089660645, train acuracy: 0.51171875
step: 165, val loss: 1.8565278053283691, val acuracy: 0.4645000100135803
step: 166, train loss: 1.4152884483337402, train acuracy: 0.51953125
step: 166, val loss: 1.4441044330596924, val acuracy: 0.5373333692550659
step: 167, train loss: 1.4142760038375854, train acuracy: 0.6171875
step: 167, val loss: 1.521442174911499, val acuracy: 0.5556666851043701
step: 168, train loss: 1.1357128620147705, train acuracy: 0.68359375
step: 168, val loss: 1.1554926633834839, val acuracy: 0.6493333578109741
step: 169, train loss: 1.2317583560943604, train acuracy: 0.609375
step: 169, val loss: 1.3325711488723755, val acuracy: 0.5791667103767395
step: 170, train loss: 1.1086373329162598, train acuracy: 0.66015625
step: 170, val loss: 1.1080057621002197, val acuracy: 0.6373333930969238
step: 171, train loss: 1.036487102508545, train acuracy: 0.6796875
step: 171, val loss: 1.007127046585083, val acuracy: 0.7083333730697632
step: 172, train loss: 0.9199539422988892, train acuracy: 0.74609375
step: 172, val loss: 1.002187967300415, val acuracy: 0.7085000872612
step: 173, train loss: 1.1002657413482666, train acuracy: 0.6796875
step: 173, val loss: 1.001107096672058, val acuracy: 0.7091667056083679
step: 174, train loss: 1.0328443050384521, train acuracy: 0.73046875
step: 174, val loss: 1.0151944160461426, val acuracy: 0.7095000743865967
step: 175, train loss: 0.9815073013305664, train acuracy: 0.74609375
step: 175, val loss: 1.010040283203125, val acuracy: 0.7040000557899475
step: 176, train loss: 0.9857692718505859, train acuracy: 0.69140625
step: 176, val loss: 1.0086264610290527, val acuracy: 0.7041666507720947
step: 177, train loss: 0.9455369710922241, train acuracy: 0.70703125
step: 177, val loss: 1.005998969078064, val acuracy: 0.7085000276565552
step: 178, train loss: 0.990469217300415, train acuracy: 0.69921875
step: 178, val loss: 1.003613829612732, val acuracy: 0.7096667885780334
step: 179, train loss: 1.11313796043396, train acuracy: 0.703125
step: 179, val loss: 1.010270595550537, val acuracy: 0.7103334069252014
step: 180, train loss: 1.0799281597137451, train acuracy: 0.6640625
step: 180, val loss: 1.008596658706665, val acuracy: 0.7116667032241821
step: 181, train loss: 1.0299227237701416, train acuracy: 0.73046875
step: 181, val loss: 1.0072252750396729, val acuracy: 0.7110000252723694
step: 182, train loss: 1.0377507209777832, train acuracy: 0.68359375
step: 182, val loss: 1.00618314743042, val acuracy: 0.7120000123977661
step: 183, train loss: 1.0252439975738525, train acuracy: 0.7421875
step: 183, val loss: 1.0058635473251343, val acuracy: 0.7125000357627869
step: 184, train loss: 1.0897475481033325, train acuracy: 0.69921875
step: 184, val loss: 1.0046613216400146, val acuracy: 0.7123333215713501
step: 185, train loss: 1.0253742933273315, train acuracy: 0.71484375
step: 185, val loss: 1.0040321350097656, val acuracy: 0.7123333811759949
step: 186, train loss: 0.9500813484191895, train acuracy: 0.73828125
step: 186, val loss: 1.0032732486724854, val acuracy: 0.7116667628288269
step: 187, train loss: 0.9619370698928833, train acuracy: 0.71484375
step: 187, val loss: 1.0065301656723022, val acuracy: 0.7039999961853027
step: 188, train loss: 0.8830106854438782, train acuracy: 0.73046875
step: 188, val loss: 0.989405632019043, val acuracy: 0.7100000381469727
step: 189, train loss: 1.0343408584594727, train acuracy: 0.7265625
step: 189, val loss: 1.0372437238693237, val acuracy: 0.6911667585372925
step: 190, train loss: 1.054792881011963, train acuracy: 0.671875
step: 190, val loss: 1.09457528591156, val acuracy: 0.6675000786781311
step: 191, train loss: 1.0828015804290771, train acuracy: 0.6640625
step: 191, val loss: 1.0586704015731812, val acuracy: 0.6936666965484619
step: 192, train loss: 1.0654044151306152, train acuracy: 0.6640625
step: 192, val loss: 1.051479458808899, val acuracy: 0.6965001225471497
step: 193, train loss: 0.97127765417099, train acuracy: 0.73046875
step: 193, val loss: 1.0468132495880127, val acuracy: 0.6978334188461304
step: 194, train loss: 0.9137433767318726, train acuracy: 0.74609375
step: 194, val loss: 1.0169695615768433, val acuracy: 0.7110000252723694
step: 195, train loss: 0.9691700339317322, train acuracy: 0.67578125
step: 195, val loss: 1.1444299221038818, val acuracy: 0.6183333992958069
step: 196, train loss: 0.9826936721801758, train acuracy: 0.6796875
step: 196, val loss: 1.1781425476074219, val acuracy: 0.6328333616256714
step: 197, train loss: 0.9765276312828064, train acuracy: 0.69921875
step: 197, val loss: 0.9959505200386047, val acuracy: 0.6763333678245544
step: 198, train loss: 0.9552476406097412, train acuracy: 0.6953125
step: 198, val loss: 0.9969063401222229, val acuracy: 0.6671667098999023
step: 199, train loss: 1.121843695640564, train acuracy: 0.65625
step: 199, val loss: 1.0616600513458252, val acuracy: 0.6630000472068787
step: 200, train loss: 1.0135457515716553, train acuracy: 0.65625
step: 200, val loss: 0.9790894389152527, val acuracy: 0.674666702747345
step: 201, train loss: 0.9431272745132446, train acuracy: 0.734375
step: 201, val loss: 1.0180962085723877, val acuracy: 0.6668334007263184
step: 202, train loss: 0.9490171074867249, train acuracy: 0.67578125
step: 202, val loss: 0.9358528256416321, val acuracy: 0.6963333487510681
step: 203, train loss: 0.9288042187690735, train acuracy: 0.6953125
step: 203, val loss: 0.9955154061317444, val acuracy: 0.6711666584014893
step: 204, train loss: 1.0951117277145386, train acuracy: 0.61328125
step: 204, val loss: 1.0641963481903076, val acuracy: 0.6805000305175781
step: 205, train loss: 1.0085777044296265, train acuracy: 0.6875
step: 205, val loss: 1.0444620847702026, val acuracy: 0.6858333349227905
step: 206, train loss: 1.0630494356155396, train acuracy: 0.6640625
step: 206, val loss: 1.0408703088760376, val acuracy: 0.6880000829696655
step: 207, train loss: 1.0476971864700317, train acuracy: 0.6796875
step: 207, val loss: 1.0394254922866821, val acuracy: 0.68666672706604
step: 208, train loss: 1.0252418518066406, train acuracy: 0.73046875
step: 208, val loss: 1.0381577014923096, val acuracy: 0.6856666803359985
step: 209, train loss: 1.1101136207580566, train acuracy: 0.61328125
step: 209, val loss: 1.0367109775543213, val acuracy: 0.687333345413208
step: 210, train loss: 1.0770033597946167, train acuracy: 0.6640625
step: 210, val loss: 1.036451816558838, val acuracy: 0.6886667013168335
step: 211, train loss: 1.0524966716766357, train acuracy: 0.7265625
step: 211, val loss: 1.0791603326797485, val acuracy: 0.6940001249313354
step: 212, train loss: 1.226435899734497, train acuracy: 0.62109375
step: 212, val loss: 1.1210870742797852, val acuracy: 0.6306667327880859
step: 213, train loss: 1.0991711616516113, train acuracy: 0.68359375
step: 213, val loss: 1.0759520530700684, val acuracy: 0.6651666760444641
step: 214, train loss: 1.0343616008758545, train acuracy: 0.6796875
step: 214, val loss: 1.0456691980361938, val acuracy: 0.6796666383743286
step: 215, train loss: 0.9498085379600525, train acuracy: 0.6640625
step: 215, val loss: 1.0417323112487793, val acuracy: 0.6820001006126404
step: 216, train loss: 0.9947792291641235, train acuracy: 0.68359375
step: 216, val loss: 1.0399460792541504, val acuracy: 0.6813334226608276
step: 217, train loss: 1.1201975345611572, train acuracy: 0.6484375
step: 217, val loss: 1.0628756284713745, val acuracy: 0.6726667284965515
step: 218, train loss: 0.9585548639297485, train acuracy: 0.6875
step: 218, val loss: 1.0599777698516846, val acuracy: 0.6728333830833435
step: 219, train loss: 0.9591554999351501, train acuracy: 0.72265625
step: 219, val loss: 1.0585429668426514, val acuracy: 0.6740000247955322
step: 220, train loss: 1.032801628112793, train acuracy: 0.67578125
step: 220, val loss: 1.057546854019165, val acuracy: 0.6744999885559082
step: 221, train loss: 0.9030911922454834, train acuracy: 0.69140625
step: 221, val loss: 1.0553563833236694, val acuracy: 0.675000011920929
step: 222, train loss: 1.0177960395812988, train acuracy: 0.71484375
step: 222, val loss: 1.054614543914795, val acuracy: 0.6766666769981384
step: 223, train loss: 1.1321430206298828, train acuracy: 0.6171875
step: 223, val loss: 1.0532788038253784, val acuracy: 0.6763333678245544
step: 224, train loss: 1.0669856071472168, train acuracy: 0.66015625
step: 224, val loss: 1.0529959201812744, val acuracy: 0.6773333549499512
step: 225, train loss: 1.0393071174621582, train acuracy: 0.65234375
step: 225, val loss: 1.160918951034546, val acuracy: 0.6320000290870667
step: 226, train loss: 1.0683637857437134, train acuracy: 0.62109375
step: 226, val loss: 1.1247704029083252, val acuracy: 0.6480000615119934
step: 227, train loss: 1.267195701599121, train acuracy: 0.6015625
step: 227, val loss: 1.1314737796783447, val acuracy: 0.6370000243186951
step: 228, train loss: 1.1219074726104736, train acuracy: 0.6953125
step: 228, val loss: 1.1225993633270264, val acuracy: 0.6385000348091125
step: 229, train loss: 1.1529927253723145, train acuracy: 0.63671875
step: 229, val loss: 1.0660029649734497, val acuracy: 0.6621667146682739
step: 230, train loss: 1.1569045782089233, train acuracy: 0.609375
step: 230, val loss: 1.1009771823883057, val acuracy: 0.6390000581741333
step: 231, train loss: 1.305504322052002, train acuracy: 0.609375
step: 231, val loss: 1.141837239265442, val acuracy: 0.6405000686645508
step: 232, train loss: 1.2240610122680664, train acuracy: 0.5859375
step: 232, val loss: 1.173740029335022, val acuracy: 0.6146667003631592
step: 233, train loss: 0.9745280742645264, train acuracy: 0.73046875
step: 233, val loss: 1.0966525077819824, val acuracy: 0.659333348274231
step: 234, train loss: 1.0321944952011108, train acuracy: 0.65625
step: 234, val loss: 1.0669057369232178, val acuracy: 0.6489999890327454
step: 235, train loss: 0.9921677112579346, train acuracy: 0.66796875
step: 235, val loss: 0.9901585578918457, val acuracy: 0.6841667890548706
step: 236, train loss: 1.112390398979187, train acuracy: 0.62890625
step: 236, val loss: 1.133191466331482, val acuracy: 0.6468333601951599
step: 237, train loss: 1.087461233139038, train acuracy: 0.63671875
step: 237, val loss: 1.1144030094146729, val acuracy: 0.6500000357627869
step: 238, train loss: 1.0211358070373535, train acuracy: 0.671875
step: 238, val loss: 1.1112154722213745, val acuracy: 0.6526666879653931
step: 239, train loss: 1.4268441200256348, train acuracy: 0.6015625
step: 239, val loss: 1.1099525690078735, val acuracy: 0.6518333554267883
step: 240, train loss: 1.058696985244751, train acuracy: 0.65625
step: 240, val loss: 1.1090654134750366, val acuracy: 0.6523333787918091
step: 241, train loss: 1.146278977394104, train acuracy: 0.63671875
step: 241, val loss: 1.1080927848815918, val acuracy: 0.6526667475700378
step: 242, train loss: 1.128961443901062, train acuracy: 0.68359375
step: 242, val loss: 1.1059149503707886, val acuracy: 0.6545000076293945
step: 243, train loss: 1.0680028200149536, train acuracy: 0.68359375
step: 243, val loss: 1.1053978204727173, val acuracy: 0.6550000309944153
step: 244, train loss: 1.1822401285171509, train acuracy: 0.62109375
step: 244, val loss: 1.2020443677902222, val acuracy: 0.6490000486373901
step: 245, train loss: 1.2939484119415283, train acuracy: 0.640625
step: 245, val loss: 1.184786319732666, val acuracy: 0.6511666774749756
step: 246, train loss: 1.0179803371429443, train acuracy: 0.6796875
step: 246, val loss: 1.2527104616165161, val acuracy: 0.6511667370796204
step: 247, train loss: 1.1152582168579102, train acuracy: 0.6953125
step: 247, val loss: 1.204535722732544, val acuracy: 0.6451666951179504
step: 248, train loss: 1.1479754447937012, train acuracy: 0.61328125
step: 248, val loss: 1.2203956842422485, val acuracy: 0.6298333406448364
step: 249, train loss: 1.2377638816833496, train acuracy: 0.64453125
step: 249, val loss: 1.2038681507110596, val acuracy: 0.6436667442321777
step: 250, train loss: 1.293730616569519, train acuracy: 0.62109375
step: 250, val loss: 1.2010372877120972, val acuracy: 0.6433334350585938
step: 251, train loss: 1.1112754344940186, train acuracy: 0.65625
step: 251, val loss: 1.2382475137710571, val acuracy: 0.6268333792686462
step: 252, train loss: 1.2618041038513184, train acuracy: 0.62890625
step: 252, val loss: 1.2293535470962524, val acuracy: 0.6283333897590637
step: 253, train loss: 1.1063573360443115, train acuracy: 0.69140625
step: 253, val loss: 1.224859595298767, val acuracy: 0.6310000419616699
step: 254, train loss: 1.4458768367767334, train acuracy: 0.6328125
step: 254, val loss: 1.2235629558563232, val acuracy: 0.6315000653266907
step: 255, train loss: 1.1254080533981323, train acuracy: 0.62109375
step: 255, val loss: 1.222292184829712, val acuracy: 0.6333334445953369
step: 256, train loss: 1.0929328203201294, train acuracy: 0.65234375
step: 256, val loss: 1.2506459951400757, val acuracy: 0.6255000233650208
step: 257, train loss: 1.2276866436004639, train acuracy: 0.65625
step: 257, val loss: 1.2417333126068115, val acuracy: 0.628000020980835
step: 258, train loss: 1.1903436183929443, train acuracy: 0.67578125
step: 258, val loss: 1.269674301147461, val acuracy: 0.6023333668708801
step: 259, train loss: 1.2587727308273315, train acuracy: 0.6015625
step: 259, val loss: 1.3701739311218262, val acuracy: 0.5685000419616699
step: 260, train loss: 1.1703128814697266, train acuracy: 0.69921875
step: 260, val loss: 1.296966791152954, val acuracy: 0.6315000057220459
step: 261, train loss: 1.2239347696304321, train acuracy: 0.59765625
step: 261, val loss: 1.233937382698059, val acuracy: 0.6231667399406433
step: 262, train loss: 1.1686002016067505, train acuracy: 0.66015625
step: 262, val loss: 1.225744366645813, val acuracy: 0.6255000829696655
step: 263, train loss: 1.3386480808258057, train acuracy: 0.546875
step: 263, val loss: 1.2667920589447021, val acuracy: 0.5871666669845581
step: 264, train loss: 1.3775825500488281, train acuracy: 0.59375
step: 264, val loss: 1.3198094367980957, val acuracy: 0.5835000276565552
step: 265, train loss: 1.276503324508667, train acuracy: 0.59765625
step: 265, val loss: 1.3055648803710938, val acuracy: 0.5873333215713501
step: 266, train loss: 1.1994754076004028, train acuracy: 0.58984375
step: 266, val loss: 1.302289605140686, val acuracy: 0.5935000777244568
step: 267, train loss: 1.1839834451675415, train acuracy: 0.609375
step: 267, val loss: 1.2963052988052368, val acuracy: 0.5926666855812073
step: 268, train loss: 1.408015489578247, train acuracy: 0.54296875
step: 268, val loss: 1.2938008308410645, val acuracy: 0.5906667113304138
step: 269, train loss: 1.3744608163833618, train acuracy: 0.5859375
step: 269, val loss: 1.322310447692871, val acuracy: 0.5841667056083679
step: 270, train loss: 1.2754052877426147, train acuracy: 0.6015625
step: 270, val loss: 1.3305838108062744, val acuracy: 0.5875000357627869
step: 271, train loss: 1.4109055995941162, train acuracy: 0.56640625
step: 271, val loss: 1.4023427963256836, val acuracy: 0.5791667103767395
step: 272, train loss: 1.4718254804611206, train acuracy: 0.51953125
step: 272, val loss: 1.5320632457733154, val acuracy: 0.5203333497047424
step: 273, train loss: 1.401194453239441, train acuracy: 0.5546875
step: 273, val loss: 1.3527644872665405, val acuracy: 0.5751667618751526
step: 274, train loss: 1.1449180841445923, train acuracy: 0.62890625
step: 274, val loss: 1.3744040727615356, val acuracy: 0.5691667199134827
step: 275, train loss: 1.5267435312271118, train acuracy: 0.515625
step: 275, val loss: 1.3645563125610352, val acuracy: 0.5724999904632568
step: 276, train loss: 1.229870080947876, train acuracy: 0.60546875
step: 276, val loss: 1.3886784315109253, val acuracy: 0.5815000534057617
step: 277, train loss: 4.591564655303955, train acuracy: 0.140625
step: 277, val loss: 4.764700889587402, val acuracy: 0.1171666607260704
step: 278, train loss: 2.731405735015869, train acuracy: 0.08203125
step: 278, val loss: 2.7229976654052734, val acuracy: 0.07716666907072067
step: 279, train loss: 2.7150161266326904, train acuracy: 0.12109375
step: 279, val loss: 2.6757397651672363, val acuracy: 0.08433333784341812
step: 280, train loss: 2.535318374633789, train acuracy: 0.13671875
step: 280, val loss: 2.555934429168701, val acuracy: 0.12066666781902313
step: 281, train loss: 2.661034345626831, train acuracy: 0.12109375
step: 281, val loss: 2.6228930950164795, val acuracy: 0.15833333134651184
step: 282, train loss: 2.2480413913726807, train acuracy: 0.16015625
step: 282, val loss: 2.219484806060791, val acuracy: 0.1536666601896286
step: 283, train loss: 2.317722797393799, train acuracy: 0.15625
step: 283, val loss: 2.3459081649780273, val acuracy: 0.14866667985916138
step: 284, train loss: 2.298754930496216, train acuracy: 0.1328125
step: 284, val loss: 2.3395838737487793, val acuracy: 0.15016666054725647
step: 285, train loss: 2.35994291305542, train acuracy: 0.15234375
step: 285, val loss: 2.339149236679077, val acuracy: 0.15016666054725647
step: 286, train loss: 2.320464849472046, train acuracy: 0.1484375
step: 286, val loss: 2.3389785289764404, val acuracy: 0.14916667342185974
step: 287, train loss: 2.3470242023468018, train acuracy: 0.1328125
step: 287, val loss: 2.338783025741577, val acuracy: 0.14883333444595337
step: 288, train loss: 2.376850128173828, train acuracy: 0.125
step: 288, val loss: 2.3385274410247803, val acuracy: 0.14933332800865173
step: 289, train loss: 2.3873684406280518, train acuracy: 0.1015625
step: 289, val loss: 2.3385674953460693, val acuracy: 0.148666650056839
step: 290, train loss: 4.794333457946777, train acuracy: 0.1875
step: 290, val loss: 4.794873237609863, val acuracy: 0.16500000655651093
step: 291, train loss: 3.7817611694335938, train acuracy: 0.1953125
step: 291, val loss: 3.9051806926727295, val acuracy: 0.18666666746139526
step: 292, train loss: 3.7640841007232666, train acuracy: 0.20703125
step: 292, val loss: 3.802128314971924, val acuracy: 0.19733333587646484
step: 293, train loss: 3.3243868350982666, train acuracy: 0.08984375
step: 293, val loss: 3.41828989982605, val acuracy: 0.12016665935516357
step: 294, train loss: 3.0407660007476807, train acuracy: 0.296875
step: 294, val loss: 2.9335925579071045, val acuracy: 0.27900001406669617
step: 295, train loss: 2.2007241249084473, train acuracy: 0.1796875
step: 295, val loss: 2.1637139320373535, val acuracy: 0.18466666340827942
step: 296, train loss: 2.21537184715271, train acuracy: 0.2890625
step: 296, val loss: 2.1659417152404785, val acuracy: 0.30266666412353516
step: 297, train loss: 2.1163644790649414, train acuracy: 0.23828125
step: 297, val loss: 2.138939142227173, val acuracy: 0.23266670107841492
step: 298, train loss: 1.9942240715026855, train acuracy: 0.37109375
step: 298, val loss: 2.097594738006592, val acuracy: 0.33250001072883606
step: 299, train loss: 1.6447349786758423, train acuracy: 0.44921875
step: 299, val loss: 1.6293762922286987, val acuracy: 0.4298333525657654
step: 300, train loss: 1.5405099391937256, train acuracy: 0.50390625
step: 300, val loss: 1.5382890701293945, val acuracy: 0.499666690826416
step: 301, train loss: 1.5610170364379883, train acuracy: 0.4296875
step: 301, val loss: 1.619439721107483, val acuracy: 0.4453333616256714
step: 302, train loss: 1.5903452634811401, train acuracy: 0.48828125
step: 302, val loss: 1.5740015506744385, val acuracy: 0.46500006318092346
step: 303, train loss: 1.3601727485656738, train acuracy: 0.60546875
step: 303, val loss: 1.3536458015441895, val acuracy: 0.5935000777244568
step: 304, train loss: 1.3157639503479004, train acuracy: 0.56640625
step: 304, val loss: 1.354298710823059, val acuracy: 0.5478333830833435
step: 305, train loss: 1.438224196434021, train acuracy: 0.5859375
step: 305, val loss: 1.381067156791687, val acuracy: 0.5791666507720947
step: 306, train loss: 1.4484333992004395, train acuracy: 0.58203125
step: 306, val loss: 1.3728225231170654, val acuracy: 0.5826666951179504
step: 307, train loss: 1.3475143909454346, train acuracy: 0.578125
step: 307, val loss: 1.3697565793991089, val acuracy: 0.5828333497047424
step: 308, train loss: 1.3958380222320557, train acuracy: 0.578125
step: 308, val loss: 1.3669216632843018, val acuracy: 0.5861667394638062
step: 309, train loss: 1.2082817554473877, train acuracy: 0.63671875
step: 309, val loss: 1.3660556077957153, val acuracy: 0.5875000357627869
step: 310, train loss: 1.3718568086624146, train acuracy: 0.5859375
step: 310, val loss: 1.366033673286438, val acuracy: 0.5860000252723694
step: 311, train loss: 1.3461332321166992, train acuracy: 0.578125
step: 311, val loss: 1.3651341199874878, val acuracy: 0.5864999890327454
step: 312, train loss: 1.3834396600723267, train acuracy: 0.60546875
step: 312, val loss: 1.3646291494369507, val acuracy: 0.5870000123977661
step: 313, train loss: 1.288104772567749, train acuracy: 0.58203125
step: 313, val loss: 1.4162118434906006, val acuracy: 0.549500048160553
step: 314, train loss: 1.2877252101898193, train acuracy: 0.6171875
step: 314, val loss: 1.4581743478775024, val acuracy: 0.5531666874885559
step: 315, train loss: 1.4720287322998047, train acuracy: 0.44140625
step: 315, val loss: 1.5746383666992188, val acuracy: 0.41433337330818176
step: 316, train loss: 1.3143619298934937, train acuracy: 0.625
step: 316, val loss: 1.512127161026001, val acuracy: 0.5118333697319031
step: 317, train loss: 1.5100994110107422, train acuracy: 0.484375
step: 317, val loss: 1.5787017345428467, val acuracy: 0.46300002932548523
step: 318, train loss: 1.4331960678100586, train acuracy: 0.5625
step: 318, val loss: 1.4811131954193115, val acuracy: 0.5276666283607483
step: 319, train loss: 1.350722312927246, train acuracy: 0.6015625
step: 319, val loss: 1.4773211479187012, val acuracy: 0.5233333110809326
step: 320, train loss: 1.3078440427780151, train acuracy: 0.59375
step: 320, val loss: 1.393839955329895, val acuracy: 0.515333354473114
step: 321, train loss: 2.882206916809082, train acuracy: 0.20703125
step: 321, val loss: 2.899972677230835, val acuracy: 0.19249999523162842
step: 322, train loss: 3.101377010345459, train acuracy: 0.078125
step: 322, val loss: 3.047976493835449, val acuracy: 0.09533333778381348
step: 323, train loss: 2.9026496410369873, train acuracy: 0.1171875
step: 323, val loss: 2.9527807235717773, val acuracy: 0.09566666185855865
step: 324, train loss: 3.063119649887085, train acuracy: 0.0625
step: 324, val loss: 2.9661879539489746, val acuracy: 0.09566666185855865
step: 325, train loss: 2.966010093688965, train acuracy: 0.08203125
step: 325, val loss: 2.963827610015869, val acuracy: 0.09566666930913925
step: 326, train loss: 3.003736972808838, train acuracy: 0.0859375
step: 326, val loss: 2.9628844261169434, val acuracy: 0.09566666930913925
step: 327, train loss: 2.9514291286468506, train acuracy: 0.09765625
step: 327, val loss: 2.9621543884277344, val acuracy: 0.09566666185855865
step: 328, train loss: 2.6490695476531982, train acuracy: 0.0859375
step: 328, val loss: 2.672528028488159, val acuracy: 0.09583333134651184
step: 329, train loss: 2.3948721885681152, train acuracy: 0.0859375
step: 329, val loss: 2.4175944328308105, val acuracy: 0.0976666659116745
step: 330, train loss: 2.4045190811157227, train acuracy: 0.08203125
step: 330, val loss: 2.4230215549468994, val acuracy: 0.09816666692495346
step: 331, train loss: 2.2954325675964355, train acuracy: 0.1484375
step: 331, val loss: 2.384125232696533, val acuracy: 0.12233332544565201
step: 332, train loss: 2.2407031059265137, train acuracy: 0.25
step: 332, val loss: 2.273120403289795, val acuracy: 0.19900000095367432
step: 333, train loss: 2.2985117435455322, train acuracy: 0.16796875
step: 333, val loss: 2.291383743286133, val acuracy: 0.1951666623353958
step: 334, train loss: 2.245731830596924, train acuracy: 0.21875
step: 334, val loss: 2.236158609390259, val acuracy: 0.21916666626930237
step: 335, train loss: 2.2498250007629395, train acuracy: 0.1484375
step: 335, val loss: 2.272793769836426, val acuracy: 0.14633333683013916
step: 336, train loss: 2.25586199760437, train acuracy: 0.13671875
step: 336, val loss: 2.2676496505737305, val acuracy: 0.15433332324028015
step: 337, train loss: 2.2341604232788086, train acuracy: 0.19140625
step: 337, val loss: 2.2675540447235107, val acuracy: 0.1563333421945572
step: 338, train loss: 2.3085904121398926, train acuracy: 0.13671875
step: 338, val loss: 2.267192840576172, val acuracy: 0.15600000321865082
step: 339, train loss: 2.2719497680664062, train acuracy: 0.1484375
step: 339, val loss: 2.267086982727051, val acuracy: 0.1550000011920929
step: 340, train loss: 2.235774040222168, train acuracy: 0.17578125
step: 340, val loss: 2.2669198513031006, val acuracy: 0.1538333296775818
step: 341, train loss: 2.2351198196411133, train acuracy: 0.1796875
step: 341, val loss: 2.270899534225464, val acuracy: 0.16099999845027924
step: 342, train loss: 2.2767748832702637, train acuracy: 0.16796875
step: 342, val loss: 2.2707035541534424, val acuracy: 0.16116666793823242
step: 343, train loss: 2.269108533859253, train acuracy: 0.2109375
step: 343, val loss: 2.2949740886688232, val acuracy: 0.2016666680574417
step: 344, train loss: 2.261420488357544, train acuracy: 0.21875
step: 344, val loss: 2.252112865447998, val acuracy: 0.19983333349227905
step: 345, train loss: 2.160964250564575, train acuracy: 0.2890625
step: 345, val loss: 2.2166647911071777, val acuracy: 0.24533334374427795
step: 346, train loss: 2.1297354698181152, train acuracy: 0.26171875
step: 346, val loss: 2.201594352722168, val acuracy: 0.23583334684371948
step: 347, train loss: 2.206090211868286, train acuracy: 0.25390625
step: 347, val loss: 2.2391161918640137, val acuracy: 0.2588333487510681
step: 348, train loss: 2.306213140487671, train acuracy: 0.30078125
step: 348, val loss: 2.307142734527588, val acuracy: 0.29850003123283386
step: 349, train loss: 2.094109058380127, train acuracy: 0.3125
step: 349, val loss: 2.102562427520752, val acuracy: 0.2978333532810211
step: 350, train loss: 2.061119794845581, train acuracy: 0.30078125
step: 350, val loss: 2.0976383686065674, val acuracy: 0.2983333468437195
step: 351, train loss: 2.126904010772705, train acuracy: 0.26171875
step: 351, val loss: 2.126615047454834, val acuracy: 0.2658333480358124
step: 352, train loss: 2.1526360511779785, train acuracy: 0.2578125
step: 352, val loss: 2.1210579872131348, val acuracy: 0.26983335614204407
step: 353, train loss: 2.117288827896118, train acuracy: 0.2421875
step: 353, val loss: 2.1209661960601807, val acuracy: 0.2705000042915344
step: 354, train loss: 2.1085808277130127, train acuracy: 0.25
step: 354, val loss: 2.120939254760742, val acuracy: 0.2709999978542328
step: 355, train loss: 2.1609718799591064, train acuracy: 0.23046875
step: 355, val loss: 2.121022939682007, val acuracy: 0.27166667580604553
step: 356, train loss: 2.1223108768463135, train acuracy: 0.31640625
step: 356, val loss: 2.128948211669922, val acuracy: 0.284000039100647
step: 357, train loss: 2.226076126098633, train acuracy: 0.1875
step: 357, val loss: 2.1543331146240234, val acuracy: 0.27933335304260254
step: 358, train loss: 2.1541686058044434, train acuracy: 0.296875
step: 358, val loss: 2.154904842376709, val acuracy: 0.29633334279060364
step: 359, train loss: 2.1932430267333984, train acuracy: 0.25
step: 359, val loss: 2.1336171627044678, val acuracy: 0.2823333442211151
step: 360, train loss: 2.170876979827881, train acuracy: 0.234375
step: 360, val loss: 2.114443778991699, val acuracy: 0.28450000286102295
step: 361, train loss: 2.0404131412506104, train acuracy: 0.31640625
step: 361, val loss: 2.1326422691345215, val acuracy: 0.2756666839122772
step: 362, train loss: 2.03900408744812, train acuracy: 0.30078125
step: 362, val loss: 2.0948879718780518, val acuracy: 0.2861666977405548
step: 363, train loss: 2.072950839996338, train acuracy: 0.28125
step: 363, val loss: 2.133765697479248, val acuracy: 0.29600000381469727
step: 364, train loss: 2.151615858078003, train acuracy: 0.29296875
step: 364, val loss: 2.1295905113220215, val acuracy: 0.29733335971832275
step: 365, train loss: 2.101813316345215, train acuracy: 0.296875
step: 365, val loss: 2.1284167766571045, val acuracy: 0.2979999780654907
step: 366, train loss: 2.1159183979034424, train acuracy: 0.28515625
step: 366, val loss: 2.128321409225464, val acuracy: 0.2978333532810211
step: 367, train loss: 2.080721139907837, train acuracy: 0.32421875
step: 367, val loss: 2.1282079219818115, val acuracy: 0.2978333532810211
step: 368, train loss: 2.0525970458984375, train acuracy: 0.29296875
step: 368, val loss: 2.1281299591064453, val acuracy: 0.2981666624546051
step: 369, train loss: 2.0519237518310547, train acuracy: 0.2890625
step: 369, val loss: 2.1281352043151855, val acuracy: 0.2983333468437195
step: 370, train loss: 2.2047412395477295, train acuracy: 0.2734375
step: 370, val loss: 2.130643844604492, val acuracy: 0.29866665601730347
step: 371, train loss: 2.0358309745788574, train acuracy: 0.31640625
step: 371, val loss: 2.155397891998291, val acuracy: 0.2861666679382324
step: 372, train loss: 2.047903537750244, train acuracy: 0.32421875
step: 372, val loss: 2.1405458450317383, val acuracy: 0.28466668725013733
step: 373, train loss: 2.130016803741455, train acuracy: 0.2578125
step: 373, val loss: 2.121880531311035, val acuracy: 0.2798333466053009
step: 374, train loss: 2.139211893081665, train acuracy: 0.2265625
step: 374, val loss: 2.1080965995788574, val acuracy: 0.23450002074241638
step: 375, train loss: 2.0285768508911133, train acuracy: 0.30078125
step: 375, val loss: 2.1465394496917725, val acuracy: 0.23483334481716156
step: 376, train loss: 2.046773910522461, train acuracy: 0.23828125
step: 376, val loss: 2.0445563793182373, val acuracy: 0.2658333480358124
step: 377, train loss: 2.0597798824310303, train acuracy: 0.28125
step: 377, val loss: 1.911383867263794, val acuracy: 0.3371666669845581
step: 378, train loss: 1.9271570444107056, train acuracy: 0.30078125
step: 378, val loss: 1.8898508548736572, val acuracy: 0.343500018119812
step: 379, train loss: 1.7078015804290771, train acuracy: 0.39453125
step: 379, val loss: 1.8860279321670532, val acuracy: 0.3460000157356262
step: 380, train loss: 1.8780968189239502, train acuracy: 0.35546875
step: 380, val loss: 1.8631932735443115, val acuracy: 0.34283334016799927
step: 381, train loss: 1.8208847045898438, train acuracy: 0.3515625
step: 381, val loss: 1.8616877794265747, val acuracy: 0.34400004148483276
step: 382, train loss: 1.832986831665039, train acuracy: 0.3515625
step: 382, val loss: 1.861411690711975, val acuracy: 0.34383338689804077
step: 383, train loss: 1.8607665300369263, train acuracy: 0.3515625
step: 383, val loss: 1.931859016418457, val acuracy: 0.335833340883255
step: 384, train loss: 1.8940740823745728, train acuracy: 0.35546875
step: 384, val loss: 1.9234676361083984, val acuracy: 0.338500052690506
step: 385, train loss: 1.8947213888168335, train acuracy: 0.359375
step: 385, val loss: 1.918637990951538, val acuracy: 0.33750003576278687
step: 386, train loss: 1.8602930307388306, train acuracy: 0.33984375
step: 386, val loss: 1.8897676467895508, val acuracy: 0.3368333578109741
step: 387, train loss: 1.8343839645385742, train acuracy: 0.36328125
step: 387, val loss: 1.8690712451934814, val acuracy: 0.3460000157356262
step: 388, train loss: 1.9187006950378418, train acuracy: 0.3515625
step: 388, val loss: 1.8655551671981812, val acuracy: 0.34850001335144043
step: 389, train loss: 1.8310399055480957, train acuracy: 0.4140625
step: 389, val loss: 1.8418259620666504, val acuracy: 0.3968333601951599
step: 390, train loss: 1.994709849357605, train acuracy: 0.27734375
step: 390, val loss: 1.8956494331359863, val acuracy: 0.32216668128967285
step: 391, train loss: 1.7584960460662842, train acuracy: 0.41796875
step: 391, val loss: 1.7630836963653564, val acuracy: 0.40666669607162476
step: 392, train loss: 1.8629733324050903, train acuracy: 0.44921875
step: 392, val loss: 1.7499395608901978, val acuracy: 0.4390000104904175
step: 393, train loss: 1.752233624458313, train acuracy: 0.4765625
step: 393, val loss: 1.744602084159851, val acuracy: 0.4396666884422302
step: 394, train loss: 1.7678651809692383, train acuracy: 0.4296875
step: 394, val loss: 1.7080765962600708, val acuracy: 0.42266666889190674
step: 395, train loss: 1.5842750072479248, train acuracy: 0.453125
step: 395, val loss: 1.6752359867095947, val acuracy: 0.42900002002716064
step: 396, train loss: 1.6433508396148682, train acuracy: 0.4453125
step: 396, val loss: 1.6743690967559814, val acuracy: 0.4298333525657654
step: 397, train loss: 1.514169692993164, train acuracy: 0.52734375
step: 397, val loss: 1.6779204607009888, val acuracy: 0.43266671895980835
step: 398, train loss: 1.736897349357605, train acuracy: 0.42578125
step: 398, val loss: 1.6766140460968018, val acuracy: 0.43283334374427795
step: 399, train loss: 1.6934940814971924, train acuracy: 0.42578125
step: 399, val loss: 1.6739412546157837, val acuracy: 0.4326666593551636
2017-12-04 15:03:11.886136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:03:12.155661: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x59cd230 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 15:03:12.156616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:03:12.156970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 15:03:12.156992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 15:03:12.157001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 15:03:12.157017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 15:03:12.157028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.2871041297912598, train acuracy: 0.142578125
step: 0, val loss: 2.364497661590576, val acuracy: 0.11549999564886093
step: 1, train loss: 2.2402515411376953, train acuracy: 0.130859375
step: 1, val loss: 2.268202066421509, val acuracy: 0.10716666281223297
step: 2, train loss: 2.187168836593628, train acuracy: 0.349609375
step: 2, val loss: 2.2027335166931152, val acuracy: 0.3296666741371155
step: 3, train loss: 2.2018980979919434, train acuracy: 0.10546875
step: 3, val loss: 2.1830921173095703, val acuracy: 0.11249999701976776
step: 4, train loss: 2.024146795272827, train acuracy: 0.498046875
step: 4, val loss: 2.031710147857666, val acuracy: 0.47733333706855774
step: 5, train loss: 1.97579824924469, train acuracy: 0.341796875
step: 5, val loss: 2.109565019607544, val acuracy: 0.29383334517478943
step: 6, train loss: 1.94673490524292, train acuracy: 0.3125
step: 6, val loss: 1.993231177330017, val acuracy: 0.29733335971832275
step: 7, train loss: 1.3575726747512817, train acuracy: 0.55859375
step: 7, val loss: 1.3412827253341675, val acuracy: 0.5705000758171082
step: 8, train loss: 1.0665749311447144, train acuracy: 0.64453125
step: 8, val loss: 1.0542726516723633, val acuracy: 0.6568334102630615
step: 9, train loss: 0.8121846914291382, train acuracy: 0.748046875
step: 9, val loss: 0.7474720478057861, val acuracy: 0.7695000767707825
step: 10, train loss: 0.7524415850639343, train acuracy: 0.787109375
step: 10, val loss: 0.7632407546043396, val acuracy: 0.7705000638961792
step: 11, train loss: 0.44988441467285156, train acuracy: 0.8671875
step: 11, val loss: 0.5148483514785767, val acuracy: 0.8415000438690186
step: 12, train loss: 0.4727371037006378, train acuracy: 0.837890625
step: 12, val loss: 0.550964891910553, val acuracy: 0.815166711807251
step: 13, train loss: 0.474531352519989, train acuracy: 0.837890625
step: 13, val loss: 0.5061830878257751, val acuracy: 0.8463334441184998
step: 14, train loss: 0.4667131304740906, train acuracy: 0.83984375
step: 14, val loss: 0.5361329317092896, val acuracy: 0.8240000605583191
step: 15, train loss: 0.551291286945343, train acuracy: 0.8203125
step: 15, val loss: 0.5527142882347107, val acuracy: 0.8286666870117188
step: 16, train loss: 0.4547887444496155, train acuracy: 0.8671875
step: 16, val loss: 0.5006334781646729, val acuracy: 0.8473334312438965
step: 17, train loss: 0.4601951241493225, train acuracy: 0.865234375
step: 17, val loss: 0.5045003890991211, val acuracy: 0.843500018119812
step: 18, train loss: 0.45703160762786865, train acuracy: 0.85546875
step: 18, val loss: 0.5210248231887817, val acuracy: 0.842666745185852
step: 19, train loss: 0.5054091215133667, train acuracy: 0.833984375
step: 19, val loss: 0.5128440260887146, val acuracy: 0.8418334126472473
step: 20, train loss: 0.4939858317375183, train acuracy: 0.828125
step: 20, val loss: 0.5101303458213806, val acuracy: 0.8425000905990601
step: 21, train loss: 0.5630090236663818, train acuracy: 0.830078125
step: 21, val loss: 0.5094195604324341, val acuracy: 0.8433334231376648
step: 22, train loss: 0.5998073816299438, train acuracy: 0.8203125
step: 22, val loss: 0.5089297294616699, val acuracy: 0.8431667685508728
step: 23, train loss: 0.4790987968444824, train acuracy: 0.83203125
step: 23, val loss: 0.5086600184440613, val acuracy: 0.8430001139640808
step: 24, train loss: 0.37290412187576294, train acuracy: 0.88671875
step: 24, val loss: 0.5180901288986206, val acuracy: 0.8376666903495789
step: 25, train loss: 0.8757891058921814, train acuracy: 0.7109375
step: 25, val loss: 0.8431057929992676, val acuracy: 0.7136666774749756
step: 26, train loss: 0.9191968441009521, train acuracy: 0.69921875
step: 26, val loss: 0.8164058923721313, val acuracy: 0.7176668047904968
step: 27, train loss: 0.8552339673042297, train acuracy: 0.724609375
step: 27, val loss: 0.8434838056564331, val acuracy: 0.7294999957084656
step: 28, train loss: 0.7641364932060242, train acuracy: 0.759765625
step: 28, val loss: 0.9037827253341675, val acuracy: 0.7026667594909668
step: 29, train loss: 0.7922597527503967, train acuracy: 0.740234375
step: 29, val loss: 0.820020318031311, val acuracy: 0.723666787147522
step: 30, train loss: 0.9015483856201172, train acuracy: 0.703125
step: 30, val loss: 0.8172895908355713, val acuracy: 0.7235000729560852
step: 31, train loss: 0.8260242938995361, train acuracy: 0.703125
step: 31, val loss: 0.826016366481781, val acuracy: 0.7113333940505981
step: 32, train loss: 0.7711467146873474, train acuracy: 0.732421875
step: 32, val loss: 0.8225293159484863, val acuracy: 0.7188334465026855
step: 33, train loss: 0.6831759214401245, train acuracy: 0.748046875
step: 33, val loss: 0.8185548186302185, val acuracy: 0.7078334093093872
step: 34, train loss: 0.8434883952140808, train acuracy: 0.71875
step: 34, val loss: 0.8372137546539307, val acuracy: 0.7196667790412903
step: 35, train loss: 0.8000791072845459, train acuracy: 0.732421875
step: 35, val loss: 0.8010513186454773, val acuracy: 0.7165000438690186
step: 36, train loss: 1219.9903564453125, train acuracy: 0.10546875
step: 36, val loss: 1296.280517578125, val acuracy: 0.10499999672174454
step: 37, train loss: 1202.9815673828125, train acuracy: 0.080078125
step: 37, val loss: 1169.2886962890625, val acuracy: 0.09533333778381348
step: 38, train loss: 11325.29296875, train acuracy: 0.095703125
step: 38, val loss: 11343.0234375, val acuracy: 0.10483333468437195
step: 39, train loss: 9337.9716796875, train acuracy: 0.158203125
step: 39, val loss: 10404.2431640625, val acuracy: 0.14016665518283844
step: 40, train loss: 2924677.25, train acuracy: 0.103515625
step: 40, val loss: 2979434.25, val acuracy: 0.09033332765102386
step: 41, train loss: 675183132672.0, train acuracy: 0.072265625
step: 41, val loss: 705374191616.0, val acuracy: 0.06366666406393051
step: 42, train loss: 9.616014673812498e+26, train acuracy: 0.08203125
step: 42, val loss: 9.55073902523327e+26, val acuracy: 0.07366666197776794
step: 43, train loss: nan, train acuracy: 0.078125
step: 43, val loss: nan, val acuracy: 0.10400000214576721
step: 44, train loss: nan, train acuracy: 0.1015625
step: 44, val loss: nan, val acuracy: 0.10400000214576721
step: 45, train loss: nan, train acuracy: 0.109375
step: 45, val loss: nan, val acuracy: 0.10400000214576721
step: 46, train loss: nan, train acuracy: 0.09765625
step: 46, val loss: nan, val acuracy: 0.10400000214576721
step: 47, train loss: nan, train acuracy: 0.103515625
step: 47, val loss: nan, val acuracy: 0.10400000214576721
step: 48, train loss: nan, train acuracy: 0.1015625
step: 48, val loss: nan, val acuracy: 0.10400000214576721
step: 49, train loss: nan, train acuracy: 0.099609375
step: 49, val loss: nan, val acuracy: 0.10400000214576721
step: 50, train loss: nan, train acuracy: 0.109375
step: 50, val loss: nan, val acuracy: 0.10400000214576721
step: 51, train loss: nan, train acuracy: 0.099609375
step: 51, val loss: nan, val acuracy: 0.10400000959634781
step: 52, train loss: nan, train acuracy: 0.064453125
step: 52, val loss: nan, val acuracy: 0.10400000214576721
step: 53, train loss: nan, train acuracy: 0.078125
step: 53, val loss: nan, val acuracy: 0.10400000214576721
step: 54, train loss: nan, train acuracy: 0.119140625
step: 54, val loss: nan, val acuracy: 0.10400000214576721
step: 55, train loss: nan, train acuracy: 0.12109375
step: 55, val loss: nan, val acuracy: 0.10400000214576721
step: 56, train loss: nan, train acuracy: 0.09375
step: 56, val loss: nan, val acuracy: 0.10400000214576721
step: 57, train loss: nan, train acuracy: 0.107421875
step: 57, val loss: nan, val acuracy: 0.10400000214576721
step: 58, train loss: nan, train acuracy: 0.109375
step: 58, val loss: nan, val acuracy: 0.10400000214576721
step: 59, train loss: nan, train acuracy: 0.0859375
step: 59, val loss: nan, val acuracy: 0.10400000214576721
step: 60, train loss: nan, train acuracy: 0.107421875
step: 60, val loss: nan, val acuracy: 0.10400000214576721
step: 61, train loss: nan, train acuracy: 0.107421875
step: 61, val loss: nan, val acuracy: 0.10400000214576721
step: 62, train loss: nan, train acuracy: 0.078125
step: 62, val loss: nan, val acuracy: 0.10400000214576721
step: 63, train loss: nan, train acuracy: 0.119140625
step: 63, val loss: nan, val acuracy: 0.10400000214576721
step: 64, train loss: nan, train acuracy: 0.09765625
step: 64, val loss: nan, val acuracy: 0.10400000214576721
step: 65, train loss: nan, train acuracy: 0.103515625
step: 65, val loss: nan, val acuracy: 0.10400000214576721
step: 66, train loss: nan, train acuracy: 0.083984375
step: 66, val loss: nan, val acuracy: 0.10400000214576721
step: 67, train loss: nan, train acuracy: 0.107421875
step: 67, val loss: nan, val acuracy: 0.10400000214576721
step: 68, train loss: nan, train acuracy: 0.09375
step: 68, val loss: nan, val acuracy: 0.10400000214576721
step: 69, train loss: nan, train acuracy: 0.111328125
step: 69, val loss: nan, val acuracy: 0.10400000214576721
step: 70, train loss: nan, train acuracy: 0.078125
step: 70, val loss: nan, val acuracy: 0.10400000214576721
step: 71, train loss: nan, train acuracy: 0.095703125
step: 71, val loss: nan, val acuracy: 0.10400000214576721
step: 72, train loss: nan, train acuracy: 0.080078125
step: 72, val loss: nan, val acuracy: 0.10400000214576721
step: 73, train loss: nan, train acuracy: 0.08203125
step: 73, val loss: nan, val acuracy: 0.10400000214576721
step: 74, train loss: nan, train acuracy: 0.095703125
step: 74, val loss: nan, val acuracy: 0.10400000214576721
step: 75, train loss: nan, train acuracy: 0.10546875
step: 75, val loss: nan, val acuracy: 0.10400000214576721
step: 76, train loss: nan, train acuracy: 0.107421875
step: 76, val loss: nan, val acuracy: 0.10400000214576721
step: 77, train loss: nan, train acuracy: 0.083984375
step: 77, val loss: nan, val acuracy: 0.10400000214576721
step: 78, train loss: nan, train acuracy: 0.109375
step: 78, val loss: nan, val acuracy: 0.10400000214576721
step: 79, train loss: nan, train acuracy: 0.115234375
step: 79, val loss: nan, val acuracy: 0.10400000214576721
step: 80, train loss: nan, train acuracy: 0.1015625
step: 80, val loss: nan, val acuracy: 0.10400000214576721
step: 81, train loss: nan, train acuracy: 0.107421875
step: 81, val loss: nan, val acuracy: 0.10400000214576721
step: 82, train loss: nan, train acuracy: 0.09765625
step: 82, val loss: nan, val acuracy: 0.10400000214576721
step: 83, train loss: nan, train acuracy: 0.111328125
step: 83, val loss: nan, val acuracy: 0.10400000214576721
step: 84, train loss: nan, train acuracy: 0.1015625
step: 84, val loss: nan, val acuracy: 0.10400000214576721
step: 85, train loss: nan, train acuracy: 0.072265625
step: 85, val loss: nan, val acuracy: 0.10400000214576721
step: 86, train loss: nan, train acuracy: 0.109375
step: 86, val loss: nan, val acuracy: 0.10400000214576721
step: 87, train loss: nan, train acuracy: 0.08984375
step: 87, val loss: nan, val acuracy: 0.10400000214576721
step: 88, train loss: nan, train acuracy: 0.099609375
step: 88, val loss: nan, val acuracy: 0.10400000214576721
step: 89, train loss: nan, train acuracy: 0.099609375
step: 89, val loss: nan, val acuracy: 0.10400000214576721
step: 90, train loss: nan, train acuracy: 0.087890625
step: 90, val loss: nan, val acuracy: 0.10400000214576721
step: 91, train loss: nan, train acuracy: 0.103515625
step: 91, val loss: nan, val acuracy: 0.10400000214576721
step: 92, train loss: nan, train acuracy: 0.095703125
step: 92, val loss: nan, val acuracy: 0.10400000214576721
step: 93, train loss: nan, train acuracy: 0.080078125
step: 93, val loss: nan, val acuracy: 0.10400000214576721
step: 94, train loss: nan, train acuracy: 0.109375
step: 94, val loss: nan, val acuracy: 0.10400000214576721
step: 95, train loss: nan, train acuracy: 0.095703125
step: 95, val loss: nan, val acuracy: 0.10400000214576721
step: 96, train loss: nan, train acuracy: 0.111328125
step: 96, val loss: nan, val acuracy: 0.10400000214576721
step: 97, train loss: nan, train acuracy: 0.087890625
step: 97, val loss: nan, val acuracy: 0.10400000214576721
step: 98, train loss: nan, train acuracy: 0.12109375
step: 98, val loss: nan, val acuracy: 0.10400000214576721
step: 99, train loss: nan, train acuracy: 0.095703125
step: 99, val loss: nan, val acuracy: 0.10400000214576721
step: 100, train loss: nan, train acuracy: 0.10546875
step: 100, val loss: nan, val acuracy: 0.10400000214576721
step: 101, train loss: nan, train acuracy: 0.080078125
step: 101, val loss: nan, val acuracy: 0.10400000959634781
step: 102, train loss: nan, train acuracy: 0.123046875
step: 102, val loss: nan, val acuracy: 0.10400000214576721
step: 103, train loss: nan, train acuracy: 0.1171875
step: 103, val loss: nan, val acuracy: 0.10400000214576721
step: 104, train loss: nan, train acuracy: 0.103515625
step: 104, val loss: nan, val acuracy: 0.10400000214576721
step: 105, train loss: nan, train acuracy: 0.11328125
step: 105, val loss: nan, val acuracy: 0.10400000214576721
step: 106, train loss: nan, train acuracy: 0.076171875
step: 106, val loss: nan, val acuracy: 0.10400000214576721
step: 107, train loss: nan, train acuracy: 0.107421875
step: 107, val loss: nan, val acuracy: 0.10400000214576721
step: 108, train loss: nan, train acuracy: 0.09765625
step: 108, val loss: nan, val acuracy: 0.10400000214576721
step: 109, train loss: nan, train acuracy: 0.080078125
step: 109, val loss: nan, val acuracy: 0.10400000214576721
step: 110, train loss: nan, train acuracy: 0.087890625
step: 110, val loss: nan, val acuracy: 0.10400000214576721
step: 111, train loss: nan, train acuracy: 0.087890625
step: 111, val loss: nan, val acuracy: 0.10400000214576721
step: 112, train loss: nan, train acuracy: 0.111328125
step: 112, val loss: nan, val acuracy: 0.10400000214576721
step: 113, train loss: nan, train acuracy: 0.09375
step: 113, val loss: nan, val acuracy: 0.10400000214576721
step: 114, train loss: nan, train acuracy: 0.109375
step: 114, val loss: nan, val acuracy: 0.10400000214576721
step: 115, train loss: nan, train acuracy: 0.09375
step: 115, val loss: nan, val acuracy: 0.10400000214576721
step: 116, train loss: nan, train acuracy: 0.099609375
step: 116, val loss: nan, val acuracy: 0.10400000214576721
step: 117, train loss: nan, train acuracy: 0.109375
step: 117, val loss: nan, val acuracy: 0.10400000214576721
step: 118, train loss: nan, train acuracy: 0.115234375
step: 118, val loss: nan, val acuracy: 0.10400000214576721
step: 119, train loss: nan, train acuracy: 0.1015625
step: 119, val loss: nan, val acuracy: 0.10400000214576721
step: 120, train loss: nan, train acuracy: 0.0859375
step: 120, val loss: nan, val acuracy: 0.10400000214576721
step: 121, train loss: nan, train acuracy: 0.111328125
step: 121, val loss: nan, val acuracy: 0.10400000214576721
step: 122, train loss: nan, train acuracy: 0.09375
step: 122, val loss: nan, val acuracy: 0.10400000214576721
step: 123, train loss: nan, train acuracy: 0.076171875
step: 123, val loss: nan, val acuracy: 0.10400000214576721
step: 124, train loss: nan, train acuracy: 0.11328125
step: 124, val loss: nan, val acuracy: 0.10400000214576721
step: 125, train loss: nan, train acuracy: 0.08984375
step: 125, val loss: nan, val acuracy: 0.10400000214576721
step: 126, train loss: nan, train acuracy: 0.083984375
step: 126, val loss: nan, val acuracy: 0.10400000214576721
step: 127, train loss: nan, train acuracy: 0.0859375
step: 127, val loss: nan, val acuracy: 0.10400000214576721
step: 128, train loss: nan, train acuracy: 0.076171875
step: 128, val loss: nan, val acuracy: 0.10400000214576721
step: 129, train loss: nan, train acuracy: 0.115234375
step: 129, val loss: nan, val acuracy: 0.10400000214576721
step: 130, train loss: nan, train acuracy: 0.0703125
step: 130, val loss: nan, val acuracy: 0.10400000214576721
step: 131, train loss: nan, train acuracy: 0.109375
step: 131, val loss: nan, val acuracy: 0.10400000214576721
step: 132, train loss: nan, train acuracy: 0.087890625
step: 132, val loss: nan, val acuracy: 0.10400000214576721
step: 133, train loss: nan, train acuracy: 0.103515625
step: 133, val loss: nan, val acuracy: 0.10400000214576721
step: 134, train loss: nan, train acuracy: 0.11328125
step: 134, val loss: nan, val acuracy: 0.10400000214576721
step: 135, train loss: nan, train acuracy: 0.095703125
step: 135, val loss: nan, val acuracy: 0.10400000214576721
step: 136, train loss: nan, train acuracy: 0.078125
step: 136, val loss: nan, val acuracy: 0.10400000214576721
step: 137, train loss: nan, train acuracy: 0.107421875
step: 137, val loss: nan, val acuracy: 0.10400000214576721
step: 138, train loss: nan, train acuracy: 0.099609375
step: 138, val loss: nan, val acuracy: 0.10400000214576721
step: 139, train loss: nan, train acuracy: 0.091796875
step: 139, val loss: nan, val acuracy: 0.10400000214576721
step: 140, train loss: nan, train acuracy: 0.076171875
step: 140, val loss: nan, val acuracy: 0.10400000959634781
step: 141, train loss: nan, train acuracy: 0.09375
step: 141, val loss: nan, val acuracy: 0.10400000214576721
step: 142, train loss: nan, train acuracy: 0.1171875
step: 142, val loss: nan, val acuracy: 0.10400000214576721
step: 143, train loss: nan, train acuracy: 0.09375
step: 143, val loss: nan, val acuracy: 0.10400000214576721
step: 144, train loss: nan, train acuracy: 0.08203125
step: 144, val loss: nan, val acuracy: 0.10400000214576721
step: 145, train loss: nan, train acuracy: 0.091796875
step: 145, val loss: nan, val acuracy: 0.10400000214576721
step: 146, train loss: nan, train acuracy: 0.109375
step: 146, val loss: nan, val acuracy: 0.10400000214576721
step: 147, train loss: nan, train acuracy: 0.12109375
step: 147, val loss: nan, val acuracy: 0.10400000214576721
step: 148, train loss: nan, train acuracy: 0.078125
step: 148, val loss: nan, val acuracy: 0.10400000214576721
step: 149, train loss: nan, train acuracy: 0.1015625
step: 149, val loss: nan, val acuracy: 0.10400000214576721
step: 150, train loss: nan, train acuracy: 0.109375
step: 150, val loss: nan, val acuracy: 0.10400000214576721
step: 151, train loss: nan, train acuracy: 0.09765625
step: 151, val loss: nan, val acuracy: 0.10400000214576721
step: 152, train loss: nan, train acuracy: 0.103515625
step: 152, val loss: nan, val acuracy: 0.10400000214576721
step: 153, train loss: nan, train acuracy: 0.1015625
step: 153, val loss: nan, val acuracy: 0.10400000214576721
step: 154, train loss: nan, train acuracy: 0.099609375
step: 154, val loss: nan, val acuracy: 0.10400000214576721
step: 155, train loss: nan, train acuracy: 0.109375
step: 155, val loss: nan, val acuracy: 0.10400000214576721
step: 156, train loss: nan, train acuracy: 0.099609375
step: 156, val loss: nan, val acuracy: 0.10400000214576721
step: 157, train loss: nan, train acuracy: 0.064453125
step: 157, val loss: nan, val acuracy: 0.10400000214576721
step: 158, train loss: nan, train acuracy: 0.078125
step: 158, val loss: nan, val acuracy: 0.10400000214576721
step: 159, train loss: nan, train acuracy: 0.119140625
step: 159, val loss: nan, val acuracy: 0.10400000214576721
step: 160, train loss: nan, train acuracy: 0.12109375
step: 160, val loss: nan, val acuracy: 0.10400000214576721
step: 161, train loss: nan, train acuracy: 0.09375
step: 161, val loss: nan, val acuracy: 0.10400000214576721
step: 162, train loss: nan, train acuracy: 0.107421875
step: 162, val loss: nan, val acuracy: 0.10400000214576721
step: 163, train loss: nan, train acuracy: 0.109375
step: 163, val loss: nan, val acuracy: 0.10400000214576721
step: 164, train loss: nan, train acuracy: 0.0859375
step: 164, val loss: nan, val acuracy: 0.10400000214576721
step: 165, train loss: nan, train acuracy: 0.107421875
step: 165, val loss: nan, val acuracy: 0.10400000214576721
step: 166, train loss: nan, train acuracy: 0.107421875
step: 166, val loss: nan, val acuracy: 0.10400000214576721
step: 167, train loss: nan, train acuracy: 0.078125
step: 167, val loss: nan, val acuracy: 0.10400000214576721
step: 168, train loss: nan, train acuracy: 0.119140625
step: 168, val loss: nan, val acuracy: 0.10400000214576721
step: 169, train loss: nan, train acuracy: 0.09765625
step: 169, val loss: nan, val acuracy: 0.10400000214576721
step: 170, train loss: nan, train acuracy: 0.103515625
step: 170, val loss: nan, val acuracy: 0.10400000214576721
step: 171, train loss: nan, train acuracy: 0.083984375
step: 171, val loss: nan, val acuracy: 0.10400000214576721
step: 172, train loss: nan, train acuracy: 0.107421875
step: 172, val loss: nan, val acuracy: 0.10400000214576721
step: 173, train loss: nan, train acuracy: 0.09375
step: 173, val loss: nan, val acuracy: 0.10400000214576721
step: 174, train loss: nan, train acuracy: 0.111328125
step: 174, val loss: nan, val acuracy: 0.10400000214576721
step: 175, train loss: nan, train acuracy: 0.078125
step: 175, val loss: nan, val acuracy: 0.10400000214576721
step: 176, train loss: nan, train acuracy: 0.095703125
step: 176, val loss: nan, val acuracy: 0.10400000214576721
step: 177, train loss: nan, train acuracy: 0.080078125
step: 177, val loss: nan, val acuracy: 0.10400000214576721
step: 178, train loss: nan, train acuracy: 0.08203125
step: 178, val loss: nan, val acuracy: 0.10400000214576721
step: 179, train loss: nan, train acuracy: 0.095703125
step: 179, val loss: nan, val acuracy: 0.10400000214576721
step: 180, train loss: nan, train acuracy: 0.10546875
step: 180, val loss: nan, val acuracy: 0.10400000214576721
step: 181, train loss: nan, train acuracy: 0.107421875
step: 181, val loss: nan, val acuracy: 0.10400000214576721
step: 182, train loss: nan, train acuracy: 0.083984375
step: 182, val loss: nan, val acuracy: 0.10400000214576721
step: 183, train loss: nan, train acuracy: 0.109375
step: 183, val loss: nan, val acuracy: 0.10400000214576721
step: 184, train loss: nan, train acuracy: 0.115234375
step: 184, val loss: nan, val acuracy: 0.10400000214576721
step: 185, train loss: nan, train acuracy: 0.1015625
step: 185, val loss: nan, val acuracy: 0.10400000214576721
step: 186, train loss: nan, train acuracy: 0.107421875
step: 186, val loss: nan, val acuracy: 0.10400000214576721
step: 187, train loss: nan, train acuracy: 0.09765625
step: 187, val loss: nan, val acuracy: 0.10400000214576721
step: 188, train loss: nan, train acuracy: 0.111328125
step: 188, val loss: nan, val acuracy: 0.10400000214576721
step: 189, train loss: nan, train acuracy: 0.1015625
step: 189, val loss: nan, val acuracy: 0.10400000214576721
step: 190, train loss: nan, train acuracy: 0.072265625
step: 190, val loss: nan, val acuracy: 0.10400000214576721
step: 191, train loss: nan, train acuracy: 0.109375
step: 191, val loss: nan, val acuracy: 0.10400000214576721
step: 192, train loss: nan, train acuracy: 0.08984375
step: 192, val loss: nan, val acuracy: 0.10400000214576721
step: 193, train loss: nan, train acuracy: 0.099609375
step: 193, val loss: nan, val acuracy: 0.10400000214576721
step: 194, train loss: nan, train acuracy: 0.099609375
step: 194, val loss: nan, val acuracy: 0.10400000214576721
step: 195, train loss: nan, train acuracy: 0.087890625
step: 195, val loss: nan, val acuracy: 0.10400000214576721
step: 196, train loss: nan, train acuracy: 0.103515625
step: 196, val loss: nan, val acuracy: 0.10400000214576721
step: 197, train loss: nan, train acuracy: 0.095703125
step: 197, val loss: nan, val acuracy: 0.10400000214576721
step: 198, train loss: nan, train acuracy: 0.080078125
step: 198, val loss: nan, val acuracy: 0.10400000214576721
step: 199, train loss: nan, train acuracy: 0.109375
step: 199, val loss: nan, val acuracy: 0.10400000214576721
step: 200, train loss: nan, train acuracy: 0.095703125
step: 200, val loss: nan, val acuracy: 0.10400000214576721
step: 201, train loss: nan, train acuracy: 0.111328125
step: 201, val loss: nan, val acuracy: 0.10400000214576721
step: 202, train loss: nan, train acuracy: 0.087890625
step: 202, val loss: nan, val acuracy: 0.10400000214576721
step: 203, train loss: nan, train acuracy: 0.12109375
step: 203, val loss: nan, val acuracy: 0.10400000214576721
step: 204, train loss: nan, train acuracy: 0.095703125
step: 204, val loss: nan, val acuracy: 0.10400000214576721
step: 205, train loss: nan, train acuracy: 0.10546875
step: 205, val loss: nan, val acuracy: 0.10400000214576721
step: 206, train loss: nan, train acuracy: 0.080078125
step: 206, val loss: nan, val acuracy: 0.10400000214576721
step: 207, train loss: nan, train acuracy: 0.123046875
step: 207, val loss: nan, val acuracy: 0.10400000214576721
step: 208, train loss: nan, train acuracy: 0.1171875
step: 208, val loss: nan, val acuracy: 0.10400000214576721
step: 209, train loss: nan, train acuracy: 0.103515625
step: 209, val loss: nan, val acuracy: 0.10400000214576721
step: 210, train loss: nan, train acuracy: 0.11328125
step: 210, val loss: nan, val acuracy: 0.10400000214576721
step: 211, train loss: nan, train acuracy: 0.076171875
step: 211, val loss: nan, val acuracy: 0.10400000214576721
step: 212, train loss: nan, train acuracy: 0.107421875
step: 212, val loss: nan, val acuracy: 0.10400000214576721
step: 213, train loss: nan, train acuracy: 0.09765625
step: 213, val loss: nan, val acuracy: 0.10400000214576721
step: 214, train loss: nan, train acuracy: 0.080078125
step: 214, val loss: nan, val acuracy: 0.10400000214576721
step: 215, train loss: nan, train acuracy: 0.087890625
step: 215, val loss: nan, val acuracy: 0.10400000214576721
step: 216, train loss: nan, train acuracy: 0.087890625
step: 216, val loss: nan, val acuracy: 0.10400000214576721
step: 217, train loss: nan, train acuracy: 0.111328125
step: 217, val loss: nan, val acuracy: 0.10400000214576721
step: 218, train loss: nan, train acuracy: 0.09375
step: 218, val loss: nan, val acuracy: 0.10400000214576721
step: 219, train loss: nan, train acuracy: 0.109375
step: 219, val loss: nan, val acuracy: 0.10400000214576721
step: 220, train loss: nan, train acuracy: 0.09375
step: 220, val loss: nan, val acuracy: 0.10400000214576721
step: 221, train loss: nan, train acuracy: 0.099609375
step: 221, val loss: nan, val acuracy: 0.10400000214576721
step: 222, train loss: nan, train acuracy: 0.109375
step: 222, val loss: nan, val acuracy: 0.10400000214576721
step: 223, train loss: nan, train acuracy: 0.115234375
step: 223, val loss: nan, val acuracy: 0.10400000214576721
step: 224, train loss: nan, train acuracy: 0.1015625
step: 224, val loss: nan, val acuracy: 0.10400000214576721
step: 225, train loss: nan, train acuracy: 0.0859375
step: 225, val loss: nan, val acuracy: 0.10400000214576721
step: 226, train loss: nan, train acuracy: 0.111328125
step: 226, val loss: nan, val acuracy: 0.10400000214576721
step: 227, train loss: nan, train acuracy: 0.09375
step: 227, val loss: nan, val acuracy: 0.10400000214576721
step: 228, train loss: nan, train acuracy: 0.076171875
step: 228, val loss: nan, val acuracy: 0.10400000214576721
step: 229, train loss: nan, train acuracy: 0.11328125
step: 229, val loss: nan, val acuracy: 0.10400000214576721
step: 230, train loss: nan, train acuracy: 0.08984375
step: 230, val loss: nan, val acuracy: 0.10400000214576721
step: 231, train loss: nan, train acuracy: 0.083984375
step: 231, val loss: nan, val acuracy: 0.10400000214576721
step: 232, train loss: nan, train acuracy: 0.0859375
step: 232, val loss: nan, val acuracy: 0.10400000214576721
step: 233, train loss: nan, train acuracy: 0.076171875
step: 233, val loss: nan, val acuracy: 0.10400000214576721
step: 234, train loss: nan, train acuracy: 0.115234375
step: 234, val loss: nan, val acuracy: 0.10400000214576721
step: 235, train loss: nan, train acuracy: 0.0703125
step: 235, val loss: nan, val acuracy: 0.10400000214576721
step: 236, train loss: nan, train acuracy: 0.109375
step: 236, val loss: nan, val acuracy: 0.10400000214576721
step: 237, train loss: nan, train acuracy: 0.087890625
step: 237, val loss: nan, val acuracy: 0.10400000214576721
step: 238, train loss: nan, train acuracy: 0.103515625
step: 238, val loss: nan, val acuracy: 0.10400000214576721
step: 239, train loss: nan, train acuracy: 0.11328125
step: 239, val loss: nan, val acuracy: 0.10400000214576721
step: 240, train loss: nan, train acuracy: 0.095703125
step: 240, val loss: nan, val acuracy: 0.10400000214576721
step: 241, train loss: nan, train acuracy: 0.078125
step: 241, val loss: nan, val acuracy: 0.10400000214576721
step: 242, train loss: nan, train acuracy: 0.107421875
step: 242, val loss: nan, val acuracy: 0.10400000214576721
step: 243, train loss: nan, train acuracy: 0.099609375
step: 243, val loss: nan, val acuracy: 0.10400000214576721
step: 244, train loss: nan, train acuracy: 0.091796875
step: 244, val loss: nan, val acuracy: 0.10400000214576721
step: 245, train loss: nan, train acuracy: 0.076171875
step: 245, val loss: nan, val acuracy: 0.10400000214576721
step: 246, train loss: nan, train acuracy: 0.09375
step: 246, val loss: nan, val acuracy: 0.10400000214576721
step: 247, train loss: nan, train acuracy: 0.1171875
step: 247, val loss: nan, val acuracy: 0.10400000214576721
step: 248, train loss: nan, train acuracy: 0.09375
step: 248, val loss: nan, val acuracy: 0.10400000214576721
step: 249, train loss: nan, train acuracy: 0.08203125
step: 249, val loss: nan, val acuracy: 0.10400000214576721
step: 250, train loss: nan, train acuracy: 0.091796875
step: 250, val loss: nan, val acuracy: 0.10400000214576721
step: 251, train loss: nan, train acuracy: 0.109375
step: 251, val loss: nan, val acuracy: 0.10400000214576721
step: 252, train loss: nan, train acuracy: 0.12109375
step: 252, val loss: nan, val acuracy: 0.10400000214576721
step: 253, train loss: nan, train acuracy: 0.078125
step: 253, val loss: nan, val acuracy: 0.10400000214576721
step: 254, train loss: nan, train acuracy: 0.1015625
step: 254, val loss: nan, val acuracy: 0.10400000214576721
step: 255, train loss: nan, train acuracy: 0.109375
step: 255, val loss: nan, val acuracy: 0.10400000214576721
step: 256, train loss: nan, train acuracy: 0.09765625
step: 256, val loss: nan, val acuracy: 0.10400000214576721
step: 257, train loss: nan, train acuracy: 0.103515625
step: 257, val loss: nan, val acuracy: 0.10400000214576721
step: 258, train loss: nan, train acuracy: 0.1015625
step: 258, val loss: nan, val acuracy: 0.10400000214576721
step: 259, train loss: nan, train acuracy: 0.099609375
step: 259, val loss: nan, val acuracy: 0.10400000214576721
step: 260, train loss: nan, train acuracy: 0.109375
step: 260, val loss: nan, val acuracy: 0.10400000214576721
step: 261, train loss: nan, train acuracy: 0.099609375
step: 261, val loss: nan, val acuracy: 0.10400000214576721
step: 262, train loss: nan, train acuracy: 0.064453125
step: 262, val loss: nan, val acuracy: 0.10400000214576721
step: 263, train loss: nan, train acuracy: 0.078125
step: 263, val loss: nan, val acuracy: 0.10400000214576721
step: 264, train loss: nan, train acuracy: 0.119140625
step: 264, val loss: nan, val acuracy: 0.10400000214576721
step: 265, train loss: nan, train acuracy: 0.12109375
step: 265, val loss: nan, val acuracy: 0.10400000214576721
step: 266, train loss: nan, train acuracy: 0.09375
step: 266, val loss: nan, val acuracy: 0.10400000214576721
step: 267, train loss: nan, train acuracy: 0.107421875
step: 267, val loss: nan, val acuracy: 0.10400000959634781
step: 268, train loss: nan, train acuracy: 0.109375
step: 268, val loss: nan, val acuracy: 0.10400000214576721
step: 269, train loss: nan, train acuracy: 0.0859375
step: 269, val loss: nan, val acuracy: 0.10400000214576721
step: 270, train loss: nan, train acuracy: 0.107421875
step: 270, val loss: nan, val acuracy: 0.10400000214576721
step: 271, train loss: nan, train acuracy: 0.107421875
step: 271, val loss: nan, val acuracy: 0.10400000214576721
step: 272, train loss: nan, train acuracy: 0.078125
step: 272, val loss: nan, val acuracy: 0.10400000214576721
step: 273, train loss: nan, train acuracy: 0.119140625
step: 273, val loss: nan, val acuracy: 0.10400000214576721
step: 274, train loss: nan, train acuracy: 0.09765625
step: 274, val loss: nan, val acuracy: 0.10400000214576721
step: 275, train loss: nan, train acuracy: 0.103515625
step: 275, val loss: nan, val acuracy: 0.10400000214576721
step: 276, train loss: nan, train acuracy: 0.083984375
step: 276, val loss: nan, val acuracy: 0.10400000214576721
step: 277, train loss: nan, train acuracy: 0.107421875
step: 277, val loss: nan, val acuracy: 0.10400000214576721
step: 278, train loss: nan, train acuracy: 0.09375
step: 278, val loss: nan, val acuracy: 0.10400000214576721
step: 279, train loss: nan, train acuracy: 0.111328125
step: 279, val loss: nan, val acuracy: 0.10400000214576721
step: 280, train loss: nan, train acuracy: 0.078125
step: 280, val loss: nan, val acuracy: 0.10400000214576721
step: 281, train loss: nan, train acuracy: 0.095703125
step: 281, val loss: nan, val acuracy: 0.10400000214576721
step: 282, train loss: nan, train acuracy: 0.080078125
step: 282, val loss: nan, val acuracy: 0.10400000214576721
step: 283, train loss: nan, train acuracy: 0.08203125
step: 283, val loss: nan, val acuracy: 0.10400000214576721
step: 284, train loss: nan, train acuracy: 0.095703125
step: 284, val loss: nan, val acuracy: 0.10400000214576721
step: 285, train loss: nan, train acuracy: 0.10546875
step: 285, val loss: nan, val acuracy: 0.10400000214576721
step: 286, train loss: nan, train acuracy: 0.107421875
step: 286, val loss: nan, val acuracy: 0.10400000214576721
step: 287, train loss: nan, train acuracy: 0.083984375
step: 287, val loss: nan, val acuracy: 0.10400000214576721
step: 288, train loss: nan, train acuracy: 0.109375
step: 288, val loss: nan, val acuracy: 0.10400000214576721
step: 289, train loss: nan, train acuracy: 0.115234375
step: 289, val loss: nan, val acuracy: 0.10400000214576721
step: 290, train loss: nan, train acuracy: 0.1015625
step: 290, val loss: nan, val acuracy: 0.10400000214576721
step: 291, train loss: nan, train acuracy: 0.107421875
step: 291, val loss: nan, val acuracy: 0.10400000214576721
step: 292, train loss: nan, train acuracy: 0.09765625
step: 292, val loss: nan, val acuracy: 0.10400000214576721
step: 293, train loss: nan, train acuracy: 0.111328125
step: 293, val loss: nan, val acuracy: 0.10400000214576721
step: 294, train loss: nan, train acuracy: 0.1015625
step: 294, val loss: nan, val acuracy: 0.10400000214576721
step: 295, train loss: nan, train acuracy: 0.072265625
step: 295, val loss: nan, val acuracy: 0.10400000214576721
step: 296, train loss: nan, train acuracy: 0.109375
step: 296, val loss: nan, val acuracy: 0.10400000214576721
step: 297, train loss: nan, train acuracy: 0.08984375
step: 297, val loss: nan, val acuracy: 0.10400000214576721
step: 298, train loss: nan, train acuracy: 0.099609375
step: 298, val loss: nan, val acuracy: 0.10400000214576721
step: 299, train loss: nan, train acuracy: 0.099609375
step: 299, val loss: nan, val acuracy: 0.10400000214576721
step: 300, train loss: nan, train acuracy: 0.087890625
step: 300, val loss: nan, val acuracy: 0.10400000214576721
step: 301, train loss: nan, train acuracy: 0.103515625
step: 301, val loss: nan, val acuracy: 0.10400000214576721
step: 302, train loss: nan, train acuracy: 0.095703125
step: 302, val loss: nan, val acuracy: 0.10400000214576721
step: 303, train loss: nan, train acuracy: 0.080078125
step: 303, val loss: nan, val acuracy: 0.10400000214576721
step: 304, train loss: nan, train acuracy: 0.109375
step: 304, val loss: nan, val acuracy: 0.10400000214576721
step: 305, train loss: nan, train acuracy: 0.095703125
step: 305, val loss: nan, val acuracy: 0.10400000214576721
step: 306, train loss: nan, train acuracy: 0.111328125
step: 306, val loss: nan, val acuracy: 0.10400000214576721
step: 307, train loss: nan, train acuracy: 0.087890625
step: 307, val loss: nan, val acuracy: 0.10400000214576721
step: 308, train loss: nan, train acuracy: 0.12109375
step: 308, val loss: nan, val acuracy: 0.10400000214576721
step: 309, train loss: nan, train acuracy: 0.095703125
step: 309, val loss: nan, val acuracy: 0.10400000214576721
step: 310, train loss: nan, train acuracy: 0.10546875
step: 310, val loss: nan, val acuracy: 0.10400000214576721
step: 311, train loss: nan, train acuracy: 0.080078125
step: 311, val loss: nan, val acuracy: 0.10400000214576721
step: 312, train loss: nan, train acuracy: 0.123046875
step: 312, val loss: nan, val acuracy: 0.10400000214576721
step: 313, train loss: nan, train acuracy: 0.1171875
step: 313, val loss: nan, val acuracy: 0.10400000214576721
step: 314, train loss: nan, train acuracy: 0.103515625
step: 314, val loss: nan, val acuracy: 0.10400000214576721
step: 315, train loss: nan, train acuracy: 0.11328125
step: 315, val loss: nan, val acuracy: 0.10400000214576721
step: 316, train loss: nan, train acuracy: 0.076171875
step: 316, val loss: nan, val acuracy: 0.10400000214576721
step: 317, train loss: nan, train acuracy: 0.107421875
step: 317, val loss: nan, val acuracy: 0.10400000214576721
step: 318, train loss: nan, train acuracy: 0.09765625
step: 318, val loss: nan, val acuracy: 0.10400000214576721
step: 319, train loss: nan, train acuracy: 0.080078125
step: 319, val loss: nan, val acuracy: 0.10400000214576721
step: 320, train loss: nan, train acuracy: 0.087890625
step: 320, val loss: nan, val acuracy: 0.10400000214576721
step: 321, train loss: nan, train acuracy: 0.087890625
step: 321, val loss: nan, val acuracy: 0.10400000214576721
step: 322, train loss: nan, train acuracy: 0.111328125
step: 322, val loss: nan, val acuracy: 0.10400000214576721
step: 323, train loss: nan, train acuracy: 0.09375
step: 323, val loss: nan, val acuracy: 0.10400000214576721
step: 324, train loss: nan, train acuracy: 0.109375
step: 324, val loss: nan, val acuracy: 0.10400000214576721
step: 325, train loss: nan, train acuracy: 0.09375
step: 325, val loss: nan, val acuracy: 0.10400000214576721
step: 326, train loss: nan, train acuracy: 0.099609375
step: 326, val loss: nan, val acuracy: 0.10400000214576721
step: 327, train loss: nan, train acuracy: 0.109375
step: 327, val loss: nan, val acuracy: 0.10400000214576721
step: 328, train loss: nan, train acuracy: 0.115234375
step: 328, val loss: nan, val acuracy: 0.10400000214576721
step: 329, train loss: nan, train acuracy: 0.1015625
step: 329, val loss: nan, val acuracy: 0.10400000214576721
step: 330, train loss: nan, train acuracy: 0.0859375
step: 330, val loss: nan, val acuracy: 0.10400000959634781
step: 331, train loss: nan, train acuracy: 0.111328125
step: 331, val loss: nan, val acuracy: 0.10400000214576721
step: 332, train loss: nan, train acuracy: 0.09375
step: 332, val loss: nan, val acuracy: 0.10400000214576721
step: 333, train loss: nan, train acuracy: 0.076171875
step: 333, val loss: nan, val acuracy: 0.10400000214576721
step: 334, train loss: nan, train acuracy: 0.11328125
step: 334, val loss: nan, val acuracy: 0.10400000214576721
step: 335, train loss: nan, train acuracy: 0.08984375
step: 335, val loss: nan, val acuracy: 0.10400000214576721
step: 336, train loss: nan, train acuracy: 0.083984375
step: 336, val loss: nan, val acuracy: 0.10400000214576721
step: 337, train loss: nan, train acuracy: 0.0859375
step: 337, val loss: nan, val acuracy: 0.10400000214576721
step: 338, train loss: nan, train acuracy: 0.076171875
step: 338, val loss: nan, val acuracy: 0.10400000214576721
step: 339, train loss: nan, train acuracy: 0.115234375
step: 339, val loss: nan, val acuracy: 0.10400000214576721
step: 340, train loss: nan, train acuracy: 0.0703125
step: 340, val loss: nan, val acuracy: 0.10400000214576721
step: 341, train loss: nan, train acuracy: 0.109375
step: 341, val loss: nan, val acuracy: 0.10400000214576721
step: 342, train loss: nan, train acuracy: 0.087890625
step: 342, val loss: nan, val acuracy: 0.10400000214576721
step: 343, train loss: nan, train acuracy: 0.103515625
step: 343, val loss: nan, val acuracy: 0.10400000214576721
step: 344, train loss: nan, train acuracy: 0.11328125
step: 344, val loss: nan, val acuracy: 0.10400000214576721
step: 345, train loss: nan, train acuracy: 0.095703125
step: 345, val loss: nan, val acuracy: 0.10400000214576721
step: 346, train loss: nan, train acuracy: 0.078125
step: 346, val loss: nan, val acuracy: 0.10400000214576721
step: 347, train loss: nan, train acuracy: 0.107421875
step: 347, val loss: nan, val acuracy: 0.10400000214576721
step: 348, train loss: nan, train acuracy: 0.099609375
step: 348, val loss: nan, val acuracy: 0.10400000214576721
step: 349, train loss: nan, train acuracy: 0.091796875
step: 349, val loss: nan, val acuracy: 0.10400000214576721
step: 350, train loss: nan, train acuracy: 0.076171875
step: 350, val loss: nan, val acuracy: 0.10400000214576721
step: 351, train loss: nan, train acuracy: 0.09375
step: 351, val loss: nan, val acuracy: 0.10400000214576721
step: 352, train loss: nan, train acuracy: 0.1171875
step: 352, val loss: nan, val acuracy: 0.10400000214576721
step: 353, train loss: nan, train acuracy: 0.09375
step: 353, val loss: nan, val acuracy: 0.10400000214576721
step: 354, train loss: nan, train acuracy: 0.08203125
step: 354, val loss: nan, val acuracy: 0.10400000214576721
step: 355, train loss: nan, train acuracy: 0.091796875
step: 355, val loss: nan, val acuracy: 0.10400000214576721
step: 356, train loss: nan, train acuracy: 0.109375
step: 356, val loss: nan, val acuracy: 0.10400000214576721
step: 357, train loss: nan, train acuracy: 0.12109375
step: 357, val loss: nan, val acuracy: 0.10400000214576721
step: 358, train loss: nan, train acuracy: 0.078125
step: 358, val loss: nan, val acuracy: 0.10400000214576721
step: 359, train loss: nan, train acuracy: 0.1015625
step: 359, val loss: nan, val acuracy: 0.10400000214576721
step: 360, train loss: nan, train acuracy: 0.109375
step: 360, val loss: nan, val acuracy: 0.10400000214576721
step: 361, train loss: nan, train acuracy: 0.09765625
step: 361, val loss: nan, val acuracy: 0.10400000214576721
step: 362, train loss: nan, train acuracy: 0.103515625
step: 362, val loss: nan, val acuracy: 0.10400000214576721
step: 363, train loss: nan, train acuracy: 0.1015625
step: 363, val loss: nan, val acuracy: 0.10400000214576721
step: 364, train loss: nan, train acuracy: 0.099609375
step: 364, val loss: nan, val acuracy: 0.10400000214576721
step: 365, train loss: nan, train acuracy: 0.109375
step: 365, val loss: nan, val acuracy: 0.10400000214576721
step: 366, train loss: nan, train acuracy: 0.099609375
step: 366, val loss: nan, val acuracy: 0.10400000214576721
step: 367, train loss: nan, train acuracy: 0.064453125
step: 367, val loss: nan, val acuracy: 0.10400000214576721
step: 368, train loss: nan, train acuracy: 0.078125
step: 368, val loss: nan, val acuracy: 0.10400000214576721
step: 369, train loss: nan, train acuracy: 0.119140625
step: 369, val loss: nan, val acuracy: 0.10400000214576721
step: 370, train loss: nan, train acuracy: 0.12109375
step: 370, val loss: nan, val acuracy: 0.10400000214576721
step: 371, train loss: nan, train acuracy: 0.09375
step: 371, val loss: nan, val acuracy: 0.10400000214576721
step: 372, train loss: nan, train acuracy: 0.107421875
step: 372, val loss: nan, val acuracy: 0.10400000214576721
step: 373, train loss: nan, train acuracy: 0.109375
step: 373, val loss: nan, val acuracy: 0.10400000214576721
step: 374, train loss: nan, train acuracy: 0.0859375
step: 374, val loss: nan, val acuracy: 0.10400000214576721
step: 375, train loss: nan, train acuracy: 0.107421875
step: 375, val loss: nan, val acuracy: 0.10400000214576721
step: 376, train loss: nan, train acuracy: 0.107421875
step: 376, val loss: nan, val acuracy: 0.10400000214576721
step: 377, train loss: nan, train acuracy: 0.078125
step: 377, val loss: nan, val acuracy: 0.10400000214576721
step: 378, train loss: nan, train acuracy: 0.119140625
step: 378, val loss: nan, val acuracy: 0.10400000214576721
step: 379, train loss: nan, train acuracy: 0.09765625
step: 379, val loss: nan, val acuracy: 0.10400000214576721
step: 380, train loss: nan, train acuracy: 0.103515625
step: 380, val loss: nan, val acuracy: 0.10400000214576721
step: 381, train loss: nan, train acuracy: 0.083984375
step: 381, val loss: nan, val acuracy: 0.10400000214576721
step: 382, train loss: nan, train acuracy: 0.107421875
step: 382, val loss: nan, val acuracy: 0.10400000214576721
step: 383, train loss: nan, train acuracy: 0.09375
step: 383, val loss: nan, val acuracy: 0.10400000214576721
step: 384, train loss: nan, train acuracy: 0.111328125
step: 384, val loss: nan, val acuracy: 0.10400000214576721
step: 385, train loss: nan, train acuracy: 0.078125
step: 385, val loss: nan, val acuracy: 0.10400000214576721
step: 386, train loss: nan, train acuracy: 0.095703125
step: 386, val loss: nan, val acuracy: 0.10400000214576721
step: 387, train loss: nan, train acuracy: 0.080078125
step: 387, val loss: nan, val acuracy: 0.10400000214576721
step: 388, train loss: nan, train acuracy: 0.08203125
step: 388, val loss: nan, val acuracy: 0.10400000214576721
step: 389, train loss: nan, train acuracy: 0.095703125
step: 389, val loss: nan, val acuracy: 0.10400000214576721
step: 390, train loss: nan, train acuracy: 0.10546875
step: 390, val loss: nan, val acuracy: 0.10400000214576721
step: 391, train loss: nan, train acuracy: 0.107421875
step: 391, val loss: nan, val acuracy: 0.10400000214576721
step: 392, train loss: nan, train acuracy: 0.083984375
step: 392, val loss: nan, val acuracy: 0.10400000214576721
step: 393, train loss: nan, train acuracy: 0.109375
step: 393, val loss: nan, val acuracy: 0.10400000214576721
step: 394, train loss: nan, train acuracy: 0.115234375
step: 394, val loss: nan, val acuracy: 0.10400000214576721
step: 395, train loss: nan, train acuracy: 0.1015625
step: 395, val loss: nan, val acuracy: 0.10400000214576721
step: 396, train loss: nan, train acuracy: 0.107421875
step: 396, val loss: nan, val acuracy: 0.10400000214576721
step: 397, train loss: nan, train acuracy: 0.09765625
step: 397, val loss: nan, val acuracy: 0.10400000214576721
step: 398, train loss: nan, train acuracy: 0.111328125
step: 398, val loss: nan, val acuracy: 0.10400000214576721
step: 399, train loss: nan, train acuracy: 0.1015625
step: 399, val loss: nan, val acuracy: 0.10400000214576721
2017-12-04 15:13:20.055747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:13:20.328686: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x59fb930 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 15:13:20.329459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:13:20.329730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 15:13:20.329746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 15:13:20.329752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 15:13:20.329765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 15:13:20.329773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.3484344482421875, train acuracy: 0.11328125
step: 0, val loss: 2.3801777362823486, val acuracy: 0.10700000077486038
step: 1, train loss: 2.362290143966675, train acuracy: 0.107421875
step: 1, val loss: 2.3602139949798584, val acuracy: 0.1066666692495346
step: 2, train loss: 2.360578775405884, train acuracy: 0.115234375
step: 2, val loss: 2.361713409423828, val acuracy: 0.1066666692495346
step: 3, train loss: 2.3539016246795654, train acuracy: 0.1181640625
step: 3, val loss: 2.356619358062744, val acuracy: 0.11299999803304672
step: 4, train loss: 2.3353946208953857, train acuracy: 0.1220703125
step: 4, val loss: 2.3574838638305664, val acuracy: 0.11499998718500137
step: 5, train loss: 2.3559088706970215, train acuracy: 0.1201171875
step: 5, val loss: 2.355738878250122, val acuracy: 0.12266667187213898
step: 6, train loss: 42.82673263549805, train acuracy: 0.109375
step: 6, val loss: 43.61323547363281, val acuracy: 0.09533333778381348
step: 7, train loss: 4.861304759979248, train acuracy: 0.1298828125
step: 7, val loss: 4.915410041809082, val acuracy: 0.13750000298023224
step: 8, train loss: 2.408487558364868, train acuracy: 0.1103515625
step: 8, val loss: 2.4354679584503174, val acuracy: 0.09666666388511658
step: 9, train loss: 2.397329807281494, train acuracy: 0.1572265625
step: 9, val loss: 2.4224448204040527, val acuracy: 0.14783333241939545
step: 10, train loss: 2.342064619064331, train acuracy: 0.08984375
step: 10, val loss: 2.332280158996582, val acuracy: 0.09466667473316193
step: 11, train loss: 2.3163983821868896, train acuracy: 0.0947265625
step: 11, val loss: 2.3267269134521484, val acuracy: 0.09050000458955765
step: 12, train loss: 2.3308334350585938, train acuracy: 0.0947265625
step: 12, val loss: 2.327920913696289, val acuracy: 0.08349999785423279
step: 13, train loss: 2.3291873931884766, train acuracy: 0.07421875
step: 13, val loss: 2.3274707794189453, val acuracy: 0.08649998903274536
step: 14, train loss: 2.320699691772461, train acuracy: 0.10546875
step: 14, val loss: 2.3268954753875732, val acuracy: 0.09700000286102295
step: 15, train loss: 2.33247709274292, train acuracy: 0.0947265625
step: 15, val loss: 2.326854944229126, val acuracy: 0.10116666555404663
step: 16, train loss: 2.3076562881469727, train acuracy: 0.095703125
step: 16, val loss: 2.326791524887085, val acuracy: 0.10516665875911713
step: 17, train loss: 2.3341171741485596, train acuracy: 0.1171875
step: 17, val loss: 2.33569073677063, val acuracy: 0.11033332347869873
step: 18, train loss: 2.3250746726989746, train acuracy: 0.1357421875
step: 18, val loss: 2.328183650970459, val acuracy: 0.1278333216905594
step: 19, train loss: 3.0949366092681885, train acuracy: 0.107421875
step: 19, val loss: 3.121890068054199, val acuracy: 0.09533333778381348
step: 20, train loss: 2.59328031539917, train acuracy: 0.08203125
step: 20, val loss: 2.556565999984741, val acuracy: 0.08799999952316284
step: 21, train loss: 2.410738229751587, train acuracy: 0.1044921875
step: 21, val loss: 2.411914587020874, val acuracy: 0.09533333778381348
step: 22, train loss: 2.3090457916259766, train acuracy: 0.10546875
step: 22, val loss: 2.32759690284729, val acuracy: 0.10633333027362823
step: 23, train loss: 2.282165765762329, train acuracy: 0.22265625
step: 23, val loss: 2.287083864212036, val acuracy: 0.21049997210502625
step: 24, train loss: 2.242297649383545, train acuracy: 0.134765625
step: 24, val loss: 2.2570149898529053, val acuracy: 0.11783333122730255
step: 25, train loss: 2.1658735275268555, train acuracy: 0.2255859375
step: 25, val loss: 2.1713223457336426, val acuracy: 0.21783335506916046
step: 26, train loss: 2.1156487464904785, train acuracy: 0.33984375
step: 26, val loss: 2.0334911346435547, val acuracy: 0.36916667222976685
step: 27, train loss: 1.9627183675765991, train acuracy: 0.4541015625
step: 27, val loss: 2.128571033477783, val acuracy: 0.4281666576862335
step: 28, train loss: 2.0859758853912354, train acuracy: 0.4326171875
step: 28, val loss: 2.0500919818878174, val acuracy: 0.43550002574920654
step: 29, train loss: 2.085094928741455, train acuracy: 0.44140625
step: 29, val loss: 2.056908130645752, val acuracy: 0.43566668033599854
step: 30, train loss: 1.9575159549713135, train acuracy: 0.45703125
step: 30, val loss: 2.0541629791259766, val acuracy: 0.4363333582878113
step: 31, train loss: 2.0472428798675537, train acuracy: 0.4306640625
step: 31, val loss: 2.0536837577819824, val acuracy: 0.4348333477973938
step: 32, train loss: 2.050633668899536, train acuracy: 0.4228515625
step: 32, val loss: 2.0584893226623535, val acuracy: 0.4345000088214874
step: 33, train loss: 2.634335994720459, train acuracy: 0.3583984375
step: 33, val loss: 2.669735908508301, val acuracy: 0.35733333230018616
step: 34, train loss: 2.2164206504821777, train acuracy: 0.4306640625
step: 34, val loss: 2.2582108974456787, val acuracy: 0.4124999940395355
step: 35, train loss: 2.7226204872131348, train acuracy: 0.2724609375
step: 35, val loss: 2.5851593017578125, val acuracy: 0.2875000238418579
step: 36, train loss: 3.462920665740967, train acuracy: 0.16015625
step: 36, val loss: 3.5273776054382324, val acuracy: 0.16516666114330292
step: 37, train loss: 3.434051275253296, train acuracy: 0.2568359375
step: 37, val loss: 3.380103588104248, val acuracy: 0.25550001859664917
step: 38, train loss: 3.030630111694336, train acuracy: 0.1015625
step: 38, val loss: 3.0723447799682617, val acuracy: 0.11383333057165146
step: 39, train loss: 2.9569478034973145, train acuracy: 0.1083984375
step: 39, val loss: 3.0001254081726074, val acuracy: 0.1133333295583725
step: 40, train loss: 2.5439610481262207, train acuracy: 0.09375
step: 40, val loss: 2.5370607376098633, val acuracy: 0.09816665947437286
step: 41, train loss: 2.331796169281006, train acuracy: 0.1015625
step: 41, val loss: 2.3557448387145996, val acuracy: 0.09666666388511658
step: 42, train loss: 2.29935359954834, train acuracy: 0.1240234375
step: 42, val loss: 2.3080496788024902, val acuracy: 0.09333333373069763
step: 43, train loss: 2.304220676422119, train acuracy: 0.115234375
step: 43, val loss: 2.305694580078125, val acuracy: 0.10983332991600037
step: 44, train loss: 2.2995736598968506, train acuracy: 0.1171875
step: 44, val loss: 2.302941083908081, val acuracy: 0.10949999839067459
step: 45, train loss: 2.298251152038574, train acuracy: 0.1201171875
step: 45, val loss: 2.3031373023986816, val acuracy: 0.10949999839067459
step: 46, train loss: 2.29646635055542, train acuracy: 0.125
step: 46, val loss: 2.3062241077423096, val acuracy: 0.10916665941476822
step: 47, train loss: 2.29750919342041, train acuracy: 0.12109375
step: 47, val loss: 2.3052902221679688, val acuracy: 0.10916665941476822
step: 48, train loss: 2.2978384494781494, train acuracy: 0.123046875
step: 48, val loss: 2.303042411804199, val acuracy: 0.11033332347869873
step: 49, train loss: 2.294008493423462, train acuracy: 0.125
step: 49, val loss: 2.3049721717834473, val acuracy: 0.10899999737739563
step: 50, train loss: 2.3003110885620117, train acuracy: 0.1240234375
step: 50, val loss: 2.3033363819122314, val acuracy: 0.1054999977350235
step: 51, train loss: 2.2980589866638184, train acuracy: 0.12109375
step: 51, val loss: 2.302478075027466, val acuracy: 0.11216666549444199
step: 52, train loss: 2.297576665878296, train acuracy: 0.1220703125
step: 52, val loss: 2.3033952713012695, val acuracy: 0.10966666787862778
step: 53, train loss: 2.298947811126709, train acuracy: 0.119140625
step: 53, val loss: 2.302220582962036, val acuracy: 0.09566666185855865
step: 54, train loss: 2.2969062328338623, train acuracy: 0.1171875
step: 54, val loss: 2.3045029640197754, val acuracy: 0.11100000143051147
step: 55, train loss: 2.299917697906494, train acuracy: 0.1181640625
step: 55, val loss: 2.302349328994751, val acuracy: 0.1081666648387909
step: 56, train loss: 2.2989039421081543, train acuracy: 0.115234375
step: 56, val loss: 2.3026680946350098, val acuracy: 0.11016666889190674
step: 57, train loss: 2.3006298542022705, train acuracy: 0.1162109375
step: 57, val loss: 2.301987648010254, val acuracy: 0.1053333431482315
step: 58, train loss: 2.3002521991729736, train acuracy: 0.109375
step: 58, val loss: 2.302096366882324, val acuracy: 0.11049999296665192
step: 59, train loss: 2.30086612701416, train acuracy: 0.1083984375
step: 59, val loss: 2.302062511444092, val acuracy: 0.11033332347869873
step: 60, train loss: 2.2964470386505127, train acuracy: 0.1240234375
step: 60, val loss: 2.3027570247650146, val acuracy: 0.11033332347869873
step: 61, train loss: 2.299926280975342, train acuracy: 0.12109375
step: 61, val loss: 2.303483247756958, val acuracy: 0.10999999940395355
step: 62, train loss: 2.3034651279449463, train acuracy: 0.09375
step: 62, val loss: 2.3026046752929688, val acuracy: 0.11033332347869873
step: 63, train loss: 2.2973484992980957, train acuracy: 0.119140625
step: 63, val loss: 2.303837776184082, val acuracy: 0.11649999022483826
step: 64, train loss: 2.2983574867248535, train acuracy: 0.125
step: 64, val loss: 2.302447557449341, val acuracy: 0.11649999022483826
step: 65, train loss: 2.2976043224334717, train acuracy: 0.126953125
step: 65, val loss: 2.3019330501556396, val acuracy: 0.12316666543483734
step: 66, train loss: 2.291099786758423, train acuracy: 0.130859375
step: 66, val loss: 2.3002123832702637, val acuracy: 0.12966665625572205
step: 67, train loss: 2.2987191677093506, train acuracy: 0.140625
step: 67, val loss: 2.2998440265655518, val acuracy: 0.12933333218097687
step: 68, train loss: 2.295135498046875, train acuracy: 0.1455078125
step: 68, val loss: 2.2770962715148926, val acuracy: 0.1758333444595337
step: 69, train loss: 2.2674760818481445, train acuracy: 0.169921875
step: 69, val loss: 2.287715435028076, val acuracy: 0.1691666841506958
step: 70, train loss: 2.274522542953491, train acuracy: 0.1806640625
step: 70, val loss: 2.2800252437591553, val acuracy: 0.1706666648387909
step: 71, train loss: 2.27111554145813, train acuracy: 0.185546875
step: 71, val loss: 2.279632568359375, val acuracy: 0.1705000102519989
step: 72, train loss: 2.2684414386749268, train acuracy: 0.1826171875
step: 72, val loss: 2.2796106338500977, val acuracy: 0.17083334922790527
step: 73, train loss: 2.2810940742492676, train acuracy: 0.1630859375
step: 73, val loss: 2.280013084411621, val acuracy: 0.16483332216739655
step: 74, train loss: 2.2956929206848145, train acuracy: 0.13671875
step: 74, val loss: 2.2798848152160645, val acuracy: 0.16566665470600128
step: 75, train loss: 2.2693893909454346, train acuracy: 0.16015625
step: 75, val loss: 2.281602621078491, val acuracy: 0.1538333296775818
step: 76, train loss: 2.300339460372925, train acuracy: 0.1455078125
step: 76, val loss: 2.281432628631592, val acuracy: 0.15833334624767303
step: 77, train loss: 2.299858808517456, train acuracy: 0.1845703125
step: 77, val loss: 2.294685125350952, val acuracy: 0.17133331298828125
step: 78, train loss: 2.2801284790039062, train acuracy: 0.1650390625
step: 78, val loss: 2.285961627960205, val acuracy: 0.1743333339691162
step: 79, train loss: 2.27644681930542, train acuracy: 0.1513671875
step: 79, val loss: 2.285541296005249, val acuracy: 0.14816665649414062
step: 80, train loss: 2.3488223552703857, train acuracy: 0.1201171875
step: 80, val loss: 2.3613128662109375, val acuracy: 0.11499999463558197
step: 81, train loss: 2.345679521560669, train acuracy: 0.138671875
step: 81, val loss: 2.3597331047058105, val acuracy: 0.14000000059604645
step: 82, train loss: 2.3624706268310547, train acuracy: 0.1376953125
step: 82, val loss: 2.359694480895996, val acuracy: 0.14083331823349
step: 83, train loss: 2.3194446563720703, train acuracy: 0.15234375
step: 83, val loss: 2.359684705734253, val acuracy: 0.1380000114440918
step: 84, train loss: 2.3726441860198975, train acuracy: 0.15234375
step: 84, val loss: 2.3597044944763184, val acuracy: 0.12283332645893097
step: 85, train loss: 2.3609695434570312, train acuracy: 0.12109375
step: 85, val loss: 2.359816074371338, val acuracy: 0.11649999022483826
step: 86, train loss: 2.3426992893218994, train acuracy: 0.1240234375
step: 86, val loss: 2.3598012924194336, val acuracy: 0.11533333361148834
step: 87, train loss: 2.3725059032440186, train acuracy: 0.1103515625
step: 87, val loss: 2.3598124980926514, val acuracy: 0.11566665768623352
step: 88, train loss: 2.355865478515625, train acuracy: 0.1064453125
step: 88, val loss: 2.3607962131500244, val acuracy: 0.10383333265781403
step: 89, train loss: 2.380664110183716, train acuracy: 0.1025390625
step: 89, val loss: 2.360384941101074, val acuracy: 0.101666659116745
step: 90, train loss: 2.3722290992736816, train acuracy: 0.1875
step: 90, val loss: 2.3672685623168945, val acuracy: 0.1691666543483734
step: 91, train loss: 2.351827621459961, train acuracy: 0.1708984375
step: 91, val loss: 2.3613412380218506, val acuracy: 0.17550000548362732
step: 92, train loss: 2.3623037338256836, train acuracy: 0.1845703125
step: 92, val loss: 2.348848581314087, val acuracy: 0.18199999630451202
step: 93, train loss: 2.334642171859741, train acuracy: 0.1943359375
step: 93, val loss: 2.34727144241333, val acuracy: 0.18933334946632385
step: 94, train loss: 2.3295698165893555, train acuracy: 0.1396484375
step: 94, val loss: 2.3396177291870117, val acuracy: 0.11900000274181366
step: 95, train loss: 2.3073313236236572, train acuracy: 0.162109375
step: 95, val loss: 2.342628002166748, val acuracy: 0.15866665542125702
step: 96, train loss: 2.3342862129211426, train acuracy: 0.1611328125
step: 96, val loss: 2.335277557373047, val acuracy: 0.15916666388511658
step: 97, train loss: 2.216470241546631, train acuracy: 0.18359375
step: 97, val loss: 2.2284793853759766, val acuracy: 0.17866668105125427
step: 98, train loss: 2.0969347953796387, train acuracy: 0.3037109375
step: 98, val loss: 2.1458635330200195, val acuracy: 0.2876666784286499
step: 99, train loss: 2.045503616333008, train acuracy: 0.38671875
step: 99, val loss: 2.090546131134033, val acuracy: 0.3656666874885559
step: 100, train loss: 1.5614079236984253, train acuracy: 0.4794921875
step: 100, val loss: 1.6198070049285889, val acuracy: 0.45250004529953003
step: 101, train loss: 1.37583327293396, train acuracy: 0.5869140625
step: 101, val loss: 1.5504589080810547, val acuracy: 0.5483333468437195
step: 102, train loss: 1.4109883308410645, train acuracy: 0.5458984375
step: 102, val loss: 1.3568084239959717, val acuracy: 0.5519999861717224
step: 103, train loss: 1.332523226737976, train acuracy: 0.6083984375
step: 103, val loss: 1.3261802196502686, val acuracy: 0.6046667098999023
step: 104, train loss: 0.9465815424919128, train acuracy: 0.7138671875
step: 104, val loss: 0.9543933868408203, val acuracy: 0.7088333368301392
step: 105, train loss: 0.965114414691925, train acuracy: 0.7109375
step: 105, val loss: 0.9714797735214233, val acuracy: 0.7171667218208313
step: 106, train loss: 0.7486022710800171, train acuracy: 0.7783203125
step: 106, val loss: 0.8454785943031311, val acuracy: 0.7596667408943176
step: 107, train loss: 0.7514274716377258, train acuracy: 0.77734375
step: 107, val loss: 0.7485599517822266, val acuracy: 0.7763333916664124
step: 108, train loss: 2.4985928535461426, train acuracy: 0.4736328125
step: 108, val loss: 2.4353442192077637, val acuracy: 0.476000040769577
step: 109, train loss: 1.287160038948059, train acuracy: 0.6884765625
step: 109, val loss: 1.3180760145187378, val acuracy: 0.6955000162124634
step: 110, train loss: 0.7474119663238525, train acuracy: 0.759765625
step: 110, val loss: 0.80523282289505, val acuracy: 0.751166820526123
step: 111, train loss: 0.6749333739280701, train acuracy: 0.7958984375
step: 111, val loss: 0.6916332840919495, val acuracy: 0.7875000834465027
step: 112, train loss: 0.6414968371391296, train acuracy: 0.796875
step: 112, val loss: 0.6985664367675781, val acuracy: 0.7796667218208313
step: 113, train loss: 0.6952745318412781, train acuracy: 0.7783203125
step: 113, val loss: 0.711230993270874, val acuracy: 0.78600013256073
step: 114, train loss: 0.7391090393066406, train acuracy: 0.78125
step: 114, val loss: 0.7412312030792236, val acuracy: 0.765166699886322
step: 115, train loss: 0.7315590381622314, train acuracy: 0.771484375
step: 115, val loss: 0.7483397722244263, val acuracy: 0.7770000100135803
step: 116, train loss: 0.6750466823577881, train acuracy: 0.798828125
step: 116, val loss: 0.6889709830284119, val acuracy: 0.7843334078788757
step: 117, train loss: 0.7757208943367004, train acuracy: 0.763671875
step: 117, val loss: 0.7191315293312073, val acuracy: 0.78083336353302
step: 118, train loss: 0.7282910943031311, train acuracy: 0.7861328125
step: 118, val loss: 0.7147597074508667, val acuracy: 0.7823333740234375
step: 119, train loss: 0.7802380919456482, train acuracy: 0.7548828125
step: 119, val loss: 0.7139335870742798, val acuracy: 0.7825000882148743
step: 120, train loss: 0.7266181707382202, train acuracy: 0.7783203125
step: 120, val loss: 0.7133342623710632, val acuracy: 0.7818333506584167
step: 121, train loss: 0.6950472593307495, train acuracy: 0.7880859375
step: 121, val loss: 0.7123813629150391, val acuracy: 0.7820000648498535
step: 122, train loss: 0.6933283805847168, train acuracy: 0.779296875
step: 122, val loss: 0.7117611765861511, val acuracy: 0.7826667428016663
step: 123, train loss: 0.7289763689041138, train acuracy: 0.7802734375
step: 123, val loss: 0.7115899920463562, val acuracy: 0.7833333611488342
step: 124, train loss: 0.6883711218833923, train acuracy: 0.7939453125
step: 124, val loss: 0.7177741527557373, val acuracy: 0.7840000987052917
step: 125, train loss: 0.6976473927497864, train acuracy: 0.79296875
step: 125, val loss: 0.7162836790084839, val acuracy: 0.7796666622161865
step: 126, train loss: 0.6495406627655029, train acuracy: 0.796875
step: 126, val loss: 0.7356748580932617, val acuracy: 0.7740000486373901
step: 127, train loss: 0.7550718188285828, train acuracy: 0.7763671875
step: 127, val loss: 0.7427983283996582, val acuracy: 0.7701667547225952
step: 128, train loss: 0.7695760726928711, train acuracy: 0.7568359375
step: 128, val loss: 0.7400238513946533, val acuracy: 0.7706667184829712
step: 129, train loss: 0.777807891368866, train acuracy: 0.7607421875
step: 129, val loss: 0.7787022590637207, val acuracy: 0.7671666741371155
step: 130, train loss: 0.7864046096801758, train acuracy: 0.7373046875
step: 130, val loss: 0.7756597995758057, val acuracy: 0.7616667151451111
step: 131, train loss: 0.7838689088821411, train acuracy: 0.755859375
step: 131, val loss: 0.7872936129570007, val acuracy: 0.753000020980835
step: 132, train loss: 0.7300208806991577, train acuracy: 0.7724609375
step: 132, val loss: 0.7824923992156982, val acuracy: 0.7568333745002747
step: 133, train loss: 0.7514280676841736, train acuracy: 0.759765625
step: 133, val loss: 0.8131583333015442, val acuracy: 0.7526667714118958
step: 134, train loss: 0.7500705122947693, train acuracy: 0.7548828125
step: 134, val loss: 0.7951370477676392, val acuracy: 0.7543333768844604
step: 135, train loss: 0.904850959777832, train acuracy: 0.740234375
step: 135, val loss: 0.8221069574356079, val acuracy: 0.7485001087188721
step: 136, train loss: 0.7722136378288269, train acuracy: 0.76171875
step: 136, val loss: 0.7875556349754333, val acuracy: 0.7548333406448364
step: 137, train loss: 0.7335082292556763, train acuracy: 0.759765625
step: 137, val loss: 0.799354076385498, val acuracy: 0.7543333768844604
step: 138, train loss: 0.7619410157203674, train acuracy: 0.76171875
step: 138, val loss: 0.8058885931968689, val acuracy: 0.7508333921432495
step: 139, train loss: 0.870934009552002, train acuracy: 0.736328125
step: 139, val loss: 0.81895911693573, val acuracy: 0.7433333992958069
step: 140, train loss: 0.9072262048721313, train acuracy: 0.72265625
step: 140, val loss: 0.8454846143722534, val acuracy: 0.7381666898727417
step: 141, train loss: 0.844139814376831, train acuracy: 0.7333984375
step: 141, val loss: 0.8395435810089111, val acuracy: 0.7391667366027832
step: 142, train loss: 0.8894314765930176, train acuracy: 0.72265625
step: 142, val loss: 0.8540884852409363, val acuracy: 0.736500084400177
step: 143, train loss: 0.9008967876434326, train acuracy: 0.716796875
step: 143, val loss: 0.8668876886367798, val acuracy: 0.7260000109672546
step: 144, train loss: 0.8269178867340088, train acuracy: 0.73046875
step: 144, val loss: 0.8802369832992554, val acuracy: 0.721666693687439
step: 145, train loss: 0.9136001467704773, train acuracy: 0.7216796875
step: 145, val loss: 0.8437874913215637, val acuracy: 0.733833372592926
step: 146, train loss: 0.9040834307670593, train acuracy: 0.703125
step: 146, val loss: 0.8557848930358887, val acuracy: 0.7331666946411133
step: 147, train loss: 1.4966989755630493, train acuracy: 0.61328125
step: 147, val loss: 1.5163570642471313, val acuracy: 0.6156667470932007
step: 148, train loss: 1.4118566513061523, train acuracy: 0.611328125
step: 148, val loss: 1.4446378946304321, val acuracy: 0.627833366394043
step: 149, train loss: 1.5121268033981323, train acuracy: 0.6005859375
step: 149, val loss: 1.4537014961242676, val acuracy: 0.6151666641235352
step: 150, train loss: 1.5629756450653076, train acuracy: 0.59375
step: 150, val loss: 1.4571863412857056, val acuracy: 0.6231666803359985
step: 151, train loss: 1.5014005899429321, train acuracy: 0.6259765625
step: 151, val loss: 1.4366824626922607, val acuracy: 0.639833390712738
step: 152, train loss: 1.3750191926956177, train acuracy: 0.619140625
step: 152, val loss: 1.4188278913497925, val acuracy: 0.6161667108535767
step: 153, train loss: 1.5039767026901245, train acuracy: 0.619140625
step: 153, val loss: 1.4346013069152832, val acuracy: 0.6443333625793457
step: 154, train loss: 4.240581512451172, train acuracy: 0.34375
step: 154, val loss: 4.3536810874938965, val acuracy: 0.3190000355243683
step: 155, train loss: 1.9504746198654175, train acuracy: 0.4189453125
step: 155, val loss: 1.9771058559417725, val acuracy: 0.42250004410743713
step: 156, train loss: 2.0235278606414795, train acuracy: 0.37109375
step: 156, val loss: 1.9639893770217896, val acuracy: 0.38850003480911255
step: 157, train loss: 1.5034172534942627, train acuracy: 0.5244140625
step: 157, val loss: 1.4977211952209473, val acuracy: 0.5266666412353516
step: 158, train loss: 1.4718530178070068, train acuracy: 0.53515625
step: 158, val loss: 1.5166184902191162, val acuracy: 0.5323333740234375
step: 159, train loss: 1.5194945335388184, train acuracy: 0.548828125
step: 159, val loss: 1.5014235973358154, val acuracy: 0.5383333563804626
step: 160, train loss: 1.540317177772522, train acuracy: 0.5244140625
step: 160, val loss: 1.5021538734436035, val acuracy: 0.5381666421890259
step: 161, train loss: 1.4923481941223145, train acuracy: 0.5380859375
step: 161, val loss: 1.4993373155593872, val acuracy: 0.5490000247955322
step: 162, train loss: 1.5897517204284668, train acuracy: 0.5380859375
step: 162, val loss: 1.5324944257736206, val acuracy: 0.5258333683013916
step: 163, train loss: 1.4637210369110107, train acuracy: 0.5458984375
step: 163, val loss: 1.5020523071289062, val acuracy: 0.5368333458900452
step: 164, train loss: 1.5237727165222168, train acuracy: 0.5322265625
step: 164, val loss: 1.5007948875427246, val acuracy: 0.5391666889190674
step: 165, train loss: 1.482984185218811, train acuracy: 0.564453125
step: 165, val loss: 1.523359775543213, val acuracy: 0.5665000081062317
step: 166, train loss: 1.6197118759155273, train acuracy: 0.5126953125
step: 166, val loss: 1.5096765756607056, val acuracy: 0.5585000514984131
step: 167, train loss: 1.6014373302459717, train acuracy: 0.5458984375
step: 167, val loss: 1.5060172080993652, val acuracy: 0.5583333969116211
step: 168, train loss: 1.4845607280731201, train acuracy: 0.5546875
step: 168, val loss: 1.5053563117980957, val acuracy: 0.5588333606719971
step: 169, train loss: 1.566528081893921, train acuracy: 0.5439453125
step: 169, val loss: 1.5049993991851807, val acuracy: 0.5588334202766418
step: 170, train loss: 1.4961512088775635, train acuracy: 0.57421875
step: 170, val loss: 1.5174144506454468, val acuracy: 0.5509999990463257
step: 171, train loss: 1.5894098281860352, train acuracy: 0.541015625
step: 171, val loss: 1.5337278842926025, val acuracy: 0.5518333315849304
step: 172, train loss: 1.5745152235031128, train acuracy: 0.5458984375
step: 172, val loss: 1.5308008193969727, val acuracy: 0.5523333549499512
step: 173, train loss: 1.4788715839385986, train acuracy: 0.568359375
step: 173, val loss: 1.5441794395446777, val acuracy: 0.5569999814033508
step: 174, train loss: 1.567378044128418, train acuracy: 0.5537109375
step: 174, val loss: 1.5513761043548584, val acuracy: 0.5533334016799927
step: 175, train loss: 1.5728875398635864, train acuracy: 0.5361328125
step: 175, val loss: 1.5493218898773193, val acuracy: 0.5533332824707031
step: 176, train loss: 1.524889588356018, train acuracy: 0.568359375
step: 176, val loss: 1.5733438730239868, val acuracy: 0.5441666841506958
step: 177, train loss: 1.4725873470306396, train acuracy: 0.5576171875
step: 177, val loss: 1.564010739326477, val acuracy: 0.5426666736602783
step: 178, train loss: 1.5322794914245605, train acuracy: 0.546875
step: 178, val loss: 1.5538280010223389, val acuracy: 0.5498334169387817
step: 179, train loss: 1.5158225297927856, train acuracy: 0.552734375
step: 179, val loss: 1.564456820487976, val acuracy: 0.534333348274231
step: 180, train loss: 1.5313057899475098, train acuracy: 0.5419921875
step: 180, val loss: 1.5693705081939697, val acuracy: 0.5443333983421326
step: 181, train loss: 1.6362576484680176, train acuracy: 0.509765625
step: 181, val loss: 1.5964661836624146, val acuracy: 0.5108333826065063
step: 182, train loss: 1.5947260856628418, train acuracy: 0.517578125
step: 182, val loss: 1.5904202461242676, val acuracy: 0.5141667127609253
step: 183, train loss: 1.5805402994155884, train acuracy: 0.5234375
step: 183, val loss: 1.5942953824996948, val acuracy: 0.5164999961853027
step: 184, train loss: 1.6314588785171509, train acuracy: 0.4853515625
step: 184, val loss: 1.617064356803894, val acuracy: 0.5008333325386047
step: 185, train loss: 1.5638115406036377, train acuracy: 0.5126953125
step: 185, val loss: 1.5980805158615112, val acuracy: 0.5174999833106995
step: 186, train loss: 1.5967143774032593, train acuracy: 0.4990234375
step: 186, val loss: 1.6114461421966553, val acuracy: 0.5034999847412109
step: 187, train loss: 1.6377602815628052, train acuracy: 0.5009765625
step: 187, val loss: 1.6112468242645264, val acuracy: 0.5061666369438171
step: 188, train loss: 2.422396659851074, train acuracy: 0.3681640625
step: 188, val loss: 2.391031503677368, val acuracy: 0.3819999694824219
step: 189, train loss: 2.3320488929748535, train acuracy: 0.4033203125
step: 189, val loss: 2.2861204147338867, val acuracy: 0.39500004053115845
step: 190, train loss: 2.257711887359619, train acuracy: 0.3818359375
step: 190, val loss: 2.291771650314331, val acuracy: 0.3973333537578583
step: 191, train loss: 2.4221677780151367, train acuracy: 0.3876953125
step: 191, val loss: 2.2880969047546387, val acuracy: 0.40566667914390564
step: 192, train loss: 2.4208741188049316, train acuracy: 0.3955078125
step: 192, val loss: 2.2860138416290283, val acuracy: 0.406333327293396
step: 193, train loss: 2.407074213027954, train acuracy: 0.3740234375
step: 193, val loss: 2.285595655441284, val acuracy: 0.4074999690055847
step: 194, train loss: 2.5428662300109863, train acuracy: 0.375
step: 194, val loss: 2.2907140254974365, val acuracy: 0.4046667218208313
step: 195, train loss: 2.5558362007141113, train acuracy: 0.4580078125
step: 195, val loss: 2.533067226409912, val acuracy: 0.4500000476837158
step: 196, train loss: 2.748461961746216, train acuracy: 0.3955078125
step: 196, val loss: 2.567758321762085, val acuracy: 0.42516669631004333
step: 197, train loss: 2.7014026641845703, train acuracy: 0.390625
step: 197, val loss: 2.572585105895996, val acuracy: 0.38749998807907104
step: 198, train loss: 2.792078733444214, train acuracy: 0.3310546875
step: 198, val loss: 2.868910789489746, val acuracy: 0.3400000333786011
step: 199, train loss: 2.7945408821105957, train acuracy: 0.3720703125
step: 199, val loss: 2.8233304023742676, val acuracy: 0.3555000126361847
step: 200, train loss: 2.3285326957702637, train acuracy: 0.41015625
step: 200, val loss: 2.2473864555358887, val acuracy: 0.4165000319480896
step: 201, train loss: 2.021254777908325, train acuracy: 0.3916015625
step: 201, val loss: 1.981537103652954, val acuracy: 0.40583336353302
step: 202, train loss: 2.739349365234375, train acuracy: 0.2333984375
step: 202, val loss: 2.7541794776916504, val acuracy: 0.24150000512599945
step: 203, train loss: 2.490276336669922, train acuracy: 0.21484375
step: 203, val loss: 2.5661752223968506, val acuracy: 0.203000009059906
step: 204, train loss: 2.4199304580688477, train acuracy: 0.2197265625
step: 204, val loss: 2.4594011306762695, val acuracy: 0.208333358168602
step: 205, train loss: 2.379363536834717, train acuracy: 0.220703125
step: 205, val loss: 2.4659035205841064, val acuracy: 0.20750001072883606
step: 206, train loss: 2.4182541370391846, train acuracy: 0.205078125
step: 206, val loss: 2.453535318374634, val acuracy: 0.20533333718776703
step: 207, train loss: 2.337064504623413, train acuracy: 0.2099609375
step: 207, val loss: 2.448280096054077, val acuracy: 0.20633335411548615
step: 208, train loss: 2.2114877700805664, train acuracy: 0.2119140625
step: 208, val loss: 2.3020665645599365, val acuracy: 0.19350001215934753
step: 209, train loss: 2.262096643447876, train acuracy: 0.302734375
step: 209, val loss: 2.2819292545318604, val acuracy: 0.2876666784286499
step: 210, train loss: 2.1300506591796875, train acuracy: 0.30078125
step: 210, val loss: 2.2177271842956543, val acuracy: 0.273499995470047
step: 211, train loss: 2.123462438583374, train acuracy: 0.2958984375
step: 211, val loss: 2.1235575675964355, val acuracy: 0.30900001525878906
step: 212, train loss: 11.514251708984375, train acuracy: 0.1103515625
step: 212, val loss: 11.469659805297852, val acuracy: 0.11116666346788406
step: 213, train loss: 10.988811492919922, train acuracy: 0.1318359375
step: 213, val loss: 11.02639102935791, val acuracy: 0.12866666913032532
step: 214, train loss: 10.167240142822266, train acuracy: 0.27734375
step: 214, val loss: 9.970772743225098, val acuracy: 0.25600001215934753
step: 215, train loss: 4.7869133949279785, train acuracy: 0.3974609375
step: 215, val loss: 4.479170799255371, val acuracy: 0.4155000150203705
step: 216, train loss: 3.423719644546509, train acuracy: 0.087890625
step: 216, val loss: 3.388169288635254, val acuracy: 0.09200000017881393
step: 217, train loss: 3.2005722522735596, train acuracy: 0.1689453125
step: 217, val loss: 3.315309762954712, val acuracy: 0.17350000143051147
step: 218, train loss: 2.448089838027954, train acuracy: 0.1357421875
step: 218, val loss: 2.4606800079345703, val acuracy: 0.1393333226442337
step: 219, train loss: 2.3619577884674072, train acuracy: 0.1640625
step: 219, val loss: 2.4159581661224365, val acuracy: 0.14033332467079163
step: 220, train loss: 2.385394811630249, train acuracy: 0.150390625
step: 220, val loss: 2.391385555267334, val acuracy: 0.15483331680297852
step: 221, train loss: 2.3160932064056396, train acuracy: 0.1591796875
step: 221, val loss: 2.3378875255584717, val acuracy: 0.15849998593330383
step: 222, train loss: 2.2571816444396973, train acuracy: 0.2373046875
step: 222, val loss: 2.3477439880371094, val acuracy: 0.21266669034957886
step: 223, train loss: 2.236581325531006, train acuracy: 0.1591796875
step: 223, val loss: 2.1983718872070312, val acuracy: 0.17216666042804718
step: 224, train loss: 2.14996600151062, train acuracy: 0.2412109375
step: 224, val loss: 2.184992551803589, val acuracy: 0.2369999885559082
step: 225, train loss: 2.224867343902588, train acuracy: 0.1708984375
step: 225, val loss: 2.2206380367279053, val acuracy: 0.171999990940094
step: 226, train loss: 2.176490306854248, train acuracy: 0.2373046875
step: 226, val loss: 2.2225148677825928, val acuracy: 0.2331666797399521
step: 227, train loss: 2.2533135414123535, train acuracy: 0.15625
step: 227, val loss: 2.2637152671813965, val acuracy: 0.15583331882953644
step: 228, train loss: 2.1594440937042236, train acuracy: 0.2451171875
step: 228, val loss: 2.144474744796753, val acuracy: 0.24150000512599945
step: 229, train loss: 2.0590174198150635, train acuracy: 0.224609375
step: 229, val loss: 2.096640110015869, val acuracy: 0.21783334016799927
step: 230, train loss: 2.089571952819824, train acuracy: 0.2216796875
step: 230, val loss: 2.097355365753174, val acuracy: 0.22983334958553314
step: 231, train loss: 2.097355365753174, train acuracy: 0.2353515625
step: 231, val loss: 2.100468158721924, val acuracy: 0.2355000227689743
step: 232, train loss: 2.0984740257263184, train acuracy: 0.2373046875
step: 232, val loss: 2.1007285118103027, val acuracy: 0.23200002312660217
step: 233, train loss: 2.1297948360443115, train acuracy: 0.212890625
step: 233, val loss: 2.099672555923462, val acuracy: 0.23116667568683624
step: 234, train loss: 2.1531260013580322, train acuracy: 0.21484375
step: 234, val loss: 2.099656105041504, val acuracy: 0.22950001060962677
step: 235, train loss: 2.087790012359619, train acuracy: 0.2578125
step: 235, val loss: 2.1161739826202393, val acuracy: 0.2435000240802765
step: 236, train loss: 2.0898327827453613, train acuracy: 0.2314453125
step: 236, val loss: 2.1007933616638184, val acuracy: 0.22750002145767212
step: 237, train loss: 2.122837781906128, train acuracy: 0.2236328125
step: 237, val loss: 2.1131720542907715, val acuracy: 0.23333334922790527
step: 238, train loss: 2.082550287246704, train acuracy: 0.2431640625
step: 238, val loss: 2.120375871658325, val acuracy: 0.2290000021457672
step: 239, train loss: 2.1298327445983887, train acuracy: 0.2392578125
step: 239, val loss: 2.098205089569092, val acuracy: 0.24500000476837158
step: 240, train loss: 2.0860941410064697, train acuracy: 0.2373046875
step: 240, val loss: 2.0990614891052246, val acuracy: 0.23883333802223206
step: 241, train loss: 2.1180381774902344, train acuracy: 0.2177734375
step: 241, val loss: 2.0975074768066406, val acuracy: 0.2381666600704193
step: 242, train loss: 2.103219509124756, train acuracy: 0.2470703125
step: 242, val loss: 2.103567600250244, val acuracy: 0.24433332681655884
step: 243, train loss: 2.1638922691345215, train acuracy: 0.1904296875
step: 243, val loss: 2.122899293899536, val acuracy: 0.20899999141693115
step: 244, train loss: 2.1248202323913574, train acuracy: 0.2314453125
step: 244, val loss: 2.100006580352783, val acuracy: 0.24450001120567322
step: 245, train loss: 2.1237802505493164, train acuracy: 0.21875
step: 245, val loss: 2.1065688133239746, val acuracy: 0.23149999976158142
step: 246, train loss: 2.100584030151367, train acuracy: 0.2373046875
step: 246, val loss: 2.1091153621673584, val acuracy: 0.2521666884422302
step: 247, train loss: 2.0981249809265137, train acuracy: 0.24609375
step: 247, val loss: 2.109241247177124, val acuracy: 0.2643333673477173
step: 248, train loss: 2.132880449295044, train acuracy: 0.2265625
step: 248, val loss: 2.128450393676758, val acuracy: 0.2305000126361847
step: 249, train loss: 2.1293373107910156, train acuracy: 0.2431640625
step: 249, val loss: 2.1085903644561768, val acuracy: 0.2461666762828827
step: 250, train loss: 2.1458208560943604, train acuracy: 0.2333984375
step: 250, val loss: 2.1107840538024902, val acuracy: 0.25566667318344116
step: 251, train loss: 2.116720676422119, train acuracy: 0.2421875
step: 251, val loss: 2.121734380722046, val acuracy: 0.2461666762828827
step: 252, train loss: 2.123450517654419, train acuracy: 0.244140625
step: 252, val loss: 2.118947982788086, val acuracy: 0.2471666783094406
step: 253, train loss: 2.1326658725738525, train acuracy: 0.234375
step: 253, val loss: 2.12856125831604, val acuracy: 0.2513333559036255
step: 254, train loss: 2.1094818115234375, train acuracy: 0.236328125
step: 254, val loss: 2.1220414638519287, val acuracy: 0.23366667330265045
step: 255, train loss: 2.075794219970703, train acuracy: 0.26171875
step: 255, val loss: 2.1237852573394775, val acuracy: 0.2565000355243683
step: 256, train loss: 2.094067096710205, train acuracy: 0.2587890625
step: 256, val loss: 2.1235620975494385, val acuracy: 0.24150000512599945
step: 257, train loss: 2.1097099781036377, train acuracy: 0.251953125
step: 257, val loss: 2.127643346786499, val acuracy: 0.24266666173934937
step: 258, train loss: 2.163973569869995, train acuracy: 0.2216796875
step: 258, val loss: 2.1263279914855957, val acuracy: 0.24416668713092804
step: 259, train loss: 2.1158173084259033, train acuracy: 0.23828125
step: 259, val loss: 2.1241018772125244, val acuracy: 0.2460000067949295
step: 260, train loss: 2.177943706512451, train acuracy: 0.2216796875
step: 260, val loss: 2.135695457458496, val acuracy: 0.22949999570846558
step: 261, train loss: 2.1904568672180176, train acuracy: 0.240234375
step: 261, val loss: 2.1248373985290527, val acuracy: 0.2420000284910202
step: 262, train loss: 2.1790711879730225, train acuracy: 0.220703125
step: 262, val loss: 2.131099224090576, val acuracy: 0.23416666686534882
step: 263, train loss: 2.144537925720215, train acuracy: 0.2392578125
step: 263, val loss: 2.1395812034606934, val acuracy: 0.22733335196971893
step: 264, train loss: 2.1380908489227295, train acuracy: 0.22265625
step: 264, val loss: 2.12394380569458, val acuracy: 0.23749999701976776
step: 265, train loss: 2.095543384552002, train acuracy: 0.26171875
step: 265, val loss: 2.12127947807312, val acuracy: 0.24283334612846375
step: 266, train loss: 2.0783274173736572, train acuracy: 0.2392578125
step: 266, val loss: 2.126345634460449, val acuracy: 0.24183332920074463
step: 267, train loss: 2.1321585178375244, train acuracy: 0.203125
step: 267, val loss: 2.1286447048187256, val acuracy: 0.2146666795015335
step: 268, train loss: 2.1191697120666504, train acuracy: 0.2431640625
step: 268, val loss: 2.1363046169281006, val acuracy: 0.25066667795181274
step: 269, train loss: 2.127307415008545, train acuracy: 0.2197265625
step: 269, val loss: 2.136575222015381, val acuracy: 0.21683335304260254
step: 270, train loss: 2.185245990753174, train acuracy: 0.1943359375
step: 270, val loss: 2.1488232612609863, val acuracy: 0.20266667008399963
step: 271, train loss: 2.1555957794189453, train acuracy: 0.2060546875
step: 271, val loss: 2.1471641063690186, val acuracy: 0.2176666557788849
step: 272, train loss: 2.167710304260254, train acuracy: 0.2529296875
step: 272, val loss: 2.1297779083251953, val acuracy: 0.25066667795181274
step: 273, train loss: 2.107638359069824, train acuracy: 0.2646484375
step: 273, val loss: 2.1284337043762207, val acuracy: 0.25183334946632385
step: 274, train loss: 2.1083428859710693, train acuracy: 0.24609375
step: 274, val loss: 2.144928216934204, val acuracy: 0.23216667771339417
step: 275, train loss: 2.198777675628662, train acuracy: 0.2001953125
step: 275, val loss: 2.143221855163574, val acuracy: 0.22966668009757996
step: 276, train loss: 2.1209771633148193, train acuracy: 0.2978515625
step: 276, val loss: 2.1587791442871094, val acuracy: 0.27799999713897705
step: 277, train loss: 2.213974952697754, train acuracy: 0.1787109375
step: 277, val loss: 2.198174476623535, val acuracy: 0.1836666613817215
step: 278, train loss: 2.1532912254333496, train acuracy: 0.3115234375
step: 278, val loss: 2.1888158321380615, val acuracy: 0.29783332347869873
step: 279, train loss: 2.1976451873779297, train acuracy: 0.2041015625
step: 279, val loss: 2.2114150524139404, val acuracy: 0.19833335280418396
step: 280, train loss: 2.1897215843200684, train acuracy: 0.2919921875
step: 280, val loss: 2.195340156555176, val acuracy: 0.2863333523273468
step: 281, train loss: 2.1008145809173584, train acuracy: 0.2685546875
step: 281, val loss: 2.1431992053985596, val acuracy: 0.24916666746139526
step: 282, train loss: 2.4355764389038086, train acuracy: 0.1513671875
step: 282, val loss: 2.4537339210510254, val acuracy: 0.13433332741260529
step: 283, train loss: 2.4473745822906494, train acuracy: 0.1396484375
step: 283, val loss: 2.4188642501831055, val acuracy: 0.1381666511297226
step: 284, train loss: 2.3976287841796875, train acuracy: 0.16796875
step: 284, val loss: 2.421839475631714, val acuracy: 0.13716666400432587
step: 285, train loss: 2.413679599761963, train acuracy: 0.1455078125
step: 285, val loss: 2.41721773147583, val acuracy: 0.1444999873638153
step: 286, train loss: 2.3710386753082275, train acuracy: 0.15234375
step: 286, val loss: 2.421359062194824, val acuracy: 0.15299999713897705
step: 287, train loss: 2.462752342224121, train acuracy: 0.109375
step: 287, val loss: 2.4194533824920654, val acuracy: 0.1340000033378601
step: 288, train loss: 2.430227041244507, train acuracy: 0.1201171875
step: 288, val loss: 2.4190514087677, val acuracy: 0.13500000536441803
step: 289, train loss: 2.434377670288086, train acuracy: 0.130859375
step: 289, val loss: 2.421130895614624, val acuracy: 0.1278333216905594
step: 290, train loss: 2.381655693054199, train acuracy: 0.1533203125
step: 290, val loss: 2.4053075313568115, val acuracy: 0.1459999978542328
step: 291, train loss: 2.211416482925415, train acuracy: 0.318359375
step: 291, val loss: 2.218291759490967, val acuracy: 0.30266669392585754
step: 292, train loss: 2.272155284881592, train acuracy: 0.271484375
step: 292, val loss: 2.3073835372924805, val acuracy: 0.25600001215934753
step: 293, train loss: 2.3184168338775635, train acuracy: 0.2685546875
step: 293, val loss: 2.281287431716919, val acuracy: 0.26216667890548706
step: 294, train loss: 2.5037364959716797, train acuracy: 0.177734375
step: 294, val loss: 2.523634433746338, val acuracy: 0.1693333387374878
step: 295, train loss: 2.5446767807006836, train acuracy: 0.1708984375
step: 295, val loss: 2.504641532897949, val acuracy: 0.171999990940094
step: 296, train loss: 2.5884759426116943, train acuracy: 0.1396484375
step: 296, val loss: 2.5065319538116455, val acuracy: 0.17200002074241638
step: 297, train loss: 2.4820632934570312, train acuracy: 0.171875
step: 297, val loss: 2.5061557292938232, val acuracy: 0.17216667532920837
step: 298, train loss: 2.4961345195770264, train acuracy: 0.154296875
step: 298, val loss: 2.506030797958374, val acuracy: 0.1731666773557663
step: 299, train loss: 2.5018815994262695, train acuracy: 0.1533203125
step: 299, val loss: 2.5060582160949707, val acuracy: 0.1731666773557663
step: 300, train loss: 2.520866870880127, train acuracy: 0.1748046875
step: 300, val loss: 2.5060372352600098, val acuracy: 0.17249998450279236
step: 301, train loss: 2.511396884918213, train acuracy: 0.1708984375
step: 301, val loss: 2.506039619445801, val acuracy: 0.17216667532920837
step: 302, train loss: 2.584258556365967, train acuracy: 0.1318359375
step: 302, val loss: 2.5076940059661865, val acuracy: 0.16516666114330292
step: 303, train loss: 2.531979560852051, train acuracy: 0.1728515625
step: 303, val loss: 2.501898765563965, val acuracy: 0.17416666448116302
step: 304, train loss: 2.5239222049713135, train acuracy: 0.171875
step: 304, val loss: 2.5023744106292725, val acuracy: 0.1834999918937683
step: 305, train loss: 2.4930129051208496, train acuracy: 0.2041015625
step: 305, val loss: 2.501296281814575, val acuracy: 0.19966667890548706
step: 306, train loss: 2.5254921913146973, train acuracy: 0.181640625
step: 306, val loss: 2.500546932220459, val acuracy: 0.19833333790302277
step: 307, train loss: 2.463045835494995, train acuracy: 0.2001953125
step: 307, val loss: 2.4790077209472656, val acuracy: 0.19949999451637268
step: 308, train loss: 2.282059669494629, train acuracy: 0.337890625
step: 308, val loss: 2.372260570526123, val acuracy: 0.30799999833106995
step: 309, train loss: 2.367396116256714, train acuracy: 0.2568359375
step: 309, val loss: 2.373619318008423, val acuracy: 0.265166699886322
step: 310, train loss: 2.1945383548736572, train acuracy: 0.314453125
step: 310, val loss: 2.1549196243286133, val acuracy: 0.32100000977516174
step: 311, train loss: 1.9639005661010742, train acuracy: 0.3515625
step: 311, val loss: 2.0070722103118896, val acuracy: 0.34583336114883423
step: 312, train loss: 1.845744252204895, train acuracy: 0.349609375
step: 312, val loss: 1.8686622381210327, val acuracy: 0.3471667170524597
step: 313, train loss: 1.7552614212036133, train acuracy: 0.4072265625
step: 313, val loss: 1.7552348375320435, val acuracy: 0.40950000286102295
step: 314, train loss: 1.7711005210876465, train acuracy: 0.3955078125
step: 314, val loss: 1.7458049058914185, val acuracy: 0.4110000431537628
step: 315, train loss: 1.7593231201171875, train acuracy: 0.3564453125
step: 315, val loss: 1.7308509349822998, val acuracy: 0.37183332443237305
step: 316, train loss: 1.476095199584961, train acuracy: 0.5234375
step: 316, val loss: 1.4826058149337769, val acuracy: 0.5080000162124634
step: 317, train loss: 1.4084291458129883, train acuracy: 0.546875
step: 317, val loss: 1.3914692401885986, val acuracy: 0.5603333711624146
step: 318, train loss: 1.3298113346099854, train acuracy: 0.564453125
step: 318, val loss: 1.2958087921142578, val acuracy: 0.5814999938011169
step: 319, train loss: 1.2467838525772095, train acuracy: 0.6103515625
step: 319, val loss: 1.2465821504592896, val acuracy: 0.6151667237281799
step: 320, train loss: 1.2051359415054321, train acuracy: 0.6123046875
step: 320, val loss: 1.2136896848678589, val acuracy: 0.6225000619888306
step: 321, train loss: 1.0381242036819458, train acuracy: 0.6865234375
step: 321, val loss: 1.1312936544418335, val acuracy: 0.6640000939369202
step: 322, train loss: 1.1869646310806274, train acuracy: 0.658203125
step: 322, val loss: 1.1193331480026245, val acuracy: 0.671333372592926
step: 323, train loss: 1.2566972970962524, train acuracy: 0.6396484375
step: 323, val loss: 1.1254053115844727, val acuracy: 0.6671667098999023
step: 324, train loss: 1.038179636001587, train acuracy: 0.69140625
step: 324, val loss: 1.1284815073013306, val acuracy: 0.6670000553131104
step: 325, train loss: 1.188113808631897, train acuracy: 0.658203125
step: 325, val loss: 1.1266635656356812, val acuracy: 0.6663334369659424
step: 326, train loss: 1.138803482055664, train acuracy: 0.6484375
step: 326, val loss: 1.1677923202514648, val acuracy: 0.6531667113304138
step: 327, train loss: 1.276817798614502, train acuracy: 0.62890625
step: 327, val loss: 1.1631414890289307, val acuracy: 0.6533333659172058
step: 328, train loss: 1.1488486528396606, train acuracy: 0.6669921875
step: 328, val loss: 1.1675983667373657, val acuracy: 0.6558334231376648
step: 329, train loss: 1.9838628768920898, train acuracy: 0.3994140625
step: 329, val loss: 2.0687286853790283, val acuracy: 0.3921666741371155
step: 330, train loss: 1.694760799407959, train acuracy: 0.4462890625
step: 330, val loss: 1.6674391031265259, val acuracy: 0.4656667113304138
step: 331, train loss: 1.5719863176345825, train acuracy: 0.466796875
step: 331, val loss: 1.581298589706421, val acuracy: 0.46800002455711365
step: 332, train loss: 1.5533368587493896, train acuracy: 0.4853515625
step: 332, val loss: 1.5491986274719238, val acuracy: 0.4986667037010193
step: 333, train loss: 1.5528398752212524, train acuracy: 0.46875
step: 333, val loss: 1.5717706680297852, val acuracy: 0.4671666622161865
step: 334, train loss: 1.4461148977279663, train acuracy: 0.5400390625
step: 334, val loss: 1.4688079357147217, val acuracy: 0.53083336353302
step: 335, train loss: 1.4491117000579834, train acuracy: 0.560546875
step: 335, val loss: 1.4634712934494019, val acuracy: 0.5518333315849304
step: 336, train loss: 1.4502203464508057, train acuracy: 0.564453125
step: 336, val loss: 1.4566837549209595, val acuracy: 0.5531666874885559
step: 337, train loss: 1.4557210206985474, train acuracy: 0.5478515625
step: 337, val loss: 1.4568406343460083, val acuracy: 0.5531666278839111
step: 338, train loss: 1.5132566690444946, train acuracy: 0.513671875
step: 338, val loss: 1.4566874504089355, val acuracy: 0.5531666874885559
step: 339, train loss: 1.419711709022522, train acuracy: 0.576171875
step: 339, val loss: 1.4565545320510864, val acuracy: 0.5535000562667847
step: 340, train loss: 1.4418916702270508, train acuracy: 0.55078125
step: 340, val loss: 1.4563993215560913, val acuracy: 0.5535000562667847
step: 341, train loss: 1.4338412284851074, train acuracy: 0.5595703125
step: 341, val loss: 1.4563930034637451, val acuracy: 0.5535000562667847
step: 342, train loss: 1.4368826150894165, train acuracy: 0.5634765625
step: 342, val loss: 1.4566813707351685, val acuracy: 0.5538334250450134
step: 343, train loss: 1.4496262073516846, train acuracy: 0.5302734375
step: 343, val loss: 1.456694483757019, val acuracy: 0.5455000400543213
step: 344, train loss: 1.4661787748336792, train acuracy: 0.5439453125
step: 344, val loss: 1.4574718475341797, val acuracy: 0.5488333702087402
step: 345, train loss: 1.4366989135742188, train acuracy: 0.53125
step: 345, val loss: 1.4566255807876587, val acuracy: 0.5508333444595337
step: 346, train loss: 1.4442410469055176, train acuracy: 0.5185546875
step: 346, val loss: 1.4585344791412354, val acuracy: 0.5145000219345093
step: 347, train loss: 1.4906460046768188, train acuracy: 0.4921875
step: 347, val loss: 1.4647929668426514, val acuracy: 0.5136667490005493
step: 348, train loss: 1.5004600286483765, train acuracy: 0.4794921875
step: 348, val loss: 1.4629197120666504, val acuracy: 0.515333354473114
step: 349, train loss: 1.4511024951934814, train acuracy: 0.5185546875
step: 349, val loss: 1.4636832475662231, val acuracy: 0.5141667127609253
step: 350, train loss: 1.4487611055374146, train acuracy: 0.533203125
step: 350, val loss: 1.4627013206481934, val acuracy: 0.5160000324249268
step: 351, train loss: 1.4221906661987305, train acuracy: 0.5263671875
step: 351, val loss: 1.4638699293136597, val acuracy: 0.5166666507720947
step: 352, train loss: 1.4813885688781738, train acuracy: 0.498046875
step: 352, val loss: 1.4638020992279053, val acuracy: 0.5133333802223206
step: 353, train loss: 1.4788709878921509, train acuracy: 0.48828125
step: 353, val loss: 1.4627876281738281, val acuracy: 0.4878333508968353
step: 354, train loss: 1.5322155952453613, train acuracy: 0.46875
step: 354, val loss: 1.4729313850402832, val acuracy: 0.4886666536331177
step: 355, train loss: 1.4750844240188599, train acuracy: 0.5048828125
step: 355, val loss: 1.468538522720337, val acuracy: 0.5223333835601807
step: 356, train loss: 1.507565975189209, train acuracy: 0.5009765625
step: 356, val loss: 1.46689772605896, val acuracy: 0.5240000486373901
step: 357, train loss: 1.4917399883270264, train acuracy: 0.513671875
step: 357, val loss: 1.4614872932434082, val acuracy: 0.5318333506584167
step: 358, train loss: 1.4703677892684937, train acuracy: 0.5234375
step: 358, val loss: 1.4613945484161377, val acuracy: 0.5316666960716248
step: 359, train loss: 1.446873426437378, train acuracy: 0.5361328125
step: 359, val loss: 1.4616223573684692, val acuracy: 0.5320000648498535
step: 360, train loss: 1.4216489791870117, train acuracy: 0.5517578125
step: 360, val loss: 1.4616810083389282, val acuracy: 0.5350000262260437
step: 361, train loss: 1.4570735692977905, train acuracy: 0.5478515625
step: 361, val loss: 1.462869644165039, val acuracy: 0.5254999995231628
step: 362, train loss: 1.4318925142288208, train acuracy: 0.5478515625
step: 362, val loss: 1.4627798795700073, val acuracy: 0.5240000486373901
step: 363, train loss: 1.752424716949463, train acuracy: 0.43359375
step: 363, val loss: 1.7585535049438477, val acuracy: 0.42116665840148926
step: 364, train loss: 2.1639256477355957, train acuracy: 0.244140625
step: 364, val loss: 2.166663646697998, val acuracy: 0.2501666843891144
step: 365, train loss: 2.792546033859253, train acuracy: 0.3017578125
step: 365, val loss: 2.7855916023254395, val acuracy: 0.30816665291786194
step: 366, train loss: 2.512639284133911, train acuracy: 0.2568359375
step: 366, val loss: 2.4682905673980713, val acuracy: 0.28716668486595154
step: 367, train loss: 2.506294012069702, train acuracy: 0.2919921875
step: 367, val loss: 2.5006628036499023, val acuracy: 0.3018333613872528
step: 368, train loss: 2.2139785289764404, train acuracy: 0.1953125
step: 368, val loss: 2.2568273544311523, val acuracy: 0.1915000081062317
step: 369, train loss: 2.206531047821045, train acuracy: 0.265625
step: 369, val loss: 2.166335105895996, val acuracy: 0.27400001883506775
step: 370, train loss: 2.1029632091522217, train acuracy: 0.318359375
step: 370, val loss: 2.187727451324463, val acuracy: 0.3058333396911621
step: 371, train loss: 2.125837802886963, train acuracy: 0.3076171875
step: 371, val loss: 2.180666923522949, val acuracy: 0.30650001764297485
step: 372, train loss: 2.177896022796631, train acuracy: 0.318359375
step: 372, val loss: 2.1806793212890625, val acuracy: 0.30516669154167175
step: 373, train loss: 2.1580893993377686, train acuracy: 0.3095703125
step: 373, val loss: 2.1817798614501953, val acuracy: 0.3020000159740448
step: 374, train loss: 2.3215389251708984, train acuracy: 0.27734375
step: 374, val loss: 2.1815953254699707, val acuracy: 0.3016666769981384
step: 375, train loss: 2.234696626663208, train acuracy: 0.283203125
step: 375, val loss: 2.1814310550689697, val acuracy: 0.30150002241134644
step: 376, train loss: 2.235905647277832, train acuracy: 0.2861328125
step: 376, val loss: 2.181337356567383, val acuracy: 0.3016666769981384
step: 377, train loss: 2.1861367225646973, train acuracy: 0.296875
step: 377, val loss: 2.183570623397827, val acuracy: 0.2944999933242798
step: 378, train loss: 2.1001272201538086, train acuracy: 0.32421875
step: 378, val loss: 2.208526611328125, val acuracy: 0.3073333501815796
step: 379, train loss: 2.287111759185791, train acuracy: 0.154296875
step: 379, val loss: 2.254309892654419, val acuracy: 0.17900000512599945
step: 380, train loss: 2.20439076423645, train acuracy: 0.2080078125
step: 380, val loss: 2.2883362770080566, val acuracy: 0.20150001347064972
step: 381, train loss: 2.3158516883850098, train acuracy: 0.21484375
step: 381, val loss: 2.2855653762817383, val acuracy: 0.22033333778381348
step: 382, train loss: 2.2896158695220947, train acuracy: 0.294921875
step: 382, val loss: 2.2750115394592285, val acuracy: 0.30699998140335083
step: 383, train loss: 2.2888143062591553, train acuracy: 0.2978515625
step: 383, val loss: 2.2629776000976562, val acuracy: 0.30916669964790344
step: 384, train loss: 2.2938015460968018, train acuracy: 0.30859375
step: 384, val loss: 2.267375946044922, val acuracy: 0.3111667037010193
step: 385, train loss: 2.250952959060669, train acuracy: 0.3212890625
step: 385, val loss: 2.265092372894287, val acuracy: 0.312166690826416
step: 386, train loss: 2.1880030632019043, train acuracy: 0.3212890625
step: 386, val loss: 2.2655582427978516, val acuracy: 0.31050002574920654
step: 387, train loss: 2.2613539695739746, train acuracy: 0.3369140625
step: 387, val loss: 2.264997959136963, val acuracy: 0.3098333477973938
step: 388, train loss: 2.23404598236084, train acuracy: 0.318359375
step: 388, val loss: 2.2648913860321045, val acuracy: 0.3100000023841858
step: 389, train loss: 2.264134407043457, train acuracy: 0.3095703125
step: 389, val loss: 2.2627546787261963, val acuracy: 0.3081667125225067
step: 390, train loss: 2.3011834621429443, train acuracy: 0.279296875
step: 390, val loss: 2.268138885498047, val acuracy: 0.31150001287460327
step: 391, train loss: 2.213210344314575, train acuracy: 0.310546875
step: 391, val loss: 2.264741897583008, val acuracy: 0.29983335733413696
step: 392, train loss: 2.2691473960876465, train acuracy: 0.314453125
step: 392, val loss: 2.2593305110931396, val acuracy: 0.3011666536331177
step: 393, train loss: 2.8701462745666504, train acuracy: 0.287109375
step: 393, val loss: 2.958983898162842, val acuracy: 0.2695000171661377
step: 394, train loss: 7.121872425079346, train acuracy: 0.1025390625
step: 394, val loss: 7.03792667388916, val acuracy: 0.09950000047683716
step: 395, train loss: 6.556163787841797, train acuracy: 0.232421875
step: 395, val loss: 6.671651840209961, val acuracy: 0.21949999034404755
step: 396, train loss: 5.914226531982422, train acuracy: 0.2392578125
step: 396, val loss: 5.553493022918701, val acuracy: 0.23866666853427887
step: 397, train loss: 3.5515387058258057, train acuracy: 0.19140625
step: 397, val loss: 3.507657766342163, val acuracy: 0.1850000023841858
step: 398, train loss: 3.1686246395111084, train acuracy: 0.091796875
step: 398, val loss: 3.121694326400757, val acuracy: 0.1003333330154419
step: 399, train loss: 2.6540944576263428, train acuracy: 0.115234375
step: 399, val loss: 2.6690781116485596, val acuracy: 0.10333333164453506
2017-12-04 15:23:06.489801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:23:06.737728: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x9257090 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 15:23:06.738427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:23:06.738691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 15:23:06.738706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 15:23:06.738711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 15:23:06.738722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 15:23:06.738729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.420074939727783, train acuracy: 0.140625
step: 0, val loss: 2.6601362228393555, val acuracy: 0.09816665947437286
step: 1, train loss: 2.2370657920837402, train acuracy: 0.1640625
step: 1, val loss: 2.3467295169830322, val acuracy: 0.09666666388511658
step: 2, train loss: 2.2498788833618164, train acuracy: 0.125
step: 2, val loss: 2.3219006061553955, val acuracy: 0.09816667437553406
step: 3, train loss: 2.1854329109191895, train acuracy: 0.2890625
step: 3, val loss: 2.312058925628662, val acuracy: 0.19200000166893005
step: 4, train loss: 2.227123498916626, train acuracy: 0.2578125
step: 4, val loss: 2.277937650680542, val acuracy: 0.16183333098888397
step: 5, train loss: 2.309720516204834, train acuracy: 0.125
step: 5, val loss: 2.2722644805908203, val acuracy: 0.15283332765102386
step: 6, train loss: 2.2538585662841797, train acuracy: 0.15625
step: 6, val loss: 2.2720389366149902, val acuracy: 0.15866665542125702
step: 7, train loss: 2.233002185821533, train acuracy: 0.1796875
step: 7, val loss: 2.2800371646881104, val acuracy: 0.10666666179895401
step: 8, train loss: 2.2762022018432617, train acuracy: 0.0859375
step: 8, val loss: 2.272714376449585, val acuracy: 0.09666665643453598
step: 9, train loss: 2.281644105911255, train acuracy: 0.046875
step: 9, val loss: 2.2721168994903564, val acuracy: 0.09699999541044235
step: 10, train loss: 2.198347568511963, train acuracy: 0.265625
step: 10, val loss: 2.295309543609619, val acuracy: 0.15850000083446503
step: 11, train loss: 2.429617404937744, train acuracy: 0.078125
step: 11, val loss: 2.4213638305664062, val acuracy: 0.1054999977350235
step: 12, train loss: 2.4072322845458984, train acuracy: 0.109375
step: 12, val loss: 2.4065778255462646, val acuracy: 0.1054999977350235
step: 13, train loss: 2.4173083305358887, train acuracy: 0.1015625
step: 13, val loss: 2.4032583236694336, val acuracy: 0.1054999977350235
step: 14, train loss: 2.334138870239258, train acuracy: 0.1328125
step: 14, val loss: 2.403339385986328, val acuracy: 0.1054999977350235
step: 15, train loss: 2.3006091117858887, train acuracy: 0.1796875
step: 15, val loss: 2.403101921081543, val acuracy: 0.1054999977350235
step: 16, train loss: 2.4120194911956787, train acuracy: 0.0859375
step: 16, val loss: 2.4108633995056152, val acuracy: 0.1054999977350235
step: 17, train loss: 2.36098313331604, train acuracy: 0.109375
step: 17, val loss: 2.4123988151550293, val acuracy: 0.1054999977350235
step: 18, train loss: 2.395510673522949, train acuracy: 0.1015625
step: 18, val loss: 2.411182403564453, val acuracy: 0.1054999977350235
step: 19, train loss: 2.343762159347534, train acuracy: 0.1171875
step: 19, val loss: 2.4078993797302246, val acuracy: 0.1054999977350235
step: 20, train loss: 2.3530516624450684, train acuracy: 0.1328125
step: 20, val loss: 2.4074060916900635, val acuracy: 0.1054999977350235
step: 21, train loss: 2.284337043762207, train acuracy: 0.125
step: 21, val loss: 2.407151937484741, val acuracy: 0.1054999977350235
step: 22, train loss: 2.4088478088378906, train acuracy: 0.09375
step: 22, val loss: 2.4068455696105957, val acuracy: 0.1054999977350235
step: 23, train loss: 2.301544666290283, train acuracy: 0.15625
step: 23, val loss: 2.4132232666015625, val acuracy: 0.1054999977350235
step: 24, train loss: 2.3631420135498047, train acuracy: 0.1171875
step: 24, val loss: 2.4182496070861816, val acuracy: 0.1054999977350235
step: 25, train loss: 2.4361021518707275, train acuracy: 0.0546875
step: 25, val loss: 2.4169704914093018, val acuracy: 0.1054999977350235
step: 26, train loss: 2.3662240505218506, train acuracy: 0.1484375
step: 26, val loss: 2.4163196086883545, val acuracy: 0.1054999977350235
step: 27, train loss: 2.401200532913208, train acuracy: 0.1015625
step: 27, val loss: 2.4161148071289062, val acuracy: 0.1054999977350235
step: 28, train loss: 2.5301990509033203, train acuracy: 0.0625
step: 28, val loss: 2.424100637435913, val acuracy: 0.1054999977350235
step: 29, train loss: 2.301194667816162, train acuracy: 0.15625
step: 29, val loss: 2.4679360389709473, val acuracy: 0.1054999977350235
step: 30, train loss: 2.3018858432769775, train acuracy: 0.1875
step: 30, val loss: 2.4046144485473633, val acuracy: 0.1054999977350235
step: 31, train loss: 2.5173983573913574, train acuracy: 0.0859375
step: 31, val loss: 2.428598165512085, val acuracy: 0.1054999977350235
step: 32, train loss: 2.503201961517334, train acuracy: 0.109375
step: 32, val loss: 2.4542808532714844, val acuracy: 0.132833331823349
step: 33, train loss: 2.368136405944824, train acuracy: 0.0859375
step: 33, val loss: 2.335050106048584, val acuracy: 0.11133333295583725
step: 34, train loss: 2.2525010108947754, train acuracy: 0.1796875
step: 34, val loss: 2.3051376342773438, val acuracy: 0.14533331990242004
step: 35, train loss: 2.2387499809265137, train acuracy: 0.1171875
step: 35, val loss: 2.2782530784606934, val acuracy: 0.09849999845027924
step: 36, train loss: 2.172288417816162, train acuracy: 0.2421875
step: 36, val loss: 2.2429568767547607, val acuracy: 0.1548333317041397
step: 37, train loss: 2.1819801330566406, train acuracy: 0.1875
step: 37, val loss: 2.277219533920288, val acuracy: 0.1054999977350235
step: 38, train loss: 2.2737982273101807, train acuracy: 0.1015625
step: 38, val loss: 2.4277703762054443, val acuracy: 0.09666665643453598
step: 39, train loss: 2.3724708557128906, train acuracy: 0.0859375
step: 39, val loss: 2.395580291748047, val acuracy: 0.1054999977350235
step: 40, train loss: 2.2571046352386475, train acuracy: 0.1796875
step: 40, val loss: 2.287341356277466, val acuracy: 0.13950000703334808
step: 41, train loss: 2.2411699295043945, train acuracy: 0.171875
step: 41, val loss: 2.274763345718384, val acuracy: 0.1316666603088379
step: 42, train loss: 2.1731019020080566, train acuracy: 0.1796875
step: 42, val loss: 2.291860580444336, val acuracy: 0.09666666388511658
step: 43, train loss: 2.220041513442993, train acuracy: 0.1875
step: 43, val loss: 2.25372576713562, val acuracy: 0.12849999964237213
step: 44, train loss: 2.237194538116455, train acuracy: 0.1484375
step: 44, val loss: 2.245920419692993, val acuracy: 0.12616665661334991
step: 45, train loss: 2.2255637645721436, train acuracy: 0.0859375
step: 45, val loss: 2.2260873317718506, val acuracy: 0.10533333569765091
step: 46, train loss: 2.152195692062378, train acuracy: 0.1484375
step: 46, val loss: 2.1786561012268066, val acuracy: 0.1445000022649765
step: 47, train loss: 2.140468120574951, train acuracy: 0.3359375
step: 47, val loss: 2.1339550018310547, val acuracy: 0.35866665840148926
step: 48, train loss: 1.9781889915466309, train acuracy: 0.46875
step: 48, val loss: 2.0294744968414307, val acuracy: 0.4283333718776703
step: 49, train loss: 1.9759008884429932, train acuracy: 0.3125
step: 49, val loss: 1.9164574146270752, val acuracy: 0.3319999873638153
step: 50, train loss: 1.446979284286499, train acuracy: 0.65625
step: 50, val loss: 1.565206527709961, val acuracy: 0.5536667108535767
step: 51, train loss: 1.285078763961792, train acuracy: 0.546875
step: 51, val loss: 1.5227068662643433, val acuracy: 0.47450000047683716
step: 52, train loss: 1.4075380563735962, train acuracy: 0.5
step: 52, val loss: 1.6853039264678955, val acuracy: 0.4398333430290222
step: 53, train loss: 1.3452472686767578, train acuracy: 0.5234375
step: 53, val loss: 1.2666548490524292, val acuracy: 0.5925000905990601
step: 54, train loss: 1.3758808374404907, train acuracy: 0.5546875
step: 54, val loss: 1.4176377058029175, val acuracy: 0.5091667175292969
step: 55, train loss: 1.189529538154602, train acuracy: 0.6015625
step: 55, val loss: 1.4344266653060913, val acuracy: 0.5241667032241821
step: 56, train loss: 1.3301903009414673, train acuracy: 0.5703125
step: 56, val loss: 1.3610076904296875, val acuracy: 0.546166718006134
step: 57, train loss: 1.3453288078308105, train acuracy: 0.5546875
step: 57, val loss: 1.3533040285110474, val acuracy: 0.549500048160553
step: 58, train loss: 1.3561649322509766, train acuracy: 0.578125
step: 58, val loss: 1.348597764968872, val acuracy: 0.5529999732971191
step: 59, train loss: 1.3377642631530762, train acuracy: 0.5625
step: 59, val loss: 1.4157572984695435, val acuracy: 0.5398333668708801
step: 60, train loss: 1.3581527471542358, train acuracy: 0.578125
step: 60, val loss: 1.360486388206482, val acuracy: 0.5635000467300415
step: 61, train loss: 1.2351365089416504, train acuracy: 0.5859375
step: 61, val loss: 1.3952081203460693, val acuracy: 0.5206667184829712
step: 62, train loss: 1.4090325832366943, train acuracy: 0.5703125
step: 62, val loss: 1.409388542175293, val acuracy: 0.5565000772476196
step: 63, train loss: 1.3495662212371826, train acuracy: 0.5234375
step: 63, val loss: 1.3697482347488403, val acuracy: 0.5300000309944153
step: 64, train loss: 1.279403805732727, train acuracy: 0.6171875
step: 64, val loss: 1.371504306793213, val acuracy: 0.5408333539962769
step: 65, train loss: 1.4294275045394897, train acuracy: 0.5
step: 65, val loss: 1.4685460329055786, val acuracy: 0.48500004410743713
step: 66, train loss: 1.4193459749221802, train acuracy: 0.5390625
step: 66, val loss: 1.3805022239685059, val acuracy: 0.5443333387374878
step: 67, train loss: 1.4414423704147339, train acuracy: 0.5703125
step: 67, val loss: 1.4738386869430542, val acuracy: 0.5361666679382324
step: 68, train loss: 1.3855171203613281, train acuracy: 0.6171875
step: 68, val loss: 1.4635547399520874, val acuracy: 0.5285000205039978
step: 69, train loss: 1.496762752532959, train acuracy: 0.4765625
step: 69, val loss: 1.496038794517517, val acuracy: 0.5415000319480896
step: 70, train loss: 1.3859680891036987, train acuracy: 0.625
step: 70, val loss: 1.4835426807403564, val acuracy: 0.5425000190734863
step: 71, train loss: 1.5123369693756104, train acuracy: 0.5625
step: 71, val loss: 1.5159136056900024, val acuracy: 0.512333333492279
step: 72, train loss: 1.457895278930664, train acuracy: 0.5234375
step: 72, val loss: 1.5149232149124146, val acuracy: 0.5063333511352539
step: 73, train loss: 1.4713761806488037, train acuracy: 0.5078125
step: 73, val loss: 1.5094512701034546, val acuracy: 0.5139999985694885
step: 74, train loss: 1.3322142362594604, train acuracy: 0.546875
step: 74, val loss: 1.5536640882492065, val acuracy: 0.4541666805744171
step: 75, train loss: 1.6429284811019897, train acuracy: 0.40625
step: 75, val loss: 1.760759949684143, val acuracy: 0.4033333659172058
step: 76, train loss: 1.818090796470642, train acuracy: 0.375
step: 76, val loss: 1.7351782321929932, val acuracy: 0.41716668009757996
step: 77, train loss: 1.6266781091690063, train acuracy: 0.4453125
step: 77, val loss: 1.7339296340942383, val acuracy: 0.4153333604335785
step: 78, train loss: 1.6565825939178467, train acuracy: 0.5234375
step: 78, val loss: 1.732643485069275, val acuracy: 0.4193333387374878
step: 79, train loss: 1.6558420658111572, train acuracy: 0.40625
step: 79, val loss: 1.7315984964370728, val acuracy: 0.42216670513153076
step: 80, train loss: 1.7999305725097656, train acuracy: 0.3984375
step: 80, val loss: 1.7418153285980225, val acuracy: 0.4203333258628845
step: 81, train loss: 2.0783162117004395, train acuracy: 0.265625
step: 81, val loss: 2.1298890113830566, val acuracy: 0.2815000116825104
step: 82, train loss: 1.9925453662872314, train acuracy: 0.234375
step: 82, val loss: 2.09302020072937, val acuracy: 0.2149999886751175
step: 83, train loss: 2.152392625808716, train acuracy: 0.15625
step: 83, val loss: 2.056884288787842, val acuracy: 0.2211666703224182
step: 84, train loss: 1.9730724096298218, train acuracy: 0.234375
step: 84, val loss: 2.054292678833008, val acuracy: 0.22333334386348724
step: 85, train loss: 2.0336055755615234, train acuracy: 0.25
step: 85, val loss: 2.1263647079467773, val acuracy: 0.24950000643730164
step: 86, train loss: 1.9303066730499268, train acuracy: 0.2734375
step: 86, val loss: 2.037421703338623, val acuracy: 0.2618333697319031
step: 87, train loss: 1.9331644773483276, train acuracy: 0.328125
step: 87, val loss: 2.1292855739593506, val acuracy: 0.2593333423137665
step: 88, train loss: 2.066382884979248, train acuracy: 0.234375
step: 88, val loss: 2.11872935295105, val acuracy: 0.23216667771339417
step: 89, train loss: 2.3602304458618164, train acuracy: 0.0625
step: 89, val loss: 2.166604995727539, val acuracy: 0.15016666054725647
step: 90, train loss: 2.1172308921813965, train acuracy: 0.2421875
step: 90, val loss: 2.246429443359375, val acuracy: 0.21283333003520966
step: 91, train loss: 1.9850077629089355, train acuracy: 0.2265625
step: 91, val loss: 2.112527370452881, val acuracy: 0.14900000393390656
step: 92, train loss: 2.0315804481506348, train acuracy: 0.1484375
step: 92, val loss: 2.1014537811279297, val acuracy: 0.15466667711734772
step: 93, train loss: 2.0867223739624023, train acuracy: 0.21875
step: 93, val loss: 2.1136999130249023, val acuracy: 0.19083333015441895
step: 94, train loss: 6.180953025817871, train acuracy: 0.140625
step: 94, val loss: 6.8039021492004395, val acuracy: 0.16566666960716248
step: 95, train loss: 4.77919864654541, train acuracy: 0.109375
step: 95, val loss: 4.819856643676758, val acuracy: 0.1185000017285347
step: 96, train loss: 2.4378550052642822, train acuracy: 0.140625
step: 96, val loss: 2.4702301025390625, val acuracy: 0.1511666625738144
step: 97, train loss: 2.6283388137817383, train acuracy: 0.140625
step: 97, val loss: 2.486037254333496, val acuracy: 0.1444999873638153
step: 98, train loss: 2.3133111000061035, train acuracy: 0.1171875
step: 98, val loss: 2.280801296234131, val acuracy: 0.12166666984558105
step: 99, train loss: 2.1695897579193115, train acuracy: 0.2734375
step: 99, val loss: 2.2152247428894043, val acuracy: 0.2380000203847885
step: 100, train loss: 2.1885268688201904, train acuracy: 0.1640625
step: 100, val loss: 2.1883177757263184, val acuracy: 0.2006666660308838
step: 101, train loss: 2.1971609592437744, train acuracy: 0.1953125
step: 101, val loss: 2.178040027618408, val acuracy: 0.2148333340883255
step: 102, train loss: 2.1827645301818848, train acuracy: 0.28125
step: 102, val loss: 2.2207064628601074, val acuracy: 0.26733335852622986
step: 103, train loss: 2.0554661750793457, train acuracy: 0.3203125
step: 103, val loss: 2.0932557582855225, val acuracy: 0.2865000069141388
step: 104, train loss: 1.793304204940796, train acuracy: 0.40625
step: 104, val loss: 1.8646146059036255, val acuracy: 0.39250001311302185
step: 105, train loss: 1.865287184715271, train acuracy: 0.3515625
step: 105, val loss: 1.8599287271499634, val acuracy: 0.3955000340938568
step: 106, train loss: 2.017507791519165, train acuracy: 0.28125
step: 106, val loss: 1.9405930042266846, val acuracy: 0.29250001907348633
step: 107, train loss: 1.995012879371643, train acuracy: 0.28125
step: 107, val loss: 1.932631492614746, val acuracy: 0.29850003123283386
step: 108, train loss: 1.9108667373657227, train acuracy: 0.3203125
step: 108, val loss: 1.9309823513031006, val acuracy: 0.2983333468437195
step: 109, train loss: 1.9058358669281006, train acuracy: 0.3203125
step: 109, val loss: 1.9300105571746826, val acuracy: 0.2990000545978546
step: 110, train loss: 1.9233946800231934, train acuracy: 0.2890625
step: 110, val loss: 1.9283671379089355, val acuracy: 0.29966670274734497
step: 111, train loss: 1.9278290271759033, train acuracy: 0.3203125
step: 111, val loss: 1.9133968353271484, val acuracy: 0.3083333373069763
step: 112, train loss: 1.965696096420288, train acuracy: 0.3125
step: 112, val loss: 2.0025978088378906, val acuracy: 0.27149999141693115
step: 113, train loss: 2.010908842086792, train acuracy: 0.25
step: 113, val loss: 1.996706485748291, val acuracy: 0.2723333239555359
step: 114, train loss: 1.9263297319412231, train acuracy: 0.3515625
step: 114, val loss: 1.995819330215454, val acuracy: 0.2723333239555359
step: 115, train loss: 2.062534809112549, train acuracy: 0.2578125
step: 115, val loss: 1.9953325986862183, val acuracy: 0.27250000834465027
step: 116, train loss: 1.9502830505371094, train acuracy: 0.3125
step: 116, val loss: 1.9951517581939697, val acuracy: 0.27250000834465027
step: 117, train loss: 2.006214141845703, train acuracy: 0.2734375
step: 117, val loss: 1.995086908340454, val acuracy: 0.2723333537578583
step: 118, train loss: 2.0892810821533203, train acuracy: 0.2734375
step: 118, val loss: 2.006624937057495, val acuracy: 0.2863333523273468
step: 119, train loss: 2.069392442703247, train acuracy: 0.2265625
step: 119, val loss: 2.013324737548828, val acuracy: 0.25049999356269836
step: 120, train loss: 1.9758975505828857, train acuracy: 0.328125
step: 120, val loss: 2.053891897201538, val acuracy: 0.2696666717529297
step: 121, train loss: 2.033224105834961, train acuracy: 0.265625
step: 121, val loss: 2.049788475036621, val acuracy: 0.2708333730697632
step: 122, train loss: 2.105977773666382, train acuracy: 0.25
step: 122, val loss: 2.0489041805267334, val acuracy: 0.27250000834465027
step: 123, train loss: 2.1287872791290283, train acuracy: 0.234375
step: 123, val loss: 2.0478975772857666, val acuracy: 0.27216672897338867
step: 124, train loss: 2.0312509536743164, train acuracy: 0.265625
step: 124, val loss: 2.046867847442627, val acuracy: 0.2733333706855774
step: 125, train loss: 1.9600811004638672, train acuracy: 0.3671875
step: 125, val loss: 2.049138307571411, val acuracy: 0.3303333520889282
step: 126, train loss: 2.0462024211883545, train acuracy: 0.3515625
step: 126, val loss: 2.0225512981414795, val acuracy: 0.3531666398048401
step: 127, train loss: 1.8168129920959473, train acuracy: 0.484375
step: 127, val loss: 1.9167782068252563, val acuracy: 0.4071666896343231
step: 128, train loss: 1.6120891571044922, train acuracy: 0.5078125
step: 128, val loss: 1.743608832359314, val acuracy: 0.46266669034957886
step: 129, train loss: 1.6609973907470703, train acuracy: 0.484375
step: 129, val loss: 1.701692819595337, val acuracy: 0.4573333263397217
step: 130, train loss: 1.4390885829925537, train acuracy: 0.546875
step: 130, val loss: 1.4976242780685425, val acuracy: 0.5038333535194397
step: 131, train loss: 1.0971291065216064, train acuracy: 0.6953125
step: 131, val loss: 1.231855869293213, val acuracy: 0.624333381652832
step: 132, train loss: 1.2378497123718262, train acuracy: 0.5546875
step: 132, val loss: 1.2344598770141602, val acuracy: 0.5526667237281799
step: 133, train loss: 1.3478825092315674, train acuracy: 0.53125
step: 133, val loss: 1.2169991731643677, val acuracy: 0.5616666674613953
step: 134, train loss: 1.143219232559204, train acuracy: 0.6015625
step: 134, val loss: 1.3942888975143433, val acuracy: 0.5115000605583191
step: 135, train loss: 1.1335976123809814, train acuracy: 0.59375
step: 135, val loss: 1.3826231956481934, val acuracy: 0.5461666584014893
step: 136, train loss: 1.1839569807052612, train acuracy: 0.6015625
step: 136, val loss: 1.3126826286315918, val acuracy: 0.5701667070388794
step: 137, train loss: 1.2919697761535645, train acuracy: 0.5859375
step: 137, val loss: 1.2809182405471802, val acuracy: 0.5776667594909668
step: 138, train loss: 1.3312866687774658, train acuracy: 0.515625
step: 138, val loss: 1.2812384366989136, val acuracy: 0.5793333649635315
step: 139, train loss: 1.1412667036056519, train acuracy: 0.609375
step: 139, val loss: 1.2803934812545776, val acuracy: 0.5790000557899475
step: 140, train loss: 1.2540395259857178, train acuracy: 0.5625
step: 140, val loss: 1.2930855751037598, val acuracy: 0.5703333616256714
step: 141, train loss: 1.2673976421356201, train acuracy: 0.59375
step: 141, val loss: 1.2899529933929443, val acuracy: 0.5755000710487366
step: 142, train loss: 1.2551870346069336, train acuracy: 0.6015625
step: 142, val loss: 1.2886009216308594, val acuracy: 0.5755000114440918
step: 143, train loss: 1.537860631942749, train acuracy: 0.515625
step: 143, val loss: 1.287459135055542, val acuracy: 0.5750001072883606
step: 144, train loss: 1.2139804363250732, train acuracy: 0.671875
step: 144, val loss: 1.2813918590545654, val acuracy: 0.5820000171661377
step: 145, train loss: 1.0514534711837769, train acuracy: 0.6328125
step: 145, val loss: 1.33501398563385, val acuracy: 0.565833330154419
step: 146, train loss: 1.2199015617370605, train acuracy: 0.625
step: 146, val loss: 1.2801395654678345, val acuracy: 0.5848333239555359
step: 147, train loss: 1.230635166168213, train acuracy: 0.5546875
step: 147, val loss: 1.2683935165405273, val acuracy: 0.5885000824928284
step: 148, train loss: 1.2425477504730225, train acuracy: 0.578125
step: 148, val loss: 1.295122742652893, val acuracy: 0.5723333358764648
step: 149, train loss: 1.2503221035003662, train acuracy: 0.6171875
step: 149, val loss: 1.3309191465377808, val acuracy: 0.5548333525657654
step: 150, train loss: 1.2162436246871948, train acuracy: 0.6328125
step: 150, val loss: 1.3602112531661987, val acuracy: 0.5583333373069763
step: 151, train loss: 1.2022300958633423, train acuracy: 0.609375
step: 151, val loss: 1.3866091966629028, val acuracy: 0.5270000100135803
step: 152, train loss: 1.2672173976898193, train acuracy: 0.5703125
step: 152, val loss: 1.3026624917984009, val acuracy: 0.5555000305175781
step: 153, train loss: 1.2548370361328125, train acuracy: 0.5859375
step: 153, val loss: 1.3389430046081543, val acuracy: 0.5581666827201843
step: 154, train loss: 1.3096098899841309, train acuracy: 0.578125
step: 154, val loss: 1.3331124782562256, val acuracy: 0.5596666932106018
step: 155, train loss: 1.1978795528411865, train acuracy: 0.609375
step: 155, val loss: 1.4101616144180298, val acuracy: 0.5214999914169312
step: 156, train loss: 1.3538614511489868, train acuracy: 0.53125
step: 156, val loss: 1.34674870967865, val acuracy: 0.5618333220481873
step: 157, train loss: 1.298520803451538, train acuracy: 0.625
step: 157, val loss: 1.327885627746582, val acuracy: 0.5550000071525574
step: 158, train loss: 1.3161498308181763, train acuracy: 0.5546875
step: 158, val loss: 1.3595377206802368, val acuracy: 0.5649999976158142
step: 159, train loss: 1.2821615934371948, train acuracy: 0.6640625
step: 159, val loss: 1.353093147277832, val acuracy: 0.5670000910758972
step: 160, train loss: 1.385617971420288, train acuracy: 0.5
step: 160, val loss: 1.3555971384048462, val acuracy: 0.5421667098999023
step: 161, train loss: 1.391113042831421, train acuracy: 0.5546875
step: 161, val loss: 1.3523749113082886, val acuracy: 0.5433334112167358
step: 162, train loss: 1.4043704271316528, train acuracy: 0.5390625
step: 162, val loss: 1.3515946865081787, val acuracy: 0.5429999828338623
step: 163, train loss: 1.356032371520996, train acuracy: 0.515625
step: 163, val loss: 1.3500237464904785, val acuracy: 0.5448333621025085
step: 164, train loss: 1.3587143421173096, train acuracy: 0.5390625
step: 164, val loss: 1.3941494226455688, val acuracy: 0.5361667275428772
step: 165, train loss: 1.3985413312911987, train acuracy: 0.5390625
step: 165, val loss: 1.4383820295333862, val acuracy: 0.5559999942779541
step: 166, train loss: 1.166909098625183, train acuracy: 0.609375
step: 166, val loss: 1.3463432788848877, val acuracy: 0.5556666851043701
step: 167, train loss: 1.3944467306137085, train acuracy: 0.5
step: 167, val loss: 1.3458071947097778, val acuracy: 0.5553333759307861
step: 168, train loss: 1.1738464832305908, train acuracy: 0.65625
step: 168, val loss: 1.3452168703079224, val acuracy: 0.5565000176429749
step: 169, train loss: 1.1086947917938232, train acuracy: 0.609375
step: 169, val loss: 1.3812308311462402, val acuracy: 0.5583333373069763
step: 170, train loss: 1.5703542232513428, train acuracy: 0.484375
step: 170, val loss: 1.3903082609176636, val acuracy: 0.5295000672340393
step: 171, train loss: 1.4212195873260498, train acuracy: 0.546875
step: 171, val loss: 1.4452069997787476, val acuracy: 0.5444999933242798
step: 172, train loss: 1.4086496829986572, train acuracy: 0.515625
step: 172, val loss: 1.4092142581939697, val acuracy: 0.5246667265892029
step: 173, train loss: 1.3356103897094727, train acuracy: 0.5703125
step: 173, val loss: 1.4599030017852783, val acuracy: 0.5460000038146973
step: 174, train loss: 1.1963852643966675, train acuracy: 0.59375
step: 174, val loss: 1.429953694343567, val acuracy: 0.5263333320617676
step: 175, train loss: 1.368251919746399, train acuracy: 0.5
step: 175, val loss: 1.409727931022644, val acuracy: 0.5238333940505981
step: 176, train loss: 1.465370774269104, train acuracy: 0.4921875
step: 176, val loss: 1.4004732370376587, val acuracy: 0.5270000100135803
step: 177, train loss: 1.2073142528533936, train acuracy: 0.5859375
step: 177, val loss: 1.3976882696151733, val acuracy: 0.5293333530426025
step: 178, train loss: 1.3095883131027222, train acuracy: 0.59375
step: 178, val loss: 1.4660468101501465, val acuracy: 0.5223333835601807
step: 179, train loss: 1.1173772811889648, train acuracy: 0.6171875
step: 179, val loss: 1.4314014911651611, val acuracy: 0.5208333730697632
step: 180, train loss: 1.3792738914489746, train acuracy: 0.53125
step: 180, val loss: 1.5460638999938965, val acuracy: 0.47083333134651184
step: 181, train loss: 1.3469963073730469, train acuracy: 0.546875
step: 181, val loss: 1.6497021913528442, val acuracy: 0.500166654586792
step: 182, train loss: 1.3269248008728027, train acuracy: 0.6015625
step: 182, val loss: 1.5463327169418335, val acuracy: 0.5081666707992554
step: 183, train loss: 1.2801744937896729, train acuracy: 0.59375
step: 183, val loss: 1.4221765995025635, val acuracy: 0.5400000214576721
step: 184, train loss: 1.3306667804718018, train acuracy: 0.5859375
step: 184, val loss: 1.4094024896621704, val acuracy: 0.5368334054946899
step: 185, train loss: 1.333531379699707, train acuracy: 0.5078125
step: 185, val loss: 1.3816239833831787, val acuracy: 0.5273333191871643
step: 186, train loss: 1.385211706161499, train acuracy: 0.4921875
step: 186, val loss: 1.3866779804229736, val acuracy: 0.5118333697319031
step: 187, train loss: 1.3594236373901367, train acuracy: 0.515625
step: 187, val loss: 1.3725019693374634, val acuracy: 0.5226666927337646
step: 188, train loss: 1.3652094602584839, train acuracy: 0.5
step: 188, val loss: 1.4197920560836792, val acuracy: 0.5200000405311584
step: 189, train loss: 1.3657995462417603, train acuracy: 0.5703125
step: 189, val loss: 1.410747766494751, val acuracy: 0.5240000486373901
step: 190, train loss: 1.6749346256256104, train acuracy: 0.4453125
step: 190, val loss: 1.409256100654602, val acuracy: 0.5243333578109741
step: 191, train loss: 1.3692775964736938, train acuracy: 0.5234375
step: 191, val loss: 1.4086586236953735, val acuracy: 0.5245000123977661
step: 192, train loss: 1.463578224182129, train acuracy: 0.5546875
step: 192, val loss: 1.4451414346694946, val acuracy: 0.5228333473205566
step: 193, train loss: 1.4837827682495117, train acuracy: 0.453125
step: 193, val loss: 1.4439719915390015, val acuracy: 0.5121667385101318
step: 194, train loss: 1.6597729921340942, train acuracy: 0.5078125
step: 194, val loss: 1.437940001487732, val acuracy: 0.5130000114440918
step: 195, train loss: 1.4194607734680176, train acuracy: 0.5703125
step: 195, val loss: 1.4355205297470093, val acuracy: 0.5131667256355286
step: 196, train loss: 1.4566891193389893, train acuracy: 0.484375
step: 196, val loss: 1.433725357055664, val acuracy: 0.5141667127609253
step: 197, train loss: 1.330721139907837, train acuracy: 0.5546875
step: 197, val loss: 1.485296368598938, val acuracy: 0.5139999985694885
step: 198, train loss: 1.1447933912277222, train acuracy: 0.6171875
step: 198, val loss: 1.4421452283859253, val acuracy: 0.5394999980926514
step: 199, train loss: 1.2640514373779297, train acuracy: 0.609375
step: 199, val loss: 1.4618592262268066, val acuracy: 0.5086666941642761
step: 200, train loss: 1.52505624294281, train acuracy: 0.5078125
step: 200, val loss: 1.43682861328125, val acuracy: 0.5260000228881836
step: 201, train loss: 1.369254469871521, train acuracy: 0.5234375
step: 201, val loss: 1.4342217445373535, val acuracy: 0.5266667008399963
step: 202, train loss: 1.4212175607681274, train acuracy: 0.5
step: 202, val loss: 1.4461565017700195, val acuracy: 0.5136666893959045
step: 203, train loss: 14.224905014038086, train acuracy: 0.1640625
step: 203, val loss: 13.782297134399414, val acuracy: 0.18516667187213898
step: 204, train loss: 13.137234687805176, train acuracy: 0.1328125
step: 204, val loss: 13.81702995300293, val acuracy: 0.12349999696016312
step: 205, train loss: 4.375843048095703, train acuracy: 0.15625
step: 205, val loss: 4.301446437835693, val acuracy: 0.09516666829586029
step: 206, train loss: 3.5942416191101074, train acuracy: 0.1328125
step: 206, val loss: 3.793231725692749, val acuracy: 0.09816665947437286
step: 207, train loss: 2.777209997177124, train acuracy: 0.125
step: 207, val loss: 2.833371639251709, val acuracy: 0.1054999977350235
step: 208, train loss: 2.3711864948272705, train acuracy: 0.1796875
step: 208, val loss: 2.59053897857666, val acuracy: 0.10983332991600037
step: 209, train loss: 2.422576427459717, train acuracy: 0.140625
step: 209, val loss: 2.4304592609405518, val acuracy: 0.11816666275262833
step: 210, train loss: 2.32613205909729, train acuracy: 0.109375
step: 210, val loss: 2.3644723892211914, val acuracy: 0.09666665643453598
step: 211, train loss: 2.3169093132019043, train acuracy: 0.171875
step: 211, val loss: 2.353640556335449, val acuracy: 0.09666665643453598
step: 212, train loss: 2.302788734436035, train acuracy: 0.1640625
step: 212, val loss: 2.332956314086914, val acuracy: 0.1054999977350235
step: 213, train loss: 2.3209633827209473, train acuracy: 0.09375
step: 213, val loss: 2.3148956298828125, val acuracy: 0.1054999977350235
step: 214, train loss: 2.2627696990966797, train acuracy: 0.1328125
step: 214, val loss: 2.3269050121307373, val acuracy: 0.09666666388511658
step: 215, train loss: 2.2699830532073975, train acuracy: 0.1640625
step: 215, val loss: 2.325223445892334, val acuracy: 0.1054999977350235
step: 216, train loss: 2.2805252075195312, train acuracy: 0.1015625
step: 216, val loss: 2.317422389984131, val acuracy: 0.09666667133569717
step: 217, train loss: 2.3003897666931152, train acuracy: 0.1328125
step: 217, val loss: 2.3112263679504395, val acuracy: 0.1054999977350235
step: 218, train loss: 2.293025016784668, train acuracy: 0.1484375
step: 218, val loss: 2.307853937149048, val acuracy: 0.1054999977350235
step: 219, train loss: 2.2941033840179443, train acuracy: 0.1171875
step: 219, val loss: 2.3064467906951904, val acuracy: 0.10899998992681503
step: 220, train loss: 2.296194076538086, train acuracy: 0.109375
step: 220, val loss: 2.305448532104492, val acuracy: 0.1054999977350235
step: 221, train loss: 2.2541351318359375, train acuracy: 0.140625
step: 221, val loss: 2.3178207874298096, val acuracy: 0.09816667437553406
step: 222, train loss: 2.2985329627990723, train acuracy: 0.1484375
step: 222, val loss: 2.311699867248535, val acuracy: 0.1054999977350235
step: 223, train loss: 2.2374768257141113, train acuracy: 0.171875
step: 223, val loss: 2.3222289085388184, val acuracy: 0.10899999737739563
step: 224, train loss: 2.284801483154297, train acuracy: 0.1328125
step: 224, val loss: 2.3173084259033203, val acuracy: 0.09816665947437286
step: 225, train loss: 2.291846752166748, train acuracy: 0.15625
step: 225, val loss: 2.3169143199920654, val acuracy: 0.09816667437553406
step: 226, train loss: 2.302433490753174, train acuracy: 0.140625
step: 226, val loss: 2.310486316680908, val acuracy: 0.10899998992681503
step: 227, train loss: 2.2945432662963867, train acuracy: 0.125
step: 227, val loss: 2.3083860874176025, val acuracy: 0.09816665947437286
step: 228, train loss: 2.2976880073547363, train acuracy: 0.109375
step: 228, val loss: 2.3045380115509033, val acuracy: 0.09816665947437286
step: 229, train loss: 2.287996292114258, train acuracy: 0.1328125
step: 229, val loss: 2.305138349533081, val acuracy: 0.10400000214576721
step: 230, train loss: 2.2879819869995117, train acuracy: 0.15625
step: 230, val loss: 2.3039119243621826, val acuracy: 0.1054999977350235
step: 231, train loss: 2.2881927490234375, train acuracy: 0.140625
step: 231, val loss: 2.306551456451416, val acuracy: 0.1053333431482315
step: 232, train loss: 2.2934422492980957, train acuracy: 0.1171875
step: 232, val loss: 2.306570529937744, val acuracy: 0.09666665643453598
step: 233, train loss: 2.2951385974884033, train acuracy: 0.125
step: 233, val loss: 2.306204319000244, val acuracy: 0.09666666388511658
step: 234, train loss: 2.2883286476135254, train acuracy: 0.1328125
step: 234, val loss: 2.3054444789886475, val acuracy: 0.10899998992681503
step: 235, train loss: 2.2716755867004395, train acuracy: 0.1484375
step: 235, val loss: 2.3070902824401855, val acuracy: 0.10899999737739563
step: 236, train loss: 2.292065143585205, train acuracy: 0.125
step: 236, val loss: 2.30702543258667, val acuracy: 0.10899998992681503
step: 237, train loss: 2.303489923477173, train acuracy: 0.1015625
step: 237, val loss: 2.304032564163208, val acuracy: 0.10899998992681503
step: 238, train loss: 2.2614035606384277, train acuracy: 0.15625
step: 238, val loss: 2.3127317428588867, val acuracy: 0.10899998992681503
step: 239, train loss: 2.3025782108306885, train acuracy: 0.0859375
step: 239, val loss: 2.3078598976135254, val acuracy: 0.10899998992681503
step: 240, train loss: 2.2985615730285645, train acuracy: 0.1171875
step: 240, val loss: 2.3035101890563965, val acuracy: 0.10899998992681503
step: 241, train loss: 2.2698593139648438, train acuracy: 0.1328125
step: 241, val loss: 2.3101329803466797, val acuracy: 0.10899999737739563
step: 242, train loss: 2.297375202178955, train acuracy: 0.109375
step: 242, val loss: 2.308319568634033, val acuracy: 0.10899998992681503
step: 243, train loss: 2.2882778644561768, train acuracy: 0.140625
step: 243, val loss: 2.3093366622924805, val acuracy: 0.1054999977350235
step: 244, train loss: 2.268803596496582, train acuracy: 0.1953125
step: 244, val loss: 2.31295108795166, val acuracy: 0.09533333778381348
step: 245, train loss: 2.2730276584625244, train acuracy: 0.1328125
step: 245, val loss: 2.3119847774505615, val acuracy: 0.09816665947437286
step: 246, train loss: 2.305999755859375, train acuracy: 0.125
step: 246, val loss: 2.3050973415374756, val acuracy: 0.10899998992681503
step: 247, train loss: 2.2846508026123047, train acuracy: 0.15625
step: 247, val loss: 2.303692579269409, val acuracy: 0.1053333431482315
step: 248, train loss: 2.2854437828063965, train acuracy: 0.1171875
step: 248, val loss: 2.3057212829589844, val acuracy: 0.1053333431482315
step: 249, train loss: 2.287501335144043, train acuracy: 0.1015625
step: 249, val loss: 2.3045642375946045, val acuracy: 0.1053333431482315
step: 250, train loss: 2.292851209640503, train acuracy: 0.140625
step: 250, val loss: 2.3050403594970703, val acuracy: 0.1054999977350235
step: 251, train loss: 2.286363363265991, train acuracy: 0.1171875
step: 251, val loss: 2.3081893920898438, val acuracy: 0.1054999977350235
step: 252, train loss: 2.2994308471679688, train acuracy: 0.125
step: 252, val loss: 2.3050994873046875, val acuracy: 0.10899998992681503
step: 253, train loss: 2.2703139781951904, train acuracy: 0.140625
step: 253, val loss: 2.3083226680755615, val acuracy: 0.09533333778381348
step: 254, train loss: 2.2845299243927, train acuracy: 0.125
step: 254, val loss: 2.3097474575042725, val acuracy: 0.09533333778381348
step: 255, train loss: 2.2838499546051025, train acuracy: 0.15625
step: 255, val loss: 2.307354688644409, val acuracy: 0.10899999737739563
step: 256, train loss: 2.296736240386963, train acuracy: 0.09375
step: 256, val loss: 2.304089307785034, val acuracy: 0.10899998992681503
step: 257, train loss: 2.2759580612182617, train acuracy: 0.15625
step: 257, val loss: 2.3050589561462402, val acuracy: 0.1053333431482315
step: 258, train loss: 2.3009791374206543, train acuracy: 0.09375
step: 258, val loss: 2.3041486740112305, val acuracy: 0.1053333431482315
step: 259, train loss: 2.291837692260742, train acuracy: 0.125
step: 259, val loss: 2.304978847503662, val acuracy: 0.1053333431482315
step: 260, train loss: 2.2641897201538086, train acuracy: 0.171875
step: 260, val loss: 2.3116137981414795, val acuracy: 0.10899998992681503
step: 261, train loss: 2.3053317070007324, train acuracy: 0.078125
step: 261, val loss: 2.306226968765259, val acuracy: 0.10899998992681503
step: 262, train loss: 2.2921743392944336, train acuracy: 0.1484375
step: 262, val loss: 2.3071115016937256, val acuracy: 0.09533333778381348
step: 263, train loss: 2.2999370098114014, train acuracy: 0.1015625
step: 263, val loss: 2.3037936687469482, val acuracy: 0.10899998992681503
step: 264, train loss: 2.293278217315674, train acuracy: 0.125
step: 264, val loss: 2.304272413253784, val acuracy: 0.10899999737739563
step: 265, train loss: 2.284175157546997, train acuracy: 0.140625
step: 265, val loss: 2.3077034950256348, val acuracy: 0.09816665947437286
step: 266, train loss: 2.3019566535949707, train acuracy: 0.1171875
step: 266, val loss: 2.3049912452697754, val acuracy: 0.1054999977350235
step: 267, train loss: 2.2884678840637207, train acuracy: 0.140625
step: 267, val loss: 2.305171012878418, val acuracy: 0.10899998992681503
step: 268, train loss: 2.301276683807373, train acuracy: 0.109375
step: 268, val loss: 2.3031609058380127, val acuracy: 0.10899999737739563
step: 269, train loss: 2.290046453475952, train acuracy: 0.140625
step: 269, val loss: 2.305922746658325, val acuracy: 0.09816665947437286
step: 270, train loss: 2.281102180480957, train acuracy: 0.15625
step: 270, val loss: 2.3072261810302734, val acuracy: 0.09816667437553406
step: 271, train loss: 2.275925874710083, train acuracy: 0.15625
step: 271, val loss: 2.309656858444214, val acuracy: 0.09666665643453598
step: 272, train loss: 2.2945806980133057, train acuracy: 0.1171875
step: 272, val loss: 2.306032419204712, val acuracy: 0.10883332788944244
step: 273, train loss: 2.287407398223877, train acuracy: 0.140625
step: 273, val loss: 2.3083925247192383, val acuracy: 0.09816665947437286
step: 274, train loss: 2.299025535583496, train acuracy: 0.1015625
step: 274, val loss: 2.307952404022217, val acuracy: 0.09816665947437286
step: 275, train loss: 2.294999599456787, train acuracy: 0.1328125
step: 275, val loss: 2.3063552379608154, val acuracy: 0.09749999642372131
step: 276, train loss: 2.2874562740325928, train acuracy: 0.171875
step: 276, val loss: 2.303809404373169, val acuracy: 0.1053333431482315
step: 277, train loss: 2.283914804458618, train acuracy: 0.140625
step: 277, val loss: 2.3055789470672607, val acuracy: 0.10533333569765091
step: 278, train loss: 2.2877588272094727, train acuracy: 0.1328125
step: 278, val loss: 2.3068573474884033, val acuracy: 0.1054999977350235
step: 279, train loss: 2.2890331745147705, train acuracy: 0.1171875
step: 279, val loss: 2.3060269355773926, val acuracy: 0.09533333778381348
step: 280, train loss: 2.2989706993103027, train acuracy: 0.1484375
step: 280, val loss: 2.3039300441741943, val acuracy: 0.10899998992681503
step: 281, train loss: 2.278393268585205, train acuracy: 0.15625
step: 281, val loss: 2.3085901737213135, val acuracy: 0.09749999642372131
step: 282, train loss: 2.2729408740997314, train acuracy: 0.171875
step: 282, val loss: 2.3119053840637207, val acuracy: 0.1054999977350235
step: 283, train loss: 2.308460235595703, train acuracy: 0.1015625
step: 283, val loss: 2.306972026824951, val acuracy: 0.09749999642372131
step: 284, train loss: 2.300670623779297, train acuracy: 0.1015625
step: 284, val loss: 2.305067539215088, val acuracy: 0.09749999642372131
step: 285, train loss: 2.2965989112854004, train acuracy: 0.1015625
step: 285, val loss: 2.30342960357666, val acuracy: 0.09749999642372131
step: 286, train loss: 2.294329881668091, train acuracy: 0.09375
step: 286, val loss: 2.305018663406372, val acuracy: 0.09749999642372131
step: 287, train loss: 2.290370464324951, train acuracy: 0.1171875
step: 287, val loss: 2.3046250343322754, val acuracy: 0.09533333778381348
step: 288, train loss: 2.289586067199707, train acuracy: 0.140625
step: 288, val loss: 2.3056564331054688, val acuracy: 0.10899999737739563
step: 289, train loss: 2.2963619232177734, train acuracy: 0.1328125
step: 289, val loss: 2.306391716003418, val acuracy: 0.09666666388511658
step: 290, train loss: 2.2759552001953125, train acuracy: 0.1484375
step: 290, val loss: 2.3073575496673584, val acuracy: 0.09533333778381348
step: 291, train loss: 2.289850950241089, train acuracy: 0.1171875
step: 291, val loss: 2.307229995727539, val acuracy: 0.09533333778381348
step: 292, train loss: 2.260654926300049, train acuracy: 0.171875
step: 292, val loss: 2.3120577335357666, val acuracy: 0.10899998992681503
step: 293, train loss: 2.2826449871063232, train acuracy: 0.15625
step: 293, val loss: 2.312504291534424, val acuracy: 0.09816667437553406
step: 294, train loss: 2.2948367595672607, train acuracy: 0.140625
step: 294, val loss: 2.309452772140503, val acuracy: 0.1054999977350235
step: 295, train loss: 2.2960727214813232, train acuracy: 0.1171875
step: 295, val loss: 2.3090219497680664, val acuracy: 0.1054999977350235
step: 296, train loss: 2.2981152534484863, train acuracy: 0.140625
step: 296, val loss: 2.30755615234375, val acuracy: 0.09816665947437286
step: 297, train loss: 2.2927510738372803, train acuracy: 0.1484375
step: 297, val loss: 2.307997703552246, val acuracy: 0.09666665643453598
step: 298, train loss: 2.2880895137786865, train acuracy: 0.125
step: 298, val loss: 2.3092668056488037, val acuracy: 0.09533333778381348
step: 299, train loss: 2.305079936981201, train acuracy: 0.1171875
step: 299, val loss: 2.3064205646514893, val acuracy: 0.09816665947437286
step: 300, train loss: 2.295935869216919, train acuracy: 0.125
step: 300, val loss: 2.306706428527832, val acuracy: 0.09816667437553406
step: 301, train loss: 2.293447971343994, train acuracy: 0.140625
step: 301, val loss: 2.3064215183258057, val acuracy: 0.09666666388511658
step: 302, train loss: 2.2881383895874023, train acuracy: 0.125
step: 302, val loss: 2.3047754764556885, val acuracy: 0.09666666388511658
step: 303, train loss: 2.2812392711639404, train acuracy: 0.1484375
step: 303, val loss: 2.3071112632751465, val acuracy: 0.09816665947437286
step: 304, train loss: 2.291872501373291, train acuracy: 0.109375
step: 304, val loss: 2.305816173553467, val acuracy: 0.09816665947437286
step: 305, train loss: 2.270195722579956, train acuracy: 0.171875
step: 305, val loss: 2.311728000640869, val acuracy: 0.09816665947437286
step: 306, train loss: 2.2934656143188477, train acuracy: 0.1171875
step: 306, val loss: 2.3089258670806885, val acuracy: 0.09816667437553406
step: 307, train loss: 2.2852842807769775, train acuracy: 0.1171875
step: 307, val loss: 2.3092007637023926, val acuracy: 0.09816667437553406
step: 308, train loss: 2.285111427307129, train acuracy: 0.1640625
step: 308, val loss: 2.310699701309204, val acuracy: 0.09816665947437286
step: 309, train loss: 2.2942352294921875, train acuracy: 0.1328125
step: 309, val loss: 2.3094429969787598, val acuracy: 0.09816665947437286
step: 310, train loss: 2.2925448417663574, train acuracy: 0.078125
step: 310, val loss: 2.3057146072387695, val acuracy: 0.09816665947437286
step: 311, train loss: 2.2910404205322266, train acuracy: 0.1015625
step: 311, val loss: 2.307114839553833, val acuracy: 0.09816665947437286
step: 312, train loss: 2.291447639465332, train acuracy: 0.1328125
step: 312, val loss: 2.3060319423675537, val acuracy: 0.10899998992681503
step: 313, train loss: 2.2939505577087402, train acuracy: 0.1015625
step: 313, val loss: 2.306581735610962, val acuracy: 0.10899998992681503
step: 314, train loss: 2.302699565887451, train acuracy: 0.109375
step: 314, val loss: 2.304469108581543, val acuracy: 0.09666666388511658
step: 315, train loss: 2.2821266651153564, train acuracy: 0.1484375
step: 315, val loss: 2.308218240737915, val acuracy: 0.09533333778381348
step: 316, train loss: 2.2794690132141113, train acuracy: 0.1328125
step: 316, val loss: 2.3104825019836426, val acuracy: 0.09533333778381348
step: 317, train loss: 2.2914881706237793, train acuracy: 0.1171875
step: 317, val loss: 2.3070569038391113, val acuracy: 0.10899999737739563
step: 318, train loss: 2.2887825965881348, train acuracy: 0.1171875
step: 318, val loss: 2.3087620735168457, val acuracy: 0.10400000214576721
step: 319, train loss: 2.2930800914764404, train acuracy: 0.1484375
step: 319, val loss: 2.307563304901123, val acuracy: 0.10899998992681503
step: 320, train loss: 2.2957043647766113, train acuracy: 0.125
step: 320, val loss: 2.306039571762085, val acuracy: 0.10899999737739563
step: 321, train loss: 2.2988133430480957, train acuracy: 0.09375
step: 321, val loss: 2.3043689727783203, val acuracy: 0.10899999737739563
step: 322, train loss: 2.2860374450683594, train acuracy: 0.1484375
step: 322, val loss: 2.305424213409424, val acuracy: 0.10899999737739563
step: 323, train loss: 2.299539089202881, train acuracy: 0.09375
step: 323, val loss: 2.3042354583740234, val acuracy: 0.10899998992681503
step: 324, train loss: 2.2842912673950195, train acuracy: 0.1484375
step: 324, val loss: 2.3058667182922363, val acuracy: 0.10899998992681503
step: 325, train loss: 2.298703670501709, train acuracy: 0.1015625
step: 325, val loss: 2.3058249950408936, val acuracy: 0.10899998992681503
step: 326, train loss: 2.2991726398468018, train acuracy: 0.125
step: 326, val loss: 2.305774688720703, val acuracy: 0.10400000214576721
step: 327, train loss: 2.2723708152770996, train acuracy: 0.1640625
step: 327, val loss: 2.311112880706787, val acuracy: 0.09749999642372131
step: 328, train loss: 2.2914891242980957, train acuracy: 0.125
step: 328, val loss: 2.3080215454101562, val acuracy: 0.09666666388511658
step: 329, train loss: 2.2884411811828613, train acuracy: 0.140625
step: 329, val loss: 2.3086540699005127, val acuracy: 0.10899998992681503
step: 330, train loss: 2.287062644958496, train acuracy: 0.140625
step: 330, val loss: 2.306689500808716, val acuracy: 0.10899999737739563
step: 331, train loss: 2.297689914703369, train acuracy: 0.1171875
step: 331, val loss: 2.3063275814056396, val acuracy: 0.10899999737739563
step: 332, train loss: 2.282853841781616, train acuracy: 0.1640625
step: 332, val loss: 2.3053085803985596, val acuracy: 0.10899999737739563
step: 333, train loss: 2.2934064865112305, train acuracy: 0.0703125
step: 333, val loss: 2.305162191390991, val acuracy: 0.10899999737739563
step: 334, train loss: 2.299311637878418, train acuracy: 0.1015625
step: 334, val loss: 2.3049163818359375, val acuracy: 0.10899998992681503
step: 335, train loss: 2.2691526412963867, train acuracy: 0.125
step: 335, val loss: 2.3073337078094482, val acuracy: 0.10899998992681503
step: 336, train loss: 2.3026342391967773, train acuracy: 0.09375
step: 336, val loss: 2.3054099082946777, val acuracy: 0.10899998992681503
step: 337, train loss: 2.2816178798675537, train acuracy: 0.109375
step: 337, val loss: 2.3086163997650146, val acuracy: 0.10899999737739563
step: 338, train loss: 2.2784945964813232, train acuracy: 0.15625
step: 338, val loss: 2.3090243339538574, val acuracy: 0.10899999737739563
step: 339, train loss: 2.2734017372131348, train acuracy: 0.1484375
step: 339, val loss: 2.310365915298462, val acuracy: 0.10899999737739563
step: 340, train loss: 2.2955565452575684, train acuracy: 0.140625
step: 340, val loss: 2.310115098953247, val acuracy: 0.09533333778381348
step: 341, train loss: 2.294252395629883, train acuracy: 0.109375
step: 341, val loss: 2.3065829277038574, val acuracy: 0.09533333778381348
step: 342, train loss: 2.2954840660095215, train acuracy: 0.1015625
step: 342, val loss: 2.305659294128418, val acuracy: 0.09533333778381348
step: 343, train loss: 2.290281057357788, train acuracy: 0.1484375
step: 343, val loss: 2.307284116744995, val acuracy: 0.09533333778381348
step: 344, train loss: 2.3063817024230957, train acuracy: 0.078125
step: 344, val loss: 2.304093360900879, val acuracy: 0.09533333778381348
step: 345, train loss: 2.28822660446167, train acuracy: 0.1171875
step: 345, val loss: 2.3051507472991943, val acuracy: 0.09533333778381348
step: 346, train loss: 2.287515878677368, train acuracy: 0.140625
step: 346, val loss: 2.3056094646453857, val acuracy: 0.1054999977350235
step: 347, train loss: 2.299823045730591, train acuracy: 0.109375
step: 347, val loss: 2.3037056922912598, val acuracy: 0.1054999977350235
step: 348, train loss: 2.295551300048828, train acuracy: 0.1171875
step: 348, val loss: 2.3038134574890137, val acuracy: 0.1054999977350235
step: 349, train loss: 2.2935941219329834, train acuracy: 0.1171875
step: 349, val loss: 2.3047146797180176, val acuracy: 0.1054999977350235
step: 350, train loss: 2.2949352264404297, train acuracy: 0.1484375
step: 350, val loss: 2.303330421447754, val acuracy: 0.10899998992681503
step: 351, train loss: 2.2964682579040527, train acuracy: 0.1171875
step: 351, val loss: 2.304093837738037, val acuracy: 0.10899998992681503
step: 352, train loss: 2.270336866378784, train acuracy: 0.1640625
step: 352, val loss: 2.309622287750244, val acuracy: 0.10899999737739563
step: 353, train loss: 2.2923378944396973, train acuracy: 0.125
step: 353, val loss: 2.308542013168335, val acuracy: 0.10899998992681503
step: 354, train loss: 2.2917709350585938, train acuracy: 0.109375
step: 354, val loss: 2.3059146404266357, val acuracy: 0.10899999737739563
step: 355, train loss: 2.296430826187134, train acuracy: 0.109375
step: 355, val loss: 2.305755376815796, val acuracy: 0.10899998992681503
step: 356, train loss: 2.3020901679992676, train acuracy: 0.1015625
step: 356, val loss: 2.3042094707489014, val acuracy: 0.10899998992681503
step: 357, train loss: 2.30025315284729, train acuracy: 0.125
step: 357, val loss: 2.3036961555480957, val acuracy: 0.10899999737739563
step: 358, train loss: 2.2883219718933105, train acuracy: 0.09375
step: 358, val loss: 2.3031768798828125, val acuracy: 0.10899999737739563
step: 359, train loss: 2.3007965087890625, train acuracy: 0.109375
step: 359, val loss: 2.302974224090576, val acuracy: 0.10899999737739563
step: 360, train loss: 2.2715678215026855, train acuracy: 0.125
step: 360, val loss: 2.307065486907959, val acuracy: 0.10899998992681503
step: 361, train loss: 2.2764644622802734, train acuracy: 0.171875
step: 361, val loss: 2.307891845703125, val acuracy: 0.10899998992681503
step: 362, train loss: 2.2880196571350098, train acuracy: 0.1796875
step: 362, val loss: 2.30875563621521, val acuracy: 0.09666666388511658
step: 363, train loss: 2.3008487224578857, train acuracy: 0.1328125
step: 363, val loss: 2.30688214302063, val acuracy: 0.10899998992681503
step: 364, train loss: 2.2996907234191895, train acuracy: 0.1171875
step: 364, val loss: 2.306469440460205, val acuracy: 0.10899999737739563
step: 365, train loss: 2.2925968170166016, train acuracy: 0.09375
step: 365, val loss: 2.3058218955993652, val acuracy: 0.10899998992681503
step: 366, train loss: 2.295532703399658, train acuracy: 0.1171875
step: 366, val loss: 2.303614377975464, val acuracy: 0.10899999737739563
step: 367, train loss: 2.29641056060791, train acuracy: 0.1171875
step: 367, val loss: 2.303845167160034, val acuracy: 0.10899998992681503
step: 368, train loss: 2.297593116760254, train acuracy: 0.1328125
step: 368, val loss: 2.3048582077026367, val acuracy: 0.09816667437553406
step: 369, train loss: 2.2827844619750977, train acuracy: 0.15625
step: 369, val loss: 2.3046469688415527, val acuracy: 0.10899999737739563
step: 370, train loss: 2.3008313179016113, train acuracy: 0.1015625
step: 370, val loss: 2.302953004837036, val acuracy: 0.10899999737739563
step: 371, train loss: 2.2928507328033447, train acuracy: 0.1328125
step: 371, val loss: 2.3030362129211426, val acuracy: 0.10899998992681503
step: 372, train loss: 2.2907681465148926, train acuracy: 0.109375
step: 372, val loss: 2.3050589561462402, val acuracy: 0.10899998992681503
step: 373, train loss: 2.2685842514038086, train acuracy: 0.1875
step: 373, val loss: 2.3076820373535156, val acuracy: 0.10899998992681503
step: 374, train loss: 2.293968915939331, train acuracy: 0.1328125
step: 374, val loss: 2.3069870471954346, val acuracy: 0.10899998992681503
step: 375, train loss: 2.2973313331604004, train acuracy: 0.09375
step: 375, val loss: 2.3068008422851562, val acuracy: 0.10899999737739563
step: 376, train loss: 2.291172981262207, train acuracy: 0.1171875
step: 376, val loss: 2.306997299194336, val acuracy: 0.10899999737739563
step: 377, train loss: 2.266338348388672, train acuracy: 0.1796875
step: 377, val loss: 2.3124284744262695, val acuracy: 0.09533333778381348
step: 378, train loss: 2.298029899597168, train acuracy: 0.0703125
step: 378, val loss: 2.3086800575256348, val acuracy: 0.09533333778381348
step: 379, train loss: 2.2843708992004395, train acuracy: 0.1328125
step: 379, val loss: 2.3088059425354004, val acuracy: 0.10899998992681503
step: 380, train loss: 2.2973403930664062, train acuracy: 0.1171875
step: 380, val loss: 2.3076581954956055, val acuracy: 0.09533333778381348
step: 381, train loss: 2.29563045501709, train acuracy: 0.1484375
step: 381, val loss: 2.3054075241088867, val acuracy: 0.10899999737739563
step: 382, train loss: 2.2992630004882812, train acuracy: 0.1328125
step: 382, val loss: 2.3039262294769287, val acuracy: 0.10899998992681503
step: 383, train loss: 2.285466432571411, train acuracy: 0.1328125
step: 383, val loss: 2.3052995204925537, val acuracy: 0.10899999737739563
step: 384, train loss: 2.268737316131592, train acuracy: 0.125
step: 384, val loss: 2.307288646697998, val acuracy: 0.10899999737739563
step: 385, train loss: 2.293621063232422, train acuracy: 0.109375
step: 385, val loss: 2.3065333366394043, val acuracy: 0.10899998992681503
step: 386, train loss: 2.2950751781463623, train acuracy: 0.1328125
step: 386, val loss: 2.3056130409240723, val acuracy: 0.10899999737739563
step: 387, train loss: 2.3012428283691406, train acuracy: 0.1015625
step: 387, val loss: 2.3041467666625977, val acuracy: 0.10899998992681503
step: 388, train loss: 2.2974181175231934, train acuracy: 0.109375
step: 388, val loss: 2.3046228885650635, val acuracy: 0.10899998992681503
step: 389, train loss: 2.277430534362793, train acuracy: 0.15625
step: 389, val loss: 2.3069071769714355, val acuracy: 0.10899998992681503
step: 390, train loss: 2.298365354537964, train acuracy: 0.125
step: 390, val loss: 2.30511474609375, val acuracy: 0.10899999737739563
step: 391, train loss: 2.298600435256958, train acuracy: 0.1171875
step: 391, val loss: 2.304981231689453, val acuracy: 0.10899999737739563
step: 392, train loss: 2.284857749938965, train acuracy: 0.1328125
step: 392, val loss: 2.3058199882507324, val acuracy: 0.10899998992681503
step: 393, train loss: 2.2868518829345703, train acuracy: 0.1015625
step: 393, val loss: 2.305874824523926, val acuracy: 0.10899998992681503
step: 394, train loss: 2.2845118045806885, train acuracy: 0.09375
step: 394, val loss: 2.3073177337646484, val acuracy: 0.10899999737739563
step: 395, train loss: 2.2595808506011963, train acuracy: 0.1484375
step: 395, val loss: 2.3117454051971436, val acuracy: 0.10899998992681503
step: 396, train loss: 2.3017003536224365, train acuracy: 0.1328125
step: 396, val loss: 2.30879282951355, val acuracy: 0.1054999977350235
step: 397, train loss: 2.2925848960876465, train acuracy: 0.1328125
step: 397, val loss: 2.3078885078430176, val acuracy: 0.10899999737739563
step: 398, train loss: 2.2968544960021973, train acuracy: 0.15625
step: 398, val loss: 2.305738687515259, val acuracy: 0.10899998992681503
step: 399, train loss: 2.2865614891052246, train acuracy: 0.140625
step: 399, val loss: 2.3065907955169678, val acuracy: 0.10899999737739563
2017-12-04 15:25:43.285680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:25:43.534007: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x8a369f0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 15:25:43.534693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:25:43.534960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 15:25:43.534975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 15:25:43.534981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 15:25:43.534993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 15:25:43.535001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.3208389282226562, train acuracy: 0.18359375
step: 0, val loss: 2.3937582969665527, val acuracy: 0.12133331596851349
step: 1, train loss: 2.227036952972412, train acuracy: 0.19140625
step: 1, val loss: 2.299321413040161, val acuracy: 0.15916664898395538
step: 2, train loss: 2.2779526710510254, train acuracy: 0.09765625
step: 2, val loss: 2.292956590652466, val acuracy: 0.12166666239500046
step: 3, train loss: 2.259150743484497, train acuracy: 0.1484375
step: 3, val loss: 2.2742276191711426, val acuracy: 0.1316666603088379
step: 4, train loss: 2.2584030628204346, train acuracy: 0.12109375
step: 4, val loss: 2.2553701400756836, val acuracy: 0.11349999159574509
step: 5, train loss: 2.115980625152588, train acuracy: 0.25
step: 5, val loss: 2.188067674636841, val acuracy: 0.18916666507720947
step: 6, train loss: 2.0547852516174316, train acuracy: 0.2578125
step: 6, val loss: 2.0800106525421143, val acuracy: 0.23766666650772095
step: 7, train loss: 1.9588608741760254, train acuracy: 0.31640625
step: 7, val loss: 1.977278709411621, val acuracy: 0.3046666979789734
step: 8, train loss: 1.337830901145935, train acuracy: 0.515625
step: 8, val loss: 1.432626724243164, val acuracy: 0.4908334016799927
step: 9, train loss: 1.115980863571167, train acuracy: 0.6171875
step: 9, val loss: 1.2094800472259521, val acuracy: 0.6173333525657654
step: 10, train loss: 1.1085000038146973, train acuracy: 0.66796875
step: 10, val loss: 1.1796616315841675, val acuracy: 0.6330000758171082
step: 11, train loss: 1.1318318843841553, train acuracy: 0.6015625
step: 11, val loss: 1.177056074142456, val acuracy: 0.6013333797454834
step: 12, train loss: 0.87804114818573, train acuracy: 0.6953125
step: 12, val loss: 0.928398072719574, val acuracy: 0.6921666860580444
step: 13, train loss: 0.9116114974021912, train acuracy: 0.6484375
step: 13, val loss: 1.0038180351257324, val acuracy: 0.6503333449363708
step: 14, train loss: 1.0706528425216675, train acuracy: 0.65234375
step: 14, val loss: 1.092983603477478, val acuracy: 0.6450000405311584
step: 15, train loss: 1.050851821899414, train acuracy: 0.61328125
step: 15, val loss: 1.1696492433547974, val acuracy: 0.5896666646003723
step: 16, train loss: 0.9660133123397827, train acuracy: 0.66796875
step: 16, val loss: 1.0425105094909668, val acuracy: 0.6550000905990601
step: 17, train loss: 1.0771702527999878, train acuracy: 0.62890625
step: 17, val loss: 1.1081902980804443, val acuracy: 0.6098334193229675
step: 18, train loss: 1.0111002922058105, train acuracy: 0.6796875
step: 18, val loss: 1.014085054397583, val acuracy: 0.6633333563804626
step: 19, train loss: 1.0853670835494995, train acuracy: 0.6328125
step: 19, val loss: 1.0321074724197388, val acuracy: 0.6421667337417603
step: 20, train loss: 1.015533447265625, train acuracy: 0.65625
step: 20, val loss: 1.0197750329971313, val acuracy: 0.6470000743865967
step: 21, train loss: 1.0176255702972412, train acuracy: 0.62890625
step: 21, val loss: 1.0476223230361938, val acuracy: 0.6170001029968262
step: 22, train loss: 2.5290517807006836, train acuracy: 0.4140625
step: 22, val loss: 2.6823086738586426, val acuracy: 0.37400001287460327
step: 23, train loss: 1.546090841293335, train acuracy: 0.5078125
step: 23, val loss: 1.784706950187683, val acuracy: 0.4591667056083679
step: 24, train loss: 1.5803709030151367, train acuracy: 0.49609375
step: 24, val loss: 1.6687664985656738, val acuracy: 0.4725000560283661
step: 25, train loss: 1.385353922843933, train acuracy: 0.57421875
step: 25, val loss: 1.5111029148101807, val acuracy: 0.5175000429153442
step: 26, train loss: 1.469657063484192, train acuracy: 0.62109375
step: 26, val loss: 1.5206875801086426, val acuracy: 0.5605000257492065
step: 27, train loss: 1.4430878162384033, train acuracy: 0.578125
step: 27, val loss: 1.504747986793518, val acuracy: 0.5625
step: 28, train loss: 1.4981447458267212, train acuracy: 0.5625
step: 28, val loss: 1.5049302577972412, val acuracy: 0.562000036239624
step: 29, train loss: 1.4652206897735596, train acuracy: 0.5859375
step: 29, val loss: 1.5116243362426758, val acuracy: 0.5688333511352539
step: 30, train loss: 1.440717339515686, train acuracy: 0.62109375
step: 30, val loss: 1.5104401111602783, val acuracy: 0.5673333406448364
step: 31, train loss: 1.5834044218063354, train acuracy: 0.53125
step: 31, val loss: 1.5091383457183838, val acuracy: 0.5698333382606506
step: 32, train loss: 1.4780787229537964, train acuracy: 0.5859375
step: 32, val loss: 1.5085269212722778, val acuracy: 0.5691666603088379
step: 33, train loss: 1.5208243131637573, train acuracy: 0.59375
step: 33, val loss: 1.5084035396575928, val acuracy: 0.5701667070388794
step: 34, train loss: 1.4985597133636475, train acuracy: 0.58203125
step: 34, val loss: 1.5081422328948975, val acuracy: 0.5706666707992554
step: 35, train loss: 1.4384690523147583, train acuracy: 0.609375
step: 35, val loss: 1.5078754425048828, val acuracy: 0.5691667199134827
step: 36, train loss: 1.4806195497512817, train acuracy: 0.5703125
step: 36, val loss: 1.5078377723693848, val acuracy: 0.5700000524520874
step: 37, train loss: 1.414093255996704, train acuracy: 0.62109375
step: 37, val loss: 1.507699728012085, val acuracy: 0.5698333382606506
step: 38, train loss: 1.484397053718567, train acuracy: 0.53515625
step: 38, val loss: 1.5091785192489624, val acuracy: 0.5426666736602783
step: 39, train loss: 1.467031717300415, train acuracy: 0.56640625
step: 39, val loss: 1.5086051225662231, val acuracy: 0.5431666970252991
step: 40, train loss: 1.5447640419006348, train acuracy: 0.4921875
step: 40, val loss: 1.5082035064697266, val acuracy: 0.5425000190734863
step: 41, train loss: 1.5157647132873535, train acuracy: 0.55078125
step: 41, val loss: 1.5143874883651733, val acuracy: 0.5174999833106995
step: 42, train loss: 1.4727423191070557, train acuracy: 0.546875
step: 42, val loss: 1.5311795473098755, val acuracy: 0.5370000600814819
step: 43, train loss: 1.4989066123962402, train acuracy: 0.55078125
step: 43, val loss: 1.5577995777130127, val acuracy: 0.5496666431427002
step: 44, train loss: 1.4949662685394287, train acuracy: 0.5859375
step: 44, val loss: 1.53342604637146, val acuracy: 0.5783333778381348
step: 45, train loss: 1.5617189407348633, train acuracy: 0.46484375
step: 45, val loss: 1.581164836883545, val acuracy: 0.49133336544036865
step: 46, train loss: 1.5069520473480225, train acuracy: 0.546875
step: 46, val loss: 1.5231391191482544, val acuracy: 0.5635000467300415
step: 47, train loss: 1.4299107789993286, train acuracy: 0.6015625
step: 47, val loss: 1.5275659561157227, val acuracy: 0.5246667265892029
step: 48, train loss: 1.4234167337417603, train acuracy: 0.578125
step: 48, val loss: 1.519240140914917, val acuracy: 0.5240000486373901
step: 49, train loss: 1.461237907409668, train acuracy: 0.55859375
step: 49, val loss: 1.547353982925415, val acuracy: 0.4975000321865082
step: 50, train loss: 1.428110122680664, train acuracy: 0.5859375
step: 50, val loss: 1.561379313468933, val acuracy: 0.5128333568572998
step: 51, train loss: 1.5851911306381226, train acuracy: 0.53125
step: 51, val loss: 1.5644481182098389, val acuracy: 0.5254999995231628
step: 52, train loss: 1.5541918277740479, train acuracy: 0.5390625
step: 52, val loss: 1.5598505735397339, val acuracy: 0.5285000801086426
step: 53, train loss: 1.6488404273986816, train acuracy: 0.49609375
step: 53, val loss: 1.5579079389572144, val acuracy: 0.5318333506584167
step: 54, train loss: 1.4184130430221558, train acuracy: 0.56640625
step: 54, val loss: 1.5539847612380981, val acuracy: 0.5321667194366455
step: 55, train loss: 1.5460262298583984, train acuracy: 0.5390625
step: 55, val loss: 1.5866913795471191, val acuracy: 0.5073333978652954
step: 56, train loss: 1.4537345170974731, train acuracy: 0.578125
step: 56, val loss: 1.5552154779434204, val acuracy: 0.5390000343322754
step: 57, train loss: 1.6128346920013428, train acuracy: 0.4765625
step: 57, val loss: 1.6675260066986084, val acuracy: 0.46000003814697266
step: 58, train loss: 1.6441105604171753, train acuracy: 0.4609375
step: 58, val loss: 1.7244151830673218, val acuracy: 0.437166690826416
step: 59, train loss: 1.6720085144042969, train acuracy: 0.484375
step: 59, val loss: 1.7041223049163818, val acuracy: 0.4545000195503235
step: 60, train loss: 1.664892554283142, train acuracy: 0.48046875
step: 60, val loss: 1.7030112743377686, val acuracy: 0.4568333327770233
step: 61, train loss: 1.7165522575378418, train acuracy: 0.4453125
step: 61, val loss: 1.6945018768310547, val acuracy: 0.46683335304260254
step: 62, train loss: 1.7362366914749146, train acuracy: 0.41796875
step: 62, val loss: 1.7828516960144043, val acuracy: 0.41083335876464844
step: 63, train loss: 1.7422902584075928, train acuracy: 0.421875
step: 63, val loss: 1.7564942836761475, val acuracy: 0.4348333477973938
step: 64, train loss: 1.7006162405014038, train acuracy: 0.46484375
step: 64, val loss: 1.7521591186523438, val acuracy: 0.43666669726371765
step: 65, train loss: 1.6686233282089233, train acuracy: 0.49609375
step: 65, val loss: 1.7396904230117798, val acuracy: 0.46250003576278687
step: 66, train loss: 1.673923373222351, train acuracy: 0.49609375
step: 66, val loss: 1.7298874855041504, val acuracy: 0.46666666865348816
step: 67, train loss: 1.6626027822494507, train acuracy: 0.4921875
step: 67, val loss: 1.7134370803833008, val acuracy: 0.46933332085609436
step: 68, train loss: 1.6995078325271606, train acuracy: 0.44140625
step: 68, val loss: 1.6886790990829468, val acuracy: 0.46033331751823425
step: 69, train loss: 1.6684763431549072, train acuracy: 0.484375
step: 69, val loss: 1.6575196981430054, val acuracy: 0.4819999933242798
step: 70, train loss: 1.6801345348358154, train acuracy: 0.3203125
step: 70, val loss: 1.6746283769607544, val acuracy: 0.3238333463668823
step: 71, train loss: 1.4582560062408447, train acuracy: 0.56640625
step: 71, val loss: 1.4575080871582031, val acuracy: 0.5386666655540466
step: 72, train loss: 1.3876981735229492, train acuracy: 0.55859375
step: 72, val loss: 1.4467265605926514, val acuracy: 0.5455000400543213
step: 73, train loss: 1.4285005331039429, train acuracy: 0.49609375
step: 73, val loss: 1.3726454973220825, val acuracy: 0.48483335971832275
step: 74, train loss: 1.3565808534622192, train acuracy: 0.58984375
step: 74, val loss: 1.3744066953659058, val acuracy: 0.5643333792686462
step: 75, train loss: 0.9592992663383484, train acuracy: 0.71875
step: 75, val loss: 1.0522522926330566, val acuracy: 0.6865000128746033
step: 76, train loss: 0.9850161671638489, train acuracy: 0.7265625
step: 76, val loss: 1.0214073657989502, val acuracy: 0.7053333520889282
step: 77, train loss: 1.013516902923584, train acuracy: 0.7109375
step: 77, val loss: 1.031737208366394, val acuracy: 0.7024999856948853
step: 78, train loss: 1.0300209522247314, train acuracy: 0.7109375
step: 78, val loss: 1.055472493171692, val acuracy: 0.7168333530426025
step: 79, train loss: 0.9720655083656311, train acuracy: 0.72265625
step: 79, val loss: 1.0400207042694092, val acuracy: 0.690500020980835
step: 80, train loss: 1.1018964052200317, train acuracy: 0.73046875
step: 80, val loss: 1.1089895963668823, val acuracy: 0.7160000205039978
step: 81, train loss: 1.0742288827896118, train acuracy: 0.71484375
step: 81, val loss: 1.0266385078430176, val acuracy: 0.7281667590141296
step: 82, train loss: 1.1201810836791992, train acuracy: 0.6953125
step: 82, val loss: 1.063113808631897, val acuracy: 0.7283334136009216
step: 83, train loss: 1.0381286144256592, train acuracy: 0.7265625
step: 83, val loss: 1.0586578845977783, val acuracy: 0.7290000915527344
step: 84, train loss: 0.992639422416687, train acuracy: 0.75
step: 84, val loss: 1.0587451457977295, val acuracy: 0.7283333539962769
step: 85, train loss: 1.1178383827209473, train acuracy: 0.6796875
step: 85, val loss: 1.0580365657806396, val acuracy: 0.7148333787918091
step: 86, train loss: 1.0908578634262085, train acuracy: 0.69921875
step: 86, val loss: 1.0725098848342896, val acuracy: 0.7130000591278076
step: 87, train loss: 1.06179678440094, train acuracy: 0.69921875
step: 87, val loss: 1.0711212158203125, val acuracy: 0.7143333554267883
step: 88, train loss: 1.011594533920288, train acuracy: 0.76953125
step: 88, val loss: 1.0699036121368408, val acuracy: 0.7171667218208313
step: 89, train loss: 1.0245418548583984, train acuracy: 0.7578125
step: 89, val loss: 1.0695215463638306, val acuracy: 0.717833399772644
step: 90, train loss: 1.0638513565063477, train acuracy: 0.7109375
step: 90, val loss: 1.074249267578125, val acuracy: 0.7118334174156189
step: 91, train loss: 5.45172119140625, train acuracy: 0.1875
step: 91, val loss: 5.547296524047852, val acuracy: 0.19433332979679108
step: 92, train loss: 1.9630827903747559, train acuracy: 0.31640625
step: 92, val loss: 2.008758068084717, val acuracy: 0.3108333647251129
step: 93, train loss: 1.9863557815551758, train acuracy: 0.37109375
step: 93, val loss: 2.0230472087860107, val acuracy: 0.31283336877822876
step: 94, train loss: 1.9902430772781372, train acuracy: 0.33203125
step: 94, val loss: 1.997133731842041, val acuracy: 0.32350000739097595
step: 95, train loss: 1.9303910732269287, train acuracy: 0.359375
step: 95, val loss: 1.9748295545578003, val acuracy: 0.31716668605804443
step: 96, train loss: 2.0407426357269287, train acuracy: 0.29296875
step: 96, val loss: 1.9754893779754639, val acuracy: 0.3161666691303253
step: 97, train loss: 1.9639394283294678, train acuracy: 0.3125
step: 97, val loss: 1.9748961925506592, val acuracy: 0.31566667556762695
step: 98, train loss: 2.0060830116271973, train acuracy: 0.3125
step: 98, val loss: 1.9747387170791626, val acuracy: 0.3153333365917206
step: 99, train loss: 1.9744670391082764, train acuracy: 0.30859375
step: 99, val loss: 1.9747185707092285, val acuracy: 0.3160000145435333
step: 100, train loss: 1.987708568572998, train acuracy: 0.31640625
step: 100, val loss: 1.9746618270874023, val acuracy: 0.3163333535194397
step: 101, train loss: 1.987624168395996, train acuracy: 0.3359375
step: 101, val loss: 1.974623203277588, val acuracy: 0.3165000081062317
step: 102, train loss: 1.9789857864379883, train acuracy: 0.328125
step: 102, val loss: 1.973952054977417, val acuracy: 0.31150001287460327
step: 103, train loss: 1.9704017639160156, train acuracy: 0.31640625
step: 103, val loss: 1.9789963960647583, val acuracy: 0.2890000343322754
step: 104, train loss: 1.9836771488189697, train acuracy: 0.29296875
step: 104, val loss: 1.9784544706344604, val acuracy: 0.28966668248176575
step: 105, train loss: 2.0084805488586426, train acuracy: 0.28125
step: 105, val loss: 1.9767102003097534, val acuracy: 0.28583332896232605
step: 106, train loss: 1.9873921871185303, train acuracy: 0.30859375
step: 106, val loss: 1.976203203201294, val acuracy: 0.2866666615009308
step: 107, train loss: 1.9351320266723633, train acuracy: 0.3125
step: 107, val loss: 1.9761155843734741, val acuracy: 0.2865000069141388
step: 108, train loss: 1.9606422185897827, train acuracy: 0.29296875
step: 108, val loss: 1.9680626392364502, val acuracy: 0.27766668796539307
step: 109, train loss: 2.0004653930664062, train acuracy: 0.265625
step: 109, val loss: 1.9688719511032104, val acuracy: 0.28183335065841675
step: 110, train loss: 1.9141972064971924, train acuracy: 0.328125
step: 110, val loss: 1.9519466161727905, val acuracy: 0.32466667890548706
step: 111, train loss: 1.9648782014846802, train acuracy: 0.23828125
step: 111, val loss: 1.9647647142410278, val acuracy: 0.23233333230018616
step: 112, train loss: 1.9478342533111572, train acuracy: 0.34765625
step: 112, val loss: 1.9601643085479736, val acuracy: 0.32466667890548706
step: 113, train loss: 1.872998595237732, train acuracy: 0.3671875
step: 113, val loss: 1.904133915901184, val acuracy: 0.35333335399627686
step: 114, train loss: 1.5727683305740356, train acuracy: 0.42578125
step: 114, val loss: 1.6364753246307373, val acuracy: 0.41333332657814026
step: 115, train loss: 6.188224792480469, train acuracy: 0.3203125
step: 115, val loss: 6.524134159088135, val acuracy: 0.3070000410079956
step: 116, train loss: 5.633694171905518, train acuracy: 0.15234375
step: 116, val loss: 5.992473602294922, val acuracy: 0.12016665935516357
step: 117, train loss: 6.067183494567871, train acuracy: 0.11328125
step: 117, val loss: 6.119925498962402, val acuracy: 0.09749999642372131
step: 118, train loss: 5.850036144256592, train acuracy: 0.15234375
step: 118, val loss: 5.301787376403809, val acuracy: 0.1978333443403244
step: 119, train loss: 2.191723346710205, train acuracy: 0.2421875
step: 119, val loss: 2.3381359577178955, val acuracy: 0.23766666650772095
step: 120, train loss: 2.3285436630249023, train acuracy: 0.1875
step: 120, val loss: 2.3646678924560547, val acuracy: 0.16366665065288544
step: 121, train loss: 2.338721752166748, train acuracy: 0.19140625
step: 121, val loss: 2.4329721927642822, val acuracy: 0.20633333921432495
step: 122, train loss: 2.0603010654449463, train acuracy: 0.234375
step: 122, val loss: 2.1544532775878906, val acuracy: 0.21683335304260254
step: 123, train loss: 2.14304256439209, train acuracy: 0.33984375
step: 123, val loss: 2.136725425720215, val acuracy: 0.3243333399295807
step: 124, train loss: 1.9385623931884766, train acuracy: 0.37890625
step: 124, val loss: 2.0025131702423096, val acuracy: 0.3828333616256714
step: 125, train loss: 1.6598964929580688, train acuracy: 0.484375
step: 125, val loss: 1.6948908567428589, val acuracy: 0.4635000228881836
step: 126, train loss: 1.5922496318817139, train acuracy: 0.484375
step: 126, val loss: 1.7020752429962158, val acuracy: 0.4726666808128357
step: 127, train loss: 1.5422782897949219, train acuracy: 0.5
step: 127, val loss: 1.5980361700057983, val acuracy: 0.49116671085357666
step: 128, train loss: 1.3902807235717773, train acuracy: 0.53125
step: 128, val loss: 1.3803508281707764, val acuracy: 0.5590000748634338
step: 129, train loss: 1.3562904596328735, train acuracy: 0.59375
step: 129, val loss: 1.3191362619400024, val acuracy: 0.5983334183692932
step: 130, train loss: 1.0229215621948242, train acuracy: 0.66796875
step: 130, val loss: 1.1517596244812012, val acuracy: 0.6431666612625122
step: 131, train loss: 1.0724291801452637, train acuracy: 0.63671875
step: 131, val loss: 1.130968451499939, val acuracy: 0.6501666903495789
step: 132, train loss: 0.9654342532157898, train acuracy: 0.6953125
step: 132, val loss: 1.0601000785827637, val acuracy: 0.6321666836738586
step: 133, train loss: 0.8362536430358887, train acuracy: 0.74609375
step: 133, val loss: 0.8970828056335449, val acuracy: 0.7235000729560852
step: 134, train loss: 0.7781615257263184, train acuracy: 0.73046875
step: 134, val loss: 0.8126381039619446, val acuracy: 0.7366667985916138
step: 135, train loss: 0.7258493900299072, train acuracy: 0.73046875
step: 135, val loss: 0.8878170251846313, val acuracy: 0.708166778087616
step: 136, train loss: 0.5695104598999023, train acuracy: 0.80859375
step: 136, val loss: 0.8566335439682007, val acuracy: 0.7356667518615723
step: 137, train loss: 0.6948738098144531, train acuracy: 0.765625
step: 137, val loss: 0.7568461298942566, val acuracy: 0.7571667432785034
step: 138, train loss: 0.5449166297912598, train acuracy: 0.796875
step: 138, val loss: 0.7988718748092651, val acuracy: 0.7448334693908691
step: 139, train loss: 0.7387113571166992, train acuracy: 0.75390625
step: 139, val loss: 0.8485269546508789, val acuracy: 0.7134999632835388
step: 140, train loss: 0.849867582321167, train acuracy: 0.7421875
step: 140, val loss: 0.8050605058670044, val acuracy: 0.7380000948905945
step: 141, train loss: 0.8295528292655945, train acuracy: 0.69921875
step: 141, val loss: 0.8913735747337341, val acuracy: 0.6971666812896729
step: 142, train loss: 0.9488375782966614, train acuracy: 0.73828125
step: 142, val loss: 0.9329607486724854, val acuracy: 0.7066666483879089
step: 143, train loss: 0.8352761268615723, train acuracy: 0.71484375
step: 143, val loss: 0.9807950854301453, val acuracy: 0.677333414554596
step: 144, train loss: 0.6620146632194519, train acuracy: 0.80859375
step: 144, val loss: 0.7025002241134644, val acuracy: 0.7855000495910645
step: 145, train loss: 0.6966250538825989, train acuracy: 0.78515625
step: 145, val loss: 0.7422575354576111, val acuracy: 0.7748333215713501
step: 146, train loss: 0.856228232383728, train acuracy: 0.7421875
step: 146, val loss: 0.8427273631095886, val acuracy: 0.7305000424385071
step: 147, train loss: 0.8950967192649841, train acuracy: 0.703125
step: 147, val loss: 0.947739839553833, val acuracy: 0.7030000686645508
step: 148, train loss: 0.8349159955978394, train acuracy: 0.71875
step: 148, val loss: 0.8909618258476257, val acuracy: 0.7088333368301392
step: 149, train loss: 0.9744127988815308, train acuracy: 0.6640625
step: 149, val loss: 0.8634033799171448, val acuracy: 0.7203333973884583
step: 150, train loss: 0.7943457961082458, train acuracy: 0.71875
step: 150, val loss: 0.8620051145553589, val acuracy: 0.7171667218208313
step: 151, train loss: 0.646727442741394, train acuracy: 0.76171875
step: 151, val loss: 0.8107938766479492, val acuracy: 0.7340000867843628
step: 152, train loss: 1.3252735137939453, train acuracy: 0.6171875
step: 152, val loss: 1.3861114978790283, val acuracy: 0.6165000200271606
step: 153, train loss: 0.8812732100486755, train acuracy: 0.71875
step: 153, val loss: 0.893686830997467, val acuracy: 0.7060000896453857
step: 154, train loss: 0.819122850894928, train acuracy: 0.75
step: 154, val loss: 0.9578081369400024, val acuracy: 0.6795000433921814
step: 155, train loss: 1.121227502822876, train acuracy: 0.6328125
step: 155, val loss: 1.040656328201294, val acuracy: 0.6571667790412903
step: 156, train loss: 1.0482145547866821, train acuracy: 0.625
step: 156, val loss: 1.0564393997192383, val acuracy: 0.6486667394638062
step: 157, train loss: 0.7246636152267456, train acuracy: 0.76171875
step: 157, val loss: 0.9017027020454407, val acuracy: 0.7095000743865967
step: 158, train loss: 0.9521963000297546, train acuracy: 0.703125
step: 158, val loss: 0.8911316394805908, val acuracy: 0.7173333764076233
step: 159, train loss: 0.7747882604598999, train acuracy: 0.734375
step: 159, val loss: 0.9331030249595642, val acuracy: 0.6886667013168335
step: 160, train loss: 0.9542088508605957, train acuracy: 0.69921875
step: 160, val loss: 0.9209696054458618, val acuracy: 0.7035000920295715
step: 161, train loss: 0.8936290740966797, train acuracy: 0.67578125
step: 161, val loss: 0.9178118705749512, val acuracy: 0.7051666975021362
step: 162, train loss: 0.815781831741333, train acuracy: 0.7265625
step: 162, val loss: 0.9152575135231018, val acuracy: 0.7068334221839905
step: 163, train loss: 0.8902348875999451, train acuracy: 0.6953125
step: 163, val loss: 0.914119303226471, val acuracy: 0.7076666951179504
step: 164, train loss: 0.9056116938591003, train acuracy: 0.6953125
step: 164, val loss: 0.9137042760848999, val acuracy: 0.7074999809265137
step: 165, train loss: 0.8527645468711853, train acuracy: 0.70703125
step: 165, val loss: 0.9126017689704895, val acuracy: 0.7090001106262207
step: 166, train loss: 0.9740960597991943, train acuracy: 0.64453125
step: 166, val loss: 0.911619246006012, val acuracy: 0.7085000872612
step: 167, train loss: 0.8849642872810364, train acuracy: 0.7109375
step: 167, val loss: 0.9115439653396606, val acuracy: 0.7081667184829712
step: 168, train loss: 0.9456969499588013, train acuracy: 0.69140625
step: 168, val loss: 0.911613404750824, val acuracy: 0.7073333859443665
step: 169, train loss: 0.8733450770378113, train acuracy: 0.70703125
step: 169, val loss: 0.9303387403488159, val acuracy: 0.7013333439826965
step: 170, train loss: 1.0379130840301514, train acuracy: 0.64453125
step: 170, val loss: 0.9187217950820923, val acuracy: 0.7059999704360962
step: 171, train loss: 0.8765912652015686, train acuracy: 0.69921875
step: 171, val loss: 1.0560603141784668, val acuracy: 0.6730000376701355
step: 172, train loss: 0.9435438513755798, train acuracy: 0.69921875
step: 172, val loss: 1.0282331705093384, val acuracy: 0.6580000519752502
step: 173, train loss: 0.9814475774765015, train acuracy: 0.69921875
step: 173, val loss: 0.9408127665519714, val acuracy: 0.6916667222976685
step: 174, train loss: 0.9616772532463074, train acuracy: 0.66015625
step: 174, val loss: 0.9585459232330322, val acuracy: 0.6788334250450134
step: 175, train loss: 0.9459265470504761, train acuracy: 0.6875
step: 175, val loss: 0.930435836315155, val acuracy: 0.6856667399406433
step: 176, train loss: 0.9478098154067993, train acuracy: 0.6640625
step: 176, val loss: 0.9538626670837402, val acuracy: 0.6700000762939453
step: 177, train loss: 0.901870846748352, train acuracy: 0.69921875
step: 177, val loss: 0.9744176268577576, val acuracy: 0.6728334426879883
step: 178, train loss: 0.9430956840515137, train acuracy: 0.6484375
step: 178, val loss: 0.9520038366317749, val acuracy: 0.6673333644866943
step: 179, train loss: 1.0270646810531616, train acuracy: 0.67578125
step: 179, val loss: 0.9990159273147583, val acuracy: 0.674000084400177
step: 180, train loss: 0.9438776969909668, train acuracy: 0.67578125
step: 180, val loss: 0.9895637035369873, val acuracy: 0.6743333339691162
step: 181, train loss: 1.1153544187545776, train acuracy: 0.64453125
step: 181, val loss: 1.0976765155792236, val acuracy: 0.6245000958442688
step: 182, train loss: 0.8388046622276306, train acuracy: 0.73046875
step: 182, val loss: 1.0327436923980713, val acuracy: 0.6621667742729187
step: 183, train loss: 0.9413920640945435, train acuracy: 0.72265625
step: 183, val loss: 0.9933251738548279, val acuracy: 0.6711666584014893
step: 184, train loss: 1.0437196493148804, train acuracy: 0.66796875
step: 184, val loss: 1.0162267684936523, val acuracy: 0.6636667847633362
step: 185, train loss: 0.9718773365020752, train acuracy: 0.70703125
step: 185, val loss: 1.0209259986877441, val acuracy: 0.6578332781791687
step: 186, train loss: 1.074676275253296, train acuracy: 0.67578125
step: 186, val loss: 1.015155553817749, val acuracy: 0.6600000262260437
step: 187, train loss: 0.8717824220657349, train acuracy: 0.71484375
step: 187, val loss: 0.9990603923797607, val acuracy: 0.675000011920929
step: 188, train loss: 1.1928226947784424, train acuracy: 0.6015625
step: 188, val loss: 1.021531581878662, val acuracy: 0.655666708946228
step: 189, train loss: 0.8780046701431274, train acuracy: 0.69921875
step: 189, val loss: 1.0170403718948364, val acuracy: 0.658833384513855
step: 190, train loss: 1.005174160003662, train acuracy: 0.6640625
step: 190, val loss: 1.0153695344924927, val acuracy: 0.659333348274231
step: 191, train loss: 1.0446643829345703, train acuracy: 0.63671875
step: 191, val loss: 1.038594365119934, val acuracy: 0.6401667594909668
step: 192, train loss: 1.011289358139038, train acuracy: 0.6953125
step: 192, val loss: 1.0859745740890503, val acuracy: 0.6451667547225952
step: 193, train loss: 1.0209230184555054, train acuracy: 0.63671875
step: 193, val loss: 1.0473012924194336, val acuracy: 0.6306667327880859
step: 194, train loss: 0.9374054074287415, train acuracy: 0.6875
step: 194, val loss: 1.0429192781448364, val acuracy: 0.6530001163482666
step: 195, train loss: 0.9142223000526428, train acuracy: 0.67578125
step: 195, val loss: 1.031954050064087, val acuracy: 0.6420000791549683
step: 196, train loss: 0.9026299715042114, train acuracy: 0.71875
step: 196, val loss: 1.0986632108688354, val acuracy: 0.6530000567436218
step: 197, train loss: 0.9996386170387268, train acuracy: 0.65625
step: 197, val loss: 1.069787621498108, val acuracy: 0.6276666522026062
step: 198, train loss: 0.982392430305481, train acuracy: 0.6796875
step: 198, val loss: 1.107787847518921, val acuracy: 0.6438333988189697
step: 199, train loss: 1.0553334951400757, train acuracy: 0.61328125
step: 199, val loss: 1.0539727210998535, val acuracy: 0.6295000314712524
step: 200, train loss: 1.0685410499572754, train acuracy: 0.6484375
step: 200, val loss: 1.0462977886199951, val acuracy: 0.6316666603088379
step: 201, train loss: 0.8950905799865723, train acuracy: 0.67578125
step: 201, val loss: 1.0449188947677612, val acuracy: 0.6326667070388794
step: 202, train loss: 0.9986403584480286, train acuracy: 0.6484375
step: 202, val loss: 1.0432653427124023, val acuracy: 0.6428333520889282
step: 203, train loss: 1.1558969020843506, train acuracy: 0.55859375
step: 203, val loss: 1.1871410608291626, val acuracy: 0.5661666989326477
step: 204, train loss: 1.1264091730117798, train acuracy: 0.625
step: 204, val loss: 1.1321816444396973, val acuracy: 0.6040000319480896
step: 205, train loss: 4.771892070770264, train acuracy: 0.19140625
step: 205, val loss: 5.300097465515137, val acuracy: 0.1508333384990692
step: 206, train loss: 1.656684398651123, train acuracy: 0.51953125
step: 206, val loss: 1.8996471166610718, val acuracy: 0.468666672706604
step: 207, train loss: 1.7296043634414673, train acuracy: 0.59375
step: 207, val loss: 1.8946928977966309, val acuracy: 0.502500057220459
step: 208, train loss: 1.7785441875457764, train acuracy: 0.578125
step: 208, val loss: 1.8190178871154785, val acuracy: 0.5120000839233398
step: 209, train loss: 1.9703471660614014, train acuracy: 0.50390625
step: 209, val loss: 1.8152239322662354, val acuracy: 0.5110000371932983
step: 210, train loss: 1.6901482343673706, train acuracy: 0.5078125
step: 210, val loss: 1.8121631145477295, val acuracy: 0.5115000009536743
step: 211, train loss: 1.7956769466400146, train acuracy: 0.5390625
step: 211, val loss: 1.8342868089675903, val acuracy: 0.5010000467300415
step: 212, train loss: 1.8299208879470825, train acuracy: 0.5078125
step: 212, val loss: 1.829148769378662, val acuracy: 0.5018333792686462
step: 213, train loss: 1.6178333759307861, train acuracy: 0.56640625
step: 213, val loss: 1.8276307582855225, val acuracy: 0.5118334293365479
step: 214, train loss: 1.7656238079071045, train acuracy: 0.51953125
step: 214, val loss: 1.8556873798370361, val acuracy: 0.4945000112056732
step: 215, train loss: 1.6860729455947876, train acuracy: 0.546875
step: 215, val loss: 1.8390401601791382, val acuracy: 0.503166675567627
step: 216, train loss: 1.9134912490844727, train acuracy: 0.49609375
step: 216, val loss: 1.8619372844696045, val acuracy: 0.4985000491142273
step: 217, train loss: 1.8099544048309326, train acuracy: 0.5546875
step: 217, val loss: 1.8575522899627686, val acuracy: 0.49800002574920654
step: 218, train loss: 1.7095500230789185, train acuracy: 0.52734375
step: 218, val loss: 1.8528697490692139, val acuracy: 0.5000000596046448
step: 219, train loss: 2.089287042617798, train acuracy: 0.484375
step: 219, val loss: 1.8691859245300293, val acuracy: 0.4891667068004608
step: 220, train loss: 1.9740800857543945, train acuracy: 0.44921875
step: 220, val loss: 1.849623680114746, val acuracy: 0.47016671299934387
step: 221, train loss: 1.6029866933822632, train acuracy: 0.5234375
step: 221, val loss: 1.940551519393921, val acuracy: 0.4360000193119049
step: 222, train loss: 1.9131028652191162, train acuracy: 0.5
step: 222, val loss: 2.0427639484405518, val acuracy: 0.476666659116745
step: 223, train loss: 1.9628384113311768, train acuracy: 0.4296875
step: 223, val loss: 1.932971715927124, val acuracy: 0.45649999380111694
step: 224, train loss: 2.101362705230713, train acuracy: 0.46875
step: 224, val loss: 1.9153355360031128, val acuracy: 0.4611666798591614
step: 225, train loss: 1.7433428764343262, train acuracy: 0.5234375
step: 225, val loss: 1.9990825653076172, val acuracy: 0.5091666579246521
step: 226, train loss: 2.027801275253296, train acuracy: 0.4140625
step: 226, val loss: 1.956047773361206, val acuracy: 0.39233335852622986
step: 227, train loss: 1.923766016960144, train acuracy: 0.50390625
step: 227, val loss: 2.0318801403045654, val acuracy: 0.5130000114440918
step: 228, train loss: 1.9344803094863892, train acuracy: 0.4140625
step: 228, val loss: 1.9524102210998535, val acuracy: 0.3986666798591614
step: 229, train loss: 1.9447041749954224, train acuracy: 0.4609375
step: 229, val loss: 1.9220378398895264, val acuracy: 0.47550004720687866
step: 230, train loss: 1.937111258506775, train acuracy: 0.3828125
step: 230, val loss: 1.9438625574111938, val acuracy: 0.4025000035762787
step: 231, train loss: 1.8421497344970703, train acuracy: 0.41015625
step: 231, val loss: 1.9378114938735962, val acuracy: 0.40716665983200073
step: 232, train loss: 1.8251702785491943, train acuracy: 0.4921875
step: 232, val loss: 1.923116683959961, val acuracy: 0.4443333148956299
step: 233, train loss: 1.8563567399978638, train acuracy: 0.4375
step: 233, val loss: 1.9200081825256348, val acuracy: 0.4475000500679016
step: 234, train loss: 1.929142713546753, train acuracy: 0.46875
step: 234, val loss: 1.9175918102264404, val acuracy: 0.4475000500679016
step: 235, train loss: 1.8962225914001465, train acuracy: 0.43359375
step: 235, val loss: 1.9146865606307983, val acuracy: 0.42466670274734497
step: 236, train loss: 2.1542892456054688, train acuracy: 0.33203125
step: 236, val loss: 1.9512770175933838, val acuracy: 0.38850003480911255
step: 237, train loss: 2.0075273513793945, train acuracy: 0.390625
step: 237, val loss: 1.9500336647033691, val acuracy: 0.38866668939590454
step: 238, train loss: 1.9175151586532593, train acuracy: 0.3984375
step: 238, val loss: 1.9479334354400635, val acuracy: 0.3891666531562805
step: 239, train loss: 1.9351930618286133, train acuracy: 0.43359375
step: 239, val loss: 1.947350263595581, val acuracy: 0.4009999930858612
step: 240, train loss: 1.9785890579223633, train acuracy: 0.37890625
step: 240, val loss: 1.9445101022720337, val acuracy: 0.4039999842643738
step: 241, train loss: 2.122966766357422, train acuracy: 0.31640625
step: 241, val loss: 1.9607088565826416, val acuracy: 0.3803333640098572
step: 242, train loss: 1.8537899255752563, train acuracy: 0.4375
step: 242, val loss: 1.9434208869934082, val acuracy: 0.4110000431537628
step: 243, train loss: 1.9639616012573242, train acuracy: 0.421875
step: 243, val loss: 1.9419819116592407, val acuracy: 0.4138333797454834
step: 244, train loss: 4.290894985198975, train acuracy: 0.3671875
step: 244, val loss: 4.560822486877441, val acuracy: 0.35833337903022766
step: 245, train loss: 3.9633231163024902, train acuracy: 0.265625
step: 245, val loss: 3.999540090560913, val acuracy: 0.26883333921432495
step: 246, train loss: 2.1187920570373535, train acuracy: 0.30859375
step: 246, val loss: 2.14751935005188, val acuracy: 0.2853333353996277
step: 247, train loss: 1.5736619234085083, train acuracy: 0.4453125
step: 247, val loss: 1.6931052207946777, val acuracy: 0.3723333775997162
step: 248, train loss: 1.6630737781524658, train acuracy: 0.44140625
step: 248, val loss: 1.6762818098068237, val acuracy: 0.4010000228881836
step: 249, train loss: 1.3104236125946045, train acuracy: 0.57421875
step: 249, val loss: 1.4130522012710571, val acuracy: 0.5189999938011169
step: 250, train loss: 1.4732081890106201, train acuracy: 0.51953125
step: 250, val loss: 1.4118878841400146, val acuracy: 0.5355000495910645
step: 251, train loss: 1.4777730703353882, train acuracy: 0.5234375
step: 251, val loss: 1.4026919603347778, val acuracy: 0.5426667332649231
step: 252, train loss: 1.4236358404159546, train acuracy: 0.53515625
step: 252, val loss: 1.399833083152771, val acuracy: 0.5441666841506958
step: 253, train loss: 1.3134489059448242, train acuracy: 0.58203125
step: 253, val loss: 1.439379334449768, val acuracy: 0.5383333563804626
step: 254, train loss: 1.377753496170044, train acuracy: 0.55078125
step: 254, val loss: 1.3891187906265259, val acuracy: 0.5248333215713501
step: 255, train loss: 1.5126724243164062, train acuracy: 0.48828125
step: 255, val loss: 1.3922333717346191, val acuracy: 0.5440000295639038
step: 256, train loss: 1.430793046951294, train acuracy: 0.546875
step: 256, val loss: 1.3804165124893188, val acuracy: 0.534000039100647
step: 257, train loss: 1.5082852840423584, train acuracy: 0.5234375
step: 257, val loss: 1.4458562135696411, val acuracy: 0.5213333368301392
step: 258, train loss: 1.361778736114502, train acuracy: 0.5625
step: 258, val loss: 1.4371602535247803, val acuracy: 0.5265000462532043
step: 259, train loss: 1.2525556087493896, train acuracy: 0.609375
step: 259, val loss: 1.4357523918151855, val acuracy: 0.5263333320617676
step: 260, train loss: 1.4620521068572998, train acuracy: 0.55078125
step: 260, val loss: 1.4339337348937988, val acuracy: 0.5261667370796204
step: 261, train loss: 1.4808869361877441, train acuracy: 0.5234375
step: 261, val loss: 1.4331151247024536, val acuracy: 0.5268333554267883
step: 262, train loss: 1.374316930770874, train acuracy: 0.55859375
step: 262, val loss: 1.4335302114486694, val acuracy: 0.5251666903495789
step: 263, train loss: 1.4990270137786865, train acuracy: 0.484375
step: 263, val loss: 1.42776620388031, val acuracy: 0.5235000252723694
step: 264, train loss: 1.3539997339248657, train acuracy: 0.5546875
step: 264, val loss: 1.405697226524353, val acuracy: 0.5394999980926514
step: 265, train loss: 1.0498546361923218, train acuracy: 0.6953125
step: 265, val loss: 1.1520265340805054, val acuracy: 0.6163333654403687
step: 266, train loss: 1.0262047052383423, train acuracy: 0.67578125
step: 266, val loss: 1.3681275844573975, val acuracy: 0.6011667251586914
step: 267, train loss: 0.871802806854248, train acuracy: 0.73828125
step: 267, val loss: 0.9674745202064514, val acuracy: 0.6990000009536743
step: 268, train loss: 0.6516456604003906, train acuracy: 0.796875
step: 268, val loss: 0.8617742657661438, val acuracy: 0.7401667237281799
step: 269, train loss: 0.8512460589408875, train acuracy: 0.75390625
step: 269, val loss: 0.8515735268592834, val acuracy: 0.7430000901222229
step: 270, train loss: 0.8509024381637573, train acuracy: 0.7421875
step: 270, val loss: 0.9422555565834045, val acuracy: 0.7215000987052917
step: 271, train loss: 0.8276662826538086, train acuracy: 0.71875
step: 271, val loss: 0.8160465955734253, val acuracy: 0.7513333559036255
step: 272, train loss: 0.8179290890693665, train acuracy: 0.7578125
step: 272, val loss: 0.8121649026870728, val acuracy: 0.7536667585372925
step: 273, train loss: 0.8227120637893677, train acuracy: 0.73046875
step: 273, val loss: 0.8099813461303711, val acuracy: 0.755000114440918
step: 274, train loss: 0.6716280579566956, train acuracy: 0.79296875
step: 274, val loss: 0.8166979551315308, val acuracy: 0.751500129699707
step: 275, train loss: 0.8949507474899292, train acuracy: 0.734375
step: 275, val loss: 0.8646701574325562, val acuracy: 0.7423334121704102
step: 276, train loss: 0.8026999235153198, train acuracy: 0.734375
step: 276, val loss: 0.8267800807952881, val acuracy: 0.7395000457763672
step: 277, train loss: 0.7347345352172852, train acuracy: 0.75
step: 277, val loss: 0.8237167596817017, val acuracy: 0.7405000925064087
step: 278, train loss: 0.8716481328010559, train acuracy: 0.73046875
step: 278, val loss: 0.8585444688796997, val acuracy: 0.7428333759307861
step: 279, train loss: 0.8003875017166138, train acuracy: 0.7578125
step: 279, val loss: 0.818501353263855, val acuracy: 0.7500001192092896
step: 280, train loss: 0.7588999271392822, train acuracy: 0.7578125
step: 280, val loss: 0.8172404766082764, val acuracy: 0.7513333559036255
step: 281, train loss: 0.8268725872039795, train acuracy: 0.765625
step: 281, val loss: 0.8767939805984497, val acuracy: 0.7303333878517151
step: 282, train loss: 0.8616736531257629, train acuracy: 0.73828125
step: 282, val loss: 1.069068431854248, val acuracy: 0.6891666650772095
step: 283, train loss: 0.8195508122444153, train acuracy: 0.703125
step: 283, val loss: 0.8757667541503906, val acuracy: 0.7170000076293945
step: 284, train loss: 0.7642404437065125, train acuracy: 0.74609375
step: 284, val loss: 0.8461369276046753, val acuracy: 0.7306667566299438
step: 285, train loss: 0.8036262392997742, train acuracy: 0.734375
step: 285, val loss: 0.8547205924987793, val acuracy: 0.7251666784286499
step: 286, train loss: 0.8480750322341919, train acuracy: 0.75390625
step: 286, val loss: 0.8528722524642944, val acuracy: 0.7256667613983154
step: 287, train loss: 0.8652199506759644, train acuracy: 0.73828125
step: 287, val loss: 0.852019190788269, val acuracy: 0.7258334159851074
step: 288, train loss: 0.8196869492530823, train acuracy: 0.71875
step: 288, val loss: 0.8505764603614807, val acuracy: 0.7273334264755249
step: 289, train loss: 0.8008878827095032, train acuracy: 0.74609375
step: 289, val loss: 0.8499121069908142, val acuracy: 0.7263334393501282
step: 290, train loss: 0.8123711943626404, train acuracy: 0.73046875
step: 290, val loss: 0.8494017720222473, val acuracy: 0.7273334264755249
step: 291, train loss: 0.895366907119751, train acuracy: 0.70703125
step: 291, val loss: 0.8488079309463501, val acuracy: 0.7285000681877136
step: 292, train loss: 0.9190139770507812, train acuracy: 0.6953125
step: 292, val loss: 0.8484756946563721, val acuracy: 0.7283334136009216
step: 293, train loss: 0.7759501338005066, train acuracy: 0.7578125
step: 293, val loss: 0.8481478691101074, val acuracy: 0.7285000681877136
step: 294, train loss: 0.8505513668060303, train acuracy: 0.74609375
step: 294, val loss: 0.8481346964836121, val acuracy: 0.7285000681877136
step: 295, train loss: 0.8383012413978577, train acuracy: 0.77734375
step: 295, val loss: 0.8480602502822876, val acuracy: 0.7285000681877136
step: 296, train loss: 0.8013015985488892, train acuracy: 0.78125
step: 296, val loss: 0.8480371236801147, val acuracy: 0.7290000319480896
step: 297, train loss: 0.8303408622741699, train acuracy: 0.74609375
step: 297, val loss: 0.8475280404090881, val acuracy: 0.7283334136009216
step: 298, train loss: 0.7802557945251465, train acuracy: 0.76171875
step: 298, val loss: 0.8470027446746826, val acuracy: 0.7281667590141296
step: 299, train loss: 0.8176185488700867, train acuracy: 0.7265625
step: 299, val loss: 0.8469148278236389, val acuracy: 0.7283334136009216
step: 300, train loss: 0.853773832321167, train acuracy: 0.7109375
step: 300, val loss: 0.8598791360855103, val acuracy: 0.7168333530426025
step: 301, train loss: 0.6847870945930481, train acuracy: 0.7890625
step: 301, val loss: 0.8969927430152893, val acuracy: 0.718500018119812
step: 302, train loss: 0.8424161672592163, train acuracy: 0.7421875
step: 302, val loss: 0.8590934872627258, val acuracy: 0.718666672706604
step: 303, train loss: 0.9276101589202881, train acuracy: 0.734375
step: 303, val loss: 0.8628304600715637, val acuracy: 0.7291666865348816
step: 304, train loss: 0.7963074445724487, train acuracy: 0.734375
step: 304, val loss: 0.8593139052391052, val acuracy: 0.7315000295639038
step: 305, train loss: 0.9052911400794983, train acuracy: 0.70703125
step: 305, val loss: 0.8520044088363647, val acuracy: 0.7355000376701355
step: 306, train loss: 0.9111818671226501, train acuracy: 0.71484375
step: 306, val loss: 0.8668376803398132, val acuracy: 0.7263333797454834
step: 307, train loss: 0.7933856248855591, train acuracy: 0.75
step: 307, val loss: 0.8648492693901062, val acuracy: 0.7265000939369202
step: 308, train loss: 0.8412201404571533, train acuracy: 0.73046875
step: 308, val loss: 0.8692446947097778, val acuracy: 0.7015000581741333
step: 309, train loss: 0.6969806551933289, train acuracy: 0.81640625
step: 309, val loss: 0.889873743057251, val acuracy: 0.7266667485237122
step: 310, train loss: 0.8611337542533875, train acuracy: 0.6953125
step: 310, val loss: 0.8687623739242554, val acuracy: 0.7186667323112488
step: 311, train loss: 0.7948178052902222, train acuracy: 0.74609375
step: 311, val loss: 0.8896524310112, val acuracy: 0.6865000128746033
step: 312, train loss: 0.9253495335578918, train acuracy: 0.68359375
step: 312, val loss: 0.8784384727478027, val acuracy: 0.7115000486373901
step: 313, train loss: 0.8879649639129639, train acuracy: 0.71875
step: 313, val loss: 0.8768918514251709, val acuracy: 0.7130000591278076
step: 314, train loss: 0.841368556022644, train acuracy: 0.72265625
step: 314, val loss: 0.8758984804153442, val acuracy: 0.7128333449363708
step: 315, train loss: 0.8861820101737976, train acuracy: 0.7109375
step: 315, val loss: 0.9074235558509827, val acuracy: 0.7131667733192444
step: 316, train loss: 0.8139649629592896, train acuracy: 0.7890625
step: 316, val loss: 0.8746898174285889, val acuracy: 0.721333384513855
step: 317, train loss: 0.9801293611526489, train acuracy: 0.671875
step: 317, val loss: 0.9223765730857849, val acuracy: 0.7028334736824036
step: 318, train loss: 0.891586184501648, train acuracy: 0.72265625
step: 318, val loss: 0.8732524514198303, val acuracy: 0.7198333740234375
step: 319, train loss: 0.8309234976768494, train acuracy: 0.72265625
step: 319, val loss: 0.8913021683692932, val acuracy: 0.7113333940505981
step: 320, train loss: 0.9519537687301636, train acuracy: 0.6953125
step: 320, val loss: 0.9798965454101562, val acuracy: 0.6748334169387817
step: 321, train loss: 0.796745777130127, train acuracy: 0.75
step: 321, val loss: 0.891808032989502, val acuracy: 0.705500066280365
step: 322, train loss: 0.9554228782653809, train acuracy: 0.67578125
step: 322, val loss: 0.9420724511146545, val acuracy: 0.6791666746139526
step: 323, train loss: 0.8563582301139832, train acuracy: 0.6953125
step: 323, val loss: 0.8870107531547546, val acuracy: 0.7091667652130127
step: 324, train loss: 0.8764925003051758, train acuracy: 0.69140625
step: 324, val loss: 0.900754988193512, val acuracy: 0.6958333253860474
step: 325, train loss: 0.9027712941169739, train acuracy: 0.7109375
step: 325, val loss: 0.9505802392959595, val acuracy: 0.6896666884422302
step: 326, train loss: 0.9713541269302368, train acuracy: 0.703125
step: 326, val loss: 0.9419856667518616, val acuracy: 0.6933333873748779
step: 327, train loss: 0.878342866897583, train acuracy: 0.703125
step: 327, val loss: 0.9398810863494873, val acuracy: 0.6944999694824219
step: 328, train loss: 0.9916878938674927, train acuracy: 0.67578125
step: 328, val loss: 0.9387890696525574, val acuracy: 0.6935000419616699
step: 329, train loss: 0.9300491809844971, train acuracy: 0.68359375
step: 329, val loss: 0.9427973628044128, val acuracy: 0.6828334331512451
step: 330, train loss: 0.8775085210800171, train acuracy: 0.73046875
step: 330, val loss: 0.950077474117279, val acuracy: 0.6763333678245544
step: 331, train loss: 0.9337392449378967, train acuracy: 0.6953125
step: 331, val loss: 0.9396429657936096, val acuracy: 0.684166669845581
step: 332, train loss: 0.7710660696029663, train acuracy: 0.7734375
step: 332, val loss: 0.9378194212913513, val acuracy: 0.6831667423248291
step: 333, train loss: 0.9679347276687622, train acuracy: 0.68359375
step: 333, val loss: 0.9575735330581665, val acuracy: 0.6784999966621399
step: 334, train loss: 1.0349316596984863, train acuracy: 0.6484375
step: 334, val loss: 0.9835003614425659, val acuracy: 0.6650000810623169
step: 335, train loss: 0.9464752078056335, train acuracy: 0.67578125
step: 335, val loss: 0.9419534802436829, val acuracy: 0.6765000820159912
step: 336, train loss: 1.0962707996368408, train acuracy: 0.640625
step: 336, val loss: 0.9764320850372314, val acuracy: 0.6670000553131104
step: 337, train loss: 0.9056249260902405, train acuracy: 0.7421875
step: 337, val loss: 0.9742472171783447, val acuracy: 0.6683334112167358
step: 338, train loss: 0.9993506669998169, train acuracy: 0.67578125
step: 338, val loss: 0.9906272888183594, val acuracy: 0.6761667132377625
step: 339, train loss: 1.022922158241272, train acuracy: 0.66796875
step: 339, val loss: 0.987833559513092, val acuracy: 0.6786667108535767
step: 340, train loss: 0.9247063398361206, train acuracy: 0.70703125
step: 340, val loss: 0.9864853620529175, val acuracy: 0.6791667342185974
step: 341, train loss: 1.0084052085876465, train acuracy: 0.66015625
step: 341, val loss: 0.985851526260376, val acuracy: 0.6791667342185974
step: 342, train loss: 0.9767257571220398, train acuracy: 0.6875
step: 342, val loss: 0.9809932708740234, val acuracy: 0.6800000667572021
step: 343, train loss: 0.9981813430786133, train acuracy: 0.671875
step: 343, val loss: 1.0112746953964233, val acuracy: 0.6695000529289246
step: 344, train loss: 1.0505679845809937, train acuracy: 0.62109375
step: 344, val loss: 1.0104926824569702, val acuracy: 0.6694999933242798
step: 345, train loss: 0.8970052003860474, train acuracy: 0.703125
step: 345, val loss: 1.0159728527069092, val acuracy: 0.6636666655540466
step: 346, train loss: 0.9544519782066345, train acuracy: 0.68359375
step: 346, val loss: 1.02685546875, val acuracy: 0.6593334674835205
step: 347, train loss: 0.9780077934265137, train acuracy: 0.7109375
step: 347, val loss: 1.0077193975448608, val acuracy: 0.674500048160553
step: 348, train loss: 0.9733691811561584, train acuracy: 0.65625
step: 348, val loss: 1.0141183137893677, val acuracy: 0.6740000247955322
step: 349, train loss: 0.906333863735199, train acuracy: 0.7265625
step: 349, val loss: 1.012253999710083, val acuracy: 0.674500048160553
step: 350, train loss: 1.1078687906265259, train acuracy: 0.66015625
step: 350, val loss: 1.0146838426589966, val acuracy: 0.687333345413208
step: 351, train loss: 1.0768307447433472, train acuracy: 0.59765625
step: 351, val loss: 1.0253509283065796, val acuracy: 0.6560000777244568
step: 352, train loss: 1.0346720218658447, train acuracy: 0.6640625
step: 352, val loss: 1.0340654850006104, val acuracy: 0.6511666774749756
step: 353, train loss: 1.0862681865692139, train acuracy: 0.609375
step: 353, val loss: 1.0316145420074463, val acuracy: 0.6528333425521851
step: 354, train loss: 0.9540408849716187, train acuracy: 0.69140625
step: 354, val loss: 1.0251028537750244, val acuracy: 0.6515000462532043
step: 355, train loss: 1.0554505586624146, train acuracy: 0.65625
step: 355, val loss: 1.024114966392517, val acuracy: 0.6516667604446411
step: 356, train loss: 1.0935487747192383, train acuracy: 0.6328125
step: 356, val loss: 1.070479393005371, val acuracy: 0.6286666393280029
step: 357, train loss: 1.0857205390930176, train acuracy: 0.62890625
step: 357, val loss: 1.0313127040863037, val acuracy: 0.6598334312438965
step: 358, train loss: 0.9558892250061035, train acuracy: 0.71484375
step: 358, val loss: 1.0477349758148193, val acuracy: 0.6421667337417603
step: 359, train loss: 1.139525294303894, train acuracy: 0.578125
step: 359, val loss: 1.0437928438186646, val acuracy: 0.6513333916664124
step: 360, train loss: 1.0793997049331665, train acuracy: 0.640625
step: 360, val loss: 1.0275275707244873, val acuracy: 0.6496667265892029
step: 361, train loss: 0.8685994148254395, train acuracy: 0.73046875
step: 361, val loss: 1.0334818363189697, val acuracy: 0.6405000686645508
step: 362, train loss: 0.9871038198471069, train acuracy: 0.6640625
step: 362, val loss: 1.0430243015289307, val acuracy: 0.6420000195503235
step: 363, train loss: 1.0158969163894653, train acuracy: 0.671875
step: 363, val loss: 1.042945384979248, val acuracy: 0.6406667232513428
step: 364, train loss: 1.0235519409179688, train acuracy: 0.6640625
step: 364, val loss: 1.0498713254928589, val acuracy: 0.6308333873748779
step: 365, train loss: 1.0634758472442627, train acuracy: 0.6640625
step: 365, val loss: 1.0718125104904175, val acuracy: 0.6331666707992554
step: 366, train loss: 0.9737973213195801, train acuracy: 0.72265625
step: 366, val loss: 1.0170522928237915, val acuracy: 0.6573334336280823
step: 367, train loss: 0.9519374966621399, train acuracy: 0.703125
step: 367, val loss: 1.0125644207000732, val acuracy: 0.6581667065620422
step: 368, train loss: 0.9991464614868164, train acuracy: 0.68359375
step: 368, val loss: 1.040462613105774, val acuracy: 0.6525000333786011
step: 369, train loss: 1.0258830785751343, train acuracy: 0.64453125
step: 369, val loss: 1.016258955001831, val acuracy: 0.6628334522247314
step: 370, train loss: 1.1202365159988403, train acuracy: 0.61328125
step: 370, val loss: 1.0163859128952026, val acuracy: 0.6626666784286499
step: 371, train loss: 0.9847404360771179, train acuracy: 0.69140625
step: 371, val loss: 1.0346641540527344, val acuracy: 0.658833384513855
step: 372, train loss: 0.9986448884010315, train acuracy: 0.68359375
step: 372, val loss: 1.0321178436279297, val acuracy: 0.658833384513855
step: 373, train loss: 0.9851064682006836, train acuracy: 0.671875
step: 373, val loss: 1.030585765838623, val acuracy: 0.6580000519752502
step: 374, train loss: 0.9261067509651184, train acuracy: 0.69140625
step: 374, val loss: 1.0137420892715454, val acuracy: 0.6614999771118164
step: 375, train loss: 0.9483224749565125, train acuracy: 0.6796875
step: 375, val loss: 1.017690658569336, val acuracy: 0.65583336353302
step: 376, train loss: 1.128583312034607, train acuracy: 0.62890625
step: 376, val loss: 1.016219139099121, val acuracy: 0.6568333506584167
step: 377, train loss: 1.0458430051803589, train acuracy: 0.6875
step: 377, val loss: 1.0154353380203247, val acuracy: 0.6575000286102295
step: 378, train loss: 0.9491605758666992, train acuracy: 0.68359375
step: 378, val loss: 1.0148409605026245, val acuracy: 0.6578333973884583
step: 379, train loss: 0.9323272705078125, train acuracy: 0.703125
step: 379, val loss: 1.0141410827636719, val acuracy: 0.6578333377838135
step: 380, train loss: 1.1220215559005737, train acuracy: 0.62109375
step: 380, val loss: 1.016353726387024, val acuracy: 0.6578333377838135
step: 381, train loss: 1.0016785860061646, train acuracy: 0.6484375
step: 381, val loss: 1.0271070003509521, val acuracy: 0.6595000624656677
step: 382, train loss: 0.9542663097381592, train acuracy: 0.671875
step: 382, val loss: 1.0208845138549805, val acuracy: 0.6545000076293945
step: 383, train loss: 1.0753237009048462, train acuracy: 0.63671875
step: 383, val loss: 1.020500898361206, val acuracy: 0.6550000309944153
step: 384, train loss: 0.9628326892852783, train acuracy: 0.70703125
step: 384, val loss: 1.0201462507247925, val acuracy: 0.6536667346954346
step: 385, train loss: 1.012074589729309, train acuracy: 0.671875
step: 385, val loss: 1.02829110622406, val acuracy: 0.659000039100647
step: 386, train loss: 1.0066728591918945, train acuracy: 0.65625
step: 386, val loss: 1.032360553741455, val acuracy: 0.6465000510215759
step: 387, train loss: 1.0340412855148315, train acuracy: 0.671875
step: 387, val loss: 1.043448567390442, val acuracy: 0.6655000448226929
step: 388, train loss: 0.9179055094718933, train acuracy: 0.68359375
step: 388, val loss: 1.0396604537963867, val acuracy: 0.6491667032241821
step: 389, train loss: 1.1618424654006958, train acuracy: 0.62890625
step: 389, val loss: 1.0480185747146606, val acuracy: 0.6636667251586914
step: 390, train loss: 0.9840563535690308, train acuracy: 0.70703125
step: 390, val loss: 1.0349633693695068, val acuracy: 0.6636667251586914
step: 391, train loss: 1.0268573760986328, train acuracy: 0.68359375
step: 391, val loss: 1.0283424854278564, val acuracy: 0.6668334007263184
step: 392, train loss: 1.3392664194107056, train acuracy: 0.5625
step: 392, val loss: 1.3952984809875488, val acuracy: 0.5268333554267883
step: 393, train loss: 1.2749930620193481, train acuracy: 0.56640625
step: 393, val loss: 1.2371437549591064, val acuracy: 0.5750000476837158
step: 394, train loss: 1.2632217407226562, train acuracy: 0.578125
step: 394, val loss: 1.211680293083191, val acuracy: 0.5858334302902222
step: 395, train loss: 1.1956552267074585, train acuracy: 0.609375
step: 395, val loss: 1.1498559713363647, val acuracy: 0.6259999871253967
step: 396, train loss: 0.9610776901245117, train acuracy: 0.66796875
step: 396, val loss: 1.054162621498108, val acuracy: 0.6506667137145996
step: 397, train loss: 0.7606195211410522, train acuracy: 0.7578125
step: 397, val loss: 0.9092515110969543, val acuracy: 0.7130000591278076
step: 398, train loss: 0.983372688293457, train acuracy: 0.68359375
step: 398, val loss: 0.9337454438209534, val acuracy: 0.6896666884422302
step: 399, train loss: 0.8848443627357483, train acuracy: 0.7421875
step: 399, val loss: 0.926546037197113, val acuracy: 0.6916667222976685
2017-12-04 15:30:25.468364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:30:25.709702: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x83ee0b0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 15:30:25.710430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:30:25.710679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 15:30:25.710693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 15:30:25.710699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 15:30:25.710710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 15:30:25.710717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.4111099243164062, train acuracy: 0.11328125
step: 0, val loss: 2.5535202026367188, val acuracy: 0.10400000214576721
step: 1, train loss: 2.2893166542053223, train acuracy: 0.189453125
step: 1, val loss: 2.3203587532043457, val acuracy: 0.18050000071525574
step: 2, train loss: 2.245955467224121, train acuracy: 0.134765625
step: 2, val loss: 2.272522211074829, val acuracy: 0.09666665643453598
step: 3, train loss: 2.2446277141571045, train acuracy: 0.126953125
step: 3, val loss: 2.239598035812378, val acuracy: 0.11533332616090775
step: 4, train loss: 2.174610137939453, train acuracy: 0.388671875
step: 4, val loss: 2.174186944961548, val acuracy: 0.3931666910648346
step: 5, train loss: 1.926512360572815, train acuracy: 0.53515625
step: 5, val loss: 1.9704965353012085, val acuracy: 0.4911666512489319
step: 6, train loss: 1.8821325302124023, train acuracy: 0.373046875
step: 6, val loss: 1.9195855855941772, val acuracy: 0.3893333673477173
step: 7, train loss: 1.9609670639038086, train acuracy: 0.52734375
step: 7, val loss: 1.9757152795791626, val acuracy: 0.49916666746139526
step: 8, train loss: 1.5841281414031982, train acuracy: 0.59765625
step: 8, val loss: 1.55694580078125, val acuracy: 0.6023333668708801
step: 9, train loss: 1.655153512954712, train acuracy: 0.55078125
step: 9, val loss: 1.769140601158142, val acuracy: 0.5295000076293945
step: 10, train loss: 1.3413857221603394, train acuracy: 0.626953125
step: 10, val loss: 1.4617953300476074, val acuracy: 0.6028333902359009
step: 11, train loss: 1.4519202709197998, train acuracy: 0.58984375
step: 11, val loss: 1.4829814434051514, val acuracy: 0.577833354473114
step: 12, train loss: 1.3573859930038452, train acuracy: 0.681640625
step: 12, val loss: 1.581419825553894, val acuracy: 0.6113333702087402
step: 13, train loss: 1.178261160850525, train acuracy: 0.66796875
step: 13, val loss: 1.3087382316589355, val acuracy: 0.6458333730697632
step: 14, train loss: 5.064322471618652, train acuracy: 0.095703125
step: 14, val loss: 5.054021835327148, val acuracy: 0.09183333069086075
step: 15, train loss: 2.2606019973754883, train acuracy: 0.12109375
step: 15, val loss: 2.27351713180542, val acuracy: 0.09966666251420975
step: 16, train loss: 2.270887613296509, train acuracy: 0.115234375
step: 16, val loss: 2.2567074298858643, val acuracy: 0.11833333224058151
step: 17, train loss: 1.8432321548461914, train acuracy: 0.35546875
step: 17, val loss: 1.8835699558258057, val acuracy: 0.33633333444595337
step: 18, train loss: 1.5009524822235107, train acuracy: 0.44921875
step: 18, val loss: 1.5619347095489502, val acuracy: 0.4071667194366455
step: 19, train loss: 1.0777430534362793, train acuracy: 0.63671875
step: 19, val loss: 1.0750675201416016, val acuracy: 0.6410000324249268
step: 20, train loss: 1.04440438747406, train acuracy: 0.654296875
step: 20, val loss: 1.0501002073287964, val acuracy: 0.6505000591278076
step: 21, train loss: 1.0739505290985107, train acuracy: 0.689453125
step: 21, val loss: 1.045276403427124, val acuracy: 0.6906667351722717
step: 22, train loss: 1.081479549407959, train acuracy: 0.662109375
step: 22, val loss: 1.0454258918762207, val acuracy: 0.6490000486373901
step: 23, train loss: 0.5656550526618958, train acuracy: 0.81640625
step: 23, val loss: 0.6285332441329956, val acuracy: 0.7966667413711548
step: 24, train loss: 0.46699342131614685, train acuracy: 0.861328125
step: 24, val loss: 0.5568327307701111, val acuracy: 0.8226667046546936
step: 25, train loss: 4.153352737426758, train acuracy: 0.3359375
step: 25, val loss: 4.411836624145508, val acuracy: 0.31949999928474426
step: 26, train loss: 2.1842687129974365, train acuracy: 0.474609375
step: 26, val loss: 2.1339316368103027, val acuracy: 0.48766669631004333
step: 27, train loss: 2.085113048553467, train acuracy: 0.498046875
step: 27, val loss: 2.0030269622802734, val acuracy: 0.4921666979789734
step: 28, train loss: 1.4405838251113892, train acuracy: 0.478515625
step: 28, val loss: 1.4432792663574219, val acuracy: 0.49366670846939087
step: 29, train loss: 1.172616958618164, train acuracy: 0.578125
step: 29, val loss: 1.1386747360229492, val acuracy: 0.5898333787918091
step: 30, train loss: 1.0749695301055908, train acuracy: 0.712890625
step: 30, val loss: 1.0301434993743896, val acuracy: 0.7415000796318054
step: 31, train loss: 0.7421348094940186, train acuracy: 0.720703125
step: 31, val loss: 0.7658199667930603, val acuracy: 0.721500039100647
step: 32, train loss: 0.7305544018745422, train acuracy: 0.7734375
step: 32, val loss: 0.8029688596725464, val acuracy: 0.7608333826065063
step: 33, train loss: 0.5197492837905884, train acuracy: 0.822265625
step: 33, val loss: 0.5670958757400513, val acuracy: 0.8181667327880859
step: 34, train loss: 0.5433632135391235, train acuracy: 0.810546875
step: 34, val loss: 0.5638631582260132, val acuracy: 0.8183334469795227
step: 35, train loss: 0.5024421215057373, train acuracy: 0.84375
step: 35, val loss: 0.5022884011268616, val acuracy: 0.8413334488868713
step: 36, train loss: 0.4797172546386719, train acuracy: 0.869140625
step: 36, val loss: 0.5184760093688965, val acuracy: 0.8315000534057617
step: 37, train loss: 0.42473119497299194, train acuracy: 0.857421875
step: 37, val loss: 0.4683671295642853, val acuracy: 0.8538334369659424
step: 38, train loss: 3.2534520626068115, train acuracy: 0.59375
step: 38, val loss: 3.5429463386535645, val acuracy: 0.549333393573761
step: 39, train loss: 3.21813702583313, train acuracy: 0.60546875
step: 39, val loss: 3.5650503635406494, val acuracy: 0.5530000329017639
step: 40, train loss: 1.5457637310028076, train acuracy: 0.73828125
step: 40, val loss: 1.681177020072937, val acuracy: 0.7253334522247314
step: 41, train loss: 1.210511326789856, train acuracy: 0.75390625
step: 41, val loss: 1.3167222738265991, val acuracy: 0.7306667566299438
step: 42, train loss: 1.3590278625488281, train acuracy: 0.71484375
step: 42, val loss: 1.3084735870361328, val acuracy: 0.7201666831970215
step: 43, train loss: 1.1542340517044067, train acuracy: 0.724609375
step: 43, val loss: 1.3104366064071655, val acuracy: 0.705500066280365
step: 44, train loss: 1.2430098056793213, train acuracy: 0.73046875
step: 44, val loss: 1.2704805135726929, val acuracy: 0.7103334069252014
step: 45, train loss: 1.321982979774475, train acuracy: 0.69921875
step: 45, val loss: 1.2580302953720093, val acuracy: 0.6926667094230652
step: 46, train loss: 1.4867767095565796, train acuracy: 0.669921875
step: 46, val loss: 1.2511377334594727, val acuracy: 0.6946666836738586
step: 47, train loss: 1.3413665294647217, train acuracy: 0.6875
step: 47, val loss: 1.25021231174469, val acuracy: 0.6960000395774841
step: 48, train loss: 1.5291790962219238, train acuracy: 0.69921875
step: 48, val loss: 1.3136121034622192, val acuracy: 0.7060000896453857
step: 49, train loss: 1.2758488655090332, train acuracy: 0.736328125
step: 49, val loss: 1.3147794008255005, val acuracy: 0.6995000243186951
step: 50, train loss: 1.2945351600646973, train acuracy: 0.73046875
step: 50, val loss: 1.362668752670288, val acuracy: 0.7065001130104065
step: 51, train loss: 1.3747020959854126, train acuracy: 0.6953125
step: 51, val loss: 1.2930139303207397, val acuracy: 0.7093333601951599
step: 52, train loss: 1.4606761932373047, train acuracy: 0.7109375
step: 52, val loss: 1.3203922510147095, val acuracy: 0.7095000743865967
step: 53, train loss: 1.2630051374435425, train acuracy: 0.7109375
step: 53, val loss: 1.319712519645691, val acuracy: 0.7098333835601807
step: 54, train loss: 1.4602092504501343, train acuracy: 0.701171875
step: 54, val loss: 1.313910961151123, val acuracy: 0.7090000510215759
step: 55, train loss: 1.4279295206069946, train acuracy: 0.6796875
step: 55, val loss: 1.4429134130477905, val acuracy: 0.6783334612846375
step: 56, train loss: 1.4817113876342773, train acuracy: 0.697265625
step: 56, val loss: 1.512411117553711, val acuracy: 0.7038333415985107
step: 57, train loss: 1.5023934841156006, train acuracy: 0.6796875
step: 57, val loss: 1.5284591913223267, val acuracy: 0.6688333749771118
step: 58, train loss: 1.5089434385299683, train acuracy: 0.677734375
step: 58, val loss: 1.53518545627594, val acuracy: 0.6798333525657654
step: 59, train loss: 1.746206521987915, train acuracy: 0.68359375
step: 59, val loss: 1.5361809730529785, val acuracy: 0.7116667628288269
step: 60, train loss: 1.4311728477478027, train acuracy: 0.693359375
step: 60, val loss: 1.5989832878112793, val acuracy: 0.6835000514984131
step: 61, train loss: 1.3989684581756592, train acuracy: 0.705078125
step: 61, val loss: 1.4810527563095093, val acuracy: 0.6886667013168335
step: 62, train loss: 1.3992037773132324, train acuracy: 0.7109375
step: 62, val loss: 1.5148168802261353, val acuracy: 0.6848334074020386
step: 63, train loss: 1.375862717628479, train acuracy: 0.70703125
step: 63, val loss: 1.551225185394287, val acuracy: 0.6943334341049194
step: 64, train loss: 1.6058104038238525, train acuracy: 0.65625
step: 64, val loss: 1.5984432697296143, val acuracy: 0.6658333539962769
step: 65, train loss: 1.4155430793762207, train acuracy: 0.705078125
step: 65, val loss: 1.56306791305542, val acuracy: 0.6691666841506958
step: 66, train loss: 62.312538146972656, train acuracy: 0.244140625
step: 66, val loss: 63.83222579956055, val acuracy: 0.23283334076404572
step: 67, train loss: 4.891422748565674, train acuracy: 0.103515625
step: 67, val loss: 4.866153717041016, val acuracy: 0.11349999159574509
step: 68, train loss: 4.117465019226074, train acuracy: 0.0859375
step: 68, val loss: 4.098494529724121, val acuracy: 0.08749999850988388
step: 69, train loss: 2.38419771194458, train acuracy: 0.10546875
step: 69, val loss: 2.3882768154144287, val acuracy: 0.09833332896232605
step: 70, train loss: 2.3825790882110596, train acuracy: 0.138671875
step: 70, val loss: 2.395554780960083, val acuracy: 0.12966667115688324
step: 71, train loss: 2.3052425384521484, train acuracy: 0.099609375
step: 71, val loss: 2.3027124404907227, val acuracy: 0.10583332926034927
step: 72, train loss: 2.2303736209869385, train acuracy: 0.220703125
step: 72, val loss: 2.2304415702819824, val acuracy: 0.2485000193119049
step: 73, train loss: 3.113539457321167, train acuracy: 0.138671875
step: 73, val loss: 2.9961421489715576, val acuracy: 0.16333332657814026
step: 74, train loss: 2.552584409713745, train acuracy: 0.056640625
step: 74, val loss: 2.550527811050415, val acuracy: 0.052166663110256195
step: 75, train loss: 2.289294719696045, train acuracy: 0.15625
step: 75, val loss: 2.2804765701293945, val acuracy: 0.15149998664855957
step: 76, train loss: 2.0225746631622314, train acuracy: 0.3359375
step: 76, val loss: 2.049024820327759, val acuracy: 0.3021666705608368
step: 77, train loss: 1.8050146102905273, train acuracy: 0.427734375
step: 77, val loss: 1.8102147579193115, val acuracy: 0.4023333787918091
step: 78, train loss: 1.7487797737121582, train acuracy: 0.458984375
step: 78, val loss: 1.7983171939849854, val acuracy: 0.4334999918937683
step: 79, train loss: 1.3761563301086426, train acuracy: 0.609375
step: 79, val loss: 1.3536372184753418, val acuracy: 0.581166684627533
step: 80, train loss: 1.0267127752304077, train acuracy: 0.673828125
step: 80, val loss: 1.0223588943481445, val acuracy: 0.6605000495910645
step: 81, train loss: 0.9537153244018555, train acuracy: 0.62890625
step: 81, val loss: 0.9889937043190002, val acuracy: 0.6425000429153442
step: 82, train loss: 0.8869930505752563, train acuracy: 0.69921875
step: 82, val loss: 0.9914871454238892, val acuracy: 0.6470000743865967
step: 83, train loss: 1.0784729719161987, train acuracy: 0.623046875
step: 83, val loss: 0.9540014266967773, val acuracy: 0.6755000948905945
step: 84, train loss: 0.7853781580924988, train acuracy: 0.75
step: 84, val loss: 0.8524608612060547, val acuracy: 0.721666693687439
step: 85, train loss: 0.908081591129303, train acuracy: 0.697265625
step: 85, val loss: 0.8460795879364014, val acuracy: 0.7236666679382324
step: 86, train loss: 0.8442310094833374, train acuracy: 0.7421875
step: 86, val loss: 0.8080549836158752, val acuracy: 0.7390000820159912
step: 87, train loss: 0.8275386691093445, train acuracy: 0.71484375
step: 87, val loss: 0.8094422221183777, val acuracy: 0.7308334112167358
step: 88, train loss: 0.7366740703582764, train acuracy: 0.748046875
step: 88, val loss: 0.7590729594230652, val acuracy: 0.7461667060852051
step: 89, train loss: 0.7611696124076843, train acuracy: 0.748046875
step: 89, val loss: 0.7538819313049316, val acuracy: 0.7491666674613953
step: 90, train loss: 0.8067386746406555, train acuracy: 0.767578125
step: 90, val loss: 0.7528840899467468, val acuracy: 0.749666690826416
step: 91, train loss: 0.7849991321563721, train acuracy: 0.76171875
step: 91, val loss: 0.7506816387176514, val acuracy: 0.7518333792686462
step: 92, train loss: 0.7925677299499512, train acuracy: 0.751953125
step: 92, val loss: 0.7669962048530579, val acuracy: 0.7458334565162659
step: 93, train loss: 0.7169259190559387, train acuracy: 0.748046875
step: 93, val loss: 0.7641922235488892, val acuracy: 0.7430001497268677
step: 94, train loss: 0.7522404193878174, train acuracy: 0.76171875
step: 94, val loss: 0.7631875276565552, val acuracy: 0.7450000047683716
step: 95, train loss: 0.8018871545791626, train acuracy: 0.751953125
step: 95, val loss: 0.7619935870170593, val acuracy: 0.7438334226608276
step: 96, train loss: 0.7262516617774963, train acuracy: 0.73828125
step: 96, val loss: 0.7609463930130005, val acuracy: 0.7445001006126404
step: 97, train loss: 0.7052944302558899, train acuracy: 0.765625
step: 97, val loss: 0.7604352235794067, val acuracy: 0.7441667318344116
step: 98, train loss: 0.6217232346534729, train acuracy: 0.78515625
step: 98, val loss: 0.7604060173034668, val acuracy: 0.7440000772476196
step: 99, train loss: 0.7908604741096497, train acuracy: 0.75390625
step: 99, val loss: 0.7599445581436157, val acuracy: 0.7443334460258484
step: 100, train loss: 0.7470955848693848, train acuracy: 0.79296875
step: 100, val loss: 0.7595528960227966, val acuracy: 0.7438334226608276
step: 101, train loss: 0.7773350477218628, train acuracy: 0.759765625
step: 101, val loss: 0.7769375443458557, val acuracy: 0.7413333654403687
step: 102, train loss: 0.8301941156387329, train acuracy: 0.72265625
step: 102, val loss: 0.7871942520141602, val acuracy: 0.7350000739097595
step: 103, train loss: 0.7803356051445007, train acuracy: 0.740234375
step: 103, val loss: 0.7827170491218567, val acuracy: 0.7371668219566345
step: 104, train loss: 0.746985673904419, train acuracy: 0.7421875
step: 104, val loss: 0.7831955552101135, val acuracy: 0.736833393573761
step: 105, train loss: 0.8047537803649902, train acuracy: 0.744140625
step: 105, val loss: 0.8123693466186523, val acuracy: 0.721666693687439
step: 106, train loss: 0.8481974601745605, train acuracy: 0.732421875
step: 106, val loss: 0.869476854801178, val acuracy: 0.7091667056083679
step: 107, train loss: 0.83958899974823, train acuracy: 0.69140625
step: 107, val loss: 0.8694413304328918, val acuracy: 0.6850001215934753
step: 108, train loss: 0.8290241360664368, train acuracy: 0.708984375
step: 108, val loss: 0.9041425585746765, val acuracy: 0.6781666278839111
step: 109, train loss: 0.7015417218208313, train acuracy: 0.74609375
step: 109, val loss: 0.8201751112937927, val acuracy: 0.7118334770202637
step: 110, train loss: 0.7498641014099121, train acuracy: 0.74609375
step: 110, val loss: 0.8281707763671875, val acuracy: 0.7225000858306885
step: 111, train loss: 0.889901876449585, train acuracy: 0.6875
step: 111, val loss: 0.8511543273925781, val acuracy: 0.6935000419616699
step: 112, train loss: 0.7912495732307434, train acuracy: 0.720703125
step: 112, val loss: 0.7999236583709717, val acuracy: 0.7301667928695679
step: 113, train loss: 0.8256677389144897, train acuracy: 0.69921875
step: 113, val loss: 0.8127069473266602, val acuracy: 0.7240000367164612
step: 114, train loss: 0.9161105155944824, train acuracy: 0.7265625
step: 114, val loss: 0.814239501953125, val acuracy: 0.7196667194366455
step: 115, train loss: 0.8549701571464539, train acuracy: 0.732421875
step: 115, val loss: 0.8312541246414185, val acuracy: 0.7228333950042725
step: 116, train loss: 0.7269093990325928, train acuracy: 0.755859375
step: 116, val loss: 0.8254592418670654, val acuracy: 0.721000075340271
step: 117, train loss: 0.7735552787780762, train acuracy: 0.720703125
step: 117, val loss: 0.8319762945175171, val acuracy: 0.72350013256073
step: 118, train loss: 0.7455664873123169, train acuracy: 0.728515625
step: 118, val loss: 0.8135782480239868, val acuracy: 0.733833372592926
step: 119, train loss: 1.264540195465088, train acuracy: 0.578125
step: 119, val loss: 1.2852624654769897, val acuracy: 0.5730000138282776
step: 120, train loss: 0.9504952430725098, train acuracy: 0.69140625
step: 120, val loss: 0.9537091255187988, val acuracy: 0.6940001249313354
step: 121, train loss: 0.966986358165741, train acuracy: 0.685546875
step: 121, val loss: 0.9613343477249146, val acuracy: 0.6858333945274353
step: 122, train loss: 0.9458396434783936, train acuracy: 0.673828125
step: 122, val loss: 0.9554428458213806, val acuracy: 0.6875000596046448
step: 123, train loss: 0.8537979125976562, train acuracy: 0.703125
step: 123, val loss: 1.0140427350997925, val acuracy: 0.684666633605957
step: 124, train loss: 0.9467084407806396, train acuracy: 0.677734375
step: 124, val loss: 0.9848236441612244, val acuracy: 0.6811667680740356
step: 125, train loss: 1.010129690170288, train acuracy: 0.6875
step: 125, val loss: 0.9792963266372681, val acuracy: 0.6826667785644531
step: 126, train loss: 0.9347661733627319, train acuracy: 0.712890625
step: 126, val loss: 0.9785208106040955, val acuracy: 0.6830000877380371
step: 127, train loss: 1.0612505674362183, train acuracy: 0.66015625
step: 127, val loss: 0.9780206084251404, val acuracy: 0.6826667189598083
step: 128, train loss: 1.0196927785873413, train acuracy: 0.66015625
step: 128, val loss: 1.060734748840332, val acuracy: 0.6710000038146973
step: 129, train loss: 0.9554646015167236, train acuracy: 0.720703125
step: 129, val loss: 1.188478946685791, val acuracy: 0.656166672706604
step: 130, train loss: 0.9669032692909241, train acuracy: 0.693359375
step: 130, val loss: 1.0837767124176025, val acuracy: 0.6596667170524597
step: 131, train loss: 1.187372088432312, train acuracy: 0.65234375
step: 131, val loss: 1.0746220350265503, val acuracy: 0.6676667332649231
step: 132, train loss: 0.9841094613075256, train acuracy: 0.68359375
step: 132, val loss: 1.065623164176941, val acuracy: 0.6675001382827759
step: 133, train loss: 0.9972057938575745, train acuracy: 0.705078125
step: 133, val loss: 1.0403622388839722, val acuracy: 0.6691666841506958
step: 134, train loss: 1.0257747173309326, train acuracy: 0.6875
step: 134, val loss: 1.0537415742874146, val acuracy: 0.6683333516120911
step: 135, train loss: 1.1226716041564941, train acuracy: 0.6171875
step: 135, val loss: 1.1304209232330322, val acuracy: 0.6303333640098572
step: 136, train loss: 1.036867618560791, train acuracy: 0.642578125
step: 136, val loss: 1.08669114112854, val acuracy: 0.6638333797454834
step: 137, train loss: 1.1426613330841064, train acuracy: 0.640625
step: 137, val loss: 1.0850611925125122, val acuracy: 0.6498333811759949
step: 138, train loss: 1.0276193618774414, train acuracy: 0.65625
step: 138, val loss: 1.0500836372375488, val acuracy: 0.659000039100647
step: 139, train loss: 1.0668448209762573, train acuracy: 0.68359375
step: 139, val loss: 1.1173787117004395, val acuracy: 0.6445000767707825
step: 140, train loss: 1.1569939851760864, train acuracy: 0.646484375
step: 140, val loss: 1.1067404747009277, val acuracy: 0.6438333988189697
step: 141, train loss: 0.974406898021698, train acuracy: 0.671875
step: 141, val loss: 1.1132566928863525, val acuracy: 0.659333348274231
step: 142, train loss: 3.473001003265381, train acuracy: 0.287109375
step: 142, val loss: 3.3027215003967285, val acuracy: 0.27433332800865173
step: 143, train loss: 1.6941139698028564, train acuracy: 0.447265625
step: 143, val loss: 1.6907395124435425, val acuracy: 0.43966665863990784
step: 144, train loss: 1.5713591575622559, train acuracy: 0.46484375
step: 144, val loss: 1.641596794128418, val acuracy: 0.4300000071525574
step: 145, train loss: 1.539281964302063, train acuracy: 0.505859375
step: 145, val loss: 1.5175299644470215, val acuracy: 0.5160000324249268
step: 146, train loss: 29.298715591430664, train acuracy: 0.3515625
step: 146, val loss: 29.633665084838867, val acuracy: 0.35966670513153076
step: 147, train loss: 16.255550384521484, train acuracy: 0.38671875
step: 147, val loss: 15.61003589630127, val acuracy: 0.4278333783149719
step: 148, train loss: 8.078165054321289, train acuracy: 0.40625
step: 148, val loss: 9.292034149169922, val acuracy: 0.3671666979789734
step: 149, train loss: 8.685322761535645, train acuracy: 0.12890625
step: 149, val loss: 9.061004638671875, val acuracy: 0.1185000017285347
step: 150, train loss: 8.713945388793945, train acuracy: 0.162109375
step: 150, val loss: 8.509578704833984, val acuracy: 0.18649999797344208
step: 151, train loss: 7.390130043029785, train acuracy: 0.126953125
step: 151, val loss: 7.650422096252441, val acuracy: 0.11916665732860565
step: 152, train loss: 6.10200834274292, train acuracy: 0.1171875
step: 152, val loss: 6.460951805114746, val acuracy: 0.1014999970793724
step: 153, train loss: 9.803850173950195, train acuracy: 0.111328125
step: 153, val loss: 9.740594863891602, val acuracy: 0.10583332926034927
step: 154, train loss: 8.134471893310547, train acuracy: 0.142578125
step: 154, val loss: 8.404790878295898, val acuracy: 0.1145000010728836
step: 155, train loss: 8.169500350952148, train acuracy: 0.185546875
step: 155, val loss: 7.988160610198975, val acuracy: 0.1666666567325592
step: 156, train loss: 7.840723991394043, train acuracy: 0.1328125
step: 156, val loss: 7.910656929016113, val acuracy: 0.14083331823349
step: 157, train loss: 7.129368782043457, train acuracy: 0.08984375
step: 157, val loss: 7.247311115264893, val acuracy: 0.10899999737739563
step: 158, train loss: 6.893431186676025, train acuracy: 0.10546875
step: 158, val loss: 6.681538105010986, val acuracy: 0.09733332693576813
step: 159, train loss: 2.9266085624694824, train acuracy: 0.115234375
step: 159, val loss: 2.9322001934051514, val acuracy: 0.10849999636411667
step: 160, train loss: 2.900754928588867, train acuracy: 0.18359375
step: 160, val loss: 3.042151689529419, val acuracy: 0.13750000298023224
step: 161, train loss: 3.0811400413513184, train acuracy: 0.103515625
step: 161, val loss: 3.1147444248199463, val acuracy: 0.10633332282304764
step: 162, train loss: 3.0464224815368652, train acuracy: 0.140625
step: 162, val loss: 3.2171881198883057, val acuracy: 0.12183332443237305
step: 163, train loss: 4.663956642150879, train acuracy: 0.15234375
step: 163, val loss: 4.7442426681518555, val acuracy: 0.16233333945274353
step: 164, train loss: 3.05429744720459, train acuracy: 0.08984375
step: 164, val loss: 3.0560853481292725, val acuracy: 0.10533332824707031
step: 165, train loss: 2.9408257007598877, train acuracy: 0.125
step: 165, val loss: 2.949723720550537, val acuracy: 0.11866666376590729
step: 166, train loss: 2.4310238361358643, train acuracy: 0.115234375
step: 166, val loss: 2.4255614280700684, val acuracy: 0.10899998992681503
step: 167, train loss: 2.317521810531616, train acuracy: 0.109375
step: 167, val loss: 2.326317310333252, val acuracy: 0.10899998992681503
step: 168, train loss: 2.298595428466797, train acuracy: 0.109375
step: 168, val loss: 2.311378002166748, val acuracy: 0.09533333778381348
step: 169, train loss: 2.301797866821289, train acuracy: 0.09765625
step: 169, val loss: 2.3045859336853027, val acuracy: 0.10383334010839462
step: 170, train loss: 2.2988476753234863, train acuracy: 0.111328125
step: 170, val loss: 2.304579973220825, val acuracy: 0.09549999982118607
step: 171, train loss: 2.2982215881347656, train acuracy: 0.115234375
step: 171, val loss: 2.303605079650879, val acuracy: 0.10566665977239609
step: 172, train loss: 2.2960448265075684, train acuracy: 0.125
step: 172, val loss: 2.306520462036133, val acuracy: 0.09816667437553406
step: 173, train loss: 2.297525405883789, train acuracy: 0.111328125
step: 173, val loss: 2.305161476135254, val acuracy: 0.09783333539962769
step: 174, train loss: 2.2927894592285156, train acuracy: 0.115234375
step: 174, val loss: 2.304119825363159, val acuracy: 0.10566666722297668
step: 175, train loss: 2.2931578159332275, train acuracy: 0.123046875
step: 175, val loss: 2.312533378601074, val acuracy: 0.09749999642372131
step: 176, train loss: 2.3024048805236816, train acuracy: 0.111328125
step: 176, val loss: 2.304349422454834, val acuracy: 0.0976666659116745
step: 177, train loss: 2.2947919368743896, train acuracy: 0.107421875
step: 177, val loss: 2.3046820163726807, val acuracy: 0.1041666716337204
step: 178, train loss: 2.2954750061035156, train acuracy: 0.123046875
step: 178, val loss: 2.306826114654541, val acuracy: 0.1054999977350235
step: 179, train loss: 2.304325580596924, train acuracy: 0.095703125
step: 179, val loss: 2.303814172744751, val acuracy: 0.1054999977350235
step: 180, train loss: 2.2943828105926514, train acuracy: 0.119140625
step: 180, val loss: 2.3059113025665283, val acuracy: 0.09649999439716339
step: 181, train loss: 2.2951152324676514, train acuracy: 0.12890625
step: 181, val loss: 2.306302785873413, val acuracy: 0.09816665947437286
step: 182, train loss: 2.2980899810791016, train acuracy: 0.119140625
step: 182, val loss: 2.3058722019195557, val acuracy: 0.09816667437553406
step: 183, train loss: 2.297135591506958, train acuracy: 0.115234375
step: 183, val loss: 2.306072950363159, val acuracy: 0.10899998992681503
step: 184, train loss: 2.293811082839966, train acuracy: 0.123046875
step: 184, val loss: 2.3062853813171387, val acuracy: 0.09783333539962769
step: 185, train loss: 2.3012783527374268, train acuracy: 0.115234375
step: 185, val loss: 2.3057327270507812, val acuracy: 0.10899998992681503
step: 186, train loss: 2.2929553985595703, train acuracy: 0.11328125
step: 186, val loss: 2.3070266246795654, val acuracy: 0.11150000244379044
step: 187, train loss: 2.292958974838257, train acuracy: 0.1328125
step: 187, val loss: 2.3031973838806152, val acuracy: 0.10899999737739563
step: 188, train loss: 2.300107479095459, train acuracy: 0.115234375
step: 188, val loss: 2.3044097423553467, val acuracy: 0.10899999737739563
step: 189, train loss: 2.29079008102417, train acuracy: 0.126953125
step: 189, val loss: 2.3098630905151367, val acuracy: 0.10899999737739563
step: 190, train loss: 2.2930777072906494, train acuracy: 0.126953125
step: 190, val loss: 2.3079986572265625, val acuracy: 0.09449999779462814
step: 191, train loss: 2.3021717071533203, train acuracy: 0.08984375
step: 191, val loss: 2.3021469116210938, val acuracy: 0.08633333444595337
step: 192, train loss: 2.295595169067383, train acuracy: 0.1015625
step: 192, val loss: 2.294010877609253, val acuracy: 0.1041666641831398
step: 193, train loss: 2.2872092723846436, train acuracy: 0.11328125
step: 193, val loss: 2.294037103652954, val acuracy: 0.11633333563804626
step: 194, train loss: 2.291688919067383, train acuracy: 0.15625
step: 194, val loss: 2.302591323852539, val acuracy: 0.1574999988079071
step: 195, train loss: 2.2785415649414062, train acuracy: 0.166015625
step: 195, val loss: 2.2805287837982178, val acuracy: 0.16433334350585938
step: 196, train loss: 2.274595022201538, train acuracy: 0.185546875
step: 196, val loss: 2.2789618968963623, val acuracy: 0.19433332979679108
step: 197, train loss: 2.2837233543395996, train acuracy: 0.166015625
step: 197, val loss: 2.2787744998931885, val acuracy: 0.1756666600704193
step: 198, train loss: 2.299281358718872, train acuracy: 0.171875
step: 198, val loss: 2.2821574211120605, val acuracy: 0.16866667568683624
step: 199, train loss: 2.27738618850708, train acuracy: 0.20703125
step: 199, val loss: 2.283468723297119, val acuracy: 0.17649999260902405
step: 200, train loss: 2.284416437149048, train acuracy: 0.16796875
step: 200, val loss: 2.282258987426758, val acuracy: 0.17649999260902405
step: 201, train loss: 2.283491611480713, train acuracy: 0.181640625
step: 201, val loss: 2.282191753387451, val acuracy: 0.1768333464860916
step: 202, train loss: 2.27738881111145, train acuracy: 0.173828125
step: 202, val loss: 2.2821104526519775, val acuracy: 0.1771666705608368
step: 203, train loss: 2.2417311668395996, train acuracy: 0.21875
step: 203, val loss: 2.2843751907348633, val acuracy: 0.17916667461395264
step: 204, train loss: 2.2759900093078613, train acuracy: 0.15234375
step: 204, val loss: 2.287911891937256, val acuracy: 0.14300000667572021
step: 205, train loss: 2.2817699909210205, train acuracy: 0.166015625
step: 205, val loss: 2.287428379058838, val acuracy: 0.14299999177455902
step: 206, train loss: 2.2948713302612305, train acuracy: 0.154296875
step: 206, val loss: 2.288524866104126, val acuracy: 0.140500009059906
step: 207, train loss: 2.296013832092285, train acuracy: 0.15234375
step: 207, val loss: 2.2869889736175537, val acuracy: 0.15016666054725647
step: 208, train loss: 2.2855846881866455, train acuracy: 0.126953125
step: 208, val loss: 2.2902512550354004, val acuracy: 0.13716666400432587
step: 209, train loss: 2.297996759414673, train acuracy: 0.13671875
step: 209, val loss: 2.2918860912323, val acuracy: 0.15016666054725647
step: 210, train loss: 2.2873640060424805, train acuracy: 0.14453125
step: 210, val loss: 2.291823148727417, val acuracy: 0.15199998021125793
step: 211, train loss: 2.3127925395965576, train acuracy: 0.134765625
step: 211, val loss: 2.3152055740356445, val acuracy: 0.11783332377672195
step: 212, train loss: 2.307691812515259, train acuracy: 0.146484375
step: 212, val loss: 2.3071651458740234, val acuracy: 0.15699999034404755
step: 213, train loss: 2.2915842533111572, train acuracy: 0.14453125
step: 213, val loss: 2.2975504398345947, val acuracy: 0.12449999153614044
step: 214, train loss: 2.294387102127075, train acuracy: 0.12109375
step: 214, val loss: 2.2954518795013428, val acuracy: 0.12316666543483734
step: 215, train loss: 2.2915756702423096, train acuracy: 0.150390625
step: 215, val loss: 2.2991626262664795, val acuracy: 0.12433332949876785
step: 216, train loss: 2.2934327125549316, train acuracy: 0.119140625
step: 216, val loss: 2.2969775199890137, val acuracy: 0.12833333015441895
step: 217, train loss: 2.2959187030792236, train acuracy: 0.1484375
step: 217, val loss: 2.298402786254883, val acuracy: 0.11816666275262833
step: 218, train loss: 2.2994446754455566, train acuracy: 0.111328125
step: 218, val loss: 2.295715093612671, val acuracy: 0.12266665697097778
step: 219, train loss: 2.29304838180542, train acuracy: 0.140625
step: 219, val loss: 2.296180486679077, val acuracy: 0.12466666102409363
step: 220, train loss: 2.293489933013916, train acuracy: 0.12109375
step: 220, val loss: 2.294501543045044, val acuracy: 0.12483333051204681
step: 221, train loss: 2.2934679985046387, train acuracy: 0.123046875
step: 221, val loss: 2.2945570945739746, val acuracy: 0.125166654586792
step: 222, train loss: 2.2694809436798096, train acuracy: 0.14453125
step: 222, val loss: 2.2887492179870605, val acuracy: 0.1381666511297226
step: 223, train loss: 2.2857437133789062, train acuracy: 0.15625
step: 223, val loss: 2.292053699493408, val acuracy: 0.14699998497962952
step: 224, train loss: 2.275618076324463, train acuracy: 0.1484375
step: 224, val loss: 2.284472703933716, val acuracy: 0.14283332228660583
step: 225, train loss: 2.301478862762451, train acuracy: 0.12890625
step: 225, val loss: 2.292485475540161, val acuracy: 0.14149999618530273
step: 226, train loss: 2.2452211380004883, train acuracy: 0.18359375
step: 226, val loss: 2.266519546508789, val acuracy: 0.16633331775665283
step: 227, train loss: 2.250035285949707, train acuracy: 0.181640625
step: 227, val loss: 2.2655749320983887, val acuracy: 0.16616666316986084
step: 228, train loss: 2.2984461784362793, train acuracy: 0.146484375
step: 228, val loss: 2.291062831878662, val acuracy: 0.14300000667572021
step: 229, train loss: 2.296380043029785, train acuracy: 0.15625
step: 229, val loss: 2.2674849033355713, val acuracy: 0.1573333442211151
step: 230, train loss: 2.2828640937805176, train acuracy: 0.169921875
step: 230, val loss: 2.2582170963287354, val acuracy: 0.1511666625738144
step: 231, train loss: 2.29775071144104, train acuracy: 0.111328125
step: 231, val loss: 2.2573390007019043, val acuracy: 0.15150000154972076
step: 232, train loss: 2.3022570610046387, train acuracy: 0.125
step: 232, val loss: 2.262098789215088, val acuracy: 0.1459999829530716
step: 233, train loss: 2.257918119430542, train acuracy: 0.13671875
step: 233, val loss: 2.2415904998779297, val acuracy: 0.1509999781847
step: 234, train loss: 8.923477172851562, train acuracy: 0.115234375
step: 234, val loss: 9.418234825134277, val acuracy: 0.09666665643453598
step: 235, train loss: 6.810510158538818, train acuracy: 0.095703125
step: 235, val loss: 7.3611040115356445, val acuracy: 0.1003333255648613
step: 236, train loss: 7.241790771484375, train acuracy: 0.11328125
step: 236, val loss: 7.3409857749938965, val acuracy: 0.10700000077486038
step: 237, train loss: 5.477231979370117, train acuracy: 0.09375
step: 237, val loss: 5.6216840744018555, val acuracy: 0.10599999129772186
step: 238, train loss: 3.2444796562194824, train acuracy: 0.09375
step: 238, val loss: 3.3247013092041016, val acuracy: 0.09566666930913925
step: 239, train loss: 2.664019823074341, train acuracy: 0.1328125
step: 239, val loss: 2.811166286468506, val acuracy: 0.09916666895151138
step: 240, train loss: 2.5307462215423584, train acuracy: 0.11328125
step: 240, val loss: 2.5577707290649414, val acuracy: 0.09949999302625656
step: 241, train loss: 2.393563747406006, train acuracy: 0.1015625
step: 241, val loss: 2.417491912841797, val acuracy: 0.10066666454076767
step: 242, train loss: 2.3018534183502197, train acuracy: 0.12109375
step: 242, val loss: 2.3140594959259033, val acuracy: 0.11233332753181458
step: 243, train loss: 2.2931060791015625, train acuracy: 0.130859375
step: 243, val loss: 2.313730239868164, val acuracy: 0.109499990940094
step: 244, train loss: 2.296937942504883, train acuracy: 0.134765625
step: 244, val loss: 2.3069677352905273, val acuracy: 0.10633333027362823
step: 245, train loss: 2.297625780105591, train acuracy: 0.12890625
step: 245, val loss: 2.3199756145477295, val acuracy: 0.10916665941476822
step: 246, train loss: 2.3061680793762207, train acuracy: 0.10546875
step: 246, val loss: 2.3067097663879395, val acuracy: 0.10916665941476822
step: 247, train loss: 2.2960681915283203, train acuracy: 0.109375
step: 247, val loss: 2.3052256107330322, val acuracy: 0.1054999977350235
step: 248, train loss: 2.2948524951934814, train acuracy: 0.111328125
step: 248, val loss: 2.3079299926757812, val acuracy: 0.10916665941476822
step: 249, train loss: 2.3079934120178223, train acuracy: 0.09765625
step: 249, val loss: 2.324742317199707, val acuracy: 0.1054999977350235
step: 250, train loss: 2.3047430515289307, train acuracy: 0.115234375
step: 250, val loss: 2.310114860534668, val acuracy: 0.1053333431482315
step: 251, train loss: 2.300938367843628, train acuracy: 0.11328125
step: 251, val loss: 2.306007146835327, val acuracy: 0.1053333431482315
step: 252, train loss: 2.290229320526123, train acuracy: 0.12109375
step: 252, val loss: 2.310214042663574, val acuracy: 0.10383333265781403
step: 253, train loss: 2.2961058616638184, train acuracy: 0.107421875
step: 253, val loss: 2.3215150833129883, val acuracy: 0.09816665947437286
step: 254, train loss: 2.2992844581604004, train acuracy: 0.111328125
step: 254, val loss: 2.308698892593384, val acuracy: 0.09816665947437286
step: 255, train loss: 2.298037528991699, train acuracy: 0.109375
step: 255, val loss: 2.308065414428711, val acuracy: 0.10383333265781403
step: 256, train loss: 2.2985715866088867, train acuracy: 0.12109375
step: 256, val loss: 2.3041481971740723, val acuracy: 0.10899999737739563
step: 257, train loss: 2.295644760131836, train acuracy: 0.107421875
step: 257, val loss: 2.307305335998535, val acuracy: 0.09183333069086075
step: 258, train loss: 2.301143169403076, train acuracy: 0.1015625
step: 258, val loss: 2.307279109954834, val acuracy: 0.10449999570846558
step: 259, train loss: 2.292079448699951, train acuracy: 0.12890625
step: 259, val loss: 2.307673454284668, val acuracy: 0.10966665297746658
step: 260, train loss: 2.297769069671631, train acuracy: 0.1171875
step: 260, val loss: 2.3054802417755127, val acuracy: 0.09583333134651184
step: 261, train loss: 2.299346446990967, train acuracy: 0.123046875
step: 261, val loss: 2.3048202991485596, val acuracy: 0.09866666793823242
step: 262, train loss: 2.291733503341675, train acuracy: 0.1171875
step: 262, val loss: 2.3086750507354736, val acuracy: 0.09833332896232605
step: 263, train loss: 2.288257122039795, train acuracy: 0.138671875
step: 263, val loss: 2.310637950897217, val acuracy: 0.1054999977350235
step: 264, train loss: 2.3003218173980713, train acuracy: 0.111328125
step: 264, val loss: 2.303771495819092, val acuracy: 0.1054999977350235
step: 265, train loss: 2.2851595878601074, train acuracy: 0.123046875
step: 265, val loss: 2.3103489875793457, val acuracy: 0.10516665875911713
step: 266, train loss: 2.2981672286987305, train acuracy: 0.126953125
step: 266, val loss: 2.3061583042144775, val acuracy: 0.09816665947437286
step: 267, train loss: 2.295278549194336, train acuracy: 0.107421875
step: 267, val loss: 2.3065602779388428, val acuracy: 0.10400000214576721
step: 268, train loss: 2.296097755432129, train acuracy: 0.123046875
step: 268, val loss: 2.3033640384674072, val acuracy: 0.10899998992681503
step: 269, train loss: 2.297797203063965, train acuracy: 0.119140625
step: 269, val loss: 2.3081867694854736, val acuracy: 0.09183333069086075
step: 270, train loss: 2.2980220317840576, train acuracy: 0.111328125
step: 270, val loss: 2.303450345993042, val acuracy: 0.10899999737739563
step: 271, train loss: 2.2965903282165527, train acuracy: 0.125
step: 271, val loss: 2.3025550842285156, val acuracy: 0.10483333468437195
step: 272, train loss: 2.298624038696289, train acuracy: 0.11328125
step: 272, val loss: 2.3130974769592285, val acuracy: 0.10949999839067459
step: 273, train loss: 2.295483112335205, train acuracy: 0.1328125
step: 273, val loss: 2.302799701690674, val acuracy: 0.10883332788944244
step: 274, train loss: 2.303607225418091, train acuracy: 0.06640625
step: 274, val loss: 2.308267593383789, val acuracy: 0.061000000685453415
step: 275, train loss: 2.303914785385132, train acuracy: 0.11328125
step: 275, val loss: 2.3022689819335938, val acuracy: 0.10899998992681503
step: 276, train loss: 2.2974507808685303, train acuracy: 0.11328125
step: 276, val loss: 2.303236961364746, val acuracy: 0.10899999737739563
step: 277, train loss: 2.293769121170044, train acuracy: 0.111328125
step: 277, val loss: 2.305206537246704, val acuracy: 0.10883332043886185
step: 278, train loss: 2.2974905967712402, train acuracy: 0.111328125
step: 278, val loss: 2.3098886013031006, val acuracy: 0.09833332151174545
step: 279, train loss: 2.2977726459503174, train acuracy: 0.111328125
step: 279, val loss: 2.303105592727661, val acuracy: 0.10350000113248825
step: 280, train loss: 2.292212963104248, train acuracy: 0.1171875
step: 280, val loss: 2.3200645446777344, val acuracy: 0.10916665941476822
step: 281, train loss: 2.3048222064971924, train acuracy: 0.09375
step: 281, val loss: 2.3061158657073975, val acuracy: 0.09716666489839554
step: 282, train loss: 2.300795078277588, train acuracy: 0.103515625
step: 282, val loss: 2.3036179542541504, val acuracy: 0.0963333249092102
step: 283, train loss: 2.29718279838562, train acuracy: 0.125
step: 283, val loss: 2.3048033714294434, val acuracy: 0.10600000619888306
step: 284, train loss: 2.3019304275512695, train acuracy: 0.107421875
step: 284, val loss: 2.306009531021118, val acuracy: 0.0964999869465828
step: 285, train loss: 2.296506404876709, train acuracy: 0.119140625
step: 285, val loss: 2.3055410385131836, val acuracy: 0.09650000184774399
step: 286, train loss: 2.297579050064087, train acuracy: 0.12890625
step: 286, val loss: 2.3181204795837402, val acuracy: 0.09833332896232605
step: 287, train loss: 2.3037095069885254, train acuracy: 0.119140625
step: 287, val loss: 2.3116836547851562, val acuracy: 0.09816667437553406
step: 288, train loss: 2.303544521331787, train acuracy: 0.099609375
step: 288, val loss: 2.3160459995269775, val acuracy: 0.10533333569765091
step: 289, train loss: 2.3046021461486816, train acuracy: 0.09765625
step: 289, val loss: 2.3103256225585938, val acuracy: 0.09533333778381348
step: 290, train loss: 2.3044722080230713, train acuracy: 0.107421875
step: 290, val loss: 2.306734323501587, val acuracy: 0.09533333778381348
step: 291, train loss: 2.308687448501587, train acuracy: 0.119140625
step: 291, val loss: 2.3467371463775635, val acuracy: 0.09666666388511658
step: 292, train loss: 2.3109469413757324, train acuracy: 0.091796875
step: 292, val loss: 2.319319009780884, val acuracy: 0.09683333337306976
step: 293, train loss: 2.316807508468628, train acuracy: 0.115234375
step: 293, val loss: 2.322692394256592, val acuracy: 0.10899999737739563
step: 294, train loss: 2.2961337566375732, train acuracy: 0.126953125
step: 294, val loss: 2.3100082874298096, val acuracy: 0.10899998992681503
step: 295, train loss: 2.3076796531677246, train acuracy: 0.125
step: 295, val loss: 2.3105742931365967, val acuracy: 0.09583333134651184
step: 296, train loss: 2.3189809322357178, train acuracy: 0.08984375
step: 296, val loss: 2.3101539611816406, val acuracy: 0.09583333879709244
step: 297, train loss: 2.305710554122925, train acuracy: 0.107421875
step: 297, val loss: 2.3096909523010254, val acuracy: 0.09583333879709244
step: 298, train loss: 2.3007540702819824, train acuracy: 0.109375
step: 298, val loss: 2.314344882965088, val acuracy: 0.09549999982118607
step: 299, train loss: 2.315328598022461, train acuracy: 0.08984375
step: 299, val loss: 2.31412410736084, val acuracy: 0.09549999982118607
step: 300, train loss: 2.2990453243255615, train acuracy: 0.103515625
step: 300, val loss: 2.314493179321289, val acuracy: 0.09533333033323288
step: 301, train loss: 2.3144750595092773, train acuracy: 0.08984375
step: 301, val loss: 2.314646005630493, val acuracy: 0.09549999982118607
step: 302, train loss: 2.3061795234680176, train acuracy: 0.1015625
step: 302, val loss: 2.315121650695801, val acuracy: 0.09533333778381348
step: 303, train loss: 2.296407461166382, train acuracy: 0.130859375
step: 303, val loss: 2.315035104751587, val acuracy: 0.09533333033323288
step: 304, train loss: 2.296326160430908, train acuracy: 0.1171875
step: 304, val loss: 2.3160829544067383, val acuracy: 0.1093333289027214
step: 305, train loss: 2.3035807609558105, train acuracy: 0.10546875
step: 305, val loss: 2.3168606758117676, val acuracy: 0.09583333879709244
step: 306, train loss: 2.3090715408325195, train acuracy: 0.095703125
step: 306, val loss: 2.315408229827881, val acuracy: 0.09549999982118607
step: 307, train loss: 2.3112456798553467, train acuracy: 0.08984375
step: 307, val loss: 2.314732789993286, val acuracy: 0.09533333778381348
step: 308, train loss: 2.3180222511291504, train acuracy: 0.119140625
step: 308, val loss: 2.32539701461792, val acuracy: 0.10899998992681503
step: 309, train loss: 2.300607442855835, train acuracy: 0.130859375
step: 309, val loss: 2.3214924335479736, val acuracy: 0.10899998992681503
step: 310, train loss: 2.307372570037842, train acuracy: 0.09765625
step: 310, val loss: 2.3166744709014893, val acuracy: 0.09566666930913925
step: 311, train loss: 2.3115663528442383, train acuracy: 0.091796875
step: 311, val loss: 2.3154234886169434, val acuracy: 0.09566666930913925
step: 312, train loss: 2.319837808609009, train acuracy: 0.083984375
step: 312, val loss: 2.311948299407959, val acuracy: 0.09533333778381348
step: 313, train loss: 2.317185163497925, train acuracy: 0.080078125
step: 313, val loss: 2.3141772747039795, val acuracy: 0.1053333431482315
step: 314, train loss: 2.313322067260742, train acuracy: 0.09765625
step: 314, val loss: 2.3124053478240967, val acuracy: 0.10533333569765091
step: 315, train loss: 2.306756019592285, train acuracy: 0.125
step: 315, val loss: 2.3252975940704346, val acuracy: 0.09683332592248917
step: 316, train loss: 2.325709342956543, train acuracy: 0.09375
step: 316, val loss: 2.32493257522583, val acuracy: 0.09683332592248917
step: 317, train loss: 2.321237564086914, train acuracy: 0.095703125
step: 317, val loss: 2.324939489364624, val acuracy: 0.09683332592248917
step: 318, train loss: 2.3312549591064453, train acuracy: 0.09765625
step: 318, val loss: 2.3246877193450928, val acuracy: 0.10400000214576721
step: 319, train loss: 2.3359079360961914, train acuracy: 0.08984375
step: 319, val loss: 2.324716091156006, val acuracy: 0.09683332592248917
step: 320, train loss: 2.3313043117523193, train acuracy: 0.11328125
step: 320, val loss: 2.324918031692505, val acuracy: 0.09683332592248917
step: 321, train loss: 2.333955764770508, train acuracy: 0.125
step: 321, val loss: 2.3270492553710938, val acuracy: 0.10899999737739563
step: 322, train loss: 2.3315987586975098, train acuracy: 0.08984375
step: 322, val loss: 2.3286304473876953, val acuracy: 0.10899999737739563
step: 323, train loss: 2.3269009590148926, train acuracy: 0.10546875
step: 323, val loss: 2.3263537883758545, val acuracy: 0.10533333569765091
step: 324, train loss: 2.34125018119812, train acuracy: 0.072265625
step: 324, val loss: 2.326125144958496, val acuracy: 0.1053333431482315
step: 325, train loss: 2.303441286087036, train acuracy: 0.130859375
step: 325, val loss: 2.3238768577575684, val acuracy: 0.1053333431482315
step: 326, train loss: 2.3329830169677734, train acuracy: 0.1015625
step: 326, val loss: 2.325918436050415, val acuracy: 0.1053333431482315
step: 327, train loss: 2.321362018585205, train acuracy: 0.09375
step: 327, val loss: 2.3254754543304443, val acuracy: 0.10533333569765091
step: 328, train loss: 2.3371849060058594, train acuracy: 0.08984375
step: 328, val loss: 2.3244943618774414, val acuracy: 0.10533333569765091
step: 329, train loss: 2.3248343467712402, train acuracy: 0.091796875
step: 329, val loss: 2.3238816261291504, val acuracy: 0.1053333431482315
step: 330, train loss: 2.3352158069610596, train acuracy: 0.1015625
step: 330, val loss: 2.335806131362915, val acuracy: 0.1053333431482315
step: 331, train loss: 2.3383982181549072, train acuracy: 0.09765625
step: 331, val loss: 2.32631516456604, val acuracy: 0.10533333569765091
step: 332, train loss: 2.329996109008789, train acuracy: 0.09375
step: 332, val loss: 2.324195146560669, val acuracy: 0.1053333431482315
step: 333, train loss: 2.342695713043213, train acuracy: 0.083984375
step: 333, val loss: 2.323965311050415, val acuracy: 0.10533332824707031
step: 334, train loss: 2.309375286102295, train acuracy: 0.10546875
step: 334, val loss: 2.3239850997924805, val acuracy: 0.10533333569765091
step: 335, train loss: 2.3324179649353027, train acuracy: 0.08984375
step: 335, val loss: 2.325016975402832, val acuracy: 0.10400000214576721
step: 336, train loss: 2.33400821685791, train acuracy: 0.10546875
step: 336, val loss: 2.3263988494873047, val acuracy: 0.1053333431482315
step: 337, train loss: 2.337045431137085, train acuracy: 0.08203125
step: 337, val loss: 2.3268635272979736, val acuracy: 0.10533333569765091
step: 338, train loss: 2.345273017883301, train acuracy: 0.111328125
step: 338, val loss: 2.337456703186035, val acuracy: 0.10533333569765091
step: 339, train loss: 2.3043406009674072, train acuracy: 0.125
step: 339, val loss: 2.331533432006836, val acuracy: 0.10533333569765091
step: 340, train loss: 2.3428168296813965, train acuracy: 0.11328125
step: 340, val loss: 2.3261308670043945, val acuracy: 0.10533333569765091
step: 341, train loss: 2.3258049488067627, train acuracy: 0.115234375
step: 341, val loss: 2.3260204792022705, val acuracy: 0.10533333569765091
step: 342, train loss: 2.342426061630249, train acuracy: 0.08984375
step: 342, val loss: 2.326014518737793, val acuracy: 0.1053333431482315
step: 343, train loss: 2.3336896896362305, train acuracy: 0.091796875
step: 343, val loss: 2.3259975910186768, val acuracy: 0.1053333431482315
step: 344, train loss: 2.316600799560547, train acuracy: 0.126953125
step: 344, val loss: 2.392726421356201, val acuracy: 0.09666665643453598
step: 345, train loss: 2.404442548751831, train acuracy: 0.091796875
step: 345, val loss: 2.382343292236328, val acuracy: 0.09833332896232605
step: 346, train loss: 2.363001585006714, train acuracy: 0.1015625
step: 346, val loss: 2.3647453784942627, val acuracy: 0.09750000387430191
step: 347, train loss: 2.3741416931152344, train acuracy: 0.08984375
step: 347, val loss: 2.3636858463287354, val acuracy: 0.09749999642372131
step: 348, train loss: 2.354987144470215, train acuracy: 0.099609375
step: 348, val loss: 2.3474011421203613, val acuracy: 0.10566666722297668
step: 349, train loss: 2.3202881813049316, train acuracy: 0.1015625
step: 349, val loss: 2.344698667526245, val acuracy: 0.09783333539962769
step: 350, train loss: 2.354330539703369, train acuracy: 0.1015625
step: 350, val loss: 2.340743064880371, val acuracy: 0.09916666150093079
step: 351, train loss: 2.3181397914886475, train acuracy: 0.10546875
step: 351, val loss: 2.3371219635009766, val acuracy: 0.10216666758060455
step: 352, train loss: 2.667593479156494, train acuracy: 0.076171875
step: 352, val loss: 2.711405038833618, val acuracy: 0.09033333510160446
step: 353, train loss: 2.5319387912750244, train acuracy: 0.091796875
step: 353, val loss: 2.5389819145202637, val acuracy: 0.09666667133569717
step: 354, train loss: 2.3775196075439453, train acuracy: 0.13671875
step: 354, val loss: 2.463353157043457, val acuracy: 0.0963333249092102
step: 355, train loss: 2.3503482341766357, train acuracy: 0.109375
step: 355, val loss: 2.345536708831787, val acuracy: 0.11099999397993088
step: 356, train loss: 2.3178234100341797, train acuracy: 0.12109375
step: 356, val loss: 2.324542284011841, val acuracy: 0.10716666281223297
step: 357, train loss: 2.29038405418396, train acuracy: 0.115234375
step: 357, val loss: 2.315662384033203, val acuracy: 0.11283332854509354
step: 358, train loss: 2.278657913208008, train acuracy: 0.140625
step: 358, val loss: 2.3046875, val acuracy: 0.10949999839067459
step: 359, train loss: 2.305267095565796, train acuracy: 0.087890625
step: 359, val loss: 2.303985595703125, val acuracy: 0.10949999839067459
step: 360, train loss: 2.2929301261901855, train acuracy: 0.17578125
step: 360, val loss: 2.354278087615967, val acuracy: 0.1614999920129776
step: 361, train loss: 2.132974147796631, train acuracy: 0.25390625
step: 361, val loss: 2.149167537689209, val acuracy: 0.2590000033378601
step: 362, train loss: 2.1010873317718506, train acuracy: 0.24609375
step: 362, val loss: 2.108156204223633, val acuracy: 0.24016666412353516
step: 363, train loss: 2.009575366973877, train acuracy: 0.27734375
step: 363, val loss: 2.0653467178344727, val acuracy: 0.24133333563804626
step: 364, train loss: 2.037774085998535, train acuracy: 0.228515625
step: 364, val loss: 2.056489944458008, val acuracy: 0.24250002205371857
step: 365, train loss: 2.0031564235687256, train acuracy: 0.265625
step: 365, val loss: 2.0000085830688477, val acuracy: 0.27383333444595337
step: 366, train loss: 1.811189889907837, train acuracy: 0.337890625
step: 366, val loss: 1.82863450050354, val acuracy: 0.32716667652130127
step: 367, train loss: 1.780482292175293, train acuracy: 0.37109375
step: 367, val loss: 1.754929542541504, val acuracy: 0.3800000250339508
step: 368, train loss: 1.8151381015777588, train acuracy: 0.341796875
step: 368, val loss: 1.7369720935821533, val acuracy: 0.38966667652130127
step: 369, train loss: 1.6792134046554565, train acuracy: 0.52734375
step: 369, val loss: 1.782981276512146, val acuracy: 0.4935000240802765
step: 370, train loss: 1.602104663848877, train acuracy: 0.5078125
step: 370, val loss: 1.584628939628601, val acuracy: 0.502333402633667
step: 371, train loss: 1.5898492336273193, train acuracy: 0.490234375
step: 371, val loss: 1.6004619598388672, val acuracy: 0.45233336091041565
step: 372, train loss: 1.4757603406906128, train acuracy: 0.529296875
step: 372, val loss: 1.5825258493423462, val acuracy: 0.49416667222976685
step: 373, train loss: 1.579551339149475, train acuracy: 0.45703125
step: 373, val loss: 1.63480806350708, val acuracy: 0.4321666955947876
step: 374, train loss: 1.6279152631759644, train acuracy: 0.47265625
step: 374, val loss: 1.5895529985427856, val acuracy: 0.484000027179718
step: 375, train loss: 1.5068413019180298, train acuracy: 0.57421875
step: 375, val loss: 1.6770998239517212, val acuracy: 0.5383334159851074
step: 376, train loss: 1.5929911136627197, train acuracy: 0.521484375
step: 376, val loss: 1.7072908878326416, val acuracy: 0.4988333582878113
step: 377, train loss: 1.672229290008545, train acuracy: 0.46484375
step: 377, val loss: 1.6572880744934082, val acuracy: 0.4688333570957184
step: 378, train loss: 1.587556004524231, train acuracy: 0.61328125
step: 378, val loss: 1.698641300201416, val acuracy: 0.5855000019073486
step: 379, train loss: 1.7627331018447876, train acuracy: 0.58203125
step: 379, val loss: 1.724951982498169, val acuracy: 0.5726667046546936
step: 380, train loss: 1.3946677446365356, train acuracy: 0.6015625
step: 380, val loss: 1.541572093963623, val acuracy: 0.5820000767707825
step: 381, train loss: 1.5228114128112793, train acuracy: 0.53515625
step: 381, val loss: 1.5644594430923462, val acuracy: 0.5361667275428772
step: 382, train loss: 1.5441657304763794, train acuracy: 0.576171875
step: 382, val loss: 1.6836047172546387, val acuracy: 0.5480000376701355
step: 383, train loss: 1.593567967414856, train acuracy: 0.5
step: 383, val loss: 1.7465702295303345, val acuracy: 0.4816666543483734
step: 384, train loss: 1.7759186029434204, train acuracy: 0.486328125
step: 384, val loss: 1.7156238555908203, val acuracy: 0.4893333911895752
step: 385, train loss: 1.7369483709335327, train acuracy: 0.494140625
step: 385, val loss: 1.7113090753555298, val acuracy: 0.49150004982948303
step: 386, train loss: 1.7458831071853638, train acuracy: 0.474609375
step: 386, val loss: 1.7098991870880127, val acuracy: 0.49283337593078613
step: 387, train loss: 1.7900538444519043, train acuracy: 0.486328125
step: 387, val loss: 1.7072536945343018, val acuracy: 0.49150002002716064
step: 388, train loss: 1.9070250988006592, train acuracy: 0.466796875
step: 388, val loss: 1.7046867609024048, val acuracy: 0.49166667461395264
step: 389, train loss: 1.773144006729126, train acuracy: 0.462890625
step: 389, val loss: 1.7032278776168823, val acuracy: 0.48883333802223206
step: 390, train loss: 1.6840819120407104, train acuracy: 0.453125
step: 390, val loss: 1.7022757530212402, val acuracy: 0.4905000329017639
step: 391, train loss: 1.6128653287887573, train acuracy: 0.478515625
step: 391, val loss: 1.7022725343704224, val acuracy: 0.4903333783149719
step: 392, train loss: 1.6365748643875122, train acuracy: 0.505859375
step: 392, val loss: 1.7021628618240356, val acuracy: 0.49016666412353516
step: 393, train loss: 1.658191442489624, train acuracy: 0.52734375
step: 393, val loss: 1.7014881372451782, val acuracy: 0.48850002884864807
step: 394, train loss: 1.6549419164657593, train acuracy: 0.5078125
step: 394, val loss: 1.7005879878997803, val acuracy: 0.4908333718776703
step: 395, train loss: 1.733506679534912, train acuracy: 0.49609375
step: 395, val loss: 1.7339215278625488, val acuracy: 0.49500006437301636
step: 396, train loss: 1.7508978843688965, train acuracy: 0.494140625
step: 396, val loss: 1.7023180723190308, val acuracy: 0.49150004982948303
step: 397, train loss: 1.5441781282424927, train acuracy: 0.52734375
step: 397, val loss: 1.7057753801345825, val acuracy: 0.5170000195503235
step: 398, train loss: 2.4456470012664795, train acuracy: 0.1015625
step: 398, val loss: 2.4936704635620117, val acuracy: 0.09650000184774399
step: 399, train loss: 2.5245230197906494, train acuracy: 0.119140625
step: 399, val loss: 2.4922051429748535, val acuracy: 0.09649999439716339
2017-12-04 15:35:16.152898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:35:16.397486: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x8f0df80 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 15:35:16.398191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:35:16.398447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 15:35:16.398463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 15:35:16.398469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 15:35:16.398480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 15:35:16.398487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.3163299560546875, train acuracy: 0.109375
step: 0, val loss: 2.3676979541778564, val acuracy: 0.09666666388511658
step: 1, train loss: 2.2265729904174805, train acuracy: 0.2548828125
step: 1, val loss: 2.2346277236938477, val acuracy: 0.22350001335144043
step: 2, train loss: 2.230520248413086, train acuracy: 0.2470703125
step: 2, val loss: 2.229799509048462, val acuracy: 0.24700000882148743
step: 3, train loss: 2.22572922706604, train acuracy: 0.1845703125
step: 3, val loss: 2.2406058311462402, val acuracy: 0.18433333933353424
step: 4, train loss: 2.1346702575683594, train acuracy: 0.3271484375
step: 4, val loss: 2.1467151641845703, val acuracy: 0.3148333728313446
step: 5, train loss: 1.9190760850906372, train acuracy: 0.4345703125
step: 5, val loss: 1.915338397026062, val acuracy: 0.4383333623409271
step: 6, train loss: 1.8577545881271362, train acuracy: 0.359375
step: 6, val loss: 1.898402214050293, val acuracy: 0.34800001978874207
step: 7, train loss: 1.6493717432022095, train acuracy: 0.615234375
step: 7, val loss: 1.682718276977539, val acuracy: 0.612000048160553
step: 8, train loss: 1.1292004585266113, train acuracy: 0.6064453125
step: 8, val loss: 1.2043659687042236, val acuracy: 0.5798333287239075
step: 9, train loss: 1.1674906015396118, train acuracy: 0.6484375
step: 9, val loss: 1.2130926847457886, val acuracy: 0.627333402633667
step: 10, train loss: 1.1839706897735596, train acuracy: 0.58984375
step: 10, val loss: 1.193847894668579, val acuracy: 0.5898333787918091
step: 11, train loss: 1.2610503435134888, train acuracy: 0.595703125
step: 11, val loss: 1.2112375497817993, val acuracy: 0.6188333630561829
step: 12, train loss: 1.1328233480453491, train acuracy: 0.650390625
step: 12, val loss: 1.1986098289489746, val acuracy: 0.6200000643730164
step: 13, train loss: 1.2054859399795532, train acuracy: 0.623046875
step: 13, val loss: 1.2055524587631226, val acuracy: 0.6160000562667847
step: 14, train loss: 1.2275073528289795, train acuracy: 0.6279296875
step: 14, val loss: 1.2842020988464355, val acuracy: 0.596333384513855
step: 15, train loss: 1.3610827922821045, train acuracy: 0.5703125
step: 15, val loss: 1.2989623546600342, val acuracy: 0.6006666421890259
step: 16, train loss: 1.2743662595748901, train acuracy: 0.6083984375
step: 16, val loss: 1.2877147197723389, val acuracy: 0.6068333983421326
step: 17, train loss: 1.2580652236938477, train acuracy: 0.6240234375
step: 17, val loss: 1.264493703842163, val acuracy: 0.6134999990463257
step: 18, train loss: 1.2245532274246216, train acuracy: 0.6376953125
step: 18, val loss: 1.2601178884506226, val acuracy: 0.6285000443458557
step: 19, train loss: 1.229843020439148, train acuracy: 0.623046875
step: 19, val loss: 1.2681506872177124, val acuracy: 0.6133333444595337
step: 20, train loss: 1.2880456447601318, train acuracy: 0.615234375
step: 20, val loss: 1.281967282295227, val acuracy: 0.6168333888053894
step: 21, train loss: 1.2930160760879517, train acuracy: 0.615234375
step: 21, val loss: 1.2963703870773315, val acuracy: 0.6126667261123657
step: 22, train loss: 1.2967065572738647, train acuracy: 0.609375
step: 22, val loss: 1.3066033124923706, val acuracy: 0.6105000376701355
step: 23, train loss: 1.311039686203003, train acuracy: 0.5908203125
step: 23, val loss: 1.3058192729949951, val acuracy: 0.5956667065620422
step: 24, train loss: 1.2704699039459229, train acuracy: 0.603515625
step: 24, val loss: 1.3161333799362183, val acuracy: 0.5840000510215759
step: 25, train loss: 1.3075475692749023, train acuracy: 0.572265625
step: 25, val loss: 1.3302123546600342, val acuracy: 0.5721666812896729
step: 26, train loss: 1.4241490364074707, train acuracy: 0.5478515625
step: 26, val loss: 1.3834919929504395, val acuracy: 0.5573333501815796
step: 27, train loss: 1.3430562019348145, train acuracy: 0.5634765625
step: 27, val loss: 1.387832760810852, val acuracy: 0.5611666440963745
step: 28, train loss: 1.3740488290786743, train acuracy: 0.5576171875
step: 28, val loss: 1.3496990203857422, val acuracy: 0.5590000152587891
step: 29, train loss: 1.33461594581604, train acuracy: 0.56640625
step: 29, val loss: 1.313004732131958, val acuracy: 0.5674999952316284
step: 30, train loss: 1.290751338005066, train acuracy: 0.625
step: 30, val loss: 1.3223257064819336, val acuracy: 0.5908334255218506
step: 31, train loss: 1.3123512268066406, train acuracy: 0.6005859375
step: 31, val loss: 1.3280051946640015, val acuracy: 0.596833348274231
step: 32, train loss: 1.3203434944152832, train acuracy: 0.5693359375
step: 32, val loss: 1.3353655338287354, val acuracy: 0.5736666917800903
step: 33, train loss: 1.2839685678482056, train acuracy: 0.611328125
step: 33, val loss: 1.3506863117218018, val acuracy: 0.5735000371932983
step: 34, train loss: 1.1904348134994507, train acuracy: 0.6484375
step: 34, val loss: 1.285997748374939, val acuracy: 0.6001666784286499
step: 35, train loss: 1.360059380531311, train acuracy: 0.568359375
step: 35, val loss: 1.2903306484222412, val acuracy: 0.5998333692550659
step: 36, train loss: 1.379120945930481, train acuracy: 0.556640625
step: 36, val loss: 1.3312273025512695, val acuracy: 0.5631667375564575
step: 37, train loss: 1.3024976253509521, train acuracy: 0.5546875
step: 37, val loss: 1.3393268585205078, val acuracy: 0.5545000433921814
step: 38, train loss: 1.2704187631607056, train acuracy: 0.6337890625
step: 38, val loss: 1.3525779247283936, val acuracy: 0.6095000505447388
step: 39, train loss: 1.272477388381958, train acuracy: 0.5849609375
step: 39, val loss: 1.304001808166504, val acuracy: 0.5768334269523621
step: 40, train loss: 1.3359357118606567, train acuracy: 0.5615234375
step: 40, val loss: 1.3290305137634277, val acuracy: 0.5634999871253967
step: 41, train loss: 1.3676518201828003, train acuracy: 0.5478515625
step: 41, val loss: 1.3225866556167603, val acuracy: 0.5600000619888306
step: 42, train loss: 1.3677598237991333, train acuracy: 0.580078125
step: 42, val loss: 1.3512002229690552, val acuracy: 0.5793333649635315
step: 43, train loss: 1.367282509803772, train acuracy: 0.5439453125
step: 43, val loss: 1.3719786405563354, val acuracy: 0.5375000238418579
step: 44, train loss: 1.3571099042892456, train acuracy: 0.599609375
step: 44, val loss: 1.3693039417266846, val acuracy: 0.5875000357627869
step: 45, train loss: 1.400752067565918, train acuracy: 0.568359375
step: 45, val loss: 1.353866696357727, val acuracy: 0.5761666893959045
step: 46, train loss: 1.3317400217056274, train acuracy: 0.5947265625
step: 46, val loss: 1.3778430223464966, val acuracy: 0.5770000219345093
step: 47, train loss: 1.2907160520553589, train acuracy: 0.607421875
step: 47, val loss: 1.378121018409729, val acuracy: 0.5811667442321777
step: 48, train loss: 1.33029305934906, train acuracy: 0.5849609375
step: 48, val loss: 1.3934524059295654, val acuracy: 0.5646666884422302
step: 49, train loss: 1.3342331647872925, train acuracy: 0.59765625
step: 49, val loss: 1.451831579208374, val acuracy: 0.5830000638961792
step: 50, train loss: 1.3662054538726807, train acuracy: 0.578125
step: 50, val loss: 1.4501097202301025, val acuracy: 0.549666702747345
step: 51, train loss: 1.4116098880767822, train acuracy: 0.57421875
step: 51, val loss: 1.4575352668762207, val acuracy: 0.5450000762939453
step: 52, train loss: 1.3980458974838257, train acuracy: 0.4970703125
step: 52, val loss: 1.4365081787109375, val acuracy: 0.5001667141914368
step: 53, train loss: 1.3817459344863892, train acuracy: 0.544921875
step: 53, val loss: 1.433845043182373, val acuracy: 0.5138333439826965
step: 54, train loss: 1.3547919988632202, train acuracy: 0.533203125
step: 54, val loss: 1.4244253635406494, val acuracy: 0.5165000557899475
step: 55, train loss: 1.3744006156921387, train acuracy: 0.537109375
step: 55, val loss: 1.4405001401901245, val acuracy: 0.5255000591278076
step: 56, train loss: 1.4525418281555176, train acuracy: 0.5224609375
step: 56, val loss: 1.463301420211792, val acuracy: 0.5266666412353516
step: 57, train loss: 1.3960195779800415, train acuracy: 0.5234375
step: 57, val loss: 1.4511830806732178, val acuracy: 0.48483335971832275
step: 58, train loss: 1.4215548038482666, train acuracy: 0.5224609375
step: 58, val loss: 1.5097087621688843, val acuracy: 0.5031667351722717
step: 59, train loss: 1.5593314170837402, train acuracy: 0.5224609375
step: 59, val loss: 1.5537163019180298, val acuracy: 0.531000018119812
step: 60, train loss: 1.387494444847107, train acuracy: 0.615234375
step: 60, val loss: 1.5244227647781372, val acuracy: 0.5586667060852051
step: 61, train loss: 1.4399745464324951, train acuracy: 0.5322265625
step: 61, val loss: 1.4887545108795166, val acuracy: 0.5180000066757202
step: 62, train loss: 1.4904602766036987, train acuracy: 0.5078125
step: 62, val loss: 1.5290658473968506, val acuracy: 0.499666690826416
step: 63, train loss: 1.5538431406021118, train acuracy: 0.4853515625
step: 63, val loss: 1.563424825668335, val acuracy: 0.499500036239624
step: 64, train loss: 1.4124603271484375, train acuracy: 0.5625
step: 64, val loss: 1.509770393371582, val acuracy: 0.5380000472068787
step: 65, train loss: 1.8924823999404907, train acuracy: 0.4677734375
step: 65, val loss: 1.9117127656936646, val acuracy: 0.47966668009757996
step: 66, train loss: 2.0061540603637695, train acuracy: 0.314453125
step: 66, val loss: 2.027333974838257, val acuracy: 0.3048333525657654
step: 67, train loss: 2.042980670928955, train acuracy: 0.30078125
step: 67, val loss: 2.028594970703125, val acuracy: 0.3011666536331177
step: 68, train loss: 1.7950215339660645, train acuracy: 0.3740234375
step: 68, val loss: 1.802828311920166, val acuracy: 0.36900001764297485
step: 69, train loss: 1.7915029525756836, train acuracy: 0.44140625
step: 69, val loss: 1.8289575576782227, val acuracy: 0.4320000112056732
step: 70, train loss: 1.3676501512527466, train acuracy: 0.517578125
step: 70, val loss: 1.3788743019104004, val acuracy: 0.5205000042915344
step: 71, train loss: 1.3637640476226807, train acuracy: 0.484375
step: 71, val loss: 1.3793554306030273, val acuracy: 0.4880000352859497
step: 72, train loss: 1.3574261665344238, train acuracy: 0.4970703125
step: 72, val loss: 1.3755179643630981, val acuracy: 0.5036666989326477
step: 73, train loss: 1.1572102308273315, train acuracy: 0.6181640625
step: 73, val loss: 1.1318939924240112, val acuracy: 0.6341667175292969
step: 74, train loss: 0.9277837872505188, train acuracy: 0.6943359375
step: 74, val loss: 1.0318833589553833, val acuracy: 0.659500002861023
step: 75, train loss: 0.9533230066299438, train acuracy: 0.705078125
step: 75, val loss: 0.9246669411659241, val acuracy: 0.7141667604446411
step: 76, train loss: 1.0582150220870972, train acuracy: 0.6494140625
step: 76, val loss: 1.0834914445877075, val acuracy: 0.6466667056083679
step: 77, train loss: 0.9728791117668152, train acuracy: 0.6884765625
step: 77, val loss: 0.952309787273407, val acuracy: 0.6933333873748779
step: 78, train loss: 0.9848648309707642, train acuracy: 0.6689453125
step: 78, val loss: 0.9884304404258728, val acuracy: 0.6718333959579468
step: 79, train loss: 0.9070340394973755, train acuracy: 0.7021484375
step: 79, val loss: 0.9900358319282532, val acuracy: 0.6558334231376648
step: 80, train loss: 1.0068182945251465, train acuracy: 0.662109375
step: 80, val loss: 1.0189740657806396, val acuracy: 0.6661667227745056
step: 81, train loss: 0.9926602840423584, train acuracy: 0.673828125
step: 81, val loss: 0.98839271068573, val acuracy: 0.6683334112167358
step: 82, train loss: 0.9185540676116943, train acuracy: 0.6904296875
step: 82, val loss: 0.9865872859954834, val acuracy: 0.6565001010894775
step: 83, train loss: 1.0097354650497437, train acuracy: 0.6708984375
step: 83, val loss: 1.0059092044830322, val acuracy: 0.6700000762939453
step: 84, train loss: 1.0094183683395386, train acuracy: 0.662109375
step: 84, val loss: 1.0200395584106445, val acuracy: 0.6411666870117188
step: 85, train loss: 0.9401252269744873, train acuracy: 0.677734375
step: 85, val loss: 1.0394270420074463, val acuracy: 0.661166787147522
step: 86, train loss: 0.9485893249511719, train acuracy: 0.6953125
step: 86, val loss: 1.02755868434906, val acuracy: 0.6521666646003723
step: 87, train loss: 1.0444138050079346, train acuracy: 0.6513671875
step: 87, val loss: 1.0508595705032349, val acuracy: 0.6536667346954346
step: 88, train loss: 1.0283302068710327, train acuracy: 0.6494140625
step: 88, val loss: 1.0042657852172852, val acuracy: 0.6583333611488342
step: 89, train loss: 0.9469095468521118, train acuracy: 0.66796875
step: 89, val loss: 1.0216946601867676, val acuracy: 0.6536667346954346
step: 90, train loss: 0.9969346523284912, train acuracy: 0.6640625
step: 90, val loss: 1.0436465740203857, val acuracy: 0.6393333673477173
step: 91, train loss: 0.9718366861343384, train acuracy: 0.6630859375
step: 91, val loss: 1.0493435859680176, val acuracy: 0.6420000791549683
step: 92, train loss: 1.0561439990997314, train acuracy: 0.6572265625
step: 92, val loss: 1.0939018726348877, val acuracy: 0.6405000686645508
step: 93, train loss: 1.0873812437057495, train acuracy: 0.64453125
step: 93, val loss: 1.134962797164917, val acuracy: 0.6081666946411133
step: 94, train loss: 1.1177085638046265, train acuracy: 0.6337890625
step: 94, val loss: 1.141723871231079, val acuracy: 0.6031666994094849
step: 95, train loss: 1.0673786401748657, train acuracy: 0.6455078125
step: 95, val loss: 1.1067519187927246, val acuracy: 0.640500009059906
step: 96, train loss: 1.1189296245574951, train acuracy: 0.607421875
step: 96, val loss: 1.1280044317245483, val acuracy: 0.6010000705718994
step: 97, train loss: 1.0760552883148193, train acuracy: 0.6474609375
step: 97, val loss: 1.119674801826477, val acuracy: 0.6398333311080933
step: 98, train loss: 1.1028697490692139, train acuracy: 0.6142578125
step: 98, val loss: 1.1553800106048584, val acuracy: 0.6011667251586914
step: 99, train loss: 1.1058417558670044, train acuracy: 0.6552734375
step: 99, val loss: 1.1470386981964111, val acuracy: 0.6220000386238098
step: 100, train loss: 1.060288429260254, train acuracy: 0.63671875
step: 100, val loss: 1.1519660949707031, val acuracy: 0.5926666855812073
step: 101, train loss: 1.0749495029449463, train acuracy: 0.6474609375
step: 101, val loss: 1.1985121965408325, val acuracy: 0.6171667575836182
step: 102, train loss: 1.1272801160812378, train acuracy: 0.6318359375
step: 102, val loss: 1.1898964643478394, val acuracy: 0.6128333806991577
step: 103, train loss: 1.1062957048416138, train acuracy: 0.6103515625
step: 103, val loss: 1.1612448692321777, val acuracy: 0.5975000262260437
step: 104, train loss: 1.080940842628479, train acuracy: 0.6494140625
step: 104, val loss: 1.1767945289611816, val acuracy: 0.6233333945274353
step: 105, train loss: 1.1721729040145874, train acuracy: 0.59765625
step: 105, val loss: 1.1858712434768677, val acuracy: 0.5856667160987854
step: 106, train loss: 1.1888043880462646, train acuracy: 0.615234375
step: 106, val loss: 1.2221437692642212, val acuracy: 0.5901667475700378
step: 107, train loss: 1.2766607999801636, train acuracy: 0.5546875
step: 107, val loss: 1.2374014854431152, val acuracy: 0.5621666312217712
step: 108, train loss: 1.2842531204223633, train acuracy: 0.5849609375
step: 108, val loss: 1.2499929666519165, val acuracy: 0.598833441734314
step: 109, train loss: 1.1966300010681152, train acuracy: 0.59375
step: 109, val loss: 1.275296688079834, val acuracy: 0.5659999847412109
step: 110, train loss: 1.2017194032669067, train acuracy: 0.6201171875
step: 110, val loss: 1.2930383682250977, val acuracy: 0.5836666822433472
step: 111, train loss: 1.2558344602584839, train acuracy: 0.59765625
step: 111, val loss: 1.3036739826202393, val acuracy: 0.5856667757034302
step: 112, train loss: 1.1552256345748901, train acuracy: 0.60546875
step: 112, val loss: 1.2818750143051147, val acuracy: 0.5763333439826965
step: 113, train loss: 1.1790910959243774, train acuracy: 0.595703125
step: 113, val loss: 1.2813926935195923, val acuracy: 0.577666699886322
step: 114, train loss: 1.2780338525772095, train acuracy: 0.568359375
step: 114, val loss: 1.2826194763183594, val acuracy: 0.5758333802223206
step: 115, train loss: 1.269105076789856, train acuracy: 0.5849609375
step: 115, val loss: 1.3138872385025024, val acuracy: 0.5755000114440918
step: 116, train loss: 1.2315242290496826, train acuracy: 0.583984375
step: 116, val loss: 1.3450403213500977, val acuracy: 0.5616666674613953
step: 117, train loss: 1.3567042350769043, train acuracy: 0.5517578125
step: 117, val loss: 1.3670684099197388, val acuracy: 0.5541666746139526
step: 118, train loss: 1.2022197246551514, train acuracy: 0.62890625
step: 118, val loss: 1.3803585767745972, val acuracy: 0.5760000348091125
step: 119, train loss: 1.42483651638031, train acuracy: 0.552734375
step: 119, val loss: 1.3905225992202759, val acuracy: 0.5728333592414856
step: 120, train loss: 1.3246605396270752, train acuracy: 0.587890625
step: 120, val loss: 1.434435486793518, val acuracy: 0.5538333654403687
step: 121, train loss: 1.445223093032837, train acuracy: 0.5654296875
step: 121, val loss: 1.421562910079956, val acuracy: 0.5578333139419556
step: 122, train loss: 1.3811845779418945, train acuracy: 0.5810546875
step: 122, val loss: 1.4486808776855469, val acuracy: 0.5758333802223206
step: 123, train loss: 1.4015718698501587, train acuracy: 0.5849609375
step: 123, val loss: 1.4318290948867798, val acuracy: 0.5695000290870667
step: 124, train loss: 1.4977730512619019, train acuracy: 0.544921875
step: 124, val loss: 1.4385650157928467, val acuracy: 0.5490000247955322
step: 125, train loss: 1.4386866092681885, train acuracy: 0.5703125
step: 125, val loss: 1.4635369777679443, val acuracy: 0.5555000305175781
step: 126, train loss: 1.3194735050201416, train acuracy: 0.6201171875
step: 126, val loss: 1.4669415950775146, val acuracy: 0.5771666765213013
step: 127, train loss: 1.5219731330871582, train acuracy: 0.56640625
step: 127, val loss: 1.4927148818969727, val acuracy: 0.5588333606719971
step: 128, train loss: 1.3975111246109009, train acuracy: 0.6298828125
step: 128, val loss: 1.520516276359558, val acuracy: 0.6118333339691162
step: 129, train loss: 1.521464228630066, train acuracy: 0.5634765625
step: 129, val loss: 1.4840611219406128, val acuracy: 0.5600000619888306
step: 130, train loss: 1.4432661533355713, train acuracy: 0.619140625
step: 130, val loss: 1.4981770515441895, val acuracy: 0.5983334183692932
step: 131, train loss: 1.3533884286880493, train acuracy: 0.6494140625
step: 131, val loss: 1.5233056545257568, val acuracy: 0.5981667637825012
step: 132, train loss: 1.5520967245101929, train acuracy: 0.56640625
step: 132, val loss: 1.526280164718628, val acuracy: 0.5890001058578491
step: 133, train loss: 1.5084762573242188, train acuracy: 0.5771484375
step: 133, val loss: 1.534456729888916, val acuracy: 0.5870000720024109
step: 134, train loss: 1.4716987609863281, train acuracy: 0.6064453125
step: 134, val loss: 1.537998914718628, val acuracy: 0.5845000147819519
step: 135, train loss: 1.5293093919754028, train acuracy: 0.580078125
step: 135, val loss: 1.5215353965759277, val acuracy: 0.5705000758171082
step: 136, train loss: 1.6974729299545288, train acuracy: 0.568359375
step: 136, val loss: 1.7130823135375977, val acuracy: 0.5558333396911621
step: 137, train loss: 1.5162333250045776, train acuracy: 0.5888671875
step: 137, val loss: 1.6024214029312134, val acuracy: 0.5699999928474426
step: 138, train loss: 1.583553433418274, train acuracy: 0.568359375
step: 138, val loss: 1.6375478506088257, val acuracy: 0.5466667413711548
step: 139, train loss: 1.545886516571045, train acuracy: 0.5849609375
step: 139, val loss: 1.5954203605651855, val acuracy: 0.5898333787918091
step: 140, train loss: 1.679512858390808, train acuracy: 0.57421875
step: 140, val loss: 1.596182107925415, val acuracy: 0.5963333249092102
step: 141, train loss: 1.539136528968811, train acuracy: 0.6005859375
step: 141, val loss: 1.6103919744491577, val acuracy: 0.5901666879653931
step: 142, train loss: 1.5543216466903687, train acuracy: 0.603515625
step: 142, val loss: 1.6444984674453735, val acuracy: 0.5978333353996277
step: 143, train loss: 1.5907634496688843, train acuracy: 0.63671875
step: 143, val loss: 1.6551365852355957, val acuracy: 0.6255000829696655
step: 144, train loss: 1.6132131814956665, train acuracy: 0.6259765625
step: 144, val loss: 1.6711244583129883, val acuracy: 0.6358333826065063
step: 145, train loss: 1.5046148300170898, train acuracy: 0.6416015625
step: 145, val loss: 1.6878485679626465, val acuracy: 0.611166775226593
step: 146, train loss: 1.6792645454406738, train acuracy: 0.576171875
step: 146, val loss: 1.7114694118499756, val acuracy: 0.5798333883285522
step: 147, train loss: 1.6294150352478027, train acuracy: 0.6376953125
step: 147, val loss: 1.7425705194473267, val acuracy: 0.6268333792686462
step: 148, train loss: 1.7475625276565552, train acuracy: 0.572265625
step: 148, val loss: 1.7742363214492798, val acuracy: 0.5546666979789734
step: 149, train loss: 1.6644985675811768, train acuracy: 0.5595703125
step: 149, val loss: 1.787642002105713, val acuracy: 0.5451666712760925
step: 150, train loss: 1.695088505744934, train acuracy: 0.5830078125
step: 150, val loss: 1.7999773025512695, val acuracy: 0.562666654586792
step: 151, train loss: 1.6802728176116943, train acuracy: 0.6015625
step: 151, val loss: 1.7921411991119385, val acuracy: 0.5691666603088379
step: 152, train loss: 1.7022737264633179, train acuracy: 0.5869140625
step: 152, val loss: 1.799075961112976, val acuracy: 0.5590000152587891
step: 153, train loss: 1.5338847637176514, train acuracy: 0.626953125
step: 153, val loss: 1.8268197774887085, val acuracy: 0.5941666960716248
step: 154, train loss: 1.7167422771453857, train acuracy: 0.5703125
step: 154, val loss: 1.8316830396652222, val acuracy: 0.5326666831970215
step: 155, train loss: 1.8108129501342773, train acuracy: 0.5908203125
step: 155, val loss: 1.8865593671798706, val acuracy: 0.5756666660308838
step: 156, train loss: 1.7237176895141602, train acuracy: 0.6259765625
step: 156, val loss: 1.8697998523712158, val acuracy: 0.5983332991600037
step: 157, train loss: 1.8512088060379028, train acuracy: 0.6162109375
step: 157, val loss: 1.875135898590088, val acuracy: 0.6010000109672546
step: 158, train loss: 1.8473267555236816, train acuracy: 0.6298828125
step: 158, val loss: 1.9035444259643555, val acuracy: 0.5973333716392517
step: 159, train loss: 1.943359613418579, train acuracy: 0.5517578125
step: 159, val loss: 1.9259129762649536, val acuracy: 0.5640000700950623
step: 160, train loss: 1.8442468643188477, train acuracy: 0.5595703125
step: 160, val loss: 1.9301011562347412, val acuracy: 0.5826666355133057
step: 161, train loss: 1.993844985961914, train acuracy: 0.5703125
step: 161, val loss: 1.947097897529602, val acuracy: 0.5708333849906921
step: 162, train loss: 1.8591428995132446, train acuracy: 0.5966796875
step: 162, val loss: 1.9606060981750488, val acuracy: 0.5850000381469727
step: 163, train loss: 1.9275544881820679, train acuracy: 0.6044921875
step: 163, val loss: 1.985121488571167, val acuracy: 0.6045000553131104
step: 164, train loss: 1.8291215896606445, train acuracy: 0.6298828125
step: 164, val loss: 1.9941704273223877, val acuracy: 0.5978333353996277
step: 165, train loss: 1.856986165046692, train acuracy: 0.6484375
step: 165, val loss: 2.0115039348602295, val acuracy: 0.6128333806991577
step: 166, train loss: 1.9900809526443481, train acuracy: 0.5888671875
step: 166, val loss: 2.022254467010498, val acuracy: 0.5791666507720947
step: 167, train loss: 1.938403606414795, train acuracy: 0.591796875
step: 167, val loss: 2.0715038776397705, val acuracy: 0.5706667304039001
step: 168, train loss: 2.1511735916137695, train acuracy: 0.517578125
step: 168, val loss: 2.113609790802002, val acuracy: 0.49266672134399414
step: 169, train loss: 2.123655319213867, train acuracy: 0.5419921875
step: 169, val loss: 2.1134488582611084, val acuracy: 0.5555000305175781
step: 170, train loss: 1.8987877368927002, train acuracy: 0.6484375
step: 170, val loss: 2.158918857574463, val acuracy: 0.593833327293396
step: 171, train loss: 2.118767261505127, train acuracy: 0.578125
step: 171, val loss: 2.168091297149658, val acuracy: 0.5885000228881836
step: 172, train loss: 2.0282530784606934, train acuracy: 0.6279296875
step: 172, val loss: 2.1845433712005615, val acuracy: 0.639500081539154
step: 173, train loss: 2.200852155685425, train acuracy: 0.6064453125
step: 173, val loss: 2.240818977355957, val acuracy: 0.5636667013168335
step: 174, train loss: 2.2625646591186523, train acuracy: 0.568359375
step: 174, val loss: 2.2517731189727783, val acuracy: 0.5563333630561829
step: 175, train loss: 2.126194953918457, train acuracy: 0.6279296875
step: 175, val loss: 2.193124532699585, val acuracy: 0.6056667566299438
step: 176, train loss: 2.2919657230377197, train acuracy: 0.572265625
step: 176, val loss: 2.2007267475128174, val acuracy: 0.5980000495910645
step: 177, train loss: 2.334913730621338, train acuracy: 0.576171875
step: 177, val loss: 2.2198140621185303, val acuracy: 0.5580000281333923
step: 178, train loss: 1.9460724592208862, train acuracy: 0.6240234375
step: 178, val loss: 2.2615106105804443, val acuracy: 0.5805000066757202
step: 179, train loss: 2.375607490539551, train acuracy: 0.4951171875
step: 179, val loss: 2.251760959625244, val acuracy: 0.5090000629425049
step: 180, train loss: 2.0222086906433105, train acuracy: 0.6025390625
step: 180, val loss: 2.253744602203369, val acuracy: 0.593166708946228
step: 181, train loss: 2.3612704277038574, train acuracy: 0.537109375
step: 181, val loss: 2.2826013565063477, val acuracy: 0.5170000195503235
step: 182, train loss: 2.168853521347046, train acuracy: 0.55078125
step: 182, val loss: 2.1955907344818115, val acuracy: 0.5351667404174805
step: 183, train loss: 1.90194571018219, train acuracy: 0.556640625
step: 183, val loss: 2.0451016426086426, val acuracy: 0.5313333868980408
step: 184, train loss: 1.8947895765304565, train acuracy: 0.5126953125
step: 184, val loss: 1.9519879817962646, val acuracy: 0.515500009059906
step: 185, train loss: 1.9807010889053345, train acuracy: 0.498046875
step: 185, val loss: 1.8698294162750244, val acuracy: 0.5250000357627869
step: 186, train loss: 1.694016695022583, train acuracy: 0.5595703125
step: 186, val loss: 1.9028866291046143, val acuracy: 0.5358333587646484
step: 187, train loss: 1.7617812156677246, train acuracy: 0.5107421875
step: 187, val loss: 1.8876683712005615, val acuracy: 0.4790000319480896
step: 188, train loss: 1.9164186716079712, train acuracy: 0.37109375
step: 188, val loss: 1.9214396476745605, val acuracy: 0.377666711807251
step: 189, train loss: 1.4769421815872192, train acuracy: 0.56640625
step: 189, val loss: 1.490444302558899, val acuracy: 0.5610000491142273
step: 190, train loss: 1.4236795902252197, train acuracy: 0.599609375
step: 190, val loss: 1.4488695859909058, val acuracy: 0.581000030040741
step: 191, train loss: 1.362106442451477, train acuracy: 0.580078125
step: 191, val loss: 1.3242833614349365, val acuracy: 0.5981667637825012
step: 192, train loss: 1.253875970840454, train acuracy: 0.6484375
step: 192, val loss: 1.2299860715866089, val acuracy: 0.6801667213439941
step: 193, train loss: 1.1859432458877563, train acuracy: 0.689453125
step: 193, val loss: 1.2180430889129639, val acuracy: 0.6838333010673523
step: 194, train loss: 1.1875643730163574, train acuracy: 0.6396484375
step: 194, val loss: 1.2276687622070312, val acuracy: 0.612166702747345
step: 195, train loss: 1.0663870573043823, train acuracy: 0.595703125
step: 195, val loss: 1.072340488433838, val acuracy: 0.6228334307670593
step: 196, train loss: 0.9454218745231628, train acuracy: 0.73046875
step: 196, val loss: 0.9316307306289673, val acuracy: 0.7266667485237122
step: 197, train loss: 0.9489651918411255, train acuracy: 0.7255859375
step: 197, val loss: 0.9473752379417419, val acuracy: 0.7190001010894775
step: 198, train loss: 0.9493212699890137, train acuracy: 0.70703125
step: 198, val loss: 0.9412779211997986, val acuracy: 0.7228333950042725
step: 199, train loss: 0.9298622608184814, train acuracy: 0.72265625
step: 199, val loss: 0.942374587059021, val acuracy: 0.7153333425521851
step: 200, train loss: 1.1753413677215576, train acuracy: 0.6435546875
step: 200, val loss: 1.1316888332366943, val acuracy: 0.6521667242050171
step: 201, train loss: 1.168147325515747, train acuracy: 0.64453125
step: 201, val loss: 1.139923095703125, val acuracy: 0.6448333859443665
step: 202, train loss: 1.1809903383255005, train acuracy: 0.6474609375
step: 202, val loss: 1.1406478881835938, val acuracy: 0.6453333497047424
step: 203, train loss: 1.093622088432312, train acuracy: 0.6640625
step: 203, val loss: 1.1345105171203613, val acuracy: 0.6623333692550659
step: 204, train loss: 1.0639249086380005, train acuracy: 0.6953125
step: 204, val loss: 1.171524167060852, val acuracy: 0.6691666841506958
step: 205, train loss: 1.181838035583496, train acuracy: 0.642578125
step: 205, val loss: 1.180818796157837, val acuracy: 0.6381666660308838
step: 206, train loss: 1.112579584121704, train acuracy: 0.689453125
step: 206, val loss: 1.1361093521118164, val acuracy: 0.6830000877380371
step: 207, train loss: 1.1433316469192505, train acuracy: 0.677734375
step: 207, val loss: 1.1325669288635254, val acuracy: 0.6751667261123657
step: 208, train loss: 1.1351596117019653, train acuracy: 0.677734375
step: 208, val loss: 1.1397054195404053, val acuracy: 0.6691666841506958
step: 209, train loss: 1.1147223711013794, train acuracy: 0.6767578125
step: 209, val loss: 1.1450681686401367, val acuracy: 0.6671667098999023
step: 210, train loss: 1.0743259191513062, train acuracy: 0.697265625
step: 210, val loss: 1.142672061920166, val acuracy: 0.6708333492279053
step: 211, train loss: 1.1410971879959106, train acuracy: 0.693359375
step: 211, val loss: 1.1456882953643799, val acuracy: 0.6896666884422302
step: 212, train loss: 1.1944160461425781, train acuracy: 0.662109375
step: 212, val loss: 1.1418383121490479, val acuracy: 0.6800000071525574
step: 213, train loss: 1.1155325174331665, train acuracy: 0.6748046875
step: 213, val loss: 1.1413662433624268, val acuracy: 0.6806667447090149
step: 214, train loss: 1.1309189796447754, train acuracy: 0.6748046875
step: 214, val loss: 1.1485328674316406, val acuracy: 0.6801667213439941
step: 215, train loss: 1.1929417848587036, train acuracy: 0.6650390625
step: 215, val loss: 1.1536235809326172, val acuracy: 0.686833381652832
step: 216, train loss: 1.0862836837768555, train acuracy: 0.712890625
step: 216, val loss: 1.1449165344238281, val acuracy: 0.6818333268165588
step: 217, train loss: 1.1428544521331787, train acuracy: 0.6796875
step: 217, val loss: 1.1426153182983398, val acuracy: 0.6856666803359985
step: 218, train loss: 6.114213943481445, train acuracy: 0.447265625
step: 218, val loss: 5.775148868560791, val acuracy: 0.46133333444595337
step: 219, train loss: 4.0537543296813965, train acuracy: 0.2021484375
step: 219, val loss: 3.9412941932678223, val acuracy: 0.20033332705497742
step: 220, train loss: 3.8831801414489746, train acuracy: 0.0859375
step: 220, val loss: 3.8092074394226074, val acuracy: 0.09666665643453598
step: 221, train loss: 3.4655961990356445, train acuracy: 0.1015625
step: 221, val loss: 3.435065269470215, val acuracy: 0.09749999642372131
step: 222, train loss: 2.4968185424804688, train acuracy: 0.109375
step: 222, val loss: 2.5290377140045166, val acuracy: 0.10449999570846558
step: 223, train loss: 2.323228359222412, train acuracy: 0.125
step: 223, val loss: 2.330209255218506, val acuracy: 0.10916665941476822
step: 224, train loss: 2.2789251804351807, train acuracy: 0.1044921875
step: 224, val loss: 2.306988477706909, val acuracy: 0.10350000113248825
step: 225, train loss: 2.3112404346466064, train acuracy: 0.109375
step: 225, val loss: 2.315358877182007, val acuracy: 0.09666666388511658
step: 226, train loss: 2.3165831565856934, train acuracy: 0.154296875
step: 226, val loss: 2.308450937271118, val acuracy: 0.1666666567325592
step: 227, train loss: 2.2464165687561035, train acuracy: 0.138671875
step: 227, val loss: 2.251176595687866, val acuracy: 0.1393333226442337
step: 228, train loss: 2.260103225708008, train acuracy: 0.1220703125
step: 228, val loss: 2.2529001235961914, val acuracy: 0.12199999392032623
step: 229, train loss: 2.251267910003662, train acuracy: 0.1328125
step: 229, val loss: 2.250572443008423, val acuracy: 0.12533333897590637
step: 230, train loss: 2.2553014755249023, train acuracy: 0.1171875
step: 230, val loss: 2.250520944595337, val acuracy: 0.125166654586792
step: 231, train loss: 2.593383550643921, train acuracy: 0.1591796875
step: 231, val loss: 2.5603508949279785, val acuracy: 0.1525000035762787
step: 232, train loss: 2.283179521560669, train acuracy: 0.298828125
step: 232, val loss: 2.2734827995300293, val acuracy: 0.29733335971832275
step: 233, train loss: 2.200418710708618, train acuracy: 0.2490234375
step: 233, val loss: 2.190981149673462, val acuracy: 0.2548333406448364
step: 234, train loss: 2.083946466445923, train acuracy: 0.2138671875
step: 234, val loss: 2.0844674110412598, val acuracy: 0.24000002443790436
step: 235, train loss: 1.7334626913070679, train acuracy: 0.4765625
step: 235, val loss: 1.8246548175811768, val acuracy: 0.43783336877822876
step: 236, train loss: 1.7965415716171265, train acuracy: 0.408203125
step: 236, val loss: 1.7717106342315674, val acuracy: 0.41599997878074646
step: 237, train loss: 1.2679729461669922, train acuracy: 0.61328125
step: 237, val loss: 1.271794080734253, val acuracy: 0.6100000143051147
step: 238, train loss: 1.0754762887954712, train acuracy: 0.6669921875
step: 238, val loss: 1.1219347715377808, val acuracy: 0.659333348274231
step: 239, train loss: 1.0243240594863892, train acuracy: 0.6845703125
step: 239, val loss: 1.056997537612915, val acuracy: 0.6700000762939453
step: 240, train loss: 1.0324832201004028, train acuracy: 0.65625
step: 240, val loss: 1.058395504951477, val acuracy: 0.6516667008399963
step: 241, train loss: 1.0093914270401, train acuracy: 0.6953125
step: 241, val loss: 1.0727660655975342, val acuracy: 0.6803334355354309
step: 242, train loss: 0.9354488253593445, train acuracy: 0.681640625
step: 242, val loss: 1.0690958499908447, val acuracy: 0.6368333697319031
step: 243, train loss: 0.9852028489112854, train acuracy: 0.7080078125
step: 243, val loss: 0.9569010138511658, val acuracy: 0.7115000486373901
step: 244, train loss: 0.9022130966186523, train acuracy: 0.69140625
step: 244, val loss: 0.8788279294967651, val acuracy: 0.7278333902359009
step: 245, train loss: 0.8571495413780212, train acuracy: 0.734375
step: 245, val loss: 0.887806236743927, val acuracy: 0.721166729927063
step: 246, train loss: 0.8596588373184204, train acuracy: 0.7421875
step: 246, val loss: 0.8921515941619873, val acuracy: 0.7226667404174805
step: 247, train loss: 0.8699175715446472, train acuracy: 0.7373046875
step: 247, val loss: 0.8900336027145386, val acuracy: 0.7221667170524597
step: 248, train loss: 0.8660978674888611, train acuracy: 0.7294921875
step: 248, val loss: 0.9036072492599487, val acuracy: 0.7158333659172058
step: 249, train loss: 0.9322927594184875, train acuracy: 0.73046875
step: 249, val loss: 0.9046143889427185, val acuracy: 0.7243334650993347
step: 250, train loss: 0.9139665365219116, train acuracy: 0.7099609375
step: 250, val loss: 0.909160852432251, val acuracy: 0.718500018119812
step: 251, train loss: 0.8513292074203491, train acuracy: 0.73828125
step: 251, val loss: 0.8814188838005066, val acuracy: 0.7273334264755249
step: 252, train loss: 0.9143091440200806, train acuracy: 0.708984375
step: 252, val loss: 0.892862856388092, val acuracy: 0.724000096321106
step: 253, train loss: 0.9281251430511475, train acuracy: 0.7197265625
step: 253, val loss: 0.8929868340492249, val acuracy: 0.7278334498405457
step: 254, train loss: 0.8756908178329468, train acuracy: 0.7333984375
step: 254, val loss: 0.9098067283630371, val acuracy: 0.718166708946228
step: 255, train loss: 0.9122616648674011, train acuracy: 0.72265625
step: 255, val loss: 0.919610321521759, val acuracy: 0.7155000567436218
step: 256, train loss: 0.8258081078529358, train acuracy: 0.75390625
step: 256, val loss: 0.8955811858177185, val acuracy: 0.7246667146682739
step: 257, train loss: 0.8696838021278381, train acuracy: 0.7470703125
step: 257, val loss: 0.9072256088256836, val acuracy: 0.7203333973884583
step: 258, train loss: 0.8982371687889099, train acuracy: 0.724609375
step: 258, val loss: 0.9110587239265442, val acuracy: 0.7195000648498535
step: 259, train loss: 0.8596947193145752, train acuracy: 0.7333984375
step: 259, val loss: 0.9304445385932922, val acuracy: 0.7128334045410156
step: 260, train loss: 0.8037042021751404, train acuracy: 0.7470703125
step: 260, val loss: 0.8940544724464417, val acuracy: 0.7255001068115234
step: 261, train loss: 0.9451353549957275, train acuracy: 0.7109375
step: 261, val loss: 0.9113545417785645, val acuracy: 0.7203333377838135
step: 262, train loss: 0.8605409860610962, train acuracy: 0.728515625
step: 262, val loss: 0.9190904498100281, val acuracy: 0.717666745185852
step: 263, train loss: 0.9131030440330505, train acuracy: 0.7216796875
step: 263, val loss: 0.9146077036857605, val acuracy: 0.7183334231376648
step: 264, train loss: 0.9827755689620972, train acuracy: 0.7138671875
step: 264, val loss: 0.9406751394271851, val acuracy: 0.7170000076293945
step: 265, train loss: 0.8597164750099182, train acuracy: 0.7490234375
step: 265, val loss: 0.9264414310455322, val acuracy: 0.7170000672340393
step: 266, train loss: 0.8861473202705383, train acuracy: 0.7373046875
step: 266, val loss: 0.9646168351173401, val acuracy: 0.7013334631919861
step: 267, train loss: 0.9254572987556458, train acuracy: 0.728515625
step: 267, val loss: 0.9282228350639343, val acuracy: 0.7183334231376648
step: 268, train loss: 0.8628151416778564, train acuracy: 0.7373046875
step: 268, val loss: 0.9504187107086182, val acuracy: 0.7080000638961792
step: 269, train loss: 0.8721109628677368, train acuracy: 0.7294921875
step: 269, val loss: 0.9472053647041321, val acuracy: 0.7093333601951599
step: 270, train loss: 0.9582081437110901, train acuracy: 0.716796875
step: 270, val loss: 0.9403721690177917, val acuracy: 0.7089999914169312
step: 271, train loss: 0.980209469795227, train acuracy: 0.7021484375
step: 271, val loss: 0.963692843914032, val acuracy: 0.7020000219345093
step: 272, train loss: 0.8331600427627563, train acuracy: 0.75390625
step: 272, val loss: 0.9693443775177002, val acuracy: 0.7060000896453857
step: 273, train loss: 0.9822423458099365, train acuracy: 0.6806640625
step: 273, val loss: 0.9571629762649536, val acuracy: 0.6978333592414856
step: 274, train loss: 0.869421124458313, train acuracy: 0.751953125
step: 274, val loss: 0.9770805239677429, val acuracy: 0.7000000476837158
step: 275, train loss: 1.0607281923294067, train acuracy: 0.65625
step: 275, val loss: 0.9931672215461731, val acuracy: 0.6878333687782288
step: 276, train loss: 0.9498856067657471, train acuracy: 0.7197265625
step: 276, val loss: 1.033807635307312, val acuracy: 0.693000078201294
step: 277, train loss: 0.8913037180900574, train acuracy: 0.7138671875
step: 277, val loss: 0.9663918018341064, val acuracy: 0.7016667127609253
step: 278, train loss: 0.9394658803939819, train acuracy: 0.7236328125
step: 278, val loss: 0.9649749994277954, val acuracy: 0.7074999809265137
step: 279, train loss: 0.8931291699409485, train acuracy: 0.7333984375
step: 279, val loss: 0.9434620141983032, val acuracy: 0.7091667652130127
step: 280, train loss: 0.9633866548538208, train acuracy: 0.6875
step: 280, val loss: 0.9697949886322021, val acuracy: 0.6918334364891052
step: 281, train loss: 0.9429847598075867, train acuracy: 0.7138671875
step: 281, val loss: 0.9648792743682861, val acuracy: 0.7011667490005493
step: 282, train loss: 0.8624889850616455, train acuracy: 0.740234375
step: 282, val loss: 0.9479473829269409, val acuracy: 0.7000000476837158
step: 283, train loss: 1.3852572441101074, train acuracy: 0.5908203125
step: 283, val loss: 1.355794072151184, val acuracy: 0.6081666946411133
step: 284, train loss: 1.2944375276565552, train acuracy: 0.615234375
step: 284, val loss: 1.307784080505371, val acuracy: 0.6140000224113464
step: 285, train loss: 1.3324487209320068, train acuracy: 0.603515625
step: 285, val loss: 1.3117260932922363, val acuracy: 0.6134999990463257
step: 286, train loss: 1.2061653137207031, train acuracy: 0.6630859375
step: 286, val loss: 1.3897476196289062, val acuracy: 0.6161667108535767
step: 287, train loss: 1.370177984237671, train acuracy: 0.572265625
step: 287, val loss: 1.4038097858428955, val acuracy: 0.5551667213439941
step: 288, train loss: 1.3805527687072754, train acuracy: 0.6162109375
step: 288, val loss: 1.3693020343780518, val acuracy: 0.6205000281333923
step: 289, train loss: 1.3795456886291504, train acuracy: 0.5732421875
step: 289, val loss: 1.3813847303390503, val acuracy: 0.5573333501815796
step: 290, train loss: 1.2828223705291748, train acuracy: 0.640625
step: 290, val loss: 1.3817455768585205, val acuracy: 0.6201667189598083
step: 291, train loss: 1.3109534978866577, train acuracy: 0.57421875
step: 291, val loss: 1.3996787071228027, val acuracy: 0.5636667013168335
step: 292, train loss: 1.3421438932418823, train acuracy: 0.6201171875
step: 292, val loss: 1.3760285377502441, val acuracy: 0.6158334016799927
step: 293, train loss: 1.2847120761871338, train acuracy: 0.5986328125
step: 293, val loss: 1.3636609315872192, val acuracy: 0.5890000462532043
step: 294, train loss: 1.2516664266586304, train acuracy: 0.6455078125
step: 294, val loss: 1.324246883392334, val acuracy: 0.6130000352859497
step: 295, train loss: 1.6240216493606567, train acuracy: 0.4912109375
step: 295, val loss: 1.6594300270080566, val acuracy: 0.5046666860580444
step: 296, train loss: 1.6798937320709229, train acuracy: 0.5009765625
step: 296, val loss: 1.7363225221633911, val acuracy: 0.518666684627533
step: 297, train loss: 1.761899709701538, train acuracy: 0.4228515625
step: 297, val loss: 1.7754473686218262, val acuracy: 0.4205000102519989
step: 298, train loss: 1.656901240348816, train acuracy: 0.4501953125
step: 298, val loss: 1.7023506164550781, val acuracy: 0.43400001525878906
step: 299, train loss: 1.7302160263061523, train acuracy: 0.4287109375
step: 299, val loss: 1.7086708545684814, val acuracy: 0.4308333396911621
step: 300, train loss: 1.653785228729248, train acuracy: 0.4599609375
step: 300, val loss: 1.705779790878296, val acuracy: 0.43416666984558105
step: 301, train loss: 1.7767066955566406, train acuracy: 0.427734375
step: 301, val loss: 1.7050970792770386, val acuracy: 0.4336666762828827
step: 302, train loss: 1.6965383291244507, train acuracy: 0.4716796875
step: 302, val loss: 1.7188531160354614, val acuracy: 0.4608333706855774
step: 303, train loss: 1.7055950164794922, train acuracy: 0.4423828125
step: 303, val loss: 1.7118496894836426, val acuracy: 0.4193333685398102
step: 304, train loss: 1.7194303274154663, train acuracy: 0.416015625
step: 304, val loss: 1.7102344036102295, val acuracy: 0.4194999933242798
step: 305, train loss: 1.7659040689468384, train acuracy: 0.41015625
step: 305, val loss: 1.7092291116714478, val acuracy: 0.42116665840148926
step: 306, train loss: 1.7109770774841309, train acuracy: 0.41796875
step: 306, val loss: 1.708667516708374, val acuracy: 0.42116665840148926
step: 307, train loss: 1.6908378601074219, train acuracy: 0.4287109375
step: 307, val loss: 1.7262873649597168, val acuracy: 0.406166672706604
step: 308, train loss: 1.639599323272705, train acuracy: 0.4580078125
step: 308, val loss: 1.7282280921936035, val acuracy: 0.43033337593078613
step: 309, train loss: 1.7063937187194824, train acuracy: 0.4267578125
step: 309, val loss: 1.7139911651611328, val acuracy: 0.41499999165534973
step: 310, train loss: 1.7089812755584717, train acuracy: 0.423828125
step: 310, val loss: 1.7175792455673218, val acuracy: 0.42783334851264954
step: 311, train loss: 1.9373126029968262, train acuracy: 0.4609375
step: 311, val loss: 2.069756269454956, val acuracy: 0.4413333237171173
step: 312, train loss: 2.077476739883423, train acuracy: 0.4736328125
step: 312, val loss: 2.115640640258789, val acuracy: 0.4584999978542328
step: 313, train loss: 2.068051815032959, train acuracy: 0.4638671875
step: 313, val loss: 2.0386388301849365, val acuracy: 0.45750004053115845
step: 314, train loss: 1.7747650146484375, train acuracy: 0.5087890625
step: 314, val loss: 1.7612193822860718, val acuracy: 0.5074999928474426
step: 315, train loss: 1.7764956951141357, train acuracy: 0.4853515625
step: 315, val loss: 1.7803497314453125, val acuracy: 0.4816666841506958
step: 316, train loss: 1.8918057680130005, train acuracy: 0.52734375
step: 316, val loss: 1.8500339984893799, val acuracy: 0.5220000147819519
step: 317, train loss: 1.8866053819656372, train acuracy: 0.568359375
step: 317, val loss: 1.930418848991394, val acuracy: 0.565333366394043
step: 318, train loss: 1.90818452835083, train acuracy: 0.48828125
step: 318, val loss: 1.912737488746643, val acuracy: 0.4868333339691162
step: 319, train loss: 1.40623939037323, train acuracy: 0.5830078125
step: 319, val loss: 1.4257761240005493, val acuracy: 0.5788333415985107
step: 320, train loss: 1.396549105644226, train acuracy: 0.5
step: 320, val loss: 1.4781129360198975, val acuracy: 0.4568333029747009
step: 321, train loss: 1.2299119234085083, train acuracy: 0.623046875
step: 321, val loss: 1.3183696269989014, val acuracy: 0.6095000505447388
step: 322, train loss: 1.2915699481964111, train acuracy: 0.5859375
step: 322, val loss: 1.2844032049179077, val acuracy: 0.5883333683013916
step: 323, train loss: 1.3049304485321045, train acuracy: 0.607421875
step: 323, val loss: 1.2956188917160034, val acuracy: 0.6100000143051147
step: 324, train loss: 1.2189582586288452, train acuracy: 0.634765625
step: 324, val loss: 1.2888301610946655, val acuracy: 0.6135000586509705
step: 325, train loss: 1.3492997884750366, train acuracy: 0.5703125
step: 325, val loss: 1.295851469039917, val acuracy: 0.5950000286102295
step: 326, train loss: 1.238196611404419, train acuracy: 0.6494140625
step: 326, val loss: 1.3258947134017944, val acuracy: 0.6081666946411133
step: 327, train loss: 1.4112144708633423, train acuracy: 0.53515625
step: 327, val loss: 1.3549941778182983, val acuracy: 0.5460000038146973
step: 328, train loss: 1.2965340614318848, train acuracy: 0.611328125
step: 328, val loss: 1.3385785818099976, val acuracy: 0.6096667051315308
step: 329, train loss: 1.337169885635376, train acuracy: 0.5703125
step: 329, val loss: 1.3254244327545166, val acuracy: 0.5659999847412109
step: 330, train loss: 1.2716500759124756, train acuracy: 0.619140625
step: 330, val loss: 1.3285138607025146, val acuracy: 0.6013333797454834
step: 331, train loss: 1.2462395429611206, train acuracy: 0.5908203125
step: 331, val loss: 1.3048590421676636, val acuracy: 0.5846667289733887
step: 332, train loss: 1.3174030780792236, train acuracy: 0.59375
step: 332, val loss: 1.29928719997406, val acuracy: 0.6035000085830688
step: 333, train loss: 1.264243721961975, train acuracy: 0.63671875
step: 333, val loss: 1.2912216186523438, val acuracy: 0.6070000529289246
step: 334, train loss: 1.2140989303588867, train acuracy: 0.646484375
step: 334, val loss: 1.29082190990448, val acuracy: 0.6073333024978638
step: 335, train loss: 1.3627588748931885, train acuracy: 0.515625
step: 335, val loss: 1.3620113134384155, val acuracy: 0.5260000228881836
step: 336, train loss: 1.2990442514419556, train acuracy: 0.55078125
step: 336, val loss: 1.3552476167678833, val acuracy: 0.5329999923706055
step: 337, train loss: 1.3405574560165405, train acuracy: 0.5400390625
step: 337, val loss: 1.3585724830627441, val acuracy: 0.5295000076293945
step: 338, train loss: 1.3155573606491089, train acuracy: 0.564453125
step: 338, val loss: 1.362094759941101, val acuracy: 0.5296667218208313
step: 339, train loss: 1.3263938426971436, train acuracy: 0.537109375
step: 339, val loss: 1.361825704574585, val acuracy: 0.5291666388511658
step: 340, train loss: 1.394086241722107, train acuracy: 0.5234375
step: 340, val loss: 1.3615802526474, val acuracy: 0.5274999737739563
step: 341, train loss: 1.3409512042999268, train acuracy: 0.529296875
step: 341, val loss: 1.3665316104888916, val acuracy: 0.5213333368301392
step: 342, train loss: 1.2971735000610352, train acuracy: 0.5439453125
step: 342, val loss: 1.3632293939590454, val acuracy: 0.5270000100135803
step: 343, train loss: 1.357555627822876, train acuracy: 0.533203125
step: 343, val loss: 1.3629869222640991, val acuracy: 0.5275000333786011
step: 344, train loss: 1.3598954677581787, train acuracy: 0.529296875
step: 344, val loss: 1.3637516498565674, val acuracy: 0.5254999995231628
step: 345, train loss: 1.306658148765564, train acuracy: 0.5478515625
step: 345, val loss: 1.3759393692016602, val acuracy: 0.5321666598320007
step: 346, train loss: 1.2834476232528687, train acuracy: 0.5263671875
step: 346, val loss: 1.371872901916504, val acuracy: 0.5215000510215759
step: 347, train loss: 1.4432289600372314, train acuracy: 0.4892578125
step: 347, val loss: 1.4470820426940918, val acuracy: 0.4963333308696747
step: 348, train loss: 1.4436147212982178, train acuracy: 0.515625
step: 348, val loss: 1.4764647483825684, val acuracy: 0.5104999542236328
step: 349, train loss: 1.3925775289535522, train acuracy: 0.5244140625
step: 349, val loss: 1.459062099456787, val acuracy: 0.5189999938011169
step: 350, train loss: 1.3362090587615967, train acuracy: 0.564453125
step: 350, val loss: 1.4372533559799194, val acuracy: 0.5331666469573975
step: 351, train loss: 1.3261804580688477, train acuracy: 0.568359375
step: 351, val loss: 1.4371799230575562, val acuracy: 0.5375000238418579
step: 352, train loss: 1.419585943222046, train acuracy: 0.5234375
step: 352, val loss: 1.4518791437149048, val acuracy: 0.5128333568572998
step: 353, train loss: 1.3905692100524902, train acuracy: 0.541015625
step: 353, val loss: 1.4234225749969482, val acuracy: 0.5565000772476196
step: 354, train loss: 1.3816516399383545, train acuracy: 0.5712890625
step: 354, val loss: 1.4264132976531982, val acuracy: 0.561833381652832
step: 355, train loss: 1.3653197288513184, train acuracy: 0.564453125
step: 355, val loss: 1.4195791482925415, val acuracy: 0.5649999976158142
step: 356, train loss: 1.433120608329773, train acuracy: 0.55078125
step: 356, val loss: 1.431223750114441, val acuracy: 0.549500048160553
step: 357, train loss: 1.3598467111587524, train acuracy: 0.58203125
step: 357, val loss: 1.4060992002487183, val acuracy: 0.5738334059715271
step: 358, train loss: 1.3051711320877075, train acuracy: 0.611328125
step: 358, val loss: 1.4108920097351074, val acuracy: 0.5723333954811096
step: 359, train loss: 1.4309393167495728, train acuracy: 0.572265625
step: 359, val loss: 1.4106863737106323, val acuracy: 0.5713332891464233
step: 360, train loss: 1.3268775939941406, train acuracy: 0.58203125
step: 360, val loss: 1.410969614982605, val acuracy: 0.5668333768844604
step: 361, train loss: 1.3248646259307861, train acuracy: 0.5986328125
step: 361, val loss: 1.4188542366027832, val acuracy: 0.5706667304039001
step: 362, train loss: 1.3193975687026978, train acuracy: 0.6064453125
step: 362, val loss: 1.4170984029769897, val acuracy: 0.561333417892456
step: 363, train loss: 1.3825658559799194, train acuracy: 0.580078125
step: 363, val loss: 1.4232056140899658, val acuracy: 0.5703333616256714
step: 364, train loss: 1.3213306665420532, train acuracy: 0.5888671875
step: 364, val loss: 1.4267076253890991, val acuracy: 0.5695000290870667
step: 365, train loss: 1.4509062767028809, train acuracy: 0.5693359375
step: 365, val loss: 1.41038179397583, val acuracy: 0.561833381652832
step: 366, train loss: 1.3337482213974, train acuracy: 0.57421875
step: 366, val loss: 1.4331743717193604, val acuracy: 0.5423333644866943
step: 367, train loss: 1.4251837730407715, train acuracy: 0.5322265625
step: 367, val loss: 1.4336498975753784, val acuracy: 0.5473334193229675
step: 368, train loss: 1.413525938987732, train acuracy: 0.5595703125
step: 368, val loss: 1.4487522840499878, val acuracy: 0.5601667165756226
step: 369, train loss: 1.445099949836731, train acuracy: 0.55859375
step: 369, val loss: 1.4330819845199585, val acuracy: 0.5568333268165588
step: 370, train loss: 1.3645342588424683, train acuracy: 0.5849609375
step: 370, val loss: 1.4482252597808838, val acuracy: 0.5626667141914368
step: 371, train loss: 1.4081363677978516, train acuracy: 0.5595703125
step: 371, val loss: 1.4343804121017456, val acuracy: 0.5568333864212036
step: 372, train loss: 1.3934587240219116, train acuracy: 0.576171875
step: 372, val loss: 1.4457474946975708, val acuracy: 0.5601667165756226
step: 373, train loss: 1.362574815750122, train acuracy: 0.5771484375
step: 373, val loss: 1.440585970878601, val acuracy: 0.5663334131240845
step: 374, train loss: 1.456284523010254, train acuracy: 0.5537109375
step: 374, val loss: 1.4542489051818848, val acuracy: 0.5603333711624146
step: 375, train loss: 1.4483273029327393, train acuracy: 0.55078125
step: 375, val loss: 1.441430926322937, val acuracy: 0.5571666955947876
step: 376, train loss: 1.4016090631484985, train acuracy: 0.568359375
step: 376, val loss: 1.441146969795227, val acuracy: 0.562666654586792
step: 377, train loss: 1.4853088855743408, train acuracy: 0.546875
step: 377, val loss: 1.452190637588501, val acuracy: 0.5580000281333923
step: 378, train loss: 1.441925287246704, train acuracy: 0.5517578125
step: 378, val loss: 1.5108822584152222, val acuracy: 0.5426666736602783
step: 379, train loss: 1.5152524709701538, train acuracy: 0.5283203125
step: 379, val loss: 1.4652602672576904, val acuracy: 0.5443333983421326
step: 380, train loss: 1.456206202507019, train acuracy: 0.5546875
step: 380, val loss: 1.4932911396026611, val acuracy: 0.550000011920929
step: 381, train loss: 1.507516622543335, train acuracy: 0.5185546875
step: 381, val loss: 1.4954626560211182, val acuracy: 0.5195000171661377
step: 382, train loss: 1.4264566898345947, train acuracy: 0.560546875
step: 382, val loss: 1.4803314208984375, val acuracy: 0.5491666793823242
step: 383, train loss: 1.3810746669769287, train acuracy: 0.564453125
step: 383, val loss: 1.464564561843872, val acuracy: 0.5503333806991577
step: 384, train loss: 1.4572811126708984, train acuracy: 0.546875
step: 384, val loss: 1.4401421546936035, val acuracy: 0.5471667051315308
step: 385, train loss: 1.405616044998169, train acuracy: 0.5830078125
step: 385, val loss: 1.4407269954681396, val acuracy: 0.562333345413208
step: 386, train loss: 1.3509708642959595, train acuracy: 0.5712890625
step: 386, val loss: 1.4448260068893433, val acuracy: 0.5478333830833435
step: 387, train loss: 1.4429962635040283, train acuracy: 0.537109375
step: 387, val loss: 1.4421108961105347, val acuracy: 0.5475000143051147
step: 388, train loss: 1.3999158143997192, train acuracy: 0.5576171875
step: 388, val loss: 1.4419676065444946, val acuracy: 0.5479999780654907
step: 389, train loss: 1.385465383529663, train acuracy: 0.5615234375
step: 389, val loss: 1.4419506788253784, val acuracy: 0.5485000014305115
step: 390, train loss: 1.405718207359314, train acuracy: 0.583984375
step: 390, val loss: 1.4694533348083496, val acuracy: 0.5531666874885559
step: 391, train loss: 1.3652375936508179, train acuracy: 0.5478515625
step: 391, val loss: 1.481634259223938, val acuracy: 0.5145000219345093
step: 392, train loss: 1.4949394464492798, train acuracy: 0.53515625
step: 392, val loss: 1.4434144496917725, val acuracy: 0.5538333654403687
step: 393, train loss: 1.4275622367858887, train acuracy: 0.5419921875
step: 393, val loss: 1.4562041759490967, val acuracy: 0.5373333692550659
step: 394, train loss: 1.407867670059204, train acuracy: 0.5556640625
step: 394, val loss: 1.4436794519424438, val acuracy: 0.5533334016799927
step: 395, train loss: 1.491902232170105, train acuracy: 0.5322265625
step: 395, val loss: 1.4474087953567505, val acuracy: 0.5525000095367432
step: 396, train loss: 1.4485893249511719, train acuracy: 0.537109375
step: 396, val loss: 1.447684645652771, val acuracy: 0.5371667146682739
step: 397, train loss: 1.388706088066101, train acuracy: 0.5771484375
step: 397, val loss: 1.4448527097702026, val acuracy: 0.5551666617393494
step: 398, train loss: 1.3660123348236084, train acuracy: 0.5654296875
step: 398, val loss: 1.4484316110610962, val acuracy: 0.5478333234786987
step: 399, train loss: 1.4850050210952759, train acuracy: 0.5087890625
step: 399, val loss: 1.4633656740188599, val acuracy: 0.5346667170524597
2017-12-04 15:43:25.374776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:43:25.611060: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0xb561920 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 15:43:25.611673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:43:25.611882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 15:43:25.611900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 15:43:25.611905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 15:43:25.611915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 15:43:25.611921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.426079750061035, train acuracy: 0.140625
step: 0, val loss: 2.5696983337402344, val acuracy: 0.09816665947437286
step: 1, train loss: 2.281217575073242, train acuracy: 0.1484375
step: 1, val loss: 2.3399150371551514, val acuracy: 0.1041666567325592
step: 2, train loss: 2.274787425994873, train acuracy: 0.1171875
step: 2, val loss: 2.315619707107544, val acuracy: 0.09666666388511658
step: 3, train loss: 2.19297194480896, train acuracy: 0.15625
step: 3, val loss: 2.358673334121704, val acuracy: 0.10899998992681503
step: 4, train loss: 2.2428345680236816, train acuracy: 0.2109375
step: 4, val loss: 2.272677421569824, val acuracy: 0.15549999475479126
step: 5, train loss: 2.2835726737976074, train acuracy: 0.1796875
step: 5, val loss: 2.270042657852173, val acuracy: 0.1678333282470703
step: 6, train loss: 2.2751142978668213, train acuracy: 0.2109375
step: 6, val loss: 2.269519805908203, val acuracy: 0.18983334302902222
step: 7, train loss: 2.261951446533203, train acuracy: 0.1640625
step: 7, val loss: 2.2743935585021973, val acuracy: 0.164000004529953
step: 8, train loss: 2.282968044281006, train acuracy: 0.171875
step: 8, val loss: 2.2702298164367676, val acuracy: 0.1549999862909317
step: 9, train loss: 2.2685227394104004, train acuracy: 0.1796875
step: 9, val loss: 2.2703046798706055, val acuracy: 0.15316665172576904
step: 10, train loss: 2.238521099090576, train acuracy: 0.234375
step: 10, val loss: 2.2703585624694824, val acuracy: 0.1498333215713501
step: 11, train loss: 2.275662899017334, train acuracy: 0.15625
step: 11, val loss: 2.270249128341675, val acuracy: 0.15399998426437378
step: 12, train loss: 2.273073673248291, train acuracy: 0.1953125
step: 12, val loss: 2.2700204849243164, val acuracy: 0.15600000321865082
step: 13, train loss: 2.2530221939086914, train acuracy: 0.1796875
step: 13, val loss: 2.271244525909424, val acuracy: 0.1301666647195816
step: 14, train loss: 2.2724249362945557, train acuracy: 0.125
step: 14, val loss: 2.271115779876709, val acuracy: 0.12916666269302368
step: 15, train loss: 2.2496416568756104, train acuracy: 0.25
step: 15, val loss: 2.283376932144165, val acuracy: 0.2211666703224182
step: 16, train loss: 2.2977023124694824, train acuracy: 0.2109375
step: 16, val loss: 2.3128116130828857, val acuracy: 0.1925000101327896
step: 17, train loss: 2.236471652984619, train acuracy: 0.2109375
step: 17, val loss: 2.2704694271087646, val acuracy: 0.1769999861717224
step: 18, train loss: 2.243256092071533, train acuracy: 0.140625
step: 18, val loss: 2.2559854984283447, val acuracy: 0.1340000033378601
step: 19, train loss: 2.1689581871032715, train acuracy: 0.3515625
step: 19, val loss: 2.212341070175171, val acuracy: 0.2693333625793457
step: 20, train loss: 2.1163718700408936, train acuracy: 0.328125
step: 20, val loss: 2.1761229038238525, val acuracy: 0.2588333487510681
step: 21, train loss: 2.172010898590088, train acuracy: 0.265625
step: 21, val loss: 2.2962489128112793, val acuracy: 0.2680000066757202
step: 22, train loss: 2.1031951904296875, train acuracy: 0.15625
step: 22, val loss: 2.244257926940918, val acuracy: 0.12533333897590637
step: 23, train loss: 1.9668774604797363, train acuracy: 0.375
step: 23, val loss: 2.0988590717315674, val acuracy: 0.2928333878517151
step: 24, train loss: 1.7177127599716187, train acuracy: 0.46875
step: 24, val loss: 1.7817375659942627, val acuracy: 0.43833333253860474
step: 25, train loss: 1.7271212339401245, train acuracy: 0.4375
step: 25, val loss: 1.8568216562271118, val acuracy: 0.43833333253860474
step: 26, train loss: 1.618196725845337, train acuracy: 0.5
step: 26, val loss: 1.5494272708892822, val acuracy: 0.4801667034626007
step: 27, train loss: 1.572959542274475, train acuracy: 0.4453125
step: 27, val loss: 1.6056052446365356, val acuracy: 0.45383337140083313
step: 28, train loss: 1.417781114578247, train acuracy: 0.515625
step: 28, val loss: 1.6459084749221802, val acuracy: 0.44966670870780945
step: 29, train loss: 1.2036538124084473, train acuracy: 0.625
step: 29, val loss: 1.3827623128890991, val acuracy: 0.5043333172798157
step: 30, train loss: 1.354887843132019, train acuracy: 0.53125
step: 30, val loss: 1.4186233282089233, val acuracy: 0.4960000216960907
step: 31, train loss: 1.3571884632110596, train acuracy: 0.4609375
step: 31, val loss: 1.5829906463623047, val acuracy: 0.4400000274181366
step: 32, train loss: 1.3740328550338745, train acuracy: 0.578125
step: 32, val loss: 1.3725436925888062, val acuracy: 0.5553333759307861
step: 33, train loss: 1.2428613901138306, train acuracy: 0.578125
step: 33, val loss: 1.3571200370788574, val acuracy: 0.5596666932106018
step: 34, train loss: 1.4999748468399048, train acuracy: 0.5703125
step: 34, val loss: 1.3937853574752808, val acuracy: 0.6075000166893005
step: 35, train loss: 1.2887275218963623, train acuracy: 0.609375
step: 35, val loss: 1.334365725517273, val acuracy: 0.5836666822433472
step: 36, train loss: 1.3955612182617188, train acuracy: 0.5625
step: 36, val loss: 1.3375298976898193, val acuracy: 0.567833423614502
step: 37, train loss: 1.426108479499817, train acuracy: 0.515625
step: 37, val loss: 1.4148914813995361, val acuracy: 0.5258333683013916
step: 38, train loss: 1.1599705219268799, train acuracy: 0.6875
step: 38, val loss: 1.3153232336044312, val acuracy: 0.5708333253860474
step: 39, train loss: 1.438968300819397, train acuracy: 0.5234375
step: 39, val loss: 1.4119747877120972, val acuracy: 0.5351666808128357
step: 40, train loss: 1.298342227935791, train acuracy: 0.59375
step: 40, val loss: 1.3401966094970703, val acuracy: 0.5596666932106018
step: 41, train loss: 1.4525468349456787, train acuracy: 0.46875
step: 41, val loss: 1.4797345399856567, val acuracy: 0.4723333418369293
step: 42, train loss: 1.3479421138763428, train acuracy: 0.4921875
step: 42, val loss: 1.468152642250061, val acuracy: 0.47983333468437195
step: 43, train loss: 1.4818775653839111, train acuracy: 0.4609375
step: 43, val loss: 1.460645079612732, val acuracy: 0.47966668009757996
step: 44, train loss: 1.5155272483825684, train acuracy: 0.5234375
step: 44, val loss: 1.4581611156463623, val acuracy: 0.4806666970252991
step: 45, train loss: 1.427612066268921, train acuracy: 0.4921875
step: 45, val loss: 1.4567878246307373, val acuracy: 0.4816667139530182
step: 46, train loss: 1.3401696681976318, train acuracy: 0.4921875
step: 46, val loss: 1.455119252204895, val acuracy: 0.48366671800613403
step: 47, train loss: 1.416522741317749, train acuracy: 0.4453125
step: 47, val loss: 1.4548161029815674, val acuracy: 0.48383334279060364
step: 48, train loss: 1.5033320188522339, train acuracy: 0.4765625
step: 48, val loss: 1.4544851779937744, val acuracy: 0.48466670513153076
step: 49, train loss: 1.5568766593933105, train acuracy: 0.40625
step: 49, val loss: 1.4544956684112549, val acuracy: 0.4843333065509796
step: 50, train loss: 1.3526827096939087, train acuracy: 0.53125
step: 50, val loss: 1.4783329963684082, val acuracy: 0.4776667356491089
step: 51, train loss: 1.4125617742538452, train acuracy: 0.5078125
step: 51, val loss: 1.5332510471343994, val acuracy: 0.4855000376701355
step: 52, train loss: 1.3234283924102783, train acuracy: 0.53125
step: 52, val loss: 1.463839054107666, val acuracy: 0.48466670513153076
step: 53, train loss: 1.622267246246338, train acuracy: 0.421875
step: 53, val loss: 1.4850172996520996, val acuracy: 0.4859999716281891
step: 54, train loss: 1.473085880279541, train acuracy: 0.453125
step: 54, val loss: 1.481701135635376, val acuracy: 0.4878333806991577
step: 55, train loss: 1.5309830904006958, train acuracy: 0.4609375
step: 55, val loss: 1.4800128936767578, val acuracy: 0.48766666650772095
step: 56, train loss: 1.4468237161636353, train acuracy: 0.421875
step: 56, val loss: 1.478924036026001, val acuracy: 0.4871666729450226
step: 57, train loss: 1.5184441804885864, train acuracy: 0.4765625
step: 57, val loss: 1.4781583547592163, val acuracy: 0.48716670274734497
step: 58, train loss: 1.491241693496704, train acuracy: 0.4765625
step: 58, val loss: 1.4773074388504028, val acuracy: 0.4883333444595337
step: 59, train loss: 1.6460795402526855, train acuracy: 0.3828125
step: 59, val loss: 1.5488502979278564, val acuracy: 0.46299999952316284
step: 60, train loss: 1.4064934253692627, train acuracy: 0.46875
step: 60, val loss: 1.4795359373092651, val acuracy: 0.49133336544036865
step: 61, train loss: 1.498752474784851, train acuracy: 0.4765625
step: 61, val loss: 1.5618373155593872, val acuracy: 0.4595000147819519
step: 62, train loss: 1.8703935146331787, train acuracy: 0.3671875
step: 62, val loss: 1.7102837562561035, val acuracy: 0.437166690826416
step: 63, train loss: 1.4931061267852783, train acuracy: 0.5
step: 63, val loss: 1.5329715013504028, val acuracy: 0.4698333740234375
step: 64, train loss: 1.4530417919158936, train acuracy: 0.46875
step: 64, val loss: 1.625553846359253, val acuracy: 0.4438333511352539
step: 65, train loss: 1.4145855903625488, train acuracy: 0.5
step: 65, val loss: 1.5300828218460083, val acuracy: 0.46433332562446594
step: 66, train loss: 1.542694091796875, train acuracy: 0.453125
step: 66, val loss: 1.526695728302002, val acuracy: 0.4638333320617676
step: 67, train loss: 1.5154345035552979, train acuracy: 0.4921875
step: 67, val loss: 1.6036875247955322, val acuracy: 0.4398333430290222
step: 68, train loss: 1.345271110534668, train acuracy: 0.5703125
step: 68, val loss: 1.5200526714324951, val acuracy: 0.4818333685398102
step: 69, train loss: 1.550946593284607, train acuracy: 0.4609375
step: 69, val loss: 1.623616337776184, val acuracy: 0.43416672945022583
step: 70, train loss: 1.5398714542388916, train acuracy: 0.53125
step: 70, val loss: 1.6808171272277832, val acuracy: 0.4453333616256714
step: 71, train loss: 1.6274693012237549, train acuracy: 0.390625
step: 71, val loss: 1.6673977375030518, val acuracy: 0.4243333339691162
step: 72, train loss: 1.4736626148223877, train acuracy: 0.5
step: 72, val loss: 1.544683814048767, val acuracy: 0.4791666865348816
step: 73, train loss: 1.6637630462646484, train acuracy: 0.4453125
step: 73, val loss: 1.5970277786254883, val acuracy: 0.47600001096725464
step: 74, train loss: 1.6406364440917969, train acuracy: 0.3984375
step: 74, val loss: 1.8229029178619385, val acuracy: 0.3488333523273468
step: 75, train loss: 1.543798565864563, train acuracy: 0.546875
step: 75, val loss: 1.7170699834823608, val acuracy: 0.4754999876022339
step: 76, train loss: 1.5978426933288574, train acuracy: 0.484375
step: 76, val loss: 1.6769033670425415, val acuracy: 0.43133336305618286
step: 77, train loss: 1.4419384002685547, train acuracy: 0.578125
step: 77, val loss: 1.6154319047927856, val acuracy: 0.499500036239624
step: 78, train loss: 1.5390397310256958, train acuracy: 0.5390625
step: 78, val loss: 1.656060814857483, val acuracy: 0.49766668677330017
step: 79, train loss: 1.4270483255386353, train acuracy: 0.5078125
step: 79, val loss: 1.6217163801193237, val acuracy: 0.47466668486595154
step: 80, train loss: 1.8570464849472046, train acuracy: 0.4453125
step: 80, val loss: 1.6652874946594238, val acuracy: 0.45783334970474243
step: 81, train loss: 1.5879435539245605, train acuracy: 0.421875
step: 81, val loss: 1.6559909582138062, val acuracy: 0.4610000550746918
step: 82, train loss: 1.5683419704437256, train acuracy: 0.453125
step: 82, val loss: 1.6509888172149658, val acuracy: 0.455833375453949
step: 83, train loss: 1.9771268367767334, train acuracy: 0.2734375
step: 83, val loss: 1.890787124633789, val acuracy: 0.3018333613872528
step: 84, train loss: 1.9056979417800903, train acuracy: 0.296875
step: 84, val loss: 1.8712533712387085, val acuracy: 0.3174999952316284
step: 85, train loss: 1.8233864307403564, train acuracy: 0.3046875
step: 85, val loss: 1.8703243732452393, val acuracy: 0.31833335757255554
step: 86, train loss: 1.8550368547439575, train acuracy: 0.3203125
step: 86, val loss: 1.8702102899551392, val acuracy: 0.31849998235702515
step: 87, train loss: 1.8064333200454712, train acuracy: 0.390625
step: 87, val loss: 1.8697997331619263, val acuracy: 0.31850001215934753
step: 88, train loss: 1.8771891593933105, train acuracy: 0.3359375
step: 88, val loss: 1.8694223165512085, val acuracy: 0.31816667318344116
step: 89, train loss: 1.9937840700149536, train acuracy: 0.3046875
step: 89, val loss: 1.86970853805542, val acuracy: 0.3166666626930237
step: 90, train loss: 1.876833200454712, train acuracy: 0.3359375
step: 90, val loss: 1.8700419664382935, val acuracy: 0.3161666691303253
step: 91, train loss: 1.7625428438186646, train acuracy: 0.3828125
step: 91, val loss: 1.869992971420288, val acuracy: 0.3178333640098572
step: 92, train loss: 1.8659299612045288, train acuracy: 0.34375
step: 92, val loss: 1.8718115091323853, val acuracy: 0.31533336639404297
step: 93, train loss: 2.0515453815460205, train acuracy: 0.3203125
step: 93, val loss: 1.8715424537658691, val acuracy: 0.31583333015441895
step: 94, train loss: 1.881283164024353, train acuracy: 0.3359375
step: 94, val loss: 1.87161386013031, val acuracy: 0.31550002098083496
step: 95, train loss: 1.9248847961425781, train acuracy: 0.3125
step: 95, val loss: 1.8714975118637085, val acuracy: 0.31533336639404297
step: 96, train loss: 1.9589741230010986, train acuracy: 0.25
step: 96, val loss: 1.8712725639343262, val acuracy: 0.3163333535194397
step: 97, train loss: 1.8233625888824463, train acuracy: 0.3515625
step: 97, val loss: 1.8713001012802124, val acuracy: 0.31566667556762695
step: 98, train loss: 1.671897530555725, train acuracy: 0.375
step: 98, val loss: 1.8707458972930908, val acuracy: 0.31666669249534607
step: 99, train loss: 1.882016897201538, train acuracy: 0.296875
step: 99, val loss: 1.870578408241272, val acuracy: 0.3179999887943268
step: 100, train loss: 1.8322244882583618, train acuracy: 0.3828125
step: 100, val loss: 1.8699941635131836, val acuracy: 0.31816670298576355
step: 101, train loss: 2.1674301624298096, train acuracy: 0.296875
step: 101, val loss: 2.169482469558716, val acuracy: 0.27116668224334717
step: 102, train loss: 1.993268370628357, train acuracy: 0.3359375
step: 102, val loss: 2.1422815322875977, val acuracy: 0.2750000059604645
step: 103, train loss: 2.1392884254455566, train acuracy: 0.1953125
step: 103, val loss: 2.153564929962158, val acuracy: 0.1693333238363266
step: 104, train loss: 2.0342354774475098, train acuracy: 0.1875
step: 104, val loss: 2.1434743404388428, val acuracy: 0.17016667127609253
step: 105, train loss: 2.2432198524475098, train acuracy: 0.125
step: 105, val loss: 2.1406190395355225, val acuracy: 0.17083333432674408
step: 106, train loss: 2.176356315612793, train acuracy: 0.1875
step: 106, val loss: 2.1326000690460205, val acuracy: 0.18149998784065247
step: 107, train loss: 2.14896821975708, train acuracy: 0.203125
step: 107, val loss: 2.1251914501190186, val acuracy: 0.1979999989271164
step: 108, train loss: 2.216519355773926, train acuracy: 0.1640625
step: 108, val loss: 2.18379807472229, val acuracy: 0.15983332693576813
step: 109, train loss: 2.12650203704834, train acuracy: 0.1640625
step: 109, val loss: 2.178392171859741, val acuracy: 0.16049998998641968
step: 110, train loss: 2.1256160736083984, train acuracy: 0.2265625
step: 110, val loss: 2.1775009632110596, val acuracy: 0.1615000069141388
step: 111, train loss: 2.156003952026367, train acuracy: 0.125
step: 111, val loss: 2.1765425205230713, val acuracy: 0.16216666996479034
step: 112, train loss: 2.1072378158569336, train acuracy: 0.1171875
step: 112, val loss: 2.1751720905303955, val acuracy: 0.16300000250339508
step: 113, train loss: 2.136366605758667, train acuracy: 0.375
step: 113, val loss: 2.2786056995391846, val acuracy: 0.328166663646698
step: 114, train loss: 2.2160840034484863, train acuracy: 0.34375
step: 114, val loss: 2.134770631790161, val acuracy: 0.3450000286102295
step: 115, train loss: 2.116638660430908, train acuracy: 0.3359375
step: 115, val loss: 2.186555862426758, val acuracy: 0.3019999861717224
step: 116, train loss: 2.1296048164367676, train acuracy: 0.296875
step: 116, val loss: 2.1649744510650635, val acuracy: 0.3061666786670685
step: 117, train loss: 2.105780601501465, train acuracy: 0.3125
step: 117, val loss: 2.149062156677246, val acuracy: 0.3146666884422302
step: 118, train loss: 2.085475206375122, train acuracy: 0.3203125
step: 118, val loss: 2.1876022815704346, val acuracy: 0.3100000023841858
step: 119, train loss: 1.979587435722351, train acuracy: 0.359375
step: 119, val loss: 1.9170284271240234, val acuracy: 0.3661666512489319
step: 120, train loss: 1.94050931930542, train acuracy: 0.328125
step: 120, val loss: 1.8528413772583008, val acuracy: 0.3850000202655792
step: 121, train loss: 1.7872647047042847, train acuracy: 0.3828125
step: 121, val loss: 1.8150317668914795, val acuracy: 0.40549999475479126
step: 122, train loss: 1.6863685846328735, train acuracy: 0.4921875
step: 122, val loss: 1.8850830793380737, val acuracy: 0.4111666679382324
step: 123, train loss: 1.8579919338226318, train acuracy: 0.296875
step: 123, val loss: 1.910226821899414, val acuracy: 0.29750001430511475
step: 124, train loss: 1.7953084707260132, train acuracy: 0.40625
step: 124, val loss: 1.8156795501708984, val acuracy: 0.3920000195503235
step: 125, train loss: 14.392935752868652, train acuracy: 0.203125
step: 125, val loss: 15.040111541748047, val acuracy: 0.16600000858306885
step: 126, train loss: 11.998476028442383, train acuracy: 0.09375
step: 126, val loss: 11.335808753967285, val acuracy: 0.10533333569765091
step: 127, train loss: 7.204217910766602, train acuracy: 0.109375
step: 127, val loss: 6.868311882019043, val acuracy: 0.09183333814144135
step: 128, train loss: 4.6857757568359375, train acuracy: 0.09375
step: 128, val loss: 4.538607120513916, val acuracy: 0.10266666859388351
step: 129, train loss: 3.616766929626465, train acuracy: 0.1328125
step: 129, val loss: 3.769099473953247, val acuracy: 0.09149999916553497
step: 130, train loss: 2.7021844387054443, train acuracy: 0.125
step: 130, val loss: 2.716015338897705, val acuracy: 0.10350000113248825
step: 131, train loss: 2.421724319458008, train acuracy: 0.1171875
step: 131, val loss: 2.422255039215088, val acuracy: 0.09666666388511658
step: 132, train loss: 2.305741786956787, train acuracy: 0.109375
step: 132, val loss: 2.3267693519592285, val acuracy: 0.09666666388511658
step: 133, train loss: 2.2787837982177734, train acuracy: 0.140625
step: 133, val loss: 2.32967472076416, val acuracy: 0.1054999977350235
step: 134, train loss: 2.280951738357544, train acuracy: 0.1171875
step: 134, val loss: 2.314453125, val acuracy: 0.10899999737739563
step: 135, train loss: 2.249197244644165, train acuracy: 0.1640625
step: 135, val loss: 2.333986520767212, val acuracy: 0.10899998992681503
step: 136, train loss: 2.3011348247528076, train acuracy: 0.1171875
step: 136, val loss: 2.307466506958008, val acuracy: 0.10899999737739563
step: 137, train loss: 2.271956205368042, train acuracy: 0.1640625
step: 137, val loss: 2.3154444694519043, val acuracy: 0.10533332824707031
step: 138, train loss: 2.2775511741638184, train acuracy: 0.1484375
step: 138, val loss: 2.3109817504882812, val acuracy: 0.1053333431482315
step: 139, train loss: 2.3036413192749023, train acuracy: 0.1171875
step: 139, val loss: 2.3539795875549316, val acuracy: 0.10383333265781403
step: 140, train loss: 2.284895896911621, train acuracy: 0.1640625
step: 140, val loss: 2.3107969760894775, val acuracy: 0.10899998992681503
step: 141, train loss: 2.2793121337890625, train acuracy: 0.140625
step: 141, val loss: 2.329296827316284, val acuracy: 0.09666665643453598
step: 142, train loss: 2.272674322128296, train acuracy: 0.15625
step: 142, val loss: 2.3402810096740723, val acuracy: 0.09666665643453598
step: 143, train loss: 2.2820754051208496, train acuracy: 0.1484375
step: 143, val loss: 2.3159525394439697, val acuracy: 0.09816667437553406
step: 144, train loss: 2.2742087841033936, train acuracy: 0.1640625
step: 144, val loss: 2.320438861846924, val acuracy: 0.09533333778381348
step: 145, train loss: 2.27189302444458, train acuracy: 0.15625
step: 145, val loss: 2.31862211227417, val acuracy: 0.1054999977350235
step: 146, train loss: 2.279742956161499, train acuracy: 0.1484375
step: 146, val loss: 2.3233954906463623, val acuracy: 0.1054999977350235
step: 147, train loss: 2.2925004959106445, train acuracy: 0.1328125
step: 147, val loss: 2.3079874515533447, val acuracy: 0.1053333431482315
step: 148, train loss: 2.2702574729919434, train acuracy: 0.15625
step: 148, val loss: 2.3306691646575928, val acuracy: 0.09816665947437286
step: 149, train loss: 2.2574219703674316, train acuracy: 0.1875
step: 149, val loss: 2.324218273162842, val acuracy: 0.10383333265781403
step: 150, train loss: 2.2719600200653076, train acuracy: 0.1171875
step: 150, val loss: 2.3193624019622803, val acuracy: 0.10383333265781403
step: 151, train loss: 2.287013053894043, train acuracy: 0.125
step: 151, val loss: 2.314732551574707, val acuracy: 0.1053333431482315
step: 152, train loss: 2.287060260772705, train acuracy: 0.1171875
step: 152, val loss: 2.3100829124450684, val acuracy: 0.09666666388511658
step: 153, train loss: 2.290097236633301, train acuracy: 0.1171875
step: 153, val loss: 2.307194471359253, val acuracy: 0.10533333569765091
step: 154, train loss: 2.2708683013916016, train acuracy: 0.171875
step: 154, val loss: 2.3189172744750977, val acuracy: 0.09816667437553406
step: 155, train loss: 2.269578456878662, train acuracy: 0.1640625
step: 155, val loss: 2.3184847831726074, val acuracy: 0.1054999977350235
step: 156, train loss: 2.2857413291931152, train acuracy: 0.1328125
step: 156, val loss: 2.3137969970703125, val acuracy: 0.09666666388511658
step: 157, train loss: 2.280921697616577, train acuracy: 0.140625
step: 157, val loss: 2.319589138031006, val acuracy: 0.09666665643453598
step: 158, train loss: 2.2563858032226562, train acuracy: 0.1640625
step: 158, val loss: 2.340137004852295, val acuracy: 0.10533333569765091
step: 159, train loss: 2.2573561668395996, train acuracy: 0.15625
step: 159, val loss: 2.338724136352539, val acuracy: 0.09666665643453598
step: 160, train loss: 2.286017417907715, train acuracy: 0.140625
step: 160, val loss: 2.3226840496063232, val acuracy: 0.09666666388511658
step: 161, train loss: 2.2885589599609375, train acuracy: 0.125
step: 161, val loss: 2.3125452995300293, val acuracy: 0.09666666388511658
step: 162, train loss: 2.27601957321167, train acuracy: 0.1484375
step: 162, val loss: 2.3209354877471924, val acuracy: 0.09183333069086075
step: 163, train loss: 2.272322654724121, train acuracy: 0.15625
step: 163, val loss: 2.315537452697754, val acuracy: 0.1053333431482315
step: 164, train loss: 2.29105281829834, train acuracy: 0.140625
step: 164, val loss: 2.3147506713867188, val acuracy: 0.09533333778381348
step: 165, train loss: 2.291496753692627, train acuracy: 0.1171875
step: 165, val loss: 2.312331438064575, val acuracy: 0.1054999977350235
step: 166, train loss: 2.2833402156829834, train acuracy: 0.125
step: 166, val loss: 2.311110496520996, val acuracy: 0.09183333069086075
step: 167, train loss: 2.2881202697753906, train acuracy: 0.1328125
step: 167, val loss: 2.3106184005737305, val acuracy: 0.1053333431482315
step: 168, train loss: 2.252969264984131, train acuracy: 0.1796875
step: 168, val loss: 2.323702573776245, val acuracy: 0.1054999977350235
step: 169, train loss: 2.2781662940979004, train acuracy: 0.1328125
step: 169, val loss: 2.3141958713531494, val acuracy: 0.1054999977350235
step: 170, train loss: 2.259258985519409, train acuracy: 0.15625
step: 170, val loss: 2.322495222091675, val acuracy: 0.10383333265781403
step: 171, train loss: 2.294203996658325, train acuracy: 0.1328125
step: 171, val loss: 2.3130605220794678, val acuracy: 0.09666666388511658
step: 172, train loss: 2.289661407470703, train acuracy: 0.125
step: 172, val loss: 2.309879779815674, val acuracy: 0.1053333431482315
step: 173, train loss: 2.2680742740631104, train acuracy: 0.15625
step: 173, val loss: 2.317020893096924, val acuracy: 0.1053333431482315
step: 174, train loss: 2.2793662548065186, train acuracy: 0.140625
step: 174, val loss: 2.3110337257385254, val acuracy: 0.10899999737739563
step: 175, train loss: 2.2739100456237793, train acuracy: 0.15625
step: 175, val loss: 2.3195433616638184, val acuracy: 0.09483333677053452
step: 176, train loss: 2.2792787551879883, train acuracy: 0.1328125
step: 176, val loss: 2.315476417541504, val acuracy: 0.10899998992681503
step: 177, train loss: 2.297110080718994, train acuracy: 0.1171875
step: 177, val loss: 2.3089659214019775, val acuracy: 0.09666665643453598
step: 178, train loss: 2.291731834411621, train acuracy: 0.125
step: 178, val loss: 2.308762788772583, val acuracy: 0.1054999977350235
step: 179, train loss: 2.2931787967681885, train acuracy: 0.1171875
step: 179, val loss: 2.30525541305542, val acuracy: 0.09183333069086075
step: 180, train loss: 2.273057699203491, train acuracy: 0.109375
step: 180, val loss: 2.3231825828552246, val acuracy: 0.09666665643453598
step: 181, train loss: 2.28596830368042, train acuracy: 0.15625
step: 181, val loss: 2.307565450668335, val acuracy: 0.1054999977350235
step: 182, train loss: 2.2670822143554688, train acuracy: 0.140625
step: 182, val loss: 2.323585271835327, val acuracy: 0.09666666388511658
step: 183, train loss: 2.2739291191101074, train acuracy: 0.125
step: 183, val loss: 2.3123533725738525, val acuracy: 0.09749999642372131
step: 184, train loss: 2.2971348762512207, train acuracy: 0.1171875
step: 184, val loss: 2.306612014770508, val acuracy: 0.1054999977350235
step: 185, train loss: 2.2853989601135254, train acuracy: 0.1640625
step: 185, val loss: 2.306067943572998, val acuracy: 0.10899999737739563
step: 186, train loss: 2.268336057662964, train acuracy: 0.1328125
step: 186, val loss: 2.315127372741699, val acuracy: 0.10899999737739563
step: 187, train loss: 2.2667417526245117, train acuracy: 0.1875
step: 187, val loss: 2.316016435623169, val acuracy: 0.10533333569765091
step: 188, train loss: 2.2896761894226074, train acuracy: 0.1484375
step: 188, val loss: 2.3056421279907227, val acuracy: 0.09749999642372131
step: 189, train loss: 2.286872386932373, train acuracy: 0.1328125
step: 189, val loss: 2.3088150024414062, val acuracy: 0.10383333265781403
step: 190, train loss: 2.281545877456665, train acuracy: 0.140625
step: 190, val loss: 2.311005115509033, val acuracy: 0.10899998992681503
step: 191, train loss: 2.284708023071289, train acuracy: 0.140625
step: 191, val loss: 2.3121485710144043, val acuracy: 0.09666666388511658
step: 192, train loss: 2.296539068222046, train acuracy: 0.1171875
step: 192, val loss: 2.3066391944885254, val acuracy: 0.09666666388511658
step: 193, train loss: 2.2761738300323486, train acuracy: 0.1171875
step: 193, val loss: 2.3224923610687256, val acuracy: 0.09666666388511658
step: 194, train loss: 2.2792091369628906, train acuracy: 0.1484375
step: 194, val loss: 2.3228511810302734, val acuracy: 0.09533333778381348
step: 195, train loss: 2.3002634048461914, train acuracy: 0.0859375
step: 195, val loss: 2.3063015937805176, val acuracy: 0.09533333778381348
step: 196, train loss: 2.294551134109497, train acuracy: 0.1171875
step: 196, val loss: 2.3059372901916504, val acuracy: 0.09533333778381348
step: 197, train loss: 2.27425217628479, train acuracy: 0.1328125
step: 197, val loss: 2.3114209175109863, val acuracy: 0.10899999737739563
step: 198, train loss: 2.2896082401275635, train acuracy: 0.1171875
step: 198, val loss: 2.310065746307373, val acuracy: 0.09533333778381348
step: 199, train loss: 2.2706379890441895, train acuracy: 0.15625
step: 199, val loss: 2.3169941902160645, val acuracy: 0.10899998992681503
step: 200, train loss: 2.299912214279175, train acuracy: 0.125
step: 200, val loss: 2.309192180633545, val acuracy: 0.09533333778381348
step: 201, train loss: 2.278316020965576, train acuracy: 0.140625
step: 201, val loss: 2.3118791580200195, val acuracy: 0.1053333431482315
step: 202, train loss: 2.282749652862549, train acuracy: 0.171875
step: 202, val loss: 2.3100948333740234, val acuracy: 0.1054999977350235
step: 203, train loss: 2.2784478664398193, train acuracy: 0.1171875
step: 203, val loss: 2.3126916885375977, val acuracy: 0.09666666388511658
step: 204, train loss: 2.2780561447143555, train acuracy: 0.125
step: 204, val loss: 2.3122291564941406, val acuracy: 0.09533333778381348
step: 205, train loss: 2.269301652908325, train acuracy: 0.15625
step: 205, val loss: 2.3166215419769287, val acuracy: 0.09816667437553406
step: 206, train loss: 2.2918269634246826, train acuracy: 0.1328125
step: 206, val loss: 2.3098695278167725, val acuracy: 0.09816665947437286
step: 207, train loss: 2.2837486267089844, train acuracy: 0.1171875
step: 207, val loss: 2.3104496002197266, val acuracy: 0.09816667437553406
step: 208, train loss: 2.246370553970337, train acuracy: 0.1640625
step: 208, val loss: 2.321495532989502, val acuracy: 0.09666665643453598
step: 209, train loss: 2.2921977043151855, train acuracy: 0.140625
step: 209, val loss: 2.3086798191070557, val acuracy: 0.1054999977350235
step: 210, train loss: 2.2869131565093994, train acuracy: 0.1015625
step: 210, val loss: 2.3091881275177, val acuracy: 0.1054999977350235
step: 211, train loss: 2.2453746795654297, train acuracy: 0.171875
step: 211, val loss: 2.3256170749664307, val acuracy: 0.09666665643453598
step: 212, train loss: 2.288872718811035, train acuracy: 0.1640625
step: 212, val loss: 2.3146166801452637, val acuracy: 0.1054999902844429
step: 213, train loss: 2.2977004051208496, train acuracy: 0.109375
step: 213, val loss: 2.3085551261901855, val acuracy: 0.09666665643453598
step: 214, train loss: 2.2552402019500732, train acuracy: 0.1484375
step: 214, val loss: 2.3239667415618896, val acuracy: 0.09816665947437286
step: 215, train loss: 2.2573418617248535, train acuracy: 0.1640625
step: 215, val loss: 2.324143886566162, val acuracy: 0.1054999977350235
step: 216, train loss: 2.2768032550811768, train acuracy: 0.1015625
step: 216, val loss: 2.3139448165893555, val acuracy: 0.09666666388511658
step: 217, train loss: 2.3011045455932617, train acuracy: 0.1328125
step: 217, val loss: 2.3072314262390137, val acuracy: 0.1054999977350235
step: 218, train loss: 2.2869598865509033, train acuracy: 0.1484375
step: 218, val loss: 2.307103395462036, val acuracy: 0.1054999977350235
step: 219, train loss: 2.2872180938720703, train acuracy: 0.15625
step: 219, val loss: 2.307077407836914, val acuracy: 0.09749999642372131
step: 220, train loss: 2.2960987091064453, train acuracy: 0.109375
step: 220, val loss: 2.3041505813598633, val acuracy: 0.1054999977350235
step: 221, train loss: 2.2530739307403564, train acuracy: 0.140625
step: 221, val loss: 2.3198490142822266, val acuracy: 0.10383333265781403
step: 222, train loss: 2.29856276512146, train acuracy: 0.1484375
step: 222, val loss: 2.3125832080841064, val acuracy: 0.1054999977350235
step: 223, train loss: 2.2229185104370117, train acuracy: 0.1484375
step: 223, val loss: 2.3352253437042236, val acuracy: 0.10383333265781403
step: 224, train loss: 2.2822976112365723, train acuracy: 0.1328125
step: 224, val loss: 2.3209950923919678, val acuracy: 0.09816665947437286
step: 225, train loss: 2.2919578552246094, train acuracy: 0.15625
step: 225, val loss: 2.3161489963531494, val acuracy: 0.09816665947437286
step: 226, train loss: 2.2906911373138428, train acuracy: 0.140625
step: 226, val loss: 2.3068840503692627, val acuracy: 0.10899999737739563
step: 227, train loss: 2.292336940765381, train acuracy: 0.125
step: 227, val loss: 2.3083677291870117, val acuracy: 0.09816666692495346
step: 228, train loss: 2.291731357574463, train acuracy: 0.109375
step: 228, val loss: 2.305657386779785, val acuracy: 0.09816667437553406
step: 229, train loss: 2.286749839782715, train acuracy: 0.1328125
step: 229, val loss: 2.306440830230713, val acuracy: 0.10383334010839462
step: 230, train loss: 2.2819628715515137, train acuracy: 0.15625
step: 230, val loss: 2.305194139480591, val acuracy: 0.1054999977350235
step: 231, train loss: 2.286233901977539, train acuracy: 0.140625
step: 231, val loss: 2.308448553085327, val acuracy: 0.1053333431482315
step: 232, train loss: 2.2892560958862305, train acuracy: 0.109375
step: 232, val loss: 2.309574842453003, val acuracy: 0.1053333431482315
step: 233, train loss: 2.2920868396759033, train acuracy: 0.125
step: 233, val loss: 2.307776927947998, val acuracy: 0.09666666388511658
step: 234, train loss: 2.2864952087402344, train acuracy: 0.125
step: 234, val loss: 2.304372787475586, val acuracy: 0.09749999642372131
step: 235, train loss: 2.2644636631011963, train acuracy: 0.1484375
step: 235, val loss: 2.3098220825195312, val acuracy: 0.1054999977350235
step: 236, train loss: 2.29235577583313, train acuracy: 0.125
step: 236, val loss: 2.306966543197632, val acuracy: 0.10899999737739563
step: 237, train loss: 2.2988409996032715, train acuracy: 0.125
step: 237, val loss: 2.3039140701293945, val acuracy: 0.10383333265781403
step: 238, train loss: 2.2564358711242676, train acuracy: 0.15625
step: 238, val loss: 2.3152570724487305, val acuracy: 0.10899998992681503
step: 239, train loss: 2.296982526779175, train acuracy: 0.125
step: 239, val loss: 2.3085765838623047, val acuracy: 0.09183333069086075
step: 240, train loss: 2.292285680770874, train acuracy: 0.1171875
step: 240, val loss: 2.304795742034912, val acuracy: 0.10899999737739563
step: 241, train loss: 2.268186092376709, train acuracy: 0.1328125
step: 241, val loss: 2.3093230724334717, val acuracy: 0.10899998992681503
step: 242, train loss: 2.2925825119018555, train acuracy: 0.1328125
step: 242, val loss: 2.3068199157714844, val acuracy: 0.1054999977350235
step: 243, train loss: 2.2869224548339844, train acuracy: 0.140625
step: 243, val loss: 2.307725429534912, val acuracy: 0.10533332824707031
step: 244, train loss: 2.262338638305664, train acuracy: 0.1953125
step: 244, val loss: 2.3218045234680176, val acuracy: 0.09533333778381348
step: 245, train loss: 2.2709615230560303, train acuracy: 0.1171875
step: 245, val loss: 2.3210289478302, val acuracy: 0.10899998992681503
step: 246, train loss: 2.2894937992095947, train acuracy: 0.125
step: 246, val loss: 2.3194198608398438, val acuracy: 0.10899999737739563
step: 247, train loss: 2.2971572875976562, train acuracy: 0.1015625
step: 247, val loss: 2.3107171058654785, val acuracy: 0.10899998992681503
step: 248, train loss: 2.2842254638671875, train acuracy: 0.140625
step: 248, val loss: 2.3121280670166016, val acuracy: 0.10899999737739563
step: 249, train loss: 2.3046700954437256, train acuracy: 0.1015625
step: 249, val loss: 2.307101011276245, val acuracy: 0.10533333569765091
step: 250, train loss: 2.2957603931427, train acuracy: 0.1171875
step: 250, val loss: 2.306114673614502, val acuracy: 0.10899998992681503
step: 251, train loss: 2.281465768814087, train acuracy: 0.1640625
step: 251, val loss: 2.310779094696045, val acuracy: 0.09533333778381348
step: 252, train loss: 2.3025143146514893, train acuracy: 0.0859375
step: 252, val loss: 2.307938814163208, val acuracy: 0.09533333778381348
step: 253, train loss: 2.2741408348083496, train acuracy: 0.140625
step: 253, val loss: 2.310680389404297, val acuracy: 0.09533333778381348
step: 254, train loss: 2.282804489135742, train acuracy: 0.125
step: 254, val loss: 2.31077241897583, val acuracy: 0.09533333778381348
step: 255, train loss: 2.2832279205322266, train acuracy: 0.15625
step: 255, val loss: 2.3099491596221924, val acuracy: 0.10899998992681503
step: 256, train loss: 2.2961249351501465, train acuracy: 0.09375
step: 256, val loss: 2.3072268962860107, val acuracy: 0.10899998992681503
step: 257, train loss: 2.27882719039917, train acuracy: 0.125
step: 257, val loss: 2.3079447746276855, val acuracy: 0.10383333265781403
step: 258, train loss: 2.2960546016693115, train acuracy: 0.140625
step: 258, val loss: 2.309774398803711, val acuracy: 0.09533333778381348
step: 259, train loss: 2.2978153228759766, train acuracy: 0.125
step: 259, val loss: 2.3061957359313965, val acuracy: 0.1053333431482315
step: 260, train loss: 2.258035182952881, train acuracy: 0.171875
step: 260, val loss: 2.312220335006714, val acuracy: 0.10899999737739563
step: 261, train loss: 2.2973995208740234, train acuracy: 0.078125
step: 261, val loss: 2.3047995567321777, val acuracy: 0.10899999737739563
step: 262, train loss: 2.289968490600586, train acuracy: 0.1484375
step: 262, val loss: 2.3071956634521484, val acuracy: 0.09533333778381348
step: 263, train loss: 2.292309522628784, train acuracy: 0.1015625
step: 263, val loss: 2.3046116828918457, val acuracy: 0.10899998992681503
step: 264, train loss: 2.286759614944458, train acuracy: 0.1171875
step: 264, val loss: 2.306811571121216, val acuracy: 0.09533333778381348
step: 265, train loss: 2.2871713638305664, train acuracy: 0.1328125
step: 265, val loss: 2.3089065551757812, val acuracy: 0.09666666388511658
step: 266, train loss: 2.298126220703125, train acuracy: 0.1171875
step: 266, val loss: 2.3040285110473633, val acuracy: 0.1054999977350235
step: 267, train loss: 2.2840256690979004, train acuracy: 0.140625
step: 267, val loss: 2.3072659969329834, val acuracy: 0.10899998992681503
step: 268, train loss: 2.3017444610595703, train acuracy: 0.109375
step: 268, val loss: 2.304262161254883, val acuracy: 0.10899999737739563
step: 269, train loss: 2.2934491634368896, train acuracy: 0.09375
step: 269, val loss: 2.304823398590088, val acuracy: 0.10899999737739563
step: 270, train loss: 2.2700817584991455, train acuracy: 0.15625
step: 270, val loss: 2.310615062713623, val acuracy: 0.09816667437553406
step: 271, train loss: 2.2828760147094727, train acuracy: 0.15625
step: 271, val loss: 2.310520648956299, val acuracy: 0.09666666388511658
step: 272, train loss: 2.2907156944274902, train acuracy: 0.1171875
step: 272, val loss: 2.305555582046509, val acuracy: 0.10899998992681503
step: 273, train loss: 2.288281202316284, train acuracy: 0.140625
step: 273, val loss: 2.307602643966675, val acuracy: 0.09816666692495346
step: 274, train loss: 2.2991578578948975, train acuracy: 0.1015625
step: 274, val loss: 2.306952714920044, val acuracy: 0.10899999737739563
step: 275, train loss: 2.2932546138763428, train acuracy: 0.1328125
step: 275, val loss: 2.306187868118286, val acuracy: 0.09749999642372131
step: 276, train loss: 2.2832717895507812, train acuracy: 0.171875
step: 276, val loss: 2.3068172931671143, val acuracy: 0.10533333569765091
step: 277, train loss: 2.278799057006836, train acuracy: 0.140625
step: 277, val loss: 2.306532621383667, val acuracy: 0.1053333431482315
step: 278, train loss: 2.2835793495178223, train acuracy: 0.15625
step: 278, val loss: 2.309720039367676, val acuracy: 0.09533333778381348
step: 279, train loss: 2.283942699432373, train acuracy: 0.1171875
step: 279, val loss: 2.311154842376709, val acuracy: 0.09533333778381348
step: 280, train loss: 2.291259288787842, train acuracy: 0.1484375
step: 280, val loss: 2.304550886154175, val acuracy: 0.10899999737739563
step: 281, train loss: 2.2816076278686523, train acuracy: 0.1171875
step: 281, val loss: 2.307847499847412, val acuracy: 0.10899998992681503
step: 282, train loss: 2.264291286468506, train acuracy: 0.171875
step: 282, val loss: 2.3158648014068604, val acuracy: 0.1054999977350235
step: 283, train loss: 2.3069868087768555, train acuracy: 0.1015625
step: 283, val loss: 2.3071329593658447, val acuracy: 0.09733333438634872
step: 284, train loss: 2.299288749694824, train acuracy: 0.109375
step: 284, val loss: 2.3060665130615234, val acuracy: 0.09183333069086075
step: 285, train loss: 2.296266555786133, train acuracy: 0.109375
step: 285, val loss: 2.303363084793091, val acuracy: 0.09666666388511658
step: 286, train loss: 2.284916877746582, train acuracy: 0.125
step: 286, val loss: 2.309570074081421, val acuracy: 0.09666666388511658
step: 287, train loss: 2.2982935905456543, train acuracy: 0.1171875
step: 287, val loss: 2.304161310195923, val acuracy: 0.09533333778381348
step: 288, train loss: 2.2830088138580322, train acuracy: 0.140625
step: 288, val loss: 2.307236433029175, val acuracy: 0.10899998992681503
step: 289, train loss: 2.2927932739257812, train acuracy: 0.1328125
step: 289, val loss: 2.3097569942474365, val acuracy: 0.09666666388511658
step: 290, train loss: 2.271148443222046, train acuracy: 0.1484375
step: 290, val loss: 2.3078784942626953, val acuracy: 0.09533333778381348
step: 291, train loss: 2.286933183670044, train acuracy: 0.1484375
step: 291, val loss: 2.3063085079193115, val acuracy: 0.1054999977350235
step: 292, train loss: 2.2577435970306396, train acuracy: 0.1328125
step: 292, val loss: 2.3163857460021973, val acuracy: 0.1054999977350235
step: 293, train loss: 2.2846286296844482, train acuracy: 0.109375
step: 293, val loss: 2.31475567817688, val acuracy: 0.10899999737739563
step: 294, train loss: 2.2847893238067627, train acuracy: 0.140625
step: 294, val loss: 2.313880681991577, val acuracy: 0.1054999977350235
step: 295, train loss: 2.292203426361084, train acuracy: 0.1171875
step: 295, val loss: 2.3124661445617676, val acuracy: 0.1054999977350235
step: 296, train loss: 2.2998554706573486, train acuracy: 0.140625
step: 296, val loss: 2.3108010292053223, val acuracy: 0.09816665947437286
step: 297, train loss: 2.289641857147217, train acuracy: 0.1484375
step: 297, val loss: 2.3121016025543213, val acuracy: 0.09666666388511658
step: 298, train loss: 2.279602289199829, train acuracy: 0.125
step: 298, val loss: 2.313868522644043, val acuracy: 0.09533333033323288
step: 299, train loss: 2.3062925338745117, train acuracy: 0.09375
step: 299, val loss: 2.3086860179901123, val acuracy: 0.1054999977350235
step: 300, train loss: 2.296802043914795, train acuracy: 0.109375
step: 300, val loss: 2.3074123859405518, val acuracy: 0.1054999977350235
step: 301, train loss: 2.2926955223083496, train acuracy: 0.140625
step: 301, val loss: 2.307443141937256, val acuracy: 0.09666666388511658
step: 302, train loss: 2.2840542793273926, train acuracy: 0.125
step: 302, val loss: 2.3055505752563477, val acuracy: 0.09666666388511658
step: 303, train loss: 2.281743049621582, train acuracy: 0.1484375
step: 303, val loss: 2.3068466186523438, val acuracy: 0.09816665947437286
step: 304, train loss: 2.2886176109313965, train acuracy: 0.109375
step: 304, val loss: 2.3060193061828613, val acuracy: 0.09816667437553406
step: 305, train loss: 2.266867160797119, train acuracy: 0.171875
step: 305, val loss: 2.3142776489257812, val acuracy: 0.09816665947437286
step: 306, train loss: 2.2895781993865967, train acuracy: 0.1171875
step: 306, val loss: 2.308206796646118, val acuracy: 0.09816667437553406
step: 307, train loss: 2.288130283355713, train acuracy: 0.1171875
step: 307, val loss: 2.3103129863739014, val acuracy: 0.09816667437553406
step: 308, train loss: 2.282304048538208, train acuracy: 0.1640625
step: 308, val loss: 2.3110485076904297, val acuracy: 0.09816665947437286
step: 309, train loss: 2.291924238204956, train acuracy: 0.1328125
step: 309, val loss: 2.309873580932617, val acuracy: 0.09816665947437286
step: 310, train loss: 2.2917027473449707, train acuracy: 0.078125
step: 310, val loss: 2.3053529262542725, val acuracy: 0.09816665947437286
step: 311, train loss: 2.286449909210205, train acuracy: 0.1484375
step: 311, val loss: 2.3084182739257812, val acuracy: 0.09533333778381348
step: 312, train loss: 2.290165901184082, train acuracy: 0.1328125
step: 312, val loss: 2.3074727058410645, val acuracy: 0.10899999737739563
step: 313, train loss: 2.2923829555511475, train acuracy: 0.1328125
step: 313, val loss: 2.307878017425537, val acuracy: 0.09533333778381348
step: 314, train loss: 2.3004939556121826, train acuracy: 0.109375
step: 314, val loss: 2.3056657314300537, val acuracy: 0.09666665643453598
step: 315, train loss: 2.286520481109619, train acuracy: 0.1484375
step: 315, val loss: 2.3075690269470215, val acuracy: 0.09533333778381348
step: 316, train loss: 2.271987199783325, train acuracy: 0.1328125
step: 316, val loss: 2.3167471885681152, val acuracy: 0.09533333778381348
step: 317, train loss: 2.2895779609680176, train acuracy: 0.1171875
step: 317, val loss: 2.3100790977478027, val acuracy: 0.10899998992681503
step: 318, train loss: 2.285484790802002, train acuracy: 0.1484375
step: 318, val loss: 2.3115499019622803, val acuracy: 0.09816665947437286
step: 319, train loss: 2.2901434898376465, train acuracy: 0.1484375
step: 319, val loss: 2.310631036758423, val acuracy: 0.10899998992681503
step: 320, train loss: 2.286989688873291, train acuracy: 0.125
step: 320, val loss: 2.307981252670288, val acuracy: 0.10899999737739563
step: 321, train loss: 2.295715093612671, train acuracy: 0.15625
step: 321, val loss: 2.307460069656372, val acuracy: 0.09666665643453598
step: 322, train loss: 2.288816452026367, train acuracy: 0.1484375
step: 322, val loss: 2.306796073913574, val acuracy: 0.10899998992681503
step: 323, train loss: 2.301725149154663, train acuracy: 0.09375
step: 323, val loss: 2.304853916168213, val acuracy: 0.10899998992681503
step: 324, train loss: 2.282853126525879, train acuracy: 0.1484375
step: 324, val loss: 2.306962251663208, val acuracy: 0.10899999737739563
step: 325, train loss: 2.296469211578369, train acuracy: 0.1015625
step: 325, val loss: 2.3075804710388184, val acuracy: 0.10899999737739563
step: 326, train loss: 2.2971365451812744, train acuracy: 0.125
step: 326, val loss: 2.3083784580230713, val acuracy: 0.10383333265781403
step: 327, train loss: 2.2679591178894043, train acuracy: 0.1328125
step: 327, val loss: 2.316526174545288, val acuracy: 0.09666665643453598
step: 328, train loss: 2.293799877166748, train acuracy: 0.125
step: 328, val loss: 2.307304859161377, val acuracy: 0.09666665643453598
step: 329, train loss: 2.287123680114746, train acuracy: 0.140625
step: 329, val loss: 2.307642936706543, val acuracy: 0.10899998992681503
step: 330, train loss: 2.281376838684082, train acuracy: 0.140625
step: 330, val loss: 2.3073880672454834, val acuracy: 0.10899999737739563
step: 331, train loss: 2.2952964305877686, train acuracy: 0.1171875
step: 331, val loss: 2.3066182136535645, val acuracy: 0.10899998992681503
step: 332, train loss: 2.2769267559051514, train acuracy: 0.1640625
step: 332, val loss: 2.307431936264038, val acuracy: 0.10899999737739563
step: 333, train loss: 2.2845659255981445, train acuracy: 0.15625
step: 333, val loss: 2.307346820831299, val acuracy: 0.09666666388511658
step: 334, train loss: 2.300482749938965, train acuracy: 0.1328125
step: 334, val loss: 2.3061938285827637, val acuracy: 0.1054999977350235
step: 335, train loss: 2.269477605819702, train acuracy: 0.125
step: 335, val loss: 2.308473825454712, val acuracy: 0.10899999737739563
step: 336, train loss: 2.294896364212036, train acuracy: 0.1484375
step: 336, val loss: 2.3061368465423584, val acuracy: 0.1054999977350235
step: 337, train loss: 2.2772560119628906, train acuracy: 0.140625
step: 337, val loss: 2.310931444168091, val acuracy: 0.09666666388511658
step: 338, train loss: 2.2753372192382812, train acuracy: 0.140625
step: 338, val loss: 2.311206340789795, val acuracy: 0.09666666388511658
step: 339, train loss: 2.268298387527466, train acuracy: 0.1484375
step: 339, val loss: 2.3132872581481934, val acuracy: 0.09533333778381348
step: 340, train loss: 2.2953004837036133, train acuracy: 0.140625
step: 340, val loss: 2.310138463973999, val acuracy: 0.09533333778381348
step: 341, train loss: 2.288602828979492, train acuracy: 0.109375
step: 341, val loss: 2.308279275894165, val acuracy: 0.09533333778381348
step: 342, train loss: 2.2931272983551025, train acuracy: 0.1015625
step: 342, val loss: 2.3085994720458984, val acuracy: 0.09533333778381348
step: 343, train loss: 2.2893333435058594, train acuracy: 0.1484375
step: 343, val loss: 2.310227870941162, val acuracy: 0.09533333778381348
step: 344, train loss: 2.307050943374634, train acuracy: 0.1015625
step: 344, val loss: 2.303679943084717, val acuracy: 0.10899998992681503
step: 345, train loss: 2.2816216945648193, train acuracy: 0.15625
step: 345, val loss: 2.3091907501220703, val acuracy: 0.09666666388511658
step: 346, train loss: 2.2882165908813477, train acuracy: 0.140625
step: 346, val loss: 2.3063344955444336, val acuracy: 0.1054999977350235
step: 347, train loss: 2.2979187965393066, train acuracy: 0.109375
step: 347, val loss: 2.3031327724456787, val acuracy: 0.1054999902844429
step: 348, train loss: 2.2944679260253906, train acuracy: 0.1171875
step: 348, val loss: 2.304149866104126, val acuracy: 0.1054999977350235
step: 349, train loss: 2.2926602363586426, train acuracy: 0.1171875
step: 349, val loss: 2.305607318878174, val acuracy: 0.1054999977350235
step: 350, train loss: 2.2956998348236084, train acuracy: 0.1484375
step: 350, val loss: 2.304487943649292, val acuracy: 0.10899998992681503
step: 351, train loss: 2.2981350421905518, train acuracy: 0.1171875
step: 351, val loss: 2.3047430515289307, val acuracy: 0.10899999737739563
step: 352, train loss: 2.26589298248291, train acuracy: 0.1640625
step: 352, val loss: 2.3124990463256836, val acuracy: 0.10899998992681503
step: 353, train loss: 2.2918856143951416, train acuracy: 0.125
step: 353, val loss: 2.3103718757629395, val acuracy: 0.10899999737739563
step: 354, train loss: 2.290036678314209, train acuracy: 0.109375
step: 354, val loss: 2.3072452545166016, val acuracy: 0.10899999737739563
step: 355, train loss: 2.2954893112182617, train acuracy: 0.109375
step: 355, val loss: 2.3080577850341797, val acuracy: 0.10899998992681503
step: 356, train loss: 2.3028194904327393, train acuracy: 0.1015625
step: 356, val loss: 2.3051493167877197, val acuracy: 0.10899998992681503
step: 357, train loss: 2.3008131980895996, train acuracy: 0.125
step: 357, val loss: 2.304316997528076, val acuracy: 0.10899999737739563
step: 358, train loss: 2.2854652404785156, train acuracy: 0.09375
step: 358, val loss: 2.30375599861145, val acuracy: 0.10899999737739563
step: 359, train loss: 2.3001675605773926, train acuracy: 0.109375
step: 359, val loss: 2.3044137954711914, val acuracy: 0.10899999737739563
step: 360, train loss: 2.271291732788086, train acuracy: 0.125
step: 360, val loss: 2.3081085681915283, val acuracy: 0.10899998992681503
step: 361, train loss: 2.2732527256011963, train acuracy: 0.171875
step: 361, val loss: 2.309904098510742, val acuracy: 0.10899998992681503
step: 362, train loss: 2.2830862998962402, train acuracy: 0.1796875
step: 362, val loss: 2.3116955757141113, val acuracy: 0.09666665643453598
step: 363, train loss: 2.301103115081787, train acuracy: 0.0859375
step: 363, val loss: 2.3089962005615234, val acuracy: 0.09666666388511658
step: 364, train loss: 2.301037073135376, train acuracy: 0.1171875
step: 364, val loss: 2.3072526454925537, val acuracy: 0.10899998992681503
step: 365, train loss: 2.289811611175537, train acuracy: 0.15625
step: 365, val loss: 2.306817054748535, val acuracy: 0.09816665947437286
step: 366, train loss: 2.2909669876098633, train acuracy: 0.1171875
step: 366, val loss: 2.3047165870666504, val acuracy: 0.10899998992681503
step: 367, train loss: 2.299175262451172, train acuracy: 0.1171875
step: 367, val loss: 2.303823947906494, val acuracy: 0.10899998992681503
step: 368, train loss: 2.2957191467285156, train acuracy: 0.1328125
step: 368, val loss: 2.3055214881896973, val acuracy: 0.09816666692495346
step: 369, train loss: 2.283099412918091, train acuracy: 0.15625
step: 369, val loss: 2.305037260055542, val acuracy: 0.10899998992681503
step: 370, train loss: 2.3019156455993652, train acuracy: 0.1015625
step: 370, val loss: 2.3034355640411377, val acuracy: 0.10899998992681503
step: 371, train loss: 2.2911248207092285, train acuracy: 0.1328125
step: 371, val loss: 2.303645610809326, val acuracy: 0.10899998992681503
step: 372, train loss: 2.2887234687805176, train acuracy: 0.15625
step: 372, val loss: 2.3065667152404785, val acuracy: 0.09533333778381348
step: 373, train loss: 2.264312982559204, train acuracy: 0.1875
step: 373, val loss: 2.3094310760498047, val acuracy: 0.10899999737739563
step: 374, train loss: 2.2943620681762695, train acuracy: 0.1328125
step: 374, val loss: 2.308004856109619, val acuracy: 0.10899998992681503
step: 375, train loss: 2.296109676361084, train acuracy: 0.09375
step: 375, val loss: 2.3076798915863037, val acuracy: 0.10899998992681503
step: 376, train loss: 2.291086435317993, train acuracy: 0.1171875
step: 376, val loss: 2.3080899715423584, val acuracy: 0.10899999737739563
step: 377, train loss: 2.2553629875183105, train acuracy: 0.1796875
step: 377, val loss: 2.317495346069336, val acuracy: 0.09533333778381348
step: 378, train loss: 2.2951722145080566, train acuracy: 0.0703125
step: 378, val loss: 2.308969497680664, val acuracy: 0.09533333778381348
step: 379, train loss: 2.2804818153381348, train acuracy: 0.1328125
step: 379, val loss: 2.3099777698516846, val acuracy: 0.10899998992681503
step: 380, train loss: 2.300774574279785, train acuracy: 0.09375
step: 380, val loss: 2.3080360889434814, val acuracy: 0.09816667437553406
step: 381, train loss: 2.2935738563537598, train acuracy: 0.1484375
step: 381, val loss: 2.305209159851074, val acuracy: 0.10899998992681503
step: 382, train loss: 2.2991209030151367, train acuracy: 0.1328125
step: 382, val loss: 2.303943157196045, val acuracy: 0.10899998992681503
step: 383, train loss: 2.282562732696533, train acuracy: 0.1328125
step: 383, val loss: 2.3059043884277344, val acuracy: 0.10899998992681503
step: 384, train loss: 2.262984037399292, train acuracy: 0.125
step: 384, val loss: 2.310877799987793, val acuracy: 0.10899998992681503
step: 385, train loss: 2.2903976440429688, train acuracy: 0.109375
step: 385, val loss: 2.3083574771881104, val acuracy: 0.10899999737739563
step: 386, train loss: 2.292606830596924, train acuracy: 0.1328125
step: 386, val loss: 2.3065993785858154, val acuracy: 0.10899999737739563
step: 387, train loss: 2.30165958404541, train acuracy: 0.1015625
step: 387, val loss: 2.304579019546509, val acuracy: 0.10899999737739563
step: 388, train loss: 2.2942521572113037, train acuracy: 0.109375
step: 388, val loss: 2.3063454627990723, val acuracy: 0.10899998992681503
step: 389, train loss: 2.27728271484375, train acuracy: 0.15625
step: 389, val loss: 2.3078181743621826, val acuracy: 0.10899998992681503
step: 390, train loss: 2.2950847148895264, train acuracy: 0.125
step: 390, val loss: 2.3058769702911377, val acuracy: 0.10899998992681503
step: 391, train loss: 2.2986292839050293, train acuracy: 0.1171875
step: 391, val loss: 2.3055615425109863, val acuracy: 0.10899999737739563
step: 392, train loss: 2.281733512878418, train acuracy: 0.1328125
step: 392, val loss: 2.307451009750366, val acuracy: 0.10899999737739563
step: 393, train loss: 2.285183906555176, train acuracy: 0.1015625
step: 393, val loss: 2.3068556785583496, val acuracy: 0.10899999737739563
step: 394, train loss: 2.2806546688079834, train acuracy: 0.09375
step: 394, val loss: 2.3095719814300537, val acuracy: 0.10899999737739563
step: 395, train loss: 2.2472481727600098, train acuracy: 0.1484375
step: 395, val loss: 2.321854829788208, val acuracy: 0.10899999737739563
step: 396, train loss: 2.3011136054992676, train acuracy: 0.1328125
step: 396, val loss: 2.310258388519287, val acuracy: 0.1054999977350235
step: 397, train loss: 2.288248062133789, train acuracy: 0.1328125
step: 397, val loss: 2.3075292110443115, val acuracy: 0.10899998992681503
step: 398, train loss: 2.295872449874878, train acuracy: 0.15625
step: 398, val loss: 2.3047397136688232, val acuracy: 0.10899998992681503
step: 399, train loss: 2.282332181930542, train acuracy: 0.140625
step: 399, val loss: 2.306501865386963, val acuracy: 0.10899999737739563
2017-12-04 15:45:55.219708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:45:55.473064: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0xb54e880 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 15:45:55.473773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:45:55.474052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 15:45:55.474067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 15:45:55.474073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 15:45:55.474084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 15:45:55.474091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.29378342628479, train acuracy: 0.1328125
step: 0, val loss: 2.38730788230896, val acuracy: 0.09183333069086075
step: 1, train loss: 2.186631679534912, train acuracy: 0.359375
step: 1, val loss: 2.2707200050354004, val acuracy: 0.29333335161209106
step: 2, train loss: 2.2548370361328125, train acuracy: 0.28125
step: 2, val loss: 2.267655849456787, val acuracy: 0.29350000619888306
step: 3, train loss: 2.285595655441284, train acuracy: 0.16796875
step: 3, val loss: 2.2837395668029785, val acuracy: 0.13616664707660675
step: 4, train loss: 2.308727979660034, train acuracy: 0.12890625
step: 4, val loss: 2.2805287837982178, val acuracy: 0.14800000190734863
step: 5, train loss: 2.231513261795044, train acuracy: 0.296875
step: 5, val loss: 2.2857279777526855, val acuracy: 0.27250000834465027
step: 6, train loss: 2.3000528812408447, train acuracy: 0.15234375
step: 6, val loss: 2.2793021202087402, val acuracy: 0.17800001800060272
step: 7, train loss: 2.272495746612549, train acuracy: 0.1796875
step: 7, val loss: 2.2787983417510986, val acuracy: 0.17516666650772095
step: 8, train loss: 2.289428234100342, train acuracy: 0.19140625
step: 8, val loss: 2.277952194213867, val acuracy: 0.1733333319425583
step: 9, train loss: 2.290174722671509, train acuracy: 0.171875
step: 9, val loss: 2.275507688522339, val acuracy: 0.17883333563804626
step: 10, train loss: 2.6042497158050537, train acuracy: 0.09765625
step: 10, val loss: 2.6255075931549072, val acuracy: 0.09183333814144135
step: 11, train loss: 2.312549352645874, train acuracy: 0.12109375
step: 11, val loss: 2.3269572257995605, val acuracy: 0.09666665643453598
step: 12, train loss: 2.2986786365509033, train acuracy: 0.140625
step: 12, val loss: 2.3197383880615234, val acuracy: 0.10899998992681503
step: 13, train loss: 2.308793783187866, train acuracy: 0.0859375
step: 13, val loss: 2.3310141563415527, val acuracy: 0.09700000286102295
step: 14, train loss: 2.3060693740844727, train acuracy: 0.1171875
step: 14, val loss: 2.310286521911621, val acuracy: 0.10566666722297668
step: 15, train loss: 2.3097853660583496, train acuracy: 0.10546875
step: 15, val loss: 2.3079569339752197, val acuracy: 0.10133333504199982
step: 16, train loss: 2.2975847721099854, train acuracy: 0.1015625
step: 16, val loss: 2.322655439376831, val acuracy: 0.1053333431482315
step: 17, train loss: 2.3224430084228516, train acuracy: 0.1328125
step: 17, val loss: 2.3766961097717285, val acuracy: 0.1054999977350235
step: 18, train loss: 2.28182315826416, train acuracy: 0.12109375
step: 18, val loss: 2.339109420776367, val acuracy: 0.09816665947437286
step: 19, train loss: 2.280400276184082, train acuracy: 0.078125
step: 19, val loss: 2.317683219909668, val acuracy: 0.055166665464639664
step: 20, train loss: 2.3029935359954834, train acuracy: 0.125
step: 20, val loss: 2.3466289043426514, val acuracy: 0.09666665643453598
step: 21, train loss: 2.2968971729278564, train acuracy: 0.1640625
step: 21, val loss: 2.3409085273742676, val acuracy: 0.13633333146572113
step: 22, train loss: 2.270061492919922, train acuracy: 0.14453125
step: 22, val loss: 2.3192007541656494, val acuracy: 0.10899999737739563
step: 23, train loss: 2.296865701675415, train acuracy: 0.12109375
step: 23, val loss: 2.310807943344116, val acuracy: 0.10899999737739563
step: 24, train loss: 2.256622552871704, train acuracy: 0.15234375
step: 24, val loss: 2.292418956756592, val acuracy: 0.12283332645893097
step: 25, train loss: 2.244717836380005, train acuracy: 0.16015625
step: 25, val loss: 2.260911703109741, val acuracy: 0.1381666660308838
step: 26, train loss: 2.4775311946868896, train acuracy: 0.1015625
step: 26, val loss: 2.4313411712646484, val acuracy: 0.1366666555404663
step: 27, train loss: 2.116769790649414, train acuracy: 0.3671875
step: 27, val loss: 2.1455020904541016, val acuracy: 0.34666669368743896
step: 28, train loss: 2.102893352508545, train acuracy: 0.33203125
step: 28, val loss: 2.108074188232422, val acuracy: 0.35583335161209106
step: 29, train loss: 2.107832908630371, train acuracy: 0.390625
step: 29, val loss: 2.10323166847229, val acuracy: 0.3555000126361847
step: 30, train loss: 2.1108436584472656, train acuracy: 0.37890625
step: 30, val loss: 2.1015706062316895, val acuracy: 0.3668333888053894
step: 31, train loss: 2.119556427001953, train acuracy: 0.33203125
step: 31, val loss: 2.101050853729248, val acuracy: 0.3578333556652069
step: 32, train loss: 2.0819363594055176, train acuracy: 0.42578125
step: 32, val loss: 2.0998966693878174, val acuracy: 0.3686666488647461
step: 33, train loss: 2.102700710296631, train acuracy: 0.35546875
step: 33, val loss: 2.099889039993286, val acuracy: 0.37283334136009216
step: 34, train loss: 2.0970728397369385, train acuracy: 0.359375
step: 34, val loss: 2.0994033813476562, val acuracy: 0.3723333477973938
step: 35, train loss: 2.0915260314941406, train acuracy: 0.41796875
step: 35, val loss: 2.097038745880127, val acuracy: 0.37300002574920654
step: 36, train loss: 2.1043105125427246, train acuracy: 0.3984375
step: 36, val loss: 2.0988376140594482, val acuracy: 0.39366668462753296
step: 37, train loss: 2.100079298019409, train acuracy: 0.3671875
step: 37, val loss: 2.0971274375915527, val acuracy: 0.3958333730697632
step: 38, train loss: 2.0766966342926025, train acuracy: 0.42578125
step: 38, val loss: 2.096304416656494, val acuracy: 0.3933333456516266
step: 39, train loss: 2.075819253921509, train acuracy: 0.421875
step: 39, val loss: 2.0959432125091553, val acuracy: 0.3983333706855774
step: 40, train loss: 2.1072630882263184, train acuracy: 0.3046875
step: 40, val loss: 2.102208137512207, val acuracy: 0.3255000114440918
step: 41, train loss: 2.13070011138916, train acuracy: 0.3046875
step: 41, val loss: 2.100757122039795, val acuracy: 0.33383336663246155
step: 42, train loss: 2.1491284370422363, train acuracy: 0.25
step: 42, val loss: 2.1004247665405273, val acuracy: 0.3346666991710663
step: 43, train loss: 2.0953352451324463, train acuracy: 0.32421875
step: 43, val loss: 2.1000869274139404, val acuracy: 0.3360000252723694
step: 44, train loss: 2.108344554901123, train acuracy: 0.3125
step: 44, val loss: 2.1000285148620605, val acuracy: 0.33800002932548523
step: 45, train loss: 2.1550822257995605, train acuracy: 0.203125
step: 45, val loss: 2.13436222076416, val acuracy: 0.2276666760444641
step: 46, train loss: 2.132511615753174, train acuracy: 0.2109375
step: 46, val loss: 2.13142991065979, val acuracy: 0.2330000102519989
step: 47, train loss: 2.088702440261841, train acuracy: 0.27734375
step: 47, val loss: 2.131695032119751, val acuracy: 0.23283334076404572
step: 48, train loss: 2.111541271209717, train acuracy: 0.234375
step: 48, val loss: 2.1346075534820557, val acuracy: 0.21283333003520966
step: 49, train loss: 2.1578314304351807, train acuracy: 0.20703125
step: 49, val loss: 2.133589506149292, val acuracy: 0.2163333296775818
step: 50, train loss: 2.0785086154937744, train acuracy: 0.26953125
step: 50, val loss: 2.1330323219299316, val acuracy: 0.22216668725013733
step: 51, train loss: 2.1575217247009277, train acuracy: 0.23046875
step: 51, val loss: 2.160813331604004, val acuracy: 0.22816666960716248
step: 52, train loss: 2.14597225189209, train acuracy: 0.21484375
step: 52, val loss: 2.1353790760040283, val acuracy: 0.20333333313465118
step: 53, train loss: 2.1424672603607178, train acuracy: 0.20703125
step: 53, val loss: 2.1488442420959473, val acuracy: 0.2186666876077652
step: 54, train loss: 2.1533966064453125, train acuracy: 0.24609375
step: 54, val loss: 2.1465377807617188, val acuracy: 0.21950000524520874
step: 55, train loss: 2.187685251235962, train acuracy: 0.1953125
step: 55, val loss: 2.1492156982421875, val acuracy: 0.19583334028720856
step: 56, train loss: 2.09431791305542, train acuracy: 0.31640625
step: 56, val loss: 2.1571578979492188, val acuracy: 0.23266668617725372
step: 57, train loss: 2.1848180294036865, train acuracy: 0.18359375
step: 57, val loss: 2.170393943786621, val acuracy: 0.18733333051204681
step: 58, train loss: 2.128207206726074, train acuracy: 0.20703125
step: 58, val loss: 2.147216320037842, val acuracy: 0.1915000081062317
step: 59, train loss: 2.1859641075134277, train acuracy: 0.3203125
step: 59, val loss: 2.154052972793579, val acuracy: 0.3050000071525574
step: 60, train loss: 2.1737136840820312, train acuracy: 0.2734375
step: 60, val loss: 2.15207839012146, val acuracy: 0.3035000264644623
step: 61, train loss: 2.182401180267334, train acuracy: 0.28515625
step: 61, val loss: 2.151371479034424, val acuracy: 0.3016666769981384
step: 62, train loss: 2.1880578994750977, train acuracy: 0.234375
step: 62, val loss: 2.1680805683135986, val acuracy: 0.23216667771339417
step: 63, train loss: 2.1330344676971436, train acuracy: 0.3046875
step: 63, val loss: 2.1651127338409424, val acuracy: 0.2355000078678131
step: 64, train loss: 2.140889883041382, train acuracy: 0.296875
step: 64, val loss: 2.1583898067474365, val acuracy: 0.2905000150203705
step: 65, train loss: 2.0976147651672363, train acuracy: 0.35546875
step: 65, val loss: 2.154388427734375, val acuracy: 0.2946666479110718
step: 66, train loss: 2.084683418273926, train acuracy: 0.3359375
step: 66, val loss: 2.1426892280578613, val acuracy: 0.3005000054836273
step: 67, train loss: 2.1481738090515137, train acuracy: 0.296875
step: 67, val loss: 2.147526502609253, val acuracy: 0.27416664361953735
step: 68, train loss: 2.0208241939544678, train acuracy: 0.44921875
step: 68, val loss: 2.072648048400879, val acuracy: 0.4258333444595337
step: 69, train loss: 2.015688896179199, train acuracy: 0.40625
step: 69, val loss: 2.024550676345825, val acuracy: 0.398000031709671
step: 70, train loss: 2.1811180114746094, train acuracy: 0.234375
step: 70, val loss: 2.157161235809326, val acuracy: 0.22333334386348724
step: 71, train loss: 2.152756929397583, train acuracy: 0.16796875
step: 71, val loss: 2.1514148712158203, val acuracy: 0.17899999022483826
step: 72, train loss: 1.8950541019439697, train acuracy: 0.421875
step: 72, val loss: 2.0506231784820557, val acuracy: 0.35716670751571655
step: 73, train loss: 1.9777624607086182, train acuracy: 0.359375
step: 73, val loss: 2.001121997833252, val acuracy: 0.30400002002716064
step: 74, train loss: 1.990498423576355, train acuracy: 0.3046875
step: 74, val loss: 1.9931361675262451, val acuracy: 0.3111667037010193
step: 75, train loss: 1.908717393875122, train acuracy: 0.39453125
step: 75, val loss: 2.0139212608337402, val acuracy: 0.3283333480358124
step: 76, train loss: 2.0448641777038574, train acuracy: 0.27734375
step: 76, val loss: 2.0193326473236084, val acuracy: 0.30666670203208923
step: 77, train loss: 1.9620641469955444, train acuracy: 0.3515625
step: 77, val loss: 2.065436363220215, val acuracy: 0.3188333511352539
step: 78, train loss: 2.0093793869018555, train acuracy: 0.296875
step: 78, val loss: 2.011373996734619, val acuracy: 0.320333331823349
step: 79, train loss: 1.9335649013519287, train acuracy: 0.41015625
step: 79, val loss: 2.0943522453308105, val acuracy: 0.3188333511352539
step: 80, train loss: 2.103076457977295, train acuracy: 0.33203125
step: 80, val loss: 2.111891746520996, val acuracy: 0.30266666412353516
step: 81, train loss: 2.011107921600342, train acuracy: 0.25
step: 81, val loss: 2.002587080001831, val acuracy: 0.2540000081062317
step: 82, train loss: 2.00166654586792, train acuracy: 0.2578125
step: 82, val loss: 1.99847412109375, val acuracy: 0.2691666781902313
step: 83, train loss: 1.9775755405426025, train acuracy: 0.2734375
step: 83, val loss: 1.9965441226959229, val acuracy: 0.2709999978542328
step: 84, train loss: 1.948697805404663, train acuracy: 0.2890625
step: 84, val loss: 1.996170997619629, val acuracy: 0.2710000276565552
step: 85, train loss: 2.002953052520752, train acuracy: 0.26171875
step: 85, val loss: 1.993180751800537, val acuracy: 0.3256666958332062
step: 86, train loss: 1.9269429445266724, train acuracy: 0.26171875
step: 86, val loss: 2.0096640586853027, val acuracy: 0.24400001764297485
step: 87, train loss: 2.0234501361846924, train acuracy: 0.203125
step: 87, val loss: 2.0082216262817383, val acuracy: 0.24666666984558105
step: 88, train loss: 2.015435218811035, train acuracy: 0.2578125
step: 88, val loss: 2.0072381496429443, val acuracy: 0.24883335828781128
step: 89, train loss: 2.02143931388855, train acuracy: 0.234375
step: 89, val loss: 2.0070996284484863, val acuracy: 0.2486666738986969
step: 90, train loss: 1.966231107711792, train acuracy: 0.30078125
step: 90, val loss: 2.012744426727295, val acuracy: 0.2551666796207428
step: 91, train loss: 2.0077359676361084, train acuracy: 0.27734375
step: 91, val loss: 2.00769305229187, val acuracy: 0.25683334469795227
step: 92, train loss: 1.9964452981948853, train acuracy: 0.265625
step: 92, val loss: 2.0118865966796875, val acuracy: 0.25466668605804443
step: 93, train loss: 1.987545132637024, train acuracy: 0.25390625
step: 93, val loss: 2.010668992996216, val acuracy: 0.2553333640098572
step: 94, train loss: 2.0751795768737793, train acuracy: 0.2421875
step: 94, val loss: 2.0097603797912598, val acuracy: 0.2568333148956299
step: 95, train loss: 2.042933225631714, train acuracy: 0.23828125
step: 95, val loss: 2.0094542503356934, val acuracy: 0.2568333148956299
step: 96, train loss: 2.0817062854766846, train acuracy: 0.234375
step: 96, val loss: 2.0091912746429443, val acuracy: 0.25600001215934753
step: 97, train loss: 2.0082807540893555, train acuracy: 0.26953125
step: 97, val loss: 2.008958339691162, val acuracy: 0.25583335757255554
step: 98, train loss: 1.9956698417663574, train acuracy: 0.26953125
step: 98, val loss: 2.008880376815796, val acuracy: 0.2578333616256714
step: 99, train loss: 1.95662522315979, train acuracy: 0.32421875
step: 99, val loss: 2.028599739074707, val acuracy: 0.2668333649635315
step: 100, train loss: 2.05515456199646, train acuracy: 0.26171875
step: 100, val loss: 2.0180928707122803, val acuracy: 0.2746666669845581
step: 101, train loss: 1.9456409215927124, train acuracy: 0.296875
step: 101, val loss: 2.024674654006958, val acuracy: 0.2756666839122772
step: 102, train loss: 2.0036871433258057, train acuracy: 0.28515625
step: 102, val loss: 2.0340495109558105, val acuracy: 0.2590000033378601
step: 103, train loss: 2.0409090518951416, train acuracy: 0.2109375
step: 103, val loss: 2.0498571395874023, val acuracy: 0.24133333563804626
step: 104, train loss: 1.9606740474700928, train acuracy: 0.27734375
step: 104, val loss: 2.084174871444702, val acuracy: 0.226500004529953
step: 105, train loss: 2.042827844619751, train acuracy: 0.22265625
step: 105, val loss: 2.053514003753662, val acuracy: 0.2423333376646042
step: 106, train loss: 2.0384232997894287, train acuracy: 0.2578125
step: 106, val loss: 2.0482773780822754, val acuracy: 0.25066667795181274
step: 107, train loss: 1.9562921524047852, train acuracy: 0.30078125
step: 107, val loss: 2.0417819023132324, val acuracy: 0.2538333237171173
step: 108, train loss: 1.9945411682128906, train acuracy: 0.28125
step: 108, val loss: 2.0537102222442627, val acuracy: 0.2763333320617676
step: 109, train loss: 2.0116260051727295, train acuracy: 0.33984375
step: 109, val loss: 2.062082529067993, val acuracy: 0.3005000054836273
step: 110, train loss: 2.0444157123565674, train acuracy: 0.25390625
step: 110, val loss: 2.0895400047302246, val acuracy: 0.26233333349227905
step: 111, train loss: 2.012883424758911, train acuracy: 0.1953125
step: 111, val loss: 2.16811203956604, val acuracy: 0.15583333373069763
step: 112, train loss: 2.0606863498687744, train acuracy: 0.265625
step: 112, val loss: 2.0759694576263428, val acuracy: 0.2758333384990692
step: 113, train loss: 2.1147966384887695, train acuracy: 0.33984375
step: 113, val loss: 2.0954477787017822, val acuracy: 0.33899998664855957
step: 114, train loss: 2.066288948059082, train acuracy: 0.140625
step: 114, val loss: 2.071822166442871, val acuracy: 0.14616665244102478
step: 115, train loss: 2.0412583351135254, train acuracy: 0.30859375
step: 115, val loss: 2.0748820304870605, val acuracy: 0.29366669058799744
step: 116, train loss: 2.091130018234253, train acuracy: 0.296875
step: 116, val loss: 2.0626637935638428, val acuracy: 0.312333345413208
step: 117, train loss: 2.0115015506744385, train acuracy: 0.2734375
step: 117, val loss: 2.1219234466552734, val acuracy: 0.20983333885669708
step: 118, train loss: 2.0954430103302, train acuracy: 0.3515625
step: 118, val loss: 2.084773063659668, val acuracy: 0.3460000157356262
step: 119, train loss: 2.095179557800293, train acuracy: 0.34375
step: 119, val loss: 2.079024076461792, val acuracy: 0.3460000157356262
step: 120, train loss: 2.020841121673584, train acuracy: 0.33203125
step: 120, val loss: 2.064826488494873, val acuracy: 0.2903333306312561
step: 121, train loss: 2.0579471588134766, train acuracy: 0.296875
step: 121, val loss: 2.06429386138916, val acuracy: 0.2900000214576721
step: 122, train loss: 2.0455899238586426, train acuracy: 0.35546875
step: 122, val loss: 2.083441972732544, val acuracy: 0.29366666078567505
step: 123, train loss: 2.0651090145111084, train acuracy: 0.34375
step: 123, val loss: 2.0582268238067627, val acuracy: 0.3333333730697632
step: 124, train loss: 2.0698533058166504, train acuracy: 0.40625
step: 124, val loss: 2.0726113319396973, val acuracy: 0.359333336353302
step: 125, train loss: 2.082883834838867, train acuracy: 0.31640625
step: 125, val loss: 2.0764408111572266, val acuracy: 0.2983333468437195
step: 126, train loss: 2.0708084106445312, train acuracy: 0.375
step: 126, val loss: 2.059190273284912, val acuracy: 0.3541666865348816
step: 127, train loss: 2.0269601345062256, train acuracy: 0.40625
step: 127, val loss: 2.062386989593506, val acuracy: 0.37416666746139526
step: 128, train loss: 2.0086169242858887, train acuracy: 0.4453125
step: 128, val loss: 2.0543837547302246, val acuracy: 0.390166699886322
step: 129, train loss: 2.10498046875, train acuracy: 0.1953125
step: 129, val loss: 2.07975435256958, val acuracy: 0.23350000381469727
step: 130, train loss: 1.9410545825958252, train acuracy: 0.4140625
step: 130, val loss: 1.9538874626159668, val acuracy: 0.3941666781902313
step: 131, train loss: 1.910174012184143, train acuracy: 0.46875
step: 131, val loss: 1.9103119373321533, val acuracy: 0.4415000379085541
step: 132, train loss: 1.6852738857269287, train acuracy: 0.46875
step: 132, val loss: 1.7123291492462158, val acuracy: 0.46949997544288635
step: 133, train loss: 1.5036399364471436, train acuracy: 0.4765625
step: 133, val loss: 1.6159833669662476, val acuracy: 0.4200000464916229
step: 134, train loss: 1.5336753129959106, train acuracy: 0.4375
step: 134, val loss: 1.5026427507400513, val acuracy: 0.4623333513736725
step: 135, train loss: 1.5109375715255737, train acuracy: 0.54296875
step: 135, val loss: 1.582961916923523, val acuracy: 0.5045000314712524
step: 136, train loss: 1.10060715675354, train acuracy: 0.63671875
step: 136, val loss: 1.3728593587875366, val acuracy: 0.5688334107398987
step: 137, train loss: 1.4809777736663818, train acuracy: 0.54296875
step: 137, val loss: 1.4248758554458618, val acuracy: 0.5674999952316284
step: 138, train loss: 1.453894853591919, train acuracy: 0.5703125
step: 138, val loss: 1.5959380865097046, val acuracy: 0.549833357334137
step: 139, train loss: 1.3339442014694214, train acuracy: 0.6171875
step: 139, val loss: 1.6766011714935303, val acuracy: 0.5846667289733887
step: 140, train loss: 1.5588717460632324, train acuracy: 0.609375
step: 140, val loss: 1.6234118938446045, val acuracy: 0.5890000462532043
step: 141, train loss: 1.679092288017273, train acuracy: 0.52734375
step: 141, val loss: 1.6510229110717773, val acuracy: 0.5820000171661377
step: 142, train loss: 1.6362723112106323, train acuracy: 0.56640625
step: 142, val loss: 1.8004411458969116, val acuracy: 0.5626667141914368
step: 143, train loss: 1.7481153011322021, train acuracy: 0.5703125
step: 143, val loss: 1.9233388900756836, val acuracy: 0.5371666550636292
step: 144, train loss: 1.9136741161346436, train acuracy: 0.52734375
step: 144, val loss: 1.9066020250320435, val acuracy: 0.5415000319480896
step: 145, train loss: 1.6445953845977783, train acuracy: 0.5625
step: 145, val loss: 1.737122654914856, val acuracy: 0.5871666669845581
step: 146, train loss: 1.8033459186553955, train acuracy: 0.51953125
step: 146, val loss: 1.798923373222351, val acuracy: 0.5326666831970215
step: 147, train loss: 1.8718655109405518, train acuracy: 0.56640625
step: 147, val loss: 1.969175100326538, val acuracy: 0.5379999876022339
step: 148, train loss: 1.682088851928711, train acuracy: 0.56640625
step: 148, val loss: 1.7539671659469604, val acuracy: 0.5445000529289246
step: 149, train loss: 1.9718400239944458, train acuracy: 0.51171875
step: 149, val loss: 1.7275469303131104, val acuracy: 0.5703333616256714
step: 150, train loss: 1.512787103652954, train acuracy: 0.56640625
step: 150, val loss: 1.7966574430465698, val acuracy: 0.5421666502952576
step: 151, train loss: 1.5593081712722778, train acuracy: 0.59375
step: 151, val loss: 1.7185806035995483, val acuracy: 0.5576667189598083
step: 152, train loss: 1.3846569061279297, train acuracy: 0.609375
step: 152, val loss: 1.5813066959381104, val acuracy: 0.5774999856948853
step: 153, train loss: 1.487076997756958, train acuracy: 0.62890625
step: 153, val loss: 1.5992403030395508, val acuracy: 0.5725000500679016
step: 154, train loss: 1.5885777473449707, train acuracy: 0.5625
step: 154, val loss: 1.74501633644104, val acuracy: 0.5354999899864197
step: 155, train loss: 1.5865589380264282, train acuracy: 0.546875
step: 155, val loss: 1.8019400835037231, val acuracy: 0.5471667051315308
step: 156, train loss: 1.763735055923462, train acuracy: 0.5546875
step: 156, val loss: 1.9316496849060059, val acuracy: 0.5558333396911621
step: 157, train loss: 2.0218141078948975, train acuracy: 0.4296875
step: 157, val loss: 2.1744627952575684, val acuracy: 0.3956666588783264
step: 158, train loss: 1.5417157411575317, train acuracy: 0.5546875
step: 158, val loss: 1.7378737926483154, val acuracy: 0.5043333768844604
step: 159, train loss: 1.9940636157989502, train acuracy: 0.38671875
step: 159, val loss: 1.9063671827316284, val acuracy: 0.406166672706604
step: 160, train loss: 1.709617257118225, train acuracy: 0.484375
step: 160, val loss: 1.7377671003341675, val acuracy: 0.4483333230018616
step: 161, train loss: 1.697323203086853, train acuracy: 0.44921875
step: 161, val loss: 1.7287261486053467, val acuracy: 0.45250001549720764
step: 162, train loss: 1.6602038145065308, train acuracy: 0.48828125
step: 162, val loss: 1.7214839458465576, val acuracy: 0.4658333659172058
step: 163, train loss: 1.6708804368972778, train acuracy: 0.484375
step: 163, val loss: 1.7193347215652466, val acuracy: 0.46550002694129944
step: 164, train loss: 1.5971572399139404, train acuracy: 0.49609375
step: 164, val loss: 1.718970537185669, val acuracy: 0.4661666750907898
step: 165, train loss: 1.6689338684082031, train acuracy: 0.5
step: 165, val loss: 1.7184913158416748, val acuracy: 0.4658333361148834
step: 166, train loss: 1.7796130180358887, train acuracy: 0.38671875
step: 166, val loss: 1.7181636095046997, val acuracy: 0.46683335304260254
step: 167, train loss: 1.6186933517456055, train acuracy: 0.50390625
step: 167, val loss: 1.717999815940857, val acuracy: 0.4673333168029785
step: 168, train loss: 1.7827274799346924, train acuracy: 0.4375
step: 168, val loss: 1.717909336090088, val acuracy: 0.4675000309944153
step: 169, train loss: 1.640984296798706, train acuracy: 0.4765625
step: 169, val loss: 1.7178096771240234, val acuracy: 0.46833333373069763
step: 170, train loss: 1.7992901802062988, train acuracy: 0.4453125
step: 170, val loss: 1.7176389694213867, val acuracy: 0.468500018119812
step: 171, train loss: 1.7552510499954224, train acuracy: 0.44921875
step: 171, val loss: 1.7175955772399902, val acuracy: 0.46816667914390564
step: 172, train loss: 1.698636531829834, train acuracy: 0.47265625
step: 172, val loss: 1.7175241708755493, val acuracy: 0.468500018119812
step: 173, train loss: 1.6501448154449463, train acuracy: 0.51171875
step: 173, val loss: 1.7174314260482788, val acuracy: 0.4678333103656769
step: 174, train loss: 1.6983087062835693, train acuracy: 0.50390625
step: 174, val loss: 1.7173302173614502, val acuracy: 0.46800002455711365
step: 175, train loss: 1.696163535118103, train acuracy: 0.47265625
step: 175, val loss: 1.7173007726669312, val acuracy: 0.4688333570957184
step: 176, train loss: 1.6783543825149536, train acuracy: 0.46875
step: 176, val loss: 1.71730637550354, val acuracy: 0.4688333570957184
step: 177, train loss: 1.5977827310562134, train acuracy: 0.515625
step: 177, val loss: 1.717375636100769, val acuracy: 0.468666672706604
step: 178, train loss: 1.6927746534347534, train acuracy: 0.48046875
step: 178, val loss: 1.7173575162887573, val acuracy: 0.4690000116825104
step: 179, train loss: 1.6510941982269287, train acuracy: 0.5
step: 179, val loss: 1.717188835144043, val acuracy: 0.468833327293396
step: 180, train loss: 1.7283540964126587, train acuracy: 0.46484375
step: 180, val loss: 1.7555067539215088, val acuracy: 0.44433334469795227
step: 181, train loss: 1.7292726039886475, train acuracy: 0.4609375
step: 181, val loss: 1.7369728088378906, val acuracy: 0.4700000286102295
step: 182, train loss: 1.712018370628357, train acuracy: 0.4609375
step: 182, val loss: 1.7473331689834595, val acuracy: 0.4781666696071625
step: 183, train loss: 1.6932951211929321, train acuracy: 0.5
step: 183, val loss: 1.7182186841964722, val acuracy: 0.4909999966621399
step: 184, train loss: 1.717382788658142, train acuracy: 0.4765625
step: 184, val loss: 1.7102906703948975, val acuracy: 0.4660000503063202
step: 185, train loss: 1.7137141227722168, train acuracy: 0.46875
step: 185, val loss: 1.7088018655776978, val acuracy: 0.47833338379859924
step: 186, train loss: 1.7676345109939575, train acuracy: 0.45703125
step: 186, val loss: 1.7052329778671265, val acuracy: 0.4801666736602783
step: 187, train loss: 1.688989520072937, train acuracy: 0.47265625
step: 187, val loss: 1.7079737186431885, val acuracy: 0.4826667010784149
step: 188, train loss: 1.6834306716918945, train acuracy: 0.484375
step: 188, val loss: 1.7064945697784424, val acuracy: 0.4816666841506958
step: 189, train loss: 1.644016981124878, train acuracy: 0.48828125
step: 189, val loss: 1.7291138172149658, val acuracy: 0.4624999761581421
step: 190, train loss: 1.688260555267334, train acuracy: 0.4296875
step: 190, val loss: 1.7379188537597656, val acuracy: 0.42383334040641785
step: 191, train loss: 1.662628173828125, train acuracy: 0.453125
step: 191, val loss: 1.6774063110351562, val acuracy: 0.4573333263397217
step: 192, train loss: 1.6086747646331787, train acuracy: 0.5234375
step: 192, val loss: 1.6456654071807861, val acuracy: 0.49383336305618286
step: 193, train loss: 1.56229567527771, train acuracy: 0.52734375
step: 193, val loss: 1.555059790611267, val acuracy: 0.5320000648498535
step: 194, train loss: 1.521535038948059, train acuracy: 0.53515625
step: 194, val loss: 1.5643082857131958, val acuracy: 0.5091666579246521
step: 195, train loss: 1.2158527374267578, train acuracy: 0.57421875
step: 195, val loss: 1.3702465295791626, val acuracy: 0.5363333821296692
step: 196, train loss: 1.044666051864624, train acuracy: 0.6640625
step: 196, val loss: 1.183898687362671, val acuracy: 0.6030000448226929
step: 197, train loss: 1.0244897603988647, train acuracy: 0.64453125
step: 197, val loss: 1.1282154321670532, val acuracy: 0.6096667051315308
step: 198, train loss: 1.0507750511169434, train acuracy: 0.6171875
step: 198, val loss: 1.1422613859176636, val acuracy: 0.6043334007263184
step: 199, train loss: 1.1340041160583496, train acuracy: 0.625
step: 199, val loss: 1.1279840469360352, val acuracy: 0.6111667156219482
step: 200, train loss: 1.1757078170776367, train acuracy: 0.60546875
step: 200, val loss: 1.1346969604492188, val acuracy: 0.6240000128746033
step: 201, train loss: 1.028900384902954, train acuracy: 0.65625
step: 201, val loss: 1.1252689361572266, val acuracy: 0.6105000376701355
step: 202, train loss: 1.0773221254348755, train acuracy: 0.66015625
step: 202, val loss: 1.1399173736572266, val acuracy: 0.6231666803359985
step: 203, train loss: 1.0967048406600952, train acuracy: 0.63671875
step: 203, val loss: 1.1323282718658447, val acuracy: 0.6133334040641785
step: 204, train loss: 1.1262582540512085, train acuracy: 0.62109375
step: 204, val loss: 1.176833987236023, val acuracy: 0.6025000214576721
step: 205, train loss: 1.0955872535705566, train acuracy: 0.609375
step: 205, val loss: 1.1587352752685547, val acuracy: 0.5920000672340393
step: 206, train loss: 1.1599342823028564, train acuracy: 0.60546875
step: 206, val loss: 1.1521633863449097, val acuracy: 0.6213333606719971
step: 207, train loss: 1.1146020889282227, train acuracy: 0.59765625
step: 207, val loss: 1.1747723817825317, val acuracy: 0.5838333964347839
step: 208, train loss: 1.1484663486480713, train acuracy: 0.6015625
step: 208, val loss: 1.1479321718215942, val acuracy: 0.6230000853538513
step: 209, train loss: 1.117168664932251, train acuracy: 0.625
step: 209, val loss: 1.1454161405563354, val acuracy: 0.6248334050178528
step: 210, train loss: 1.1897320747375488, train acuracy: 0.62109375
step: 210, val loss: 1.19186532497406, val acuracy: 0.5798333883285522
step: 211, train loss: 1.0784366130828857, train acuracy: 0.64453125
step: 211, val loss: 1.1506339311599731, val acuracy: 0.621666669845581
step: 212, train loss: 1.100314736366272, train acuracy: 0.66796875
step: 212, val loss: 1.1496713161468506, val acuracy: 0.6221666932106018
step: 213, train loss: 1.0801327228546143, train acuracy: 0.63671875
step: 213, val loss: 1.1484861373901367, val acuracy: 0.6216667294502258
step: 214, train loss: 1.248491883277893, train acuracy: 0.60546875
step: 214, val loss: 1.2091838121414185, val acuracy: 0.6045000553131104
step: 215, train loss: 1.1575915813446045, train acuracy: 0.6171875
step: 215, val loss: 1.1964058876037598, val acuracy: 0.5920000076293945
step: 216, train loss: 1.1123918294906616, train acuracy: 0.58203125
step: 216, val loss: 1.2085951566696167, val acuracy: 0.5600000619888306
step: 217, train loss: 1.1182217597961426, train acuracy: 0.58984375
step: 217, val loss: 1.2015734910964966, val acuracy: 0.5646666884422302
step: 218, train loss: 1.2034770250320435, train acuracy: 0.52734375
step: 218, val loss: 1.2005187273025513, val acuracy: 0.5654999613761902
step: 219, train loss: 1.1971790790557861, train acuracy: 0.58203125
step: 219, val loss: 1.212118148803711, val acuracy: 0.565333366394043
step: 220, train loss: 1.2084451913833618, train acuracy: 0.5234375
step: 220, val loss: 1.2092108726501465, val acuracy: 0.5596667528152466
step: 221, train loss: 1.1277352571487427, train acuracy: 0.60546875
step: 221, val loss: 1.1944730281829834, val acuracy: 0.5743333101272583
step: 222, train loss: 1.215319275856018, train acuracy: 0.5390625
step: 222, val loss: 1.2218167781829834, val acuracy: 0.5566666722297668
step: 223, train loss: 1.1988322734832764, train acuracy: 0.55859375
step: 223, val loss: 1.2344951629638672, val acuracy: 0.5625
step: 224, train loss: 1.2773940563201904, train acuracy: 0.5390625
step: 224, val loss: 1.2317557334899902, val acuracy: 0.5630000233650208
step: 225, train loss: 1.1669522523880005, train acuracy: 0.5546875
step: 225, val loss: 1.2237253189086914, val acuracy: 0.5676667094230652
step: 226, train loss: 1.2005760669708252, train acuracy: 0.5859375
step: 226, val loss: 1.221506953239441, val acuracy: 0.5643333792686462
step: 227, train loss: 1.30377995967865, train acuracy: 0.5625
step: 227, val loss: 1.2565374374389648, val acuracy: 0.5598333477973938
step: 228, train loss: 1.2261865139007568, train acuracy: 0.58203125
step: 228, val loss: 1.2522153854370117, val acuracy: 0.562166690826416
step: 229, train loss: 1.2762378454208374, train acuracy: 0.55078125
step: 229, val loss: 1.2390013933181763, val acuracy: 0.5686667561531067
step: 230, train loss: 1.21122407913208, train acuracy: 0.55859375
step: 230, val loss: 1.2554198503494263, val acuracy: 0.5583333373069763
step: 231, train loss: 1.228076457977295, train acuracy: 0.5703125
step: 231, val loss: 1.2515053749084473, val acuracy: 0.5613333582878113
step: 232, train loss: 1.2577141523361206, train acuracy: 0.55859375
step: 232, val loss: 1.2581866979599, val acuracy: 0.5659999847412109
step: 233, train loss: 1.2638672590255737, train acuracy: 0.52734375
step: 233, val loss: 1.2886247634887695, val acuracy: 0.561833381652832
step: 234, train loss: 1.2479946613311768, train acuracy: 0.5703125
step: 234, val loss: 1.2851896286010742, val acuracy: 0.5616666674613953
step: 235, train loss: 1.2383986711502075, train acuracy: 0.58203125
step: 235, val loss: 1.2913998365402222, val acuracy: 0.5444999933242798
step: 236, train loss: 1.368233561515808, train acuracy: 0.52734375
step: 236, val loss: 1.2883706092834473, val acuracy: 0.5471667051315308
step: 237, train loss: 1.2512849569320679, train acuracy: 0.51953125
step: 237, val loss: 1.2883284091949463, val acuracy: 0.546500027179718
step: 238, train loss: 1.2534942626953125, train acuracy: 0.56640625
step: 238, val loss: 1.2877839803695679, val acuracy: 0.5480000376701355
step: 239, train loss: 1.333350658416748, train acuracy: 0.56640625
step: 239, val loss: 1.2872304916381836, val acuracy: 0.5491666793823242
step: 240, train loss: 1.3030200004577637, train acuracy: 0.52734375
step: 240, val loss: 1.3051377534866333, val acuracy: 0.528333306312561
step: 241, train loss: 1.377561092376709, train acuracy: 0.53125
step: 241, val loss: 1.3524144887924194, val acuracy: 0.5516667366027832
step: 242, train loss: 1.2448718547821045, train acuracy: 0.58203125
step: 242, val loss: 1.3056375980377197, val acuracy: 0.5376666784286499
step: 243, train loss: 1.3041149377822876, train acuracy: 0.5234375
step: 243, val loss: 1.292386770248413, val acuracy: 0.5481666922569275
step: 244, train loss: 1.3048919439315796, train acuracy: 0.59375
step: 244, val loss: 1.3230197429656982, val acuracy: 0.5663334131240845
step: 245, train loss: 1.3138129711151123, train acuracy: 0.54296875
step: 245, val loss: 1.3790068626403809, val acuracy: 0.5126667022705078
step: 246, train loss: 1.3723132610321045, train acuracy: 0.5078125
step: 246, val loss: 1.372266173362732, val acuracy: 0.5138333439826965
step: 247, train loss: 1.2449394464492798, train acuracy: 0.60546875
step: 247, val loss: 1.373637318611145, val acuracy: 0.5338333249092102
step: 248, train loss: 1.3998091220855713, train acuracy: 0.56640625
step: 248, val loss: 1.3725252151489258, val acuracy: 0.5541667342185974
step: 249, train loss: 1.248492956161499, train acuracy: 0.56640625
step: 249, val loss: 1.3808664083480835, val acuracy: 0.5146666765213013
step: 250, train loss: 1.418705940246582, train acuracy: 0.515625
step: 250, val loss: 1.3845555782318115, val acuracy: 0.5298333168029785
step: 251, train loss: 1.37590754032135, train acuracy: 0.52734375
step: 251, val loss: 1.3677566051483154, val acuracy: 0.5201666951179504
step: 252, train loss: 1.4632205963134766, train acuracy: 0.484375
step: 252, val loss: 1.3964416980743408, val acuracy: 0.5364999771118164
step: 253, train loss: 1.3597768545150757, train acuracy: 0.5078125
step: 253, val loss: 1.4033797979354858, val acuracy: 0.5006666779518127
step: 254, train loss: 1.3492928743362427, train acuracy: 0.55078125
step: 254, val loss: 1.4991693496704102, val acuracy: 0.5
step: 255, train loss: 1.6645338535308838, train acuracy: 0.4296875
step: 255, val loss: 1.5995887517929077, val acuracy: 0.46966665983200073
step: 256, train loss: 1.626236915588379, train acuracy: 0.4921875
step: 256, val loss: 1.5839818716049194, val acuracy: 0.4751666784286499
step: 257, train loss: 1.4748984575271606, train acuracy: 0.52734375
step: 257, val loss: 1.5968587398529053, val acuracy: 0.4544999897480011
step: 258, train loss: 1.5320606231689453, train acuracy: 0.52734375
step: 258, val loss: 1.571472406387329, val acuracy: 0.5005000233650208
step: 259, train loss: 1.5447595119476318, train acuracy: 0.48828125
step: 259, val loss: 1.585895299911499, val acuracy: 0.48900002241134644
step: 260, train loss: 1.4936964511871338, train acuracy: 0.50390625
step: 260, val loss: 1.6048740148544312, val acuracy: 0.4506666660308838
step: 261, train loss: 1.6341400146484375, train acuracy: 0.4609375
step: 261, val loss: 1.590627670288086, val acuracy: 0.49549999833106995
step: 262, train loss: 1.6232166290283203, train acuracy: 0.48046875
step: 262, val loss: 1.6289345026016235, val acuracy: 0.48350006341934204
step: 263, train loss: 1.6769530773162842, train acuracy: 0.46484375
step: 263, val loss: 1.6256420612335205, val acuracy: 0.4853333830833435
step: 264, train loss: 1.6353884935379028, train acuracy: 0.49609375
step: 264, val loss: 1.62466299533844, val acuracy: 0.48416668176651
step: 265, train loss: 1.7113580703735352, train acuracy: 0.453125
step: 265, val loss: 1.6244721412658691, val acuracy: 0.4831666648387909
step: 266, train loss: 1.5104784965515137, train acuracy: 0.51171875
step: 266, val loss: 1.6330840587615967, val acuracy: 0.4514999985694885
step: 267, train loss: 1.6515705585479736, train acuracy: 0.4921875
step: 267, val loss: 1.6470767259597778, val acuracy: 0.5
step: 268, train loss: 1.5064352750778198, train acuracy: 0.5859375
step: 268, val loss: 1.6434370279312134, val acuracy: 0.49783337116241455
step: 269, train loss: 1.577142357826233, train acuracy: 0.56640625
step: 269, val loss: 1.6462315320968628, val acuracy: 0.5096666812896729
step: 270, train loss: 1.6540905237197876, train acuracy: 0.50390625
step: 270, val loss: 1.6402806043624878, val acuracy: 0.5020000338554382
step: 271, train loss: 1.7172399759292603, train acuracy: 0.40234375
step: 271, val loss: 1.6401021480560303, val acuracy: 0.486833393573761
step: 272, train loss: 1.7659375667572021, train acuracy: 0.390625
step: 272, val loss: 1.7384034395217896, val acuracy: 0.37550002336502075
step: 273, train loss: 1.8311384916305542, train acuracy: 0.35546875
step: 273, val loss: 1.7296994924545288, val acuracy: 0.3790000081062317
step: 274, train loss: 1.7522920370101929, train acuracy: 0.37109375
step: 274, val loss: 1.7295085191726685, val acuracy: 0.3798333406448364
step: 275, train loss: 1.7191845178604126, train acuracy: 0.390625
step: 275, val loss: 1.7296061515808105, val acuracy: 0.3798333704471588
step: 276, train loss: 1.7226877212524414, train acuracy: 0.35546875
step: 276, val loss: 1.7339186668395996, val acuracy: 0.3785000443458557
step: 277, train loss: 1.781923532485962, train acuracy: 0.359375
step: 277, val loss: 1.7308040857315063, val acuracy: 0.37666672468185425
step: 278, train loss: 1.7195709943771362, train acuracy: 0.35546875
step: 278, val loss: 1.7300286293029785, val acuracy: 0.37650004029273987
step: 279, train loss: 1.6646398305892944, train acuracy: 0.4296875
step: 279, val loss: 1.7295215129852295, val acuracy: 0.3763333559036255
step: 280, train loss: 1.7900665998458862, train acuracy: 0.36328125
step: 280, val loss: 1.736401915550232, val acuracy: 0.37650004029273987
step: 281, train loss: 1.648998498916626, train acuracy: 0.390625
step: 281, val loss: 1.732999324798584, val acuracy: 0.3851667046546936
step: 282, train loss: 1.6962639093399048, train acuracy: 0.38671875
step: 282, val loss: 1.7325595617294312, val acuracy: 0.38466668128967285
step: 283, train loss: 1.7536485195159912, train acuracy: 0.3984375
step: 283, val loss: 1.7320009469985962, val acuracy: 0.3838333487510681
step: 284, train loss: 1.7164874076843262, train acuracy: 0.40234375
step: 284, val loss: 1.749760627746582, val acuracy: 0.3800000250339508
step: 285, train loss: 1.5555391311645508, train acuracy: 0.4375
step: 285, val loss: 1.7426307201385498, val acuracy: 0.3836666941642761
step: 286, train loss: 1.7904796600341797, train acuracy: 0.39453125
step: 286, val loss: 1.722724199295044, val acuracy: 0.41866669058799744
step: 287, train loss: 1.672236442565918, train acuracy: 0.48828125
step: 287, val loss: 1.7446540594100952, val acuracy: 0.4463333785533905
step: 288, train loss: 1.768487811088562, train acuracy: 0.4453125
step: 288, val loss: 1.6986339092254639, val acuracy: 0.453166663646698
step: 289, train loss: 1.5562481880187988, train acuracy: 0.46484375
step: 289, val loss: 1.7188923358917236, val acuracy: 0.4336666762828827
step: 290, train loss: 1.7401739358901978, train acuracy: 0.43359375
step: 290, val loss: 1.754407286643982, val acuracy: 0.398666650056839
step: 291, train loss: 1.862462043762207, train acuracy: 0.328125
step: 291, val loss: 1.7776763439178467, val acuracy: 0.3915000259876251
step: 292, train loss: 1.7821812629699707, train acuracy: 0.39453125
step: 292, val loss: 1.7219308614730835, val acuracy: 0.40966668725013733
step: 293, train loss: 1.6213746070861816, train acuracy: 0.375
step: 293, val loss: 1.7370867729187012, val acuracy: 0.37133336067199707
step: 294, train loss: 1.5797597169876099, train acuracy: 0.45703125
step: 294, val loss: 1.6992651224136353, val acuracy: 0.4326666593551636
step: 295, train loss: 1.6725893020629883, train acuracy: 0.4453125
step: 295, val loss: 1.6867005825042725, val acuracy: 0.43816670775413513
step: 296, train loss: 1.7293517589569092, train acuracy: 0.453125
step: 296, val loss: 1.6802575588226318, val acuracy: 0.4388333559036255
step: 297, train loss: 1.7633920907974243, train acuracy: 0.38671875
step: 297, val loss: 1.7861238718032837, val acuracy: 0.35066670179367065
step: 298, train loss: 1.440950870513916, train acuracy: 0.484375
step: 298, val loss: 1.4079201221466064, val acuracy: 0.5021666884422302
step: 299, train loss: 1.282504677772522, train acuracy: 0.58984375
step: 299, val loss: 1.2829298973083496, val acuracy: 0.5613333582878113
step: 300, train loss: 1.142472267150879, train acuracy: 0.65234375
step: 300, val loss: 1.2245028018951416, val acuracy: 0.6216667294502258
step: 301, train loss: 1.0567166805267334, train acuracy: 0.62890625
step: 301, val loss: 1.1407084465026855, val acuracy: 0.6288333535194397
step: 302, train loss: 1.1771944761276245, train acuracy: 0.60546875
step: 302, val loss: 1.1172254085540771, val acuracy: 0.6271666884422302
step: 303, train loss: 1.1578773260116577, train acuracy: 0.57421875
step: 303, val loss: 1.0930671691894531, val acuracy: 0.6505000591278076
step: 304, train loss: 1.0847673416137695, train acuracy: 0.6171875
step: 304, val loss: 1.099782943725586, val acuracy: 0.6355000734329224
step: 305, train loss: 1.073987603187561, train acuracy: 0.6640625
step: 305, val loss: 1.073984146118164, val acuracy: 0.6546666622161865
step: 306, train loss: 1.116058349609375, train acuracy: 0.6484375
step: 306, val loss: 1.091227412223816, val acuracy: 0.6366667151451111
step: 307, train loss: 1.114652156829834, train acuracy: 0.625
step: 307, val loss: 1.0623528957366943, val acuracy: 0.6576666831970215
step: 308, train loss: 1.139124870300293, train acuracy: 0.64453125
step: 308, val loss: 1.0701417922973633, val acuracy: 0.6856666803359985
step: 309, train loss: 0.9534221887588501, train acuracy: 0.6875
step: 309, val loss: 1.0664677619934082, val acuracy: 0.6871667504310608
step: 310, train loss: 1.0644080638885498, train acuracy: 0.6796875
step: 310, val loss: 1.066023588180542, val acuracy: 0.6938334107398987
step: 311, train loss: 1.0431345701217651, train acuracy: 0.65234375
step: 311, val loss: 1.079028606414795, val acuracy: 0.6806666851043701
step: 312, train loss: 1.0593554973602295, train acuracy: 0.69140625
step: 312, val loss: 1.0757625102996826, val acuracy: 0.6828334331512451
step: 313, train loss: 1.0148268938064575, train acuracy: 0.66796875
step: 313, val loss: 1.073317527770996, val acuracy: 0.6826667189598083
step: 314, train loss: 1.016894817352295, train acuracy: 0.6953125
step: 314, val loss: 1.0729985237121582, val acuracy: 0.6826666593551636
step: 315, train loss: 1.1660008430480957, train acuracy: 0.65625
step: 315, val loss: 1.0727537870407104, val acuracy: 0.6841667294502258
step: 316, train loss: 1.0754274129867554, train acuracy: 0.67578125
step: 316, val loss: 1.0722200870513916, val acuracy: 0.6850000023841858
step: 317, train loss: 1.0868337154388428, train acuracy: 0.6484375
step: 317, val loss: 1.072182536125183, val acuracy: 0.6851667165756226
step: 318, train loss: 1.1071124076843262, train acuracy: 0.6953125
step: 318, val loss: 1.0717923641204834, val acuracy: 0.6853333711624146
step: 319, train loss: 0.991181492805481, train acuracy: 0.7421875
step: 319, val loss: 1.0717566013336182, val acuracy: 0.6851667761802673
step: 320, train loss: 0.9838592410087585, train acuracy: 0.71875
step: 320, val loss: 1.0719897747039795, val acuracy: 0.6846666932106018
step: 321, train loss: 1.0348891019821167, train acuracy: 0.6953125
step: 321, val loss: 1.0722155570983887, val acuracy: 0.6841667294502258
step: 322, train loss: 1.1161659955978394, train acuracy: 0.671875
step: 322, val loss: 1.0719304084777832, val acuracy: 0.6831667423248291
step: 323, train loss: 1.0634418725967407, train acuracy: 0.70703125
step: 323, val loss: 1.0715787410736084, val acuracy: 0.684499979019165
step: 324, train loss: 1.023835301399231, train acuracy: 0.72265625
step: 324, val loss: 1.0715398788452148, val acuracy: 0.684166669845581
step: 325, train loss: 1.0412367582321167, train acuracy: 0.66796875
step: 325, val loss: 1.0773135423660278, val acuracy: 0.674333393573761
step: 326, train loss: 1.0572044849395752, train acuracy: 0.6796875
step: 326, val loss: 1.0905351638793945, val acuracy: 0.6688333749771118
step: 327, train loss: 1.0165834426879883, train acuracy: 0.7109375
step: 327, val loss: 1.0894778966903687, val acuracy: 0.6686667799949646
step: 328, train loss: 1.1835676431655884, train acuracy: 0.62890625
step: 328, val loss: 1.089160442352295, val acuracy: 0.6688333749771118
step: 329, train loss: 1.1678696870803833, train acuracy: 0.6640625
step: 329, val loss: 1.1154536008834839, val acuracy: 0.6628334522247314
step: 330, train loss: 1.0895345211029053, train acuracy: 0.703125
step: 330, val loss: 1.1135443449020386, val acuracy: 0.6633334159851074
step: 331, train loss: 1.105001449584961, train acuracy: 0.65234375
step: 331, val loss: 1.1370794773101807, val acuracy: 0.659166693687439
step: 332, train loss: 1.041640043258667, train acuracy: 0.67578125
step: 332, val loss: 1.112797737121582, val acuracy: 0.6801667213439941
step: 333, train loss: 1.1741560697555542, train acuracy: 0.65625
step: 333, val loss: 1.149125576019287, val acuracy: 0.6533334255218506
step: 334, train loss: 1.1827062368392944, train acuracy: 0.63671875
step: 334, val loss: 1.1396373510360718, val acuracy: 0.6695000529289246
step: 335, train loss: 1.1784579753875732, train acuracy: 0.6953125
step: 335, val loss: 1.1350042819976807, val acuracy: 0.6723333597183228
step: 336, train loss: 1.085891842842102, train acuracy: 0.6640625
step: 336, val loss: 1.133631706237793, val acuracy: 0.6739999651908875
step: 337, train loss: 1.00899076461792, train acuracy: 0.6953125
step: 337, val loss: 1.175229549407959, val acuracy: 0.6653333902359009
step: 338, train loss: 1.1800286769866943, train acuracy: 0.6171875
step: 338, val loss: 1.1715495586395264, val acuracy: 0.6625000238418579
step: 339, train loss: 1.3055553436279297, train acuracy: 0.6015625
step: 339, val loss: 1.1657774448394775, val acuracy: 0.6655000448226929
step: 340, train loss: 1.1192301511764526, train acuracy: 0.6796875
step: 340, val loss: 1.1748757362365723, val acuracy: 0.6513333916664124
step: 341, train loss: 1.1907126903533936, train acuracy: 0.6171875
step: 341, val loss: 1.1758222579956055, val acuracy: 0.6570000648498535
step: 342, train loss: 1.2502073049545288, train acuracy: 0.625
step: 342, val loss: 1.2135093212127686, val acuracy: 0.6311666965484619
step: 343, train loss: 1.0406568050384521, train acuracy: 0.7109375
step: 343, val loss: 1.1720362901687622, val acuracy: 0.6533333659172058
step: 344, train loss: 1.1312496662139893, train acuracy: 0.6640625
step: 344, val loss: 1.170112133026123, val acuracy: 0.658333420753479
step: 345, train loss: 1.1169750690460205, train acuracy: 0.64453125
step: 345, val loss: 1.2112420797348022, val acuracy: 0.6301667094230652
step: 346, train loss: 1.08152174949646, train acuracy: 0.69140625
step: 346, val loss: 1.2134517431259155, val acuracy: 0.6375000476837158
step: 347, train loss: 1.2539597749710083, train acuracy: 0.640625
step: 347, val loss: 1.2012122869491577, val acuracy: 0.6615000367164612
step: 348, train loss: 1.2198436260223389, train acuracy: 0.5859375
step: 348, val loss: 1.2383697032928467, val acuracy: 0.6158334016799927
step: 349, train loss: 1.1486964225769043, train acuracy: 0.6015625
step: 349, val loss: 1.2298954725265503, val acuracy: 0.6181667447090149
step: 350, train loss: 1.1999843120574951, train acuracy: 0.6328125
step: 350, val loss: 1.2309778928756714, val acuracy: 0.6316666603088379
step: 351, train loss: 1.3279852867126465, train acuracy: 0.5625
step: 351, val loss: 1.2572805881500244, val acuracy: 0.6134999990463257
step: 352, train loss: 1.2269295454025269, train acuracy: 0.6171875
step: 352, val loss: 1.1849935054779053, val acuracy: 0.6483333706855774
step: 353, train loss: 1.2161400318145752, train acuracy: 0.6328125
step: 353, val loss: 1.236634612083435, val acuracy: 0.6578333377838135
step: 354, train loss: 1.5364222526550293, train acuracy: 0.44921875
step: 354, val loss: 1.5635020732879639, val acuracy: 0.4206666946411133
step: 355, train loss: 1.470381736755371, train acuracy: 0.50390625
step: 355, val loss: 1.4131242036819458, val acuracy: 0.5418333411216736
step: 356, train loss: 1.4015071392059326, train acuracy: 0.5625
step: 356, val loss: 1.399153470993042, val acuracy: 0.5506666898727417
step: 357, train loss: 1.4584476947784424, train acuracy: 0.50390625
step: 357, val loss: 1.3896666765213013, val acuracy: 0.5531667470932007
step: 358, train loss: 1.275297999382019, train acuracy: 0.5625
step: 358, val loss: 1.3909761905670166, val acuracy: 0.5391666889190674
step: 359, train loss: 1.3929805755615234, train acuracy: 0.5546875
step: 359, val loss: 1.379926323890686, val acuracy: 0.5511666536331177
step: 360, train loss: 1.429585576057434, train acuracy: 0.546875
step: 360, val loss: 1.3867883682250977, val acuracy: 0.5401667356491089
step: 361, train loss: 1.2713514566421509, train acuracy: 0.609375
step: 361, val loss: 1.380771517753601, val acuracy: 0.5483333468437195
step: 362, train loss: 1.3192064762115479, train acuracy: 0.60546875
step: 362, val loss: 1.409995198249817, val acuracy: 0.5393334031105042
step: 363, train loss: 1.4277617931365967, train acuracy: 0.51953125
step: 363, val loss: 1.3976608514785767, val acuracy: 0.5386667251586914
step: 364, train loss: 1.2887989282608032, train acuracy: 0.57421875
step: 364, val loss: 1.3783891201019287, val acuracy: 0.5508334040641785
step: 365, train loss: 1.486183524131775, train acuracy: 0.515625
step: 365, val loss: 1.4382399320602417, val acuracy: 0.5371667146682739
step: 366, train loss: 1.3229305744171143, train acuracy: 0.5625
step: 366, val loss: 1.3775336742401123, val acuracy: 0.5491666793823242
step: 367, train loss: 1.2788879871368408, train acuracy: 0.55859375
step: 367, val loss: 1.378993034362793, val acuracy: 0.5541666746139526
step: 368, train loss: 1.3792773485183716, train acuracy: 0.5625
step: 368, val loss: 1.3989126682281494, val acuracy: 0.5485000610351562
step: 369, train loss: 1.343091368675232, train acuracy: 0.57421875
step: 369, val loss: 1.3946399688720703, val acuracy: 0.5381667017936707
step: 370, train loss: 1.5558936595916748, train acuracy: 0.5
step: 370, val loss: 1.4483225345611572, val acuracy: 0.5408333539962769
step: 371, train loss: 1.434065341949463, train acuracy: 0.53515625
step: 371, val loss: 1.3956027030944824, val acuracy: 0.5425000786781311
step: 372, train loss: 1.4010493755340576, train acuracy: 0.5390625
step: 372, val loss: 1.4256404638290405, val acuracy: 0.5358333587646484
step: 373, train loss: 1.476679801940918, train acuracy: 0.50390625
step: 373, val loss: 1.4534775018692017, val acuracy: 0.5298333764076233
step: 374, train loss: 1.5036826133728027, train acuracy: 0.484375
step: 374, val loss: 1.445255994796753, val acuracy: 0.533333420753479
step: 375, train loss: 1.372151255607605, train acuracy: 0.5546875
step: 375, val loss: 1.4539800882339478, val acuracy: 0.5263333320617676
step: 376, train loss: 1.4874440431594849, train acuracy: 0.51953125
step: 376, val loss: 1.4499419927597046, val acuracy: 0.5276666879653931
step: 377, train loss: 1.5254337787628174, train acuracy: 0.5234375
step: 377, val loss: 1.4956436157226562, val acuracy: 0.5250000357627869
step: 378, train loss: 1.4541372060775757, train acuracy: 0.53125
step: 378, val loss: 1.4590370655059814, val acuracy: 0.5241667032241821
step: 379, train loss: 1.318055510520935, train acuracy: 0.60546875
step: 379, val loss: 1.4576042890548706, val acuracy: 0.5245000123977661
step: 380, train loss: 1.5079131126403809, train acuracy: 0.48828125
step: 380, val loss: 1.4611722230911255, val acuracy: 0.5245000123977661
step: 381, train loss: 1.5800563097000122, train acuracy: 0.46484375
step: 381, val loss: 1.4582010507583618, val acuracy: 0.5233334302902222
step: 382, train loss: 1.401087760925293, train acuracy: 0.53515625
step: 382, val loss: 1.4763468503952026, val acuracy: 0.5146666765213013
step: 383, train loss: 1.43716299533844, train acuracy: 0.50390625
step: 383, val loss: 1.4677259922027588, val acuracy: 0.5301666855812073
step: 384, train loss: 1.392105221748352, train acuracy: 0.57421875
step: 384, val loss: 1.453540563583374, val acuracy: 0.530666708946228
step: 385, train loss: 1.5340267419815063, train acuracy: 0.47265625
step: 385, val loss: 1.5398985147476196, val acuracy: 0.47983333468437195
step: 386, train loss: 1.5211384296417236, train acuracy: 0.49609375
step: 386, val loss: 1.5026371479034424, val acuracy: 0.49766668677330017
step: 387, train loss: 1.5576481819152832, train acuracy: 0.4609375
step: 387, val loss: 1.5199893712997437, val acuracy: 0.5076667070388794
step: 388, train loss: 1.5142778158187866, train acuracy: 0.4921875
step: 388, val loss: 1.5180269479751587, val acuracy: 0.5078333616256714
step: 389, train loss: 1.60294771194458, train acuracy: 0.515625
step: 389, val loss: 1.5181326866149902, val acuracy: 0.5083333253860474
step: 390, train loss: 1.462341547012329, train acuracy: 0.5546875
step: 390, val loss: 1.532447338104248, val acuracy: 0.503000020980835
step: 391, train loss: 1.6167351007461548, train acuracy: 0.46875
step: 391, val loss: 1.5312855243682861, val acuracy: 0.5036666989326477
step: 392, train loss: 1.4993677139282227, train acuracy: 0.48828125
step: 392, val loss: 1.5305728912353516, val acuracy: 0.5041666626930237
step: 393, train loss: 1.5666303634643555, train acuracy: 0.4921875
step: 393, val loss: 1.5299766063690186, val acuracy: 0.5045000314712524
step: 394, train loss: 1.5161566734313965, train acuracy: 0.53125
step: 394, val loss: 1.5292283296585083, val acuracy: 0.5033333897590637
step: 395, train loss: 1.580122470855713, train acuracy: 0.48828125
step: 395, val loss: 1.5286054611206055, val acuracy: 0.502833366394043
step: 396, train loss: 1.5598268508911133, train acuracy: 0.4921875
step: 396, val loss: 1.532787561416626, val acuracy: 0.4948333203792572
step: 397, train loss: 1.5282224416732788, train acuracy: 0.48828125
step: 397, val loss: 1.5315765142440796, val acuracy: 0.4958333671092987
step: 398, train loss: 1.5389678478240967, train acuracy: 0.48828125
step: 398, val loss: 1.531286358833313, val acuracy: 0.49549999833106995
step: 399, train loss: 1.488265872001648, train acuracy: 0.5
step: 399, val loss: 1.5303173065185547, val acuracy: 0.4961666464805603
2017-12-04 15:50:26.671860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:50:26.938428: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x9bc1e40 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 15:50:26.939214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:50:26.939474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 15:50:26.939489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 15:50:26.939496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 15:50:26.939508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 15:50:26.939516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.3649566173553467, train acuracy: 0.11328125
step: 0, val loss: 2.4663875102996826, val acuracy: 0.10400000214576721
step: 1, train loss: 2.273967981338501, train acuracy: 0.205078125
step: 1, val loss: 2.296544075012207, val acuracy: 0.19199998676776886
step: 2, train loss: 2.264814615249634, train acuracy: 0.134765625
step: 2, val loss: 2.2958664894104004, val acuracy: 0.09666666388511658
step: 3, train loss: 2.282139778137207, train acuracy: 0.130859375
step: 3, val loss: 2.293022394180298, val acuracy: 0.1054999977350235
step: 4, train loss: 2.2677338123321533, train acuracy: 0.1328125
step: 4, val loss: 2.2803823947906494, val acuracy: 0.11699998378753662
step: 5, train loss: 2.276637077331543, train acuracy: 0.1171875
step: 5, val loss: 2.286874771118164, val acuracy: 0.11933331936597824
step: 6, train loss: 2.2464795112609863, train acuracy: 0.23828125
step: 6, val loss: 2.2650578022003174, val acuracy: 0.20016667246818542
step: 7, train loss: 2.259927988052368, train acuracy: 0.095703125
step: 7, val loss: 2.2732677459716797, val acuracy: 0.10066666454076767
step: 8, train loss: 2.1317458152770996, train acuracy: 0.306640625
step: 8, val loss: 2.1368119716644287, val acuracy: 0.2970000207424164
step: 9, train loss: 2.1170310974121094, train acuracy: 0.1640625
step: 9, val loss: 2.130821704864502, val acuracy: 0.1339999884366989
step: 10, train loss: 1.8458625078201294, train acuracy: 0.5234375
step: 10, val loss: 1.8640406131744385, val acuracy: 0.4935000538825989
step: 11, train loss: 1.769340991973877, train acuracy: 0.60546875
step: 11, val loss: 1.777744174003601, val acuracy: 0.6048333644866943
step: 12, train loss: 7.6445770263671875, train acuracy: 0.224609375
step: 12, val loss: 7.758695602416992, val acuracy: 0.19466666877269745
step: 13, train loss: 4.580338954925537, train acuracy: 0.228515625
step: 13, val loss: 4.507076263427734, val acuracy: 0.2276666760444641
step: 14, train loss: 4.654518127441406, train acuracy: 0.392578125
step: 14, val loss: 4.682326316833496, val acuracy: 0.39116668701171875
step: 15, train loss: 4.036104679107666, train acuracy: 0.373046875
step: 15, val loss: 4.175899028778076, val acuracy: 0.35616669058799744
step: 16, train loss: 2.2174720764160156, train acuracy: 0.2734375
step: 16, val loss: 2.0540454387664795, val acuracy: 0.3031666874885559
step: 17, train loss: 1.541993260383606, train acuracy: 0.515625
step: 17, val loss: 1.5472662448883057, val acuracy: 0.4935000538825989
step: 18, train loss: 1.1514015197753906, train acuracy: 0.63671875
step: 18, val loss: 1.1721752882003784, val acuracy: 0.6058333516120911
step: 19, train loss: 0.9234578609466553, train acuracy: 0.701171875
step: 19, val loss: 0.9268310070037842, val acuracy: 0.7208333611488342
step: 20, train loss: 0.8431105613708496, train acuracy: 0.736328125
step: 20, val loss: 0.8907146453857422, val acuracy: 0.7280001044273376
step: 21, train loss: 0.8811630606651306, train acuracy: 0.736328125
step: 21, val loss: 0.8735418319702148, val acuracy: 0.7358334064483643
step: 22, train loss: 0.9493306279182434, train acuracy: 0.697265625
step: 22, val loss: 0.8718886375427246, val acuracy: 0.7361667156219482
step: 23, train loss: 0.8713198304176331, train acuracy: 0.708984375
step: 23, val loss: 0.8633338212966919, val acuracy: 0.7380000352859497
step: 24, train loss: 0.7453562021255493, train acuracy: 0.7890625
step: 24, val loss: 0.8606098890304565, val acuracy: 0.7378333806991577
step: 25, train loss: 0.9450687170028687, train acuracy: 0.74609375
step: 25, val loss: 0.8597860336303711, val acuracy: 0.7376667261123657
step: 26, train loss: 0.9439340829849243, train acuracy: 0.6953125
step: 26, val loss: 0.8675220608711243, val acuracy: 0.7390000820159912
step: 27, train loss: 0.8915522694587708, train acuracy: 0.74609375
step: 27, val loss: 0.8753173351287842, val acuracy: 0.7330000996589661
step: 28, train loss: 0.8219993114471436, train acuracy: 0.73828125
step: 28, val loss: 0.8722331523895264, val acuracy: 0.7350000739097595
step: 29, train loss: 0.8823676109313965, train acuracy: 0.748046875
step: 29, val loss: 0.872018575668335, val acuracy: 0.7348334193229675
step: 30, train loss: 0.9125385284423828, train acuracy: 0.724609375
step: 30, val loss: 0.8723071813583374, val acuracy: 0.7350000739097595
step: 31, train loss: 0.8861660957336426, train acuracy: 0.7109375
step: 31, val loss: 0.8716576099395752, val acuracy: 0.7355000376701355
step: 32, train loss: 0.8494028449058533, train acuracy: 0.740234375
step: 32, val loss: 0.8711274862289429, val acuracy: 0.7355000972747803
step: 33, train loss: 0.8832789659500122, train acuracy: 0.71875
step: 33, val loss: 0.8707472681999207, val acuracy: 0.7355000376701355
step: 34, train loss: 0.8133724927902222, train acuracy: 0.75390625
step: 34, val loss: 0.8703780174255371, val acuracy: 0.7360000610351562
step: 35, train loss: 0.9696758985519409, train acuracy: 0.734375
step: 35, val loss: 0.8698559999465942, val acuracy: 0.736166775226593
step: 36, train loss: 0.8151606321334839, train acuracy: 0.7421875
step: 36, val loss: 0.8696625232696533, val acuracy: 0.737000048160553
step: 37, train loss: 0.8636313676834106, train acuracy: 0.728515625
step: 37, val loss: 0.8850831389427185, val acuracy: 0.7288333773612976
step: 38, train loss: 0.8923404812812805, train acuracy: 0.728515625
step: 38, val loss: 0.8881582021713257, val acuracy: 0.7261667251586914
step: 39, train loss: 0.8323339223861694, train acuracy: 0.75390625
step: 39, val loss: 0.8711096048355103, val acuracy: 0.736333429813385
step: 40, train loss: 0.9357220530509949, train acuracy: 0.72265625
step: 40, val loss: 0.8809159994125366, val acuracy: 0.736500084400177
step: 41, train loss: 0.8503402471542358, train acuracy: 0.73046875
step: 41, val loss: 0.865481972694397, val acuracy: 0.7476667165756226
step: 42, train loss: 1.1911675930023193, train acuracy: 0.619140625
step: 42, val loss: 1.2307584285736084, val acuracy: 0.6070001125335693
step: 43, train loss: 0.9914540648460388, train acuracy: 0.689453125
step: 43, val loss: 1.022315502166748, val acuracy: 0.6668334007263184
step: 44, train loss: 1.0013490915298462, train acuracy: 0.669921875
step: 44, val loss: 1.0154250860214233, val acuracy: 0.689666748046875
step: 45, train loss: 1.0070284605026245, train acuracy: 0.697265625
step: 45, val loss: 1.0116430521011353, val acuracy: 0.693000078201294
step: 46, train loss: 1.0292038917541504, train acuracy: 0.69140625
step: 46, val loss: 1.0111846923828125, val acuracy: 0.6921666860580444
step: 47, train loss: 1.0223811864852905, train acuracy: 0.703125
step: 47, val loss: 1.0133686065673828, val acuracy: 0.7018333673477173
step: 48, train loss: 1.0215606689453125, train acuracy: 0.693359375
step: 48, val loss: 1.0123401880264282, val acuracy: 0.6998333930969238
step: 49, train loss: 1.0053259134292603, train acuracy: 0.671875
step: 49, val loss: 1.0113680362701416, val acuracy: 0.6765000224113464
step: 50, train loss: 0.9966967105865479, train acuracy: 0.705078125
step: 50, val loss: 1.0108851194381714, val acuracy: 0.6773333549499512
step: 51, train loss: 1.0438342094421387, train acuracy: 0.650390625
step: 51, val loss: 1.011974573135376, val acuracy: 0.6910001039505005
step: 52, train loss: 1.0407688617706299, train acuracy: 0.64453125
step: 52, val loss: 1.0189313888549805, val acuracy: 0.6668334007263184
step: 53, train loss: 0.9595089554786682, train acuracy: 0.705078125
step: 53, val loss: 1.0176019668579102, val acuracy: 0.6676666736602783
step: 54, train loss: 1.0402421951293945, train acuracy: 0.677734375
step: 54, val loss: 1.019808053970337, val acuracy: 0.7018333673477173
step: 55, train loss: 0.9644278287887573, train acuracy: 0.66015625
step: 55, val loss: 1.0256953239440918, val acuracy: 0.6516667008399963
step: 56, train loss: 1.0632834434509277, train acuracy: 0.70703125
step: 56, val loss: 1.0237555503845215, val acuracy: 0.6990000009536743
step: 57, train loss: 1.017573595046997, train acuracy: 0.671875
step: 57, val loss: 1.014751672744751, val acuracy: 0.6764999628067017
step: 58, train loss: 1.043955683708191, train acuracy: 0.689453125
step: 58, val loss: 1.0258417129516602, val acuracy: 0.6911667585372925
step: 59, train loss: 1.1581614017486572, train acuracy: 0.634765625
step: 59, val loss: 1.0247422456741333, val acuracy: 0.6918333768844604
step: 60, train loss: 0.9749335646629333, train acuracy: 0.7109375
step: 60, val loss: 1.023486852645874, val acuracy: 0.6923333406448364
step: 61, train loss: 0.9928668141365051, train acuracy: 0.732421875
step: 61, val loss: 1.023796796798706, val acuracy: 0.6919999718666077
step: 62, train loss: 1.0072041749954224, train acuracy: 0.677734375
step: 62, val loss: 1.0351637601852417, val acuracy: 0.6800000667572021
step: 63, train loss: 1.0569055080413818, train acuracy: 0.712890625
step: 63, val loss: 1.0467811822891235, val acuracy: 0.6860000491142273
step: 64, train loss: 1.0645391941070557, train acuracy: 0.69140625
step: 64, val loss: 1.0344737768173218, val acuracy: 0.6830000877380371
step: 65, train loss: 1.0084965229034424, train acuracy: 0.693359375
step: 65, val loss: 1.027815818786621, val acuracy: 0.6941666603088379
step: 66, train loss: 1.0233229398727417, train acuracy: 0.662109375
step: 66, val loss: 1.0368928909301758, val acuracy: 0.673666775226593
step: 67, train loss: 1.0399765968322754, train acuracy: 0.6875
step: 67, val loss: 1.0525026321411133, val acuracy: 0.6931666731834412
step: 68, train loss: 1.0632152557373047, train acuracy: 0.650390625
step: 68, val loss: 1.0662459135055542, val acuracy: 0.6576666831970215
step: 69, train loss: 0.9985019564628601, train acuracy: 0.68359375
step: 69, val loss: 1.0599701404571533, val acuracy: 0.6760000586509705
step: 70, train loss: 1.1663392782211304, train acuracy: 0.6328125
step: 70, val loss: 1.0831239223480225, val acuracy: 0.6486666798591614
step: 71, train loss: 1.1172667741775513, train acuracy: 0.623046875
step: 71, val loss: 1.078131079673767, val acuracy: 0.6510000824928284
step: 72, train loss: 1.0629680156707764, train acuracy: 0.666015625
step: 72, val loss: 1.085471510887146, val acuracy: 0.6793334484100342
step: 73, train loss: 1.0775521993637085, train acuracy: 0.65234375
step: 73, val loss: 1.0753395557403564, val acuracy: 0.6538333892822266
step: 74, train loss: 1.0495948791503906, train acuracy: 0.6875
step: 74, val loss: 1.0912096500396729, val acuracy: 0.6701667308807373
step: 75, train loss: 1.0916845798492432, train acuracy: 0.662109375
step: 75, val loss: 1.0896124839782715, val acuracy: 0.6696667075157166
step: 76, train loss: 1.0530738830566406, train acuracy: 0.67578125
step: 76, val loss: 1.0908485651016235, val acuracy: 0.6573333740234375
step: 77, train loss: 1.0553756952285767, train acuracy: 0.681640625
step: 77, val loss: 1.0896767377853394, val acuracy: 0.6640000939369202
step: 78, train loss: 1.0707403421401978, train acuracy: 0.67578125
step: 78, val loss: 1.0937013626098633, val acuracy: 0.6835000514984131
step: 79, train loss: 1.1075551509857178, train acuracy: 0.650390625
step: 79, val loss: 1.087437629699707, val acuracy: 0.655666708946228
step: 80, train loss: 1.1318821907043457, train acuracy: 0.671875
step: 80, val loss: 1.10280179977417, val acuracy: 0.6736667156219482
step: 81, train loss: 1.1172099113464355, train acuracy: 0.65234375
step: 81, val loss: 1.1007572412490845, val acuracy: 0.673833429813385
step: 82, train loss: 1.0757838487625122, train acuracy: 0.7109375
step: 82, val loss: 1.0927422046661377, val acuracy: 0.687333345413208
step: 83, train loss: 1.1369575262069702, train acuracy: 0.6484375
step: 83, val loss: 1.117808222770691, val acuracy: 0.655666708946228
step: 84, train loss: 1.0854086875915527, train acuracy: 0.671875
step: 84, val loss: 1.0931216478347778, val acuracy: 0.6823334097862244
step: 85, train loss: 2.1208860874176025, train acuracy: 0.341796875
step: 85, val loss: 2.1954076290130615, val acuracy: 0.34550005197525024
step: 86, train loss: 1.977577805519104, train acuracy: 0.357421875
step: 86, val loss: 2.06638240814209, val acuracy: 0.36283332109451294
step: 87, train loss: 2.0913515090942383, train acuracy: 0.353515625
step: 87, val loss: 2.0762743949890137, val acuracy: 0.3630000352859497
step: 88, train loss: 1.9627231359481812, train acuracy: 0.48046875
step: 88, val loss: 1.9910011291503906, val acuracy: 0.43016666173934937
step: 89, train loss: 1.6772311925888062, train acuracy: 0.54296875
step: 89, val loss: 1.801127314567566, val acuracy: 0.5163333415985107
step: 90, train loss: 1.5264365673065186, train acuracy: 0.55078125
step: 90, val loss: 1.4447077512741089, val acuracy: 0.5663333535194397
step: 91, train loss: 1.5273127555847168, train acuracy: 0.541015625
step: 91, val loss: 1.4085004329681396, val acuracy: 0.5581667423248291
step: 92, train loss: 1.169134497642517, train acuracy: 0.67578125
step: 92, val loss: 1.1277594566345215, val acuracy: 0.6940001249313354
step: 93, train loss: 0.9915111064910889, train acuracy: 0.734375
step: 93, val loss: 1.0812960863113403, val acuracy: 0.7120000720024109
step: 94, train loss: 1.0113309621810913, train acuracy: 0.728515625
step: 94, val loss: 1.0812987089157104, val acuracy: 0.7138333916664124
step: 95, train loss: 1.0600361824035645, train acuracy: 0.724609375
step: 95, val loss: 1.0737782716751099, val acuracy: 0.705333411693573
step: 96, train loss: 1.0201489925384521, train acuracy: 0.70703125
step: 96, val loss: 1.0573205947875977, val acuracy: 0.6866666674613953
step: 97, train loss: 1.0060445070266724, train acuracy: 0.69140625
step: 97, val loss: 1.0477535724639893, val acuracy: 0.6910001039505005
step: 98, train loss: 0.974629282951355, train acuracy: 0.71875
step: 98, val loss: 1.0491276979446411, val acuracy: 0.6936667561531067
step: 99, train loss: 1.0084463357925415, train acuracy: 0.6953125
step: 99, val loss: 1.0468497276306152, val acuracy: 0.6936666965484619
step: 100, train loss: 0.9972190260887146, train acuracy: 0.72265625
step: 100, val loss: 1.0458463430404663, val acuracy: 0.692500114440918
step: 101, train loss: 1.0461115837097168, train acuracy: 0.685546875
step: 101, val loss: 1.0666911602020264, val acuracy: 0.6690000295639038
step: 102, train loss: 1.124866008758545, train acuracy: 0.642578125
step: 102, val loss: 1.0961933135986328, val acuracy: 0.6725000739097595
step: 103, train loss: 1.0211280584335327, train acuracy: 0.681640625
step: 103, val loss: 1.0903911590576172, val acuracy: 0.673333466053009
step: 104, train loss: 1.1333357095718384, train acuracy: 0.677734375
step: 104, val loss: 1.0877848863601685, val acuracy: 0.674833357334137
step: 105, train loss: 1.086431622505188, train acuracy: 0.69140625
step: 105, val loss: 1.0860973596572876, val acuracy: 0.6738333106040955
step: 106, train loss: 1.0322784185409546, train acuracy: 0.685546875
step: 106, val loss: 1.0842547416687012, val acuracy: 0.673666775226593
step: 107, train loss: 1.072178840637207, train acuracy: 0.697265625
step: 107, val loss: 1.0778651237487793, val acuracy: 0.6635000109672546
step: 108, train loss: 1.0224268436431885, train acuracy: 0.685546875
step: 108, val loss: 1.0719765424728394, val acuracy: 0.6698333621025085
step: 109, train loss: 1.0436688661575317, train acuracy: 0.671875
step: 109, val loss: 1.072974681854248, val acuracy: 0.6661666631698608
step: 110, train loss: 0.9595657587051392, train acuracy: 0.708984375
step: 110, val loss: 1.0722602605819702, val acuracy: 0.6661667227745056
step: 111, train loss: 1.1016209125518799, train acuracy: 0.6640625
step: 111, val loss: 1.0715408325195312, val acuracy: 0.6668334007263184
step: 112, train loss: 1.0800944566726685, train acuracy: 0.6796875
step: 112, val loss: 1.0584032535552979, val acuracy: 0.6781667470932007
step: 113, train loss: 1.0702869892120361, train acuracy: 0.697265625
step: 113, val loss: 1.0537371635437012, val acuracy: 0.7011666893959045
step: 114, train loss: 1.1086456775665283, train acuracy: 0.67578125
step: 114, val loss: 1.0472140312194824, val acuracy: 0.7036666870117188
step: 115, train loss: 1.04048752784729, train acuracy: 0.69140625
step: 115, val loss: 1.0398776531219482, val acuracy: 0.7070000767707825
step: 116, train loss: 1.0081067085266113, train acuracy: 0.74609375
step: 116, val loss: 1.0415767431259155, val acuracy: 0.7130000591278076
step: 117, train loss: 1.0674285888671875, train acuracy: 0.72265625
step: 117, val loss: 1.1130865812301636, val acuracy: 0.7046667337417603
step: 118, train loss: 1.0502675771713257, train acuracy: 0.681640625
step: 118, val loss: 1.1048099994659424, val acuracy: 0.6848334074020386
step: 119, train loss: 1.07924222946167, train acuracy: 0.70703125
step: 119, val loss: 1.0516473054885864, val acuracy: 0.7140000462532043
step: 120, train loss: 1.082749366760254, train acuracy: 0.70703125
step: 120, val loss: 1.0618523359298706, val acuracy: 0.7245000004768372
step: 121, train loss: 1.0333317518234253, train acuracy: 0.71484375
step: 121, val loss: 1.0065430402755737, val acuracy: 0.7113333940505981
step: 122, train loss: 0.9578585624694824, train acuracy: 0.6796875
step: 122, val loss: 1.0388978719711304, val acuracy: 0.6408333778381348
step: 123, train loss: 0.9797844290733337, train acuracy: 0.666015625
step: 123, val loss: 1.0167447328567505, val acuracy: 0.6530001163482666
step: 124, train loss: 1.044403076171875, train acuracy: 0.6796875
step: 124, val loss: 1.0559896230697632, val acuracy: 0.6571667194366455
step: 125, train loss: 1.1063551902770996, train acuracy: 0.642578125
step: 125, val loss: 1.1056231260299683, val acuracy: 0.6280000805854797
step: 126, train loss: 0.9646362066268921, train acuracy: 0.66796875
step: 126, val loss: 1.0412598848342896, val acuracy: 0.6501666903495789
step: 127, train loss: 1.0947800874710083, train acuracy: 0.626953125
step: 127, val loss: 1.0571873188018799, val acuracy: 0.6355000734329224
step: 128, train loss: 0.9748019576072693, train acuracy: 0.650390625
step: 128, val loss: 1.0561226606369019, val acuracy: 0.6348333954811096
step: 129, train loss: 0.9280891418457031, train acuracy: 0.673828125
step: 129, val loss: 1.086992859840393, val acuracy: 0.6208333373069763
step: 130, train loss: 1.0603179931640625, train acuracy: 0.662109375
step: 130, val loss: 1.1276297569274902, val acuracy: 0.6190000176429749
step: 131, train loss: 1.1767065525054932, train acuracy: 0.587890625
step: 131, val loss: 1.121450424194336, val acuracy: 0.6019999980926514
step: 132, train loss: 0.9719523191452026, train acuracy: 0.703125
step: 132, val loss: 1.0390899181365967, val acuracy: 0.6606667041778564
step: 133, train loss: 1.0193967819213867, train acuracy: 0.6796875
step: 133, val loss: 1.0467621088027954, val acuracy: 0.6606667041778564
step: 134, train loss: 1.1266967058181763, train acuracy: 0.619140625
step: 134, val loss: 1.0960919857025146, val acuracy: 0.6233333349227905
step: 135, train loss: 1.07240629196167, train acuracy: 0.640625
step: 135, val loss: 1.0856775045394897, val acuracy: 0.6315000057220459
step: 136, train loss: 1.1532938480377197, train acuracy: 0.578125
step: 136, val loss: 1.0772351026535034, val acuracy: 0.6380000710487366
step: 137, train loss: 1.1036211252212524, train acuracy: 0.599609375
step: 137, val loss: 1.0747262239456177, val acuracy: 0.6381666660308838
step: 138, train loss: 1.0789998769760132, train acuracy: 0.623046875
step: 138, val loss: 1.071466326713562, val acuracy: 0.6191667318344116
step: 139, train loss: 1.0039607286453247, train acuracy: 0.673828125
step: 139, val loss: 1.084087610244751, val acuracy: 0.6385000348091125
step: 140, train loss: 1.0708627700805664, train acuracy: 0.623046875
step: 140, val loss: 1.110896110534668, val acuracy: 0.6095000505447388
step: 141, train loss: 0.993118405342102, train acuracy: 0.681640625
step: 141, val loss: 1.114041805267334, val acuracy: 0.6266667246818542
step: 142, train loss: 1.052676796913147, train acuracy: 0.62890625
step: 142, val loss: 1.1207281351089478, val acuracy: 0.6136667132377625
step: 143, train loss: 1.0599361658096313, train acuracy: 0.64453125
step: 143, val loss: 1.078820824623108, val acuracy: 0.624000072479248
step: 144, train loss: 0.9742986559867859, train acuracy: 0.650390625
step: 144, val loss: 1.0761692523956299, val acuracy: 0.6231666803359985
step: 145, train loss: 1.0686231851577759, train acuracy: 0.6328125
step: 145, val loss: 1.1690142154693604, val acuracy: 0.6076667308807373
step: 146, train loss: 1.1865019798278809, train acuracy: 0.6015625
step: 146, val loss: 1.157950520515442, val acuracy: 0.6083333492279053
step: 147, train loss: 1.184202790260315, train acuracy: 0.59765625
step: 147, val loss: 1.178794503211975, val acuracy: 0.6061667203903198
step: 148, train loss: 1.064652442932129, train acuracy: 0.62890625
step: 148, val loss: 1.1553494930267334, val acuracy: 0.596500039100647
step: 149, train loss: 1.1928564310073853, train acuracy: 0.58984375
step: 149, val loss: 1.1523041725158691, val acuracy: 0.5983333587646484
step: 150, train loss: 1.1784982681274414, train acuracy: 0.578125
step: 150, val loss: 1.1548739671707153, val acuracy: 0.6073334217071533
step: 151, train loss: 1.2676916122436523, train acuracy: 0.591796875
step: 151, val loss: 1.153658151626587, val acuracy: 0.6065000295639038
step: 152, train loss: 1.1672502756118774, train acuracy: 0.599609375
step: 152, val loss: 1.1676963567733765, val acuracy: 0.6020000576972961
step: 153, train loss: 1.202019453048706, train acuracy: 0.58984375
step: 153, val loss: 1.1653159856796265, val acuracy: 0.6040000319480896
step: 154, train loss: 1.1173969507217407, train acuracy: 0.615234375
step: 154, val loss: 1.2014325857162476, val acuracy: 0.5706666707992554
step: 155, train loss: 1.1600630283355713, train acuracy: 0.611328125
step: 155, val loss: 1.1970576047897339, val acuracy: 0.6078333258628845
step: 156, train loss: 1.319159746170044, train acuracy: 0.54296875
step: 156, val loss: 1.2417821884155273, val acuracy: 0.5390000343322754
step: 157, train loss: 1.1908011436462402, train acuracy: 0.591796875
step: 157, val loss: 1.189312219619751, val acuracy: 0.6113333702087402
step: 158, train loss: 1.1076033115386963, train acuracy: 0.6015625
step: 158, val loss: 1.2102068662643433, val acuracy: 0.5668333768844604
step: 159, train loss: 1.2584993839263916, train acuracy: 0.599609375
step: 159, val loss: 1.2555568218231201, val acuracy: 0.5766667127609253
step: 160, train loss: 1.1980702877044678, train acuracy: 0.595703125
step: 160, val loss: 1.217365026473999, val acuracy: 0.5961666703224182
step: 161, train loss: 1.3226925134658813, train acuracy: 0.5234375
step: 161, val loss: 1.2533528804779053, val acuracy: 0.5538333654403687
step: 162, train loss: 1.3230665922164917, train acuracy: 0.525390625
step: 162, val loss: 1.2708491086959839, val acuracy: 0.5396667718887329
step: 163, train loss: 1.240271806716919, train acuracy: 0.556640625
step: 163, val loss: 1.260080337524414, val acuracy: 0.5451666712760925
step: 164, train loss: 1.3573685884475708, train acuracy: 0.568359375
step: 164, val loss: 1.2568016052246094, val acuracy: 0.5660000443458557
step: 165, train loss: 1.2752612829208374, train acuracy: 0.54296875
step: 165, val loss: 1.263438105583191, val acuracy: 0.5630000233650208
step: 166, train loss: 1.1511414051055908, train acuracy: 0.59375
step: 166, val loss: 1.2882148027420044, val acuracy: 0.5575000047683716
step: 167, train loss: 1.3172565698623657, train acuracy: 0.54296875
step: 167, val loss: 1.3351035118103027, val acuracy: 0.5253334045410156
step: 168, train loss: 1.1863739490509033, train acuracy: 0.619140625
step: 168, val loss: 1.2586767673492432, val acuracy: 0.5765000581741333
step: 169, train loss: 1.223545789718628, train acuracy: 0.603515625
step: 169, val loss: 1.2703031301498413, val acuracy: 0.5793333053588867
step: 170, train loss: 1.23271644115448, train acuracy: 0.58203125
step: 170, val loss: 1.265436053276062, val acuracy: 0.5695000290870667
step: 171, train loss: 1.1750118732452393, train acuracy: 0.611328125
step: 171, val loss: 1.2739994525909424, val acuracy: 0.6053333282470703
step: 172, train loss: 1.2859429121017456, train acuracy: 0.537109375
step: 172, val loss: 1.2922046184539795, val acuracy: 0.5446667075157166
step: 173, train loss: 1.3181102275848389, train acuracy: 0.548828125
step: 173, val loss: 1.3045419454574585, val acuracy: 0.53083336353302
step: 174, train loss: 1.194962501525879, train acuracy: 0.62109375
step: 174, val loss: 1.3073012828826904, val acuracy: 0.6065000295639038
step: 175, train loss: 1.5620461702346802, train acuracy: 0.482421875
step: 175, val loss: 1.3427983522415161, val acuracy: 0.5356667041778564
step: 176, train loss: 1.3693264722824097, train acuracy: 0.5390625
step: 176, val loss: 1.2729281187057495, val acuracy: 0.5635000467300415
step: 177, train loss: 1.245646595954895, train acuracy: 0.591796875
step: 177, val loss: 1.2773356437683105, val acuracy: 0.5908334255218506
step: 178, train loss: 1.1839900016784668, train acuracy: 0.66796875
step: 178, val loss: 1.2962234020233154, val acuracy: 0.6496667265892029
step: 179, train loss: 1.4191540479660034, train acuracy: 0.67578125
step: 179, val loss: 1.3053406476974487, val acuracy: 0.6806667447090149
step: 180, train loss: 1.1024401187896729, train acuracy: 0.65234375
step: 180, val loss: 1.1784495115280151, val acuracy: 0.6476666927337646
step: 181, train loss: 1.1337538957595825, train acuracy: 0.658203125
step: 181, val loss: 1.1791625022888184, val acuracy: 0.6321667432785034
step: 182, train loss: 1.1749790906906128, train acuracy: 0.5859375
step: 182, val loss: 1.1987454891204834, val acuracy: 0.5680000185966492
step: 183, train loss: 1.0947601795196533, train acuracy: 0.611328125
step: 183, val loss: 1.1655131578445435, val acuracy: 0.5811667442321777
step: 184, train loss: 1.193452000617981, train acuracy: 0.583984375
step: 184, val loss: 1.187536358833313, val acuracy: 0.5706666707992554
step: 185, train loss: 1.136900544166565, train acuracy: 0.59375
step: 185, val loss: 1.137765645980835, val acuracy: 0.6016667485237122
step: 186, train loss: 1.1294934749603271, train acuracy: 0.625
step: 186, val loss: 1.1334409713745117, val acuracy: 0.6111667156219482
step: 187, train loss: 1.0900218486785889, train acuracy: 0.625
step: 187, val loss: 1.129744529724121, val acuracy: 0.6110000610351562
step: 188, train loss: 1.2100833654403687, train acuracy: 0.6015625
step: 188, val loss: 1.128939151763916, val acuracy: 0.6110000610351562
step: 189, train loss: 1.0428084135055542, train acuracy: 0.625
step: 189, val loss: 1.128652811050415, val acuracy: 0.6108333468437195
step: 190, train loss: 1.1256340742111206, train acuracy: 0.62890625
step: 190, val loss: 1.1283010244369507, val acuracy: 0.6113333702087402
step: 191, train loss: 1.115325689315796, train acuracy: 0.607421875
step: 191, val loss: 1.128036379814148, val acuracy: 0.6104999780654907
step: 192, train loss: 1.1647202968597412, train acuracy: 0.595703125
step: 192, val loss: 1.1277272701263428, val acuracy: 0.6115000247955322
step: 193, train loss: 1.0651803016662598, train acuracy: 0.64453125
step: 193, val loss: 1.1275146007537842, val acuracy: 0.6105000972747803
step: 194, train loss: 1.1174103021621704, train acuracy: 0.595703125
step: 194, val loss: 1.1274456977844238, val acuracy: 0.6111667156219482
step: 195, train loss: 1.0901196002960205, train acuracy: 0.611328125
step: 195, val loss: 1.127362608909607, val acuracy: 0.6125000715255737
step: 196, train loss: 1.2049416303634644, train acuracy: 0.59375
step: 196, val loss: 1.1269488334655762, val acuracy: 0.6128334403038025
step: 197, train loss: 1.126775860786438, train acuracy: 0.61328125
step: 197, val loss: 1.1268320083618164, val acuracy: 0.6130000352859497
step: 198, train loss: 1.0373156070709229, train acuracy: 0.638671875
step: 198, val loss: 1.1270675659179688, val acuracy: 0.6118333339691162
step: 199, train loss: 1.1093814373016357, train acuracy: 0.615234375
step: 199, val loss: 1.139403223991394, val acuracy: 0.6128333806991577
step: 200, train loss: 1.1445355415344238, train acuracy: 0.6328125
step: 200, val loss: 1.184038758277893, val acuracy: 0.6086666584014893
step: 201, train loss: 1.1805140972137451, train acuracy: 0.58203125
step: 201, val loss: 1.1748076677322388, val acuracy: 0.5954999923706055
step: 202, train loss: 1.086743712425232, train acuracy: 0.654296875
step: 202, val loss: 1.1943233013153076, val acuracy: 0.6018333435058594
step: 203, train loss: 1.2191624641418457, train acuracy: 0.583984375
step: 203, val loss: 1.1878795623779297, val acuracy: 0.590666651725769
step: 204, train loss: 1.1028201580047607, train acuracy: 0.638671875
step: 204, val loss: 1.2073310613632202, val acuracy: 0.6070000529289246
step: 205, train loss: 1.2570515871047974, train acuracy: 0.6171875
step: 205, val loss: 1.1964144706726074, val acuracy: 0.6253333687782288
step: 206, train loss: 1.0919690132141113, train acuracy: 0.63671875
step: 206, val loss: 1.2087962627410889, val acuracy: 0.6203333139419556
step: 207, train loss: 1.3576979637145996, train acuracy: 0.552734375
step: 207, val loss: 1.231406331062317, val acuracy: 0.6013333797454834
step: 208, train loss: 1.2251498699188232, train acuracy: 0.576171875
step: 208, val loss: 1.2179276943206787, val acuracy: 0.5871666669845581
step: 209, train loss: 1.137152075767517, train acuracy: 0.64453125
step: 209, val loss: 1.2256128787994385, val acuracy: 0.6006666421890259
step: 210, train loss: 1.1547824144363403, train acuracy: 0.634765625
step: 210, val loss: 1.271614670753479, val acuracy: 0.5929999947547913
step: 211, train loss: 1.2556648254394531, train acuracy: 0.626953125
step: 211, val loss: 1.3341584205627441, val acuracy: 0.5745000243186951
step: 212, train loss: 1.3526320457458496, train acuracy: 0.57421875
step: 212, val loss: 1.3678743839263916, val acuracy: 0.5420000553131104
step: 213, train loss: 1.294116497039795, train acuracy: 0.560546875
step: 213, val loss: 1.3604460954666138, val acuracy: 0.5531667470932007
step: 214, train loss: 1.1972736120224, train acuracy: 0.642578125
step: 214, val loss: 1.3906168937683105, val acuracy: 0.5916666984558105
step: 215, train loss: 1.2406384944915771, train acuracy: 0.60546875
step: 215, val loss: 1.4464397430419922, val acuracy: 0.5593333840370178
step: 216, train loss: 1.211509108543396, train acuracy: 0.572265625
step: 216, val loss: 1.224782943725586, val acuracy: 0.5751667618751526
step: 217, train loss: 1.1893980503082275, train acuracy: 0.58984375
step: 217, val loss: 1.2073860168457031, val acuracy: 0.5845000743865967
step: 218, train loss: 1.2133502960205078, train acuracy: 0.615234375
step: 218, val loss: 1.2994778156280518, val acuracy: 0.5886667370796204
step: 219, train loss: 1.1062321662902832, train acuracy: 0.654296875
step: 219, val loss: 0.987146258354187, val acuracy: 0.6835000514984131
step: 220, train loss: 0.953741729259491, train acuracy: 0.685546875
step: 220, val loss: 0.9707669615745544, val acuracy: 0.6855000257492065
step: 221, train loss: 0.8125655055046082, train acuracy: 0.72265625
step: 221, val loss: 0.8803271055221558, val acuracy: 0.7078333497047424
step: 222, train loss: 0.8163666129112244, train acuracy: 0.728515625
step: 222, val loss: 0.8661227226257324, val acuracy: 0.702666699886322
step: 223, train loss: 0.7655315399169922, train acuracy: 0.736328125
step: 223, val loss: 0.7655572891235352, val acuracy: 0.7615000009536743
step: 224, train loss: 0.758207380771637, train acuracy: 0.7421875
step: 224, val loss: 0.7791147232055664, val acuracy: 0.7456667423248291
step: 225, train loss: 0.6715795397758484, train acuracy: 0.794921875
step: 225, val loss: 0.7041424512863159, val acuracy: 0.7706667184829712
step: 226, train loss: 0.6583855152130127, train acuracy: 0.791015625
step: 226, val loss: 0.6875585913658142, val acuracy: 0.7668334245681763
step: 227, train loss: 0.532214879989624, train acuracy: 0.849609375
step: 227, val loss: 0.5918335914611816, val acuracy: 0.8285001516342163
step: 228, train loss: 0.5189352035522461, train acuracy: 0.84375
step: 228, val loss: 0.5986441373825073, val acuracy: 0.802333414554596
step: 229, train loss: 0.5356563329696655, train acuracy: 0.814453125
step: 229, val loss: 0.5418767929077148, val acuracy: 0.8265001177787781
step: 230, train loss: 0.4566512703895569, train acuracy: 0.876953125
step: 230, val loss: 0.4871857464313507, val acuracy: 0.8660001158714294
step: 231, train loss: 0.48874783515930176, train acuracy: 0.865234375
step: 231, val loss: 0.49639633297920227, val acuracy: 0.8631667494773865
step: 232, train loss: 0.5215986967086792, train acuracy: 0.85546875
step: 232, val loss: 0.5040420293807983, val acuracy: 0.8563333749771118
step: 233, train loss: 0.5245084166526794, train acuracy: 0.833984375
step: 233, val loss: 0.5243562459945679, val acuracy: 0.8331667184829712
step: 234, train loss: 0.4123341143131256, train acuracy: 0.88671875
step: 234, val loss: 0.515501856803894, val acuracy: 0.8511667251586914
step: 235, train loss: 0.5216163992881775, train acuracy: 0.86328125
step: 235, val loss: 0.5068451166152954, val acuracy: 0.8600001335144043
step: 236, train loss: 0.6083621382713318, train acuracy: 0.8125
step: 236, val loss: 0.515174150466919, val acuracy: 0.8536667227745056
step: 237, train loss: 0.49907809495925903, train acuracy: 0.861328125
step: 237, val loss: 0.5008606910705566, val acuracy: 0.8633334636688232
step: 238, train loss: 0.48747938871383667, train acuracy: 0.87109375
step: 238, val loss: 0.5012036561965942, val acuracy: 0.862166702747345
step: 239, train loss: 0.5802804231643677, train acuracy: 0.865234375
step: 239, val loss: 0.5000619292259216, val acuracy: 0.8628333806991577
step: 240, train loss: 0.4972429871559143, train acuracy: 0.84765625
step: 240, val loss: 0.4990732669830322, val acuracy: 0.8628333806991577
step: 241, train loss: 0.5475267171859741, train acuracy: 0.83984375
step: 241, val loss: 0.4985879957675934, val acuracy: 0.861833393573761
step: 242, train loss: 0.4967602491378784, train acuracy: 0.853515625
step: 242, val loss: 0.4983379542827606, val acuracy: 0.8628333806991577
step: 243, train loss: 0.48478999733924866, train acuracy: 0.875
step: 243, val loss: 0.5146171450614929, val acuracy: 0.8475000858306885
step: 244, train loss: 0.4242944121360779, train acuracy: 0.912109375
step: 244, val loss: 0.5033707022666931, val acuracy: 0.8620001077651978
step: 245, train loss: 0.5003233551979065, train acuracy: 0.84765625
step: 245, val loss: 0.5029987096786499, val acuracy: 0.8605000972747803
step: 246, train loss: 0.49434345960617065, train acuracy: 0.857421875
step: 246, val loss: 0.5023813843727112, val acuracy: 0.861666738986969
step: 247, train loss: 0.4758288860321045, train acuracy: 0.859375
step: 247, val loss: 0.5010358691215515, val acuracy: 0.861666738986969
step: 248, train loss: 0.5211672782897949, train acuracy: 0.8671875
step: 248, val loss: 0.5004534721374512, val acuracy: 0.8620001077651978
step: 249, train loss: 0.4289308190345764, train acuracy: 0.876953125
step: 249, val loss: 0.5003496408462524, val acuracy: 0.861833393573761
step: 250, train loss: 0.5064231753349304, train acuracy: 0.849609375
step: 250, val loss: 0.5002434253692627, val acuracy: 0.861833393573761
step: 251, train loss: 0.5155723094940186, train acuracy: 0.87109375
step: 251, val loss: 0.5000355839729309, val acuracy: 0.8620001077651978
step: 252, train loss: 0.49881303310394287, train acuracy: 0.869140625
step: 252, val loss: 0.4999214708805084, val acuracy: 0.8616667985916138
step: 253, train loss: 0.4638327956199646, train acuracy: 0.845703125
step: 253, val loss: 0.49982327222824097, val acuracy: 0.861000120639801
step: 254, train loss: 0.5278091430664062, train acuracy: 0.873046875
step: 254, val loss: 0.4997038245201111, val acuracy: 0.8621668219566345
step: 255, train loss: 0.5050578117370605, train acuracy: 0.8671875
step: 255, val loss: 0.4996156394481659, val acuracy: 0.8621667623519897
step: 256, train loss: 0.5657285451889038, train acuracy: 0.849609375
step: 256, val loss: 0.5121809244155884, val acuracy: 0.8591668605804443
step: 257, train loss: 0.5264119505882263, train acuracy: 0.83984375
step: 257, val loss: 0.5158155560493469, val acuracy: 0.8531667590141296
step: 258, train loss: 0.5599204897880554, train acuracy: 0.826171875
step: 258, val loss: 0.5348061323165894, val acuracy: 0.849166750907898
step: 259, train loss: 0.48881685733795166, train acuracy: 0.85546875
step: 259, val loss: 0.5438829660415649, val acuracy: 0.8355000615119934
step: 260, train loss: 0.5252633690834045, train acuracy: 0.853515625
step: 260, val loss: 0.5345450043678284, val acuracy: 0.8485000729560852
step: 261, train loss: 0.5484087467193604, train acuracy: 0.8515625
step: 261, val loss: 0.5042453408241272, val acuracy: 0.8593333959579468
step: 262, train loss: 0.5281117558479309, train acuracy: 0.83984375
step: 262, val loss: 0.5313388109207153, val acuracy: 0.8523333668708801
step: 263, train loss: 0.45524391531944275, train acuracy: 0.89453125
step: 263, val loss: 0.5152490735054016, val acuracy: 0.8554999828338623
step: 264, train loss: 0.5994948744773865, train acuracy: 0.857421875
step: 264, val loss: 0.5196097493171692, val acuracy: 0.8516667485237122
step: 265, train loss: 0.534125566482544, train acuracy: 0.8671875
step: 265, val loss: 0.5169186592102051, val acuracy: 0.8521667718887329
step: 266, train loss: 0.555132269859314, train acuracy: 0.845703125
step: 266, val loss: 0.5368207693099976, val acuracy: 0.8406667709350586
step: 267, train loss: 0.5160263180732727, train acuracy: 0.845703125
step: 267, val loss: 0.5333504676818848, val acuracy: 0.8338333964347839
step: 268, train loss: 0.43389615416526794, train acuracy: 0.880859375
step: 268, val loss: 0.5057708621025085, val acuracy: 0.8591668009757996
step: 269, train loss: 0.6187242865562439, train acuracy: 0.806640625
step: 269, val loss: 0.526268482208252, val acuracy: 0.849166750907898
step: 270, train loss: 0.489067405462265, train acuracy: 0.888671875
step: 270, val loss: 0.5233089923858643, val acuracy: 0.8548334240913391
step: 271, train loss: 0.4644921123981476, train acuracy: 0.8515625
step: 271, val loss: 0.50975501537323, val acuracy: 0.8551667332649231
step: 272, train loss: 0.5461820960044861, train acuracy: 0.83984375
step: 272, val loss: 0.5131374001502991, val acuracy: 0.8561667799949646
step: 273, train loss: 0.5456045866012573, train acuracy: 0.86328125
step: 273, val loss: 0.5120734572410583, val acuracy: 0.8556667566299438
step: 274, train loss: 0.5407345294952393, train acuracy: 0.845703125
step: 274, val loss: 0.5075863003730774, val acuracy: 0.8573333621025085
step: 275, train loss: 0.5927093625068665, train acuracy: 0.796875
step: 275, val loss: 0.6462488174438477, val acuracy: 0.7875000238418579
step: 276, train loss: 0.5390329957008362, train acuracy: 0.80859375
step: 276, val loss: 0.6321364045143127, val acuracy: 0.7950000166893005
step: 277, train loss: 0.6365430951118469, train acuracy: 0.77734375
step: 277, val loss: 0.636776328086853, val acuracy: 0.7856667041778564
step: 278, train loss: 0.6174671649932861, train acuracy: 0.76953125
step: 278, val loss: 0.6502402424812317, val acuracy: 0.7696667313575745
step: 279, train loss: 0.734131932258606, train acuracy: 0.740234375
step: 279, val loss: 0.6504651308059692, val acuracy: 0.7673333883285522
step: 280, train loss: 0.7950031161308289, train acuracy: 0.75390625
step: 280, val loss: 0.6493884325027466, val acuracy: 0.768166720867157
step: 281, train loss: 0.7109576463699341, train acuracy: 0.765625
step: 281, val loss: 0.6487211585044861, val acuracy: 0.7685000896453857
step: 282, train loss: 0.6479817628860474, train acuracy: 0.771484375
step: 282, val loss: 0.6669798493385315, val acuracy: 0.7763334512710571
step: 283, train loss: 0.5795606374740601, train acuracy: 0.798828125
step: 283, val loss: 0.6414363384246826, val acuracy: 0.7751666903495789
step: 284, train loss: 0.7137361764907837, train acuracy: 0.76171875
step: 284, val loss: 0.6493455171585083, val acuracy: 0.7781667709350586
step: 285, train loss: 0.6238663792610168, train acuracy: 0.763671875
step: 285, val loss: 0.6492921710014343, val acuracy: 0.7736667394638062
step: 286, train loss: 0.6342511177062988, train acuracy: 0.76953125
step: 286, val loss: 0.6435661911964417, val acuracy: 0.7763334512710571
step: 287, train loss: 0.6643061637878418, train acuracy: 0.763671875
step: 287, val loss: 0.6433640718460083, val acuracy: 0.7768334150314331
step: 288, train loss: 0.567219078540802, train acuracy: 0.806640625
step: 288, val loss: 0.6505410671234131, val acuracy: 0.7745000720024109
step: 289, train loss: 0.6603002548217773, train acuracy: 0.78125
step: 289, val loss: 0.6494119167327881, val acuracy: 0.7741667032241821
step: 290, train loss: 0.6479823589324951, train acuracy: 0.765625
step: 290, val loss: 0.6487187147140503, val acuracy: 0.7753333449363708
step: 291, train loss: 0.725394606590271, train acuracy: 0.748046875
step: 291, val loss: 0.6524493098258972, val acuracy: 0.7660000324249268
step: 292, train loss: 532.7330322265625, train acuracy: 0.158203125
step: 292, val loss: 496.52490234375, val acuracy: 0.1628333330154419
step: 293, train loss: 462.2229309082031, train acuracy: 0.154296875
step: 293, val loss: 473.7773132324219, val acuracy: 0.1628333181142807
step: 294, train loss: 883.1632690429688, train acuracy: 0.107421875
step: 294, val loss: 899.48974609375, val acuracy: 0.12449998408555984
step: 295, train loss: 2652.328125, train acuracy: 0.111328125
step: 295, val loss: 2628.342041015625, val acuracy: 0.09916666150093079
step: 296, train loss: 1558.33544921875, train acuracy: 0.1015625
step: 296, val loss: 1590.64404296875, val acuracy: 0.085999995470047
step: 297, train loss: 57951.828125, train acuracy: 0.09375
step: 297, val loss: 57593.94921875, val acuracy: 0.09749999642372131
step: 298, train loss: 1831782842368.0, train acuracy: 0.099609375
step: 298, val loss: 1735751630848.0, val acuracy: 0.10400000214576721
step: 299, train loss: 1.894968648042871e+25, train acuracy: 0.107421875
step: 299, val loss: 1.9139569193472944e+25, val acuracy: 0.10533333569765091
step: 300, train loss: nan, train acuracy: 0.087890625
step: 300, val loss: nan, val acuracy: 0.10400000214576721
step: 301, train loss: nan, train acuracy: 0.103515625
step: 301, val loss: nan, val acuracy: 0.10400000214576721
step: 302, train loss: nan, train acuracy: 0.095703125
step: 302, val loss: nan, val acuracy: 0.10400000214576721
step: 303, train loss: nan, train acuracy: 0.080078125
step: 303, val loss: nan, val acuracy: 0.10400000214576721
step: 304, train loss: nan, train acuracy: 0.109375
step: 304, val loss: nan, val acuracy: 0.10400000214576721
step: 305, train loss: nan, train acuracy: 0.095703125
step: 305, val loss: nan, val acuracy: 0.10400000214576721
step: 306, train loss: nan, train acuracy: 0.111328125
step: 306, val loss: nan, val acuracy: 0.10400000214576721
step: 307, train loss: nan, train acuracy: 0.087890625
step: 307, val loss: nan, val acuracy: 0.10400000214576721
step: 308, train loss: nan, train acuracy: 0.12109375
step: 308, val loss: nan, val acuracy: 0.10400000214576721
step: 309, train loss: nan, train acuracy: 0.095703125
step: 309, val loss: nan, val acuracy: 0.10400000214576721
step: 310, train loss: nan, train acuracy: 0.10546875
step: 310, val loss: nan, val acuracy: 0.10400000214576721
step: 311, train loss: nan, train acuracy: 0.080078125
step: 311, val loss: nan, val acuracy: 0.10400000214576721
step: 312, train loss: nan, train acuracy: 0.123046875
step: 312, val loss: nan, val acuracy: 0.10400000214576721
step: 313, train loss: nan, train acuracy: 0.1171875
step: 313, val loss: nan, val acuracy: 0.10400000214576721
step: 314, train loss: nan, train acuracy: 0.103515625
step: 314, val loss: nan, val acuracy: 0.10400000214576721
step: 315, train loss: nan, train acuracy: 0.11328125
step: 315, val loss: nan, val acuracy: 0.10400000214576721
step: 316, train loss: nan, train acuracy: 0.076171875
step: 316, val loss: nan, val acuracy: 0.10400000214576721
step: 317, train loss: nan, train acuracy: 0.107421875
step: 317, val loss: nan, val acuracy: 0.10400000214576721
step: 318, train loss: nan, train acuracy: 0.09765625
step: 318, val loss: nan, val acuracy: 0.10400000214576721
step: 319, train loss: nan, train acuracy: 0.080078125
step: 319, val loss: nan, val acuracy: 0.10400000214576721
step: 320, train loss: nan, train acuracy: 0.087890625
step: 320, val loss: nan, val acuracy: 0.10400000214576721
step: 321, train loss: nan, train acuracy: 0.087890625
step: 321, val loss: nan, val acuracy: 0.10400000214576721
step: 322, train loss: nan, train acuracy: 0.111328125
step: 322, val loss: nan, val acuracy: 0.10400000214576721
step: 323, train loss: nan, train acuracy: 0.09375
step: 323, val loss: nan, val acuracy: 0.10400000214576721
step: 324, train loss: nan, train acuracy: 0.109375
step: 324, val loss: nan, val acuracy: 0.10400000214576721
step: 325, train loss: nan, train acuracy: 0.09375
step: 325, val loss: nan, val acuracy: 0.10400000214576721
step: 326, train loss: nan, train acuracy: 0.099609375
step: 326, val loss: nan, val acuracy: 0.10400000214576721
step: 327, train loss: nan, train acuracy: 0.109375
step: 327, val loss: nan, val acuracy: 0.10400000214576721
step: 328, train loss: nan, train acuracy: 0.115234375
step: 328, val loss: nan, val acuracy: 0.10400000214576721
step: 329, train loss: nan, train acuracy: 0.1015625
step: 329, val loss: nan, val acuracy: 0.10400000214576721
step: 330, train loss: nan, train acuracy: 0.0859375
step: 330, val loss: nan, val acuracy: 0.10400000214576721
step: 331, train loss: nan, train acuracy: 0.111328125
step: 331, val loss: nan, val acuracy: 0.10400000214576721
step: 332, train loss: nan, train acuracy: 0.09375
step: 332, val loss: nan, val acuracy: 0.10400000214576721
step: 333, train loss: nan, train acuracy: 0.076171875
step: 333, val loss: nan, val acuracy: 0.10400000214576721
step: 334, train loss: nan, train acuracy: 0.11328125
step: 334, val loss: nan, val acuracy: 0.10400000214576721
step: 335, train loss: nan, train acuracy: 0.08984375
step: 335, val loss: nan, val acuracy: 0.10400000214576721
step: 336, train loss: nan, train acuracy: 0.083984375
step: 336, val loss: nan, val acuracy: 0.10400000214576721
step: 337, train loss: nan, train acuracy: 0.0859375
step: 337, val loss: nan, val acuracy: 0.10400000214576721
step: 338, train loss: nan, train acuracy: 0.076171875
step: 338, val loss: nan, val acuracy: 0.10400000214576721
step: 339, train loss: nan, train acuracy: 0.115234375
step: 339, val loss: nan, val acuracy: 0.10400000214576721
step: 340, train loss: nan, train acuracy: 0.0703125
step: 340, val loss: nan, val acuracy: 0.10400000214576721
step: 341, train loss: nan, train acuracy: 0.109375
step: 341, val loss: nan, val acuracy: 0.10400000214576721
step: 342, train loss: nan, train acuracy: 0.087890625
step: 342, val loss: nan, val acuracy: 0.10400000214576721
step: 343, train loss: nan, train acuracy: 0.103515625
step: 343, val loss: nan, val acuracy: 0.10400000214576721
step: 344, train loss: nan, train acuracy: 0.11328125
step: 344, val loss: nan, val acuracy: 0.10400000214576721
step: 345, train loss: nan, train acuracy: 0.095703125
step: 345, val loss: nan, val acuracy: 0.10400000214576721
step: 346, train loss: nan, train acuracy: 0.078125
step: 346, val loss: nan, val acuracy: 0.10400000214576721
step: 347, train loss: nan, train acuracy: 0.107421875
step: 347, val loss: nan, val acuracy: 0.10400000214576721
step: 348, train loss: nan, train acuracy: 0.099609375
step: 348, val loss: nan, val acuracy: 0.10400000214576721
step: 349, train loss: nan, train acuracy: 0.091796875
step: 349, val loss: nan, val acuracy: 0.10400000214576721
step: 350, train loss: nan, train acuracy: 0.076171875
step: 350, val loss: nan, val acuracy: 0.10400000214576721
step: 351, train loss: nan, train acuracy: 0.09375
step: 351, val loss: nan, val acuracy: 0.10400000214576721
step: 352, train loss: nan, train acuracy: 0.1171875
step: 352, val loss: nan, val acuracy: 0.10400000214576721
step: 353, train loss: nan, train acuracy: 0.09375
step: 353, val loss: nan, val acuracy: 0.10400000214576721
step: 354, train loss: nan, train acuracy: 0.08203125
step: 354, val loss: nan, val acuracy: 0.10400000214576721
step: 355, train loss: nan, train acuracy: 0.091796875
step: 355, val loss: nan, val acuracy: 0.10400000214576721
step: 356, train loss: nan, train acuracy: 0.109375
step: 356, val loss: nan, val acuracy: 0.10400000214576721
step: 357, train loss: nan, train acuracy: 0.12109375
step: 357, val loss: nan, val acuracy: 0.10400000214576721
step: 358, train loss: nan, train acuracy: 0.078125
step: 358, val loss: nan, val acuracy: 0.10400000214576721
step: 359, train loss: nan, train acuracy: 0.1015625
step: 359, val loss: nan, val acuracy: 0.10400000214576721
step: 360, train loss: nan, train acuracy: 0.109375
step: 360, val loss: nan, val acuracy: 0.10400000214576721
step: 361, train loss: nan, train acuracy: 0.09765625
step: 361, val loss: nan, val acuracy: 0.10400000214576721
step: 362, train loss: nan, train acuracy: 0.103515625
step: 362, val loss: nan, val acuracy: 0.10400000214576721
step: 363, train loss: nan, train acuracy: 0.1015625
step: 363, val loss: nan, val acuracy: 0.10400000214576721
step: 364, train loss: nan, train acuracy: 0.099609375
step: 364, val loss: nan, val acuracy: 0.10400000214576721
step: 365, train loss: nan, train acuracy: 0.109375
step: 365, val loss: nan, val acuracy: 0.10400000214576721
step: 366, train loss: nan, train acuracy: 0.099609375
step: 366, val loss: nan, val acuracy: 0.10400000214576721
step: 367, train loss: nan, train acuracy: 0.064453125
step: 367, val loss: nan, val acuracy: 0.10400000214576721
step: 368, train loss: nan, train acuracy: 0.078125
step: 368, val loss: nan, val acuracy: 0.10400000214576721
step: 369, train loss: nan, train acuracy: 0.119140625
step: 369, val loss: nan, val acuracy: 0.10400000214576721
step: 370, train loss: nan, train acuracy: 0.12109375
step: 370, val loss: nan, val acuracy: 0.10400000214576721
step: 371, train loss: nan, train acuracy: 0.09375
step: 371, val loss: nan, val acuracy: 0.10400000214576721
step: 372, train loss: nan, train acuracy: 0.107421875
step: 372, val loss: nan, val acuracy: 0.10400000214576721
step: 373, train loss: nan, train acuracy: 0.109375
step: 373, val loss: nan, val acuracy: 0.10400000214576721
step: 374, train loss: nan, train acuracy: 0.0859375
step: 374, val loss: nan, val acuracy: 0.10400000214576721
step: 375, train loss: nan, train acuracy: 0.107421875
step: 375, val loss: nan, val acuracy: 0.10400000214576721
step: 376, train loss: nan, train acuracy: 0.107421875
step: 376, val loss: nan, val acuracy: 0.10400000214576721
step: 377, train loss: nan, train acuracy: 0.078125
step: 377, val loss: nan, val acuracy: 0.10400000214576721
step: 378, train loss: nan, train acuracy: 0.119140625
step: 378, val loss: nan, val acuracy: 0.10400000214576721
step: 379, train loss: nan, train acuracy: 0.09765625
step: 379, val loss: nan, val acuracy: 0.10400000214576721
step: 380, train loss: nan, train acuracy: 0.103515625
step: 380, val loss: nan, val acuracy: 0.10400000214576721
step: 381, train loss: nan, train acuracy: 0.083984375
step: 381, val loss: nan, val acuracy: 0.10400000214576721
step: 382, train loss: nan, train acuracy: 0.107421875
step: 382, val loss: nan, val acuracy: 0.10400000214576721
step: 383, train loss: nan, train acuracy: 0.09375
step: 383, val loss: nan, val acuracy: 0.10400000214576721
step: 384, train loss: nan, train acuracy: 0.111328125
step: 384, val loss: nan, val acuracy: 0.10400000214576721
step: 385, train loss: nan, train acuracy: 0.078125
step: 385, val loss: nan, val acuracy: 0.10400000214576721
step: 386, train loss: nan, train acuracy: 0.095703125
step: 386, val loss: nan, val acuracy: 0.10400000214576721
step: 387, train loss: nan, train acuracy: 0.080078125
step: 387, val loss: nan, val acuracy: 0.10400000214576721
step: 388, train loss: nan, train acuracy: 0.08203125
step: 388, val loss: nan, val acuracy: 0.10400000214576721
step: 389, train loss: nan, train acuracy: 0.095703125
step: 389, val loss: nan, val acuracy: 0.10400000214576721
step: 390, train loss: nan, train acuracy: 0.10546875
step: 390, val loss: nan, val acuracy: 0.10400000214576721
step: 391, train loss: nan, train acuracy: 0.107421875
step: 391, val loss: nan, val acuracy: 0.10400000214576721
step: 392, train loss: nan, train acuracy: 0.083984375
step: 392, val loss: nan, val acuracy: 0.10400000214576721
step: 393, train loss: nan, train acuracy: 0.109375
step: 393, val loss: nan, val acuracy: 0.10400000214576721
step: 394, train loss: nan, train acuracy: 0.115234375
step: 394, val loss: nan, val acuracy: 0.10400000214576721
step: 395, train loss: nan, train acuracy: 0.1015625
step: 395, val loss: nan, val acuracy: 0.10400000214576721
step: 396, train loss: nan, train acuracy: 0.107421875
step: 396, val loss: nan, val acuracy: 0.10400000214576721
step: 397, train loss: nan, train acuracy: 0.09765625
step: 397, val loss: nan, val acuracy: 0.10400000214576721
step: 398, train loss: nan, train acuracy: 0.111328125
step: 398, val loss: nan, val acuracy: 0.10400000214576721
step: 399, train loss: nan, train acuracy: 0.1015625
step: 399, val loss: nan, val acuracy: 0.10400000214576721
2017-12-04 15:57:54.009934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:57:54.266652: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0xa2297c0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 15:57:54.267612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 15:57:54.267967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 15:57:54.267989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 15:57:54.268005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 15:57:54.268021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 15:57:54.268031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
m=15, b=1024
step: 0, train loss: 2.3499231338500977, train acuracy: 0.169921875
step: 0, val loss: 2.384284019470215, val acuracy: 0.16133332252502441
step: 1, train loss: 2.255868434906006, train acuracy: 0.294921875
step: 1, val loss: 2.2576146125793457, val acuracy: 0.2933333218097687
step: 2, train loss: 2.2612221240997314, train acuracy: 0.2802734375
step: 2, val loss: 2.254636526107788, val acuracy: 0.3058333694934845
step: 3, train loss: 2.246450901031494, train acuracy: 0.294921875
step: 3, val loss: 2.2537662982940674, val acuracy: 0.28566670417785645
step: 4, train loss: 2.2501790523529053, train acuracy: 0.30859375
step: 4, val loss: 2.2535109519958496, val acuracy: 0.28733333945274353
step: 5, train loss: 2.2539544105529785, train acuracy: 0.2900390625
step: 5, val loss: 2.253384590148926, val acuracy: 0.2926666736602783
step: 6, train loss: 2.252239227294922, train acuracy: 0.30859375
step: 6, val loss: 2.253398895263672, val acuracy: 0.28850001096725464
step: 7, train loss: 2.2596960067749023, train acuracy: 0.2216796875
step: 7, val loss: 2.253540277481079, val acuracy: 0.24416667222976685
step: 8, train loss: 2.244180679321289, train acuracy: 0.25390625
step: 8, val loss: 2.253232479095459, val acuracy: 0.24300001561641693
step: 9, train loss: 2.2537152767181396, train acuracy: 0.173828125
step: 9, val loss: 2.2612223625183105, val acuracy: 0.15666666626930237
step: 10, train loss: 2.260361433029175, train acuracy: 0.1767578125
step: 10, val loss: 2.2597410678863525, val acuracy: 0.18066665530204773
step: 11, train loss: 2.25150203704834, train acuracy: 0.146484375
step: 11, val loss: 2.2576165199279785, val acuracy: 0.1340000033378601
step: 12, train loss: 2.2563626766204834, train acuracy: 0.1279296875
step: 12, val loss: 2.2576303482055664, val acuracy: 0.1274999976158142
step: 13, train loss: 2.2574853897094727, train acuracy: 0.1171875
step: 13, val loss: 2.2598721981048584, val acuracy: 0.11316666007041931
step: 14, train loss: 2.2419002056121826, train acuracy: 0.1552734375
step: 14, val loss: 2.2701799869537354, val acuracy: 0.11833333224058151
step: 15, train loss: 2.248095989227295, train acuracy: 0.171875
step: 15, val loss: 2.253873348236084, val acuracy: 0.15716665983200073
step: 16, train loss: 2.248974561691284, train acuracy: 0.171875
step: 16, val loss: 2.2532312870025635, val acuracy: 0.15266667306423187
step: 17, train loss: 2.250370502471924, train acuracy: 0.2275390625
step: 17, val loss: 2.254986047744751, val acuracy: 0.2095000147819519
step: 18, train loss: 2.2558250427246094, train acuracy: 0.193359375
step: 18, val loss: 2.256337881088257, val acuracy: 0.1928333342075348
step: 19, train loss: 2.250478744506836, train acuracy: 0.28515625
step: 19, val loss: 2.2591490745544434, val acuracy: 0.24966666102409363
step: 20, train loss: 2.254286050796509, train acuracy: 0.2216796875
step: 20, val loss: 2.2524051666259766, val acuracy: 0.24816666543483734
step: 21, train loss: 2.2567036151885986, train acuracy: 0.2451171875
step: 21, val loss: 2.255527973175049, val acuracy: 0.2485000193119049
step: 22, train loss: 2.257141590118408, train acuracy: 0.201171875
step: 22, val loss: 2.2577123641967773, val acuracy: 0.20516666769981384
step: 23, train loss: 2.253262519836426, train acuracy: 0.2216796875
step: 23, val loss: 2.256502151489258, val acuracy: 0.20666667819023132
step: 24, train loss: 2.255462169647217, train acuracy: 0.208984375
step: 24, val loss: 2.2564778327941895, val acuracy: 0.21166665852069855
step: 25, train loss: 2.2603049278259277, train acuracy: 0.125
step: 25, val loss: 2.259692430496216, val acuracy: 0.1290000081062317
step: 26, train loss: 2.2461371421813965, train acuracy: 0.1962890625
step: 26, val loss: 2.263817310333252, val acuracy: 0.1848333477973938
step: 27, train loss: 2.258474111557007, train acuracy: 0.1201171875
step: 27, val loss: 2.277498245239258, val acuracy: 0.10400000214576721
step: 28, train loss: 2.2639825344085693, train acuracy: 0.13671875
step: 28, val loss: 2.2702884674072266, val acuracy: 0.12566664814949036
step: 29, train loss: 2.2557168006896973, train acuracy: 0.130859375
step: 29, val loss: 2.266838788986206, val acuracy: 0.12699998915195465
step: 30, train loss: 2.278597593307495, train acuracy: 0.130859375
step: 30, val loss: 2.2681996822357178, val acuracy: 0.13833333551883698
step: 31, train loss: 2.2778897285461426, train acuracy: 0.12109375
step: 31, val loss: 2.266219139099121, val acuracy: 0.1289999932050705
step: 32, train loss: 2.263740301132202, train acuracy: 0.1298828125
step: 32, val loss: 2.2658987045288086, val acuracy: 0.12433332949876785
step: 33, train loss: 2.261348009109497, train acuracy: 0.1240234375
step: 33, val loss: 2.265801191329956, val acuracy: 0.12449999898672104
step: 34, train loss: 2.26639723777771, train acuracy: 0.1162109375
step: 34, val loss: 2.265836000442505, val acuracy: 0.11549998819828033
step: 35, train loss: 2.267974853515625, train acuracy: 0.1240234375
step: 35, val loss: 2.2657651901245117, val acuracy: 0.11283333599567413
step: 36, train loss: 2.284743547439575, train acuracy: 0.1201171875
step: 36, val loss: 2.2673909664154053, val acuracy: 0.12099999189376831
step: 37, train loss: 2.260558605194092, train acuracy: 0.1123046875
step: 37, val loss: 2.2718188762664795, val acuracy: 0.10216666758060455
step: 38, train loss: 2.2869873046875, train acuracy: 0.0986328125
step: 38, val loss: 2.2760984897613525, val acuracy: 0.09783332794904709
step: 39, train loss: 2.389540672302246, train acuracy: 0.1513671875
step: 39, val loss: 2.3779714107513428, val acuracy: 0.15349999070167542
step: 40, train loss: 2.3380775451660156, train acuracy: 0.162109375
step: 40, val loss: 2.3648273944854736, val acuracy: 0.14766667783260345
step: 41, train loss: 2.329864025115967, train acuracy: 0.103515625
step: 41, val loss: 2.336092472076416, val acuracy: 0.11133333295583725
step: 42, train loss: 2.1914079189300537, train acuracy: 0.1728515625
step: 42, val loss: 2.187058448791504, val acuracy: 0.16333332657814026
step: 43, train loss: 2.146449327468872, train acuracy: 0.1484375
step: 43, val loss: 2.1210973262786865, val acuracy: 0.1496666669845581
step: 44, train loss: 2.138272762298584, train acuracy: 0.189453125
step: 44, val loss: 2.1625285148620605, val acuracy: 0.19449999928474426
step: 45, train loss: 1.9827123880386353, train acuracy: 0.3583984375
step: 45, val loss: 1.9966537952423096, val acuracy: 0.3425000309944153
step: 46, train loss: 1.997065782546997, train acuracy: 0.3115234375
step: 46, val loss: 2.0194146633148193, val acuracy: 0.296333372592926
step: 47, train loss: 1.912405014038086, train acuracy: 0.423828125
step: 47, val loss: 1.9567326307296753, val acuracy: 0.3906666934490204
step: 48, train loss: 1.9476213455200195, train acuracy: 0.3017578125
step: 48, val loss: 1.9525123834609985, val acuracy: 0.2813333570957184
step: 49, train loss: 1.9140123128890991, train acuracy: 0.212890625
step: 49, val loss: 1.923634648323059, val acuracy: 0.20766666531562805
step: 50, train loss: 1.8662875890731812, train acuracy: 0.353515625
step: 50, val loss: 1.8992573022842407, val acuracy: 0.33750003576278687
step: 51, train loss: 1.8625874519348145, train acuracy: 0.369140625
step: 51, val loss: 1.914688229560852, val acuracy: 0.33383336663246155
step: 52, train loss: 1.7556769847869873, train acuracy: 0.46484375
step: 52, val loss: 1.8310459852218628, val acuracy: 0.45333337783813477
step: 53, train loss: 1.75651216506958, train acuracy: 0.4599609375
step: 53, val loss: 1.7697184085845947, val acuracy: 0.437333345413208
step: 54, train loss: 1.748219609260559, train acuracy: 0.3740234375
step: 54, val loss: 1.770187258720398, val acuracy: 0.3760000467300415
step: 55, train loss: 1.6281814575195312, train acuracy: 0.421875
step: 55, val loss: 1.6670019626617432, val acuracy: 0.4078333377838135
step: 56, train loss: 1.5544084310531616, train acuracy: 0.404296875
step: 56, val loss: 1.5628159046173096, val acuracy: 0.4100000262260437
step: 57, train loss: 1.4628727436065674, train acuracy: 0.4716796875
step: 57, val loss: 1.471075415611267, val acuracy: 0.49916666746139526
step: 58, train loss: 1.3174381256103516, train acuracy: 0.5712890625
step: 58, val loss: 1.4133329391479492, val acuracy: 0.5714999437332153
step: 59, train loss: 1.2758861780166626, train acuracy: 0.5947265625
step: 59, val loss: 1.2645891904830933, val acuracy: 0.5820000171661377
step: 60, train loss: 0.9298520684242249, train acuracy: 0.6953125
step: 60, val loss: 0.9638569355010986, val acuracy: 0.6826667785644531
step: 61, train loss: 0.8190654516220093, train acuracy: 0.7392578125
step: 61, val loss: 0.8953605890274048, val acuracy: 0.7075001001358032
step: 62, train loss: 0.8852929472923279, train acuracy: 0.669921875
step: 62, val loss: 0.8953468203544617, val acuracy: 0.6921666860580444
step: 63, train loss: 0.7340397834777832, train acuracy: 0.7685546875
step: 63, val loss: 0.7377618551254272, val acuracy: 0.7565000057220459
step: 64, train loss: 0.7126967906951904, train acuracy: 0.7724609375
step: 64, val loss: 0.736748218536377, val acuracy: 0.7501667737960815
step: 65, train loss: 0.7607486248016357, train acuracy: 0.73828125
step: 65, val loss: 0.7111691236495972, val acuracy: 0.764500081539154
step: 66, train loss: 0.587660551071167, train acuracy: 0.82421875
step: 66, val loss: 0.6486151814460754, val acuracy: 0.7913334369659424
step: 67, train loss: 1.5074182748794556, train acuracy: 0.5341796875
step: 67, val loss: 1.4910777807235718, val acuracy: 0.5331667065620422
step: 68, train loss: 0.8200223445892334, train acuracy: 0.6962890625
step: 68, val loss: 0.8909351229667664, val acuracy: 0.675000011920929
step: 69, train loss: 3.7603015899658203, train acuracy: 0.251953125
step: 69, val loss: 3.6438393592834473, val acuracy: 0.2615000307559967
step: 70, train loss: 1.5579544305801392, train acuracy: 0.40625
step: 70, val loss: 1.5573573112487793, val acuracy: 0.413833349943161
step: 71, train loss: 1.2462949752807617, train acuracy: 0.6220703125
step: 71, val loss: 1.2713481187820435, val acuracy: 0.6305000185966492
step: 72, train loss: 0.9328246116638184, train acuracy: 0.681640625
step: 72, val loss: 0.9262773394584656, val acuracy: 0.6893333792686462
step: 73, train loss: 0.7325745820999146, train acuracy: 0.7646484375
step: 73, val loss: 0.7310839891433716, val acuracy: 0.7610000371932983
step: 74, train loss: 0.6558132767677307, train acuracy: 0.7939453125
step: 74, val loss: 0.7322354316711426, val acuracy: 0.7520000338554382
step: 75, train loss: 0.8249235153198242, train acuracy: 0.765625
step: 75, val loss: 0.7452836632728577, val acuracy: 0.768166720867157
step: 76, train loss: 0.7269917130470276, train acuracy: 0.77734375
step: 76, val loss: 0.7285150289535522, val acuracy: 0.7556667327880859
step: 77, train loss: 0.7616657614707947, train acuracy: 0.7587890625
step: 77, val loss: 0.7510943412780762, val acuracy: 0.7658333778381348
step: 78, train loss: 0.6788074374198914, train acuracy: 0.7763671875
step: 78, val loss: 0.6921054720878601, val acuracy: 0.7633333802223206
step: 79, train loss: 0.7000750303268433, train acuracy: 0.796875
step: 79, val loss: 0.7133595943450928, val acuracy: 0.7733334302902222
step: 80, train loss: 0.7324047088623047, train acuracy: 0.7666015625
step: 80, val loss: 0.7269238829612732, val acuracy: 0.7546666264533997
step: 81, train loss: 0.6708348989486694, train acuracy: 0.7841796875
step: 81, val loss: 0.6327728629112244, val acuracy: 0.8013333678245544
step: 82, train loss: 0.5619542002677917, train acuracy: 0.802734375
step: 82, val loss: 0.6205746531486511, val acuracy: 0.8033334016799927
step: 83, train loss: 0.628611147403717, train acuracy: 0.794921875
step: 83, val loss: 0.6386951804161072, val acuracy: 0.7973334193229675
step: 84, train loss: 0.6643993854522705, train acuracy: 0.7939453125
step: 84, val loss: 0.6566809415817261, val acuracy: 0.7870000004768372
step: 85, train loss: 0.5690554976463318, train acuracy: 0.806640625
step: 85, val loss: 0.6609985828399658, val acuracy: 0.7953333854675293
step: 86, train loss: 0.5528026223182678, train acuracy: 0.8203125
step: 86, val loss: 0.6284079551696777, val acuracy: 0.8000000715255737
step: 87, train loss: 0.6624675393104553, train acuracy: 0.8046875
step: 87, val loss: 0.6224125027656555, val acuracy: 0.8070000410079956
step: 88, train loss: 0.6539039611816406, train acuracy: 0.7998046875
step: 88, val loss: 0.620464563369751, val acuracy: 0.8036667108535767
step: 89, train loss: 0.6281355619430542, train acuracy: 0.7822265625
step: 89, val loss: 0.6653729677200317, val acuracy: 0.7943333983421326
step: 90, train loss: 0.6259884834289551, train acuracy: 0.8056640625
step: 90, val loss: 0.6624096035957336, val acuracy: 0.7950000762939453
step: 91, train loss: 0.6454464197158813, train acuracy: 0.8037109375
step: 91, val loss: 0.6894260048866272, val acuracy: 0.786500096321106
step: 92, train loss: 0.7515205144882202, train acuracy: 0.7900390625
step: 92, val loss: 0.7344378232955933, val acuracy: 0.7723333835601807
step: 93, train loss: 0.6760827302932739, train acuracy: 0.79296875
step: 93, val loss: 0.6756727695465088, val acuracy: 0.7903333902359009
step: 94, train loss: 0.6781026124954224, train acuracy: 0.7861328125
step: 94, val loss: 0.6750435829162598, val acuracy: 0.7903334498405457
step: 95, train loss: 0.6493420004844666, train acuracy: 0.7998046875
step: 95, val loss: 0.6677332520484924, val acuracy: 0.7890000343322754
step: 96, train loss: 0.684154212474823, train acuracy: 0.7841796875
step: 96, val loss: 0.6605252623558044, val acuracy: 0.7953333854675293
step: 97, train loss: 0.7235952615737915, train acuracy: 0.78125
step: 97, val loss: 0.6733574271202087, val acuracy: 0.7885000109672546
step: 98, train loss: 0.6923341155052185, train acuracy: 0.787109375
step: 98, val loss: 0.6881910562515259, val acuracy: 0.7873333692550659
step: 99, train loss: 0.6707567572593689, train acuracy: 0.7861328125
step: 99, val loss: 0.6536695957183838, val acuracy: 0.7890000343322754
step: 100, train loss: 0.5880745649337769, train acuracy: 0.818359375
step: 100, val loss: 0.6528525352478027, val acuracy: 0.7941667437553406
step: 101, train loss: 0.6319587826728821, train acuracy: 0.7919921875
step: 101, val loss: 0.679255485534668, val acuracy: 0.7740001082420349
step: 102, train loss: 0.6425356268882751, train acuracy: 0.8017578125
step: 102, val loss: 0.705213725566864, val acuracy: 0.7804999947547913
step: 103, train loss: 0.6261093616485596, train acuracy: 0.7890625
step: 103, val loss: 0.6638807654380798, val acuracy: 0.7863333821296692
step: 104, train loss: 0.6366876363754272, train acuracy: 0.8173828125
step: 104, val loss: 0.6472102403640747, val acuracy: 0.799500048160553
step: 105, train loss: 0.6027566194534302, train acuracy: 0.8076171875
step: 105, val loss: 0.603069543838501, val acuracy: 0.8085000514984131
step: 106, train loss: 0.539682924747467, train acuracy: 0.8271484375
step: 106, val loss: 0.6179236173629761, val acuracy: 0.8020000457763672
step: 107, train loss: 0.6131312251091003, train acuracy: 0.7939453125
step: 107, val loss: 0.6147181391716003, val acuracy: 0.8035000562667847
step: 108, train loss: 0.6838834285736084, train acuracy: 0.796875
step: 108, val loss: 0.6202700138092041, val acuracy: 0.8009999990463257
step: 109, train loss: 0.614596426486969, train acuracy: 0.818359375
step: 109, val loss: 0.6197677850723267, val acuracy: 0.8020000457763672
step: 110, train loss: 0.585728108882904, train acuracy: 0.798828125
step: 110, val loss: 0.6530848145484924, val acuracy: 0.7813333868980408
step: 111, train loss: 0.68340665102005, train acuracy: 0.7841796875
step: 111, val loss: 0.6416249871253967, val acuracy: 0.7943333387374878
step: 112, train loss: 0.5789437890052795, train acuracy: 0.822265625
step: 112, val loss: 0.6186977624893188, val acuracy: 0.8015000224113464
step: 113, train loss: 0.5637822151184082, train acuracy: 0.8076171875
step: 113, val loss: 0.6314365863800049, val acuracy: 0.8016667366027832
step: 114, train loss: 0.6103243827819824, train acuracy: 0.802734375
step: 114, val loss: 0.6404559016227722, val acuracy: 0.7896667718887329
step: 115, train loss: 0.6975095868110657, train acuracy: 0.79296875
step: 115, val loss: 0.6435149908065796, val acuracy: 0.7943334579467773
step: 116, train loss: 0.5448237657546997, train acuracy: 0.8203125
step: 116, val loss: 0.6326631903648376, val acuracy: 0.7991667985916138
step: 117, train loss: 0.6703070402145386, train acuracy: 0.783203125
step: 117, val loss: 0.6271662712097168, val acuracy: 0.799833357334137
step: 118, train loss: 0.602195143699646, train acuracy: 0.81640625
step: 118, val loss: 0.6325889825820923, val acuracy: 0.7940001487731934
step: 119, train loss: 0.7309360504150391, train acuracy: 0.771484375
step: 119, val loss: 0.6283263564109802, val acuracy: 0.7996667623519897
step: 120, train loss: 0.6043948531150818, train acuracy: 0.79296875
step: 120, val loss: 0.6441718339920044, val acuracy: 0.7908334136009216
step: 121, train loss: 0.6208463907241821, train acuracy: 0.7998046875
step: 121, val loss: 0.6457685232162476, val acuracy: 0.7955000996589661
step: 122, train loss: 0.5645989179611206, train acuracy: 0.8115234375
step: 122, val loss: 0.6163336038589478, val acuracy: 0.8030001521110535
step: 123, train loss: 0.7577115893363953, train acuracy: 0.7529296875
step: 123, val loss: 0.7570021152496338, val acuracy: 0.7550000548362732
step: 124, train loss: 0.7764345407485962, train acuracy: 0.7392578125
step: 124, val loss: 0.7387306094169617, val acuracy: 0.7583334445953369
step: 125, train loss: 0.720137357711792, train acuracy: 0.779296875
step: 125, val loss: 0.7737640142440796, val acuracy: 0.7623333930969238
step: 126, train loss: 0.7080014944076538, train acuracy: 0.755859375
step: 126, val loss: 0.8205443620681763, val acuracy: 0.7348333597183228
step: 127, train loss: 0.8307790756225586, train acuracy: 0.7509765625
step: 127, val loss: 0.7593185305595398, val acuracy: 0.7616667151451111
step: 128, train loss: 0.7298197150230408, train acuracy: 0.763671875
step: 128, val loss: 0.7580440044403076, val acuracy: 0.7501667141914368
step: 129, train loss: 0.7553157806396484, train acuracy: 0.7626953125
step: 129, val loss: 0.7696387767791748, val acuracy: 0.7635000944137573
step: 130, train loss: 0.7579581141471863, train acuracy: 0.76171875
step: 130, val loss: 0.7449674606323242, val acuracy: 0.7556667327880859
step: 131, train loss: 0.7023566961288452, train acuracy: 0.791015625
step: 131, val loss: 0.7585465312004089, val acuracy: 0.7610000371932983
step: 132, train loss: 0.7586110830307007, train acuracy: 0.73828125
step: 132, val loss: 0.7644742131233215, val acuracy: 0.7431667447090149
step: 133, train loss: 0.818977952003479, train acuracy: 0.74609375
step: 133, val loss: 0.7636228799819946, val acuracy: 0.7608334422111511
step: 134, train loss: 0.7097799181938171, train acuracy: 0.7802734375
step: 134, val loss: 0.7559237480163574, val acuracy: 0.7556667327880859
step: 135, train loss: 0.7400437593460083, train acuracy: 0.7626953125
step: 135, val loss: 0.744935154914856, val acuracy: 0.7623334527015686
step: 136, train loss: 0.7335255146026611, train acuracy: 0.76953125
step: 136, val loss: 0.7428905963897705, val acuracy: 0.7591667771339417
step: 137, train loss: 0.6770154237747192, train acuracy: 0.765625
step: 137, val loss: 0.7502987384796143, val acuracy: 0.7503334879875183
step: 138, train loss: 0.6448478102684021, train acuracy: 0.78515625
step: 138, val loss: 0.7624483108520508, val acuracy: 0.7561667561531067
step: 139, train loss: 0.812021017074585, train acuracy: 0.7431640625
step: 139, val loss: 0.7748647928237915, val acuracy: 0.749500036239624
step: 140, train loss: 2.201617956161499, train acuracy: 0.4638671875
step: 140, val loss: 2.168224334716797, val acuracy: 0.4766666889190674
step: 141, train loss: 1.1666758060455322, train acuracy: 0.6650390625
step: 141, val loss: 1.1093546152114868, val acuracy: 0.6801667213439941
step: 142, train loss: 1.4815702438354492, train acuracy: 0.4384765625
step: 142, val loss: 1.4836220741271973, val acuracy: 0.4308333396911621
step: 143, train loss: 1.4489836692810059, train acuracy: 0.447265625
step: 143, val loss: 1.4199341535568237, val acuracy: 0.4570000171661377
step: 144, train loss: 1.4732956886291504, train acuracy: 0.4560546875
step: 144, val loss: 1.4250379800796509, val acuracy: 0.45366668701171875
step: 145, train loss: 1.4150722026824951, train acuracy: 0.4501953125
step: 145, val loss: 1.4229316711425781, val acuracy: 0.4555000066757202
step: 146, train loss: 1.4692891836166382, train acuracy: 0.4375
step: 146, val loss: 1.422489881515503, val acuracy: 0.4553333520889282
step: 147, train loss: 1.4394949674606323, train acuracy: 0.4599609375
step: 147, val loss: 1.4220885038375854, val acuracy: 0.4556666910648346
step: 148, train loss: 1.4248309135437012, train acuracy: 0.4462890625
step: 148, val loss: 1.4220194816589355, val acuracy: 0.4556666612625122
step: 149, train loss: 1.4152302742004395, train acuracy: 0.462890625
step: 149, val loss: 1.4217643737792969, val acuracy: 0.45516666769981384
step: 150, train loss: 1.4523626565933228, train acuracy: 0.451171875
step: 150, val loss: 1.4219536781311035, val acuracy: 0.4560000002384186
step: 151, train loss: 1.3889213800430298, train acuracy: 0.46484375
step: 151, val loss: 1.4220374822616577, val acuracy: 0.45750001072883606
step: 152, train loss: 1.3890572786331177, train acuracy: 0.4580078125
step: 152, val loss: 1.4218173027038574, val acuracy: 0.4585000276565552
step: 153, train loss: 1.40742826461792, train acuracy: 0.4560546875
step: 153, val loss: 1.4219356775283813, val acuracy: 0.4598333537578583
step: 154, train loss: 1.3669757843017578, train acuracy: 0.4765625
step: 154, val loss: 1.4217450618743896, val acuracy: 0.46033334732055664
step: 155, train loss: 1.4058866500854492, train acuracy: 0.4658203125
step: 155, val loss: 1.4216474294662476, val acuracy: 0.46033334732055664
step: 156, train loss: 1.3663883209228516, train acuracy: 0.48046875
step: 156, val loss: 1.4264142513275146, val acuracy: 0.4531666934490204
step: 157, train loss: 1.3892170190811157, train acuracy: 0.4765625
step: 157, val loss: 1.428697943687439, val acuracy: 0.455500066280365
step: 158, train loss: 1.4157381057739258, train acuracy: 0.4609375
step: 158, val loss: 1.4279630184173584, val acuracy: 0.45516669750213623
step: 159, train loss: 1.4638187885284424, train acuracy: 0.4658203125
step: 159, val loss: 1.4275362491607666, val acuracy: 0.4553333520889282
step: 160, train loss: 1.4635411500930786, train acuracy: 0.4658203125
step: 160, val loss: 1.4315760135650635, val acuracy: 0.46533334255218506
step: 161, train loss: 1.5309059619903564, train acuracy: 0.4638671875
step: 161, val loss: 1.5302600860595703, val acuracy: 0.45133331418037415
step: 162, train loss: 1.556344985961914, train acuracy: 0.455078125
step: 162, val loss: 1.5617766380310059, val acuracy: 0.4531667232513428
step: 163, train loss: 1.5754364728927612, train acuracy: 0.482421875
step: 163, val loss: 1.5523812770843506, val acuracy: 0.47566670179367065
step: 164, train loss: 1.5841761827468872, train acuracy: 0.4697265625
step: 164, val loss: 1.5540246963500977, val acuracy: 0.476333349943161
step: 165, train loss: 1.5120757818222046, train acuracy: 0.5283203125
step: 165, val loss: 1.552728533744812, val acuracy: 0.5191667079925537
step: 166, train loss: 1.4981170892715454, train acuracy: 0.5185546875
step: 166, val loss: 1.5230213403701782, val acuracy: 0.5320000052452087
step: 167, train loss: 1.6577250957489014, train acuracy: 0.5146484375
step: 167, val loss: 1.537063479423523, val acuracy: 0.5514999628067017
step: 168, train loss: 1.4539175033569336, train acuracy: 0.54296875
step: 168, val loss: 1.4911189079284668, val acuracy: 0.5519999861717224
step: 169, train loss: 1.5204243659973145, train acuracy: 0.53125
step: 169, val loss: 1.500199317932129, val acuracy: 0.5353333950042725
step: 170, train loss: 1.4810503721237183, train acuracy: 0.5126953125
step: 170, val loss: 1.5327143669128418, val acuracy: 0.49766671657562256
step: 171, train loss: 1.5465216636657715, train acuracy: 0.478515625
step: 171, val loss: 1.592515230178833, val acuracy: 0.4361667037010193
step: 172, train loss: 1.154431939125061, train acuracy: 0.6416015625
step: 172, val loss: 1.1826645135879517, val acuracy: 0.6198334097862244
step: 173, train loss: 1.1609418392181396, train acuracy: 0.607421875
step: 173, val loss: 1.1987875699996948, val acuracy: 0.6069999933242798
step: 174, train loss: 1.1592490673065186, train acuracy: 0.62890625
step: 174, val loss: 1.1864888668060303, val acuracy: 0.6146667003631592
step: 175, train loss: 1.1342134475708008, train acuracy: 0.642578125
step: 175, val loss: 1.1515772342681885, val acuracy: 0.6220000386238098
step: 176, train loss: 1.1166322231292725, train acuracy: 0.6318359375
step: 176, val loss: 1.0975364446640015, val acuracy: 0.6388333439826965
step: 177, train loss: 1.0642101764678955, train acuracy: 0.658203125
step: 177, val loss: 1.0985417366027832, val acuracy: 0.6348333954811096
step: 178, train loss: 1.0739657878875732, train acuracy: 0.6533203125
step: 178, val loss: 1.0973178148269653, val acuracy: 0.6348333358764648
step: 179, train loss: 1.082474946975708, train acuracy: 0.6640625
step: 179, val loss: 1.0962867736816406, val acuracy: 0.6381667256355286
step: 180, train loss: 1.087496280670166, train acuracy: 0.64453125
step: 180, val loss: 1.1005561351776123, val acuracy: 0.6361667513847351
step: 181, train loss: 1.1369471549987793, train acuracy: 0.6376953125
step: 181, val loss: 1.1150457859039307, val acuracy: 0.6350000500679016
step: 182, train loss: 1.117510199546814, train acuracy: 0.5966796875
step: 182, val loss: 1.1333571672439575, val acuracy: 0.59333336353302
step: 183, train loss: 1.1377743482589722, train acuracy: 0.646484375
step: 183, val loss: 1.1404162645339966, val acuracy: 0.6393333673477173
step: 184, train loss: 1.0823783874511719, train acuracy: 0.638671875
step: 184, val loss: 1.1098301410675049, val acuracy: 0.6400001049041748
step: 185, train loss: 1.108070969581604, train acuracy: 0.6328125
step: 185, val loss: 1.1113781929016113, val acuracy: 0.6491667032241821
step: 186, train loss: 1.0844250917434692, train acuracy: 0.650390625
step: 186, val loss: 1.1099579334259033, val acuracy: 0.6478333473205566
step: 187, train loss: 1.1071299314498901, train acuracy: 0.638671875
step: 187, val loss: 1.108230710029602, val acuracy: 0.6426666378974915
step: 188, train loss: 1.113073468208313, train acuracy: 0.6337890625
step: 188, val loss: 1.1104978322982788, val acuracy: 0.6390000581741333
step: 189, train loss: 1.0922589302062988, train acuracy: 0.6328125
step: 189, val loss: 1.1086100339889526, val acuracy: 0.6386667490005493
step: 190, train loss: 1.0620436668395996, train acuracy: 0.6484375
step: 190, val loss: 1.1079115867614746, val acuracy: 0.6391667127609253
step: 191, train loss: 1.1290193796157837, train acuracy: 0.63671875
step: 191, val loss: 1.107865810394287, val acuracy: 0.6396666765213013
step: 192, train loss: 1.1886436939239502, train acuracy: 0.6083984375
step: 192, val loss: 1.2287700176239014, val acuracy: 0.5866666436195374
step: 193, train loss: 1.1042234897613525, train acuracy: 0.630859375
step: 193, val loss: 1.1488292217254639, val acuracy: 0.6190000772476196
step: 194, train loss: 1.1098650693893433, train acuracy: 0.6328125
step: 194, val loss: 1.1306931972503662, val acuracy: 0.6340000629425049
step: 195, train loss: 1.1076425313949585, train acuracy: 0.6513671875
step: 195, val loss: 1.1389861106872559, val acuracy: 0.6580000519752502
step: 196, train loss: 1.2571110725402832, train acuracy: 0.59765625
step: 196, val loss: 1.1354117393493652, val acuracy: 0.6423333883285522
step: 197, train loss: 1.1423782110214233, train acuracy: 0.669921875
step: 197, val loss: 1.130958080291748, val acuracy: 0.6720000505447388
step: 198, train loss: 1.0328049659729004, train acuracy: 0.669921875
step: 198, val loss: 1.095536231994629, val acuracy: 0.6598333120346069
step: 199, train loss: 1.5022531747817993, train acuracy: 0.421875
step: 199, val loss: 1.4642001390457153, val acuracy: 0.43400001525878906
step: 200, train loss: 1.0808321237564087, train acuracy: 0.6171875
step: 200, val loss: 1.1182637214660645, val acuracy: 0.627833366394043
step: 201, train loss: 1.15423583984375, train acuracy: 0.63671875
step: 201, val loss: 1.141411542892456, val acuracy: 0.6463333964347839
step: 202, train loss: 1.1949154138565063, train acuracy: 0.638671875
step: 202, val loss: 1.1229931116104126, val acuracy: 0.6411666870117188
step: 203, train loss: 1.077001690864563, train acuracy: 0.666015625
step: 203, val loss: 1.1089904308319092, val acuracy: 0.6705000996589661
step: 204, train loss: 0.9921643137931824, train acuracy: 0.685546875
step: 204, val loss: 1.0695093870162964, val acuracy: 0.6675000786781311
step: 205, train loss: 1.0414252281188965, train acuracy: 0.6884765625
step: 205, val loss: 1.0628079175949097, val acuracy: 0.684166669845581
step: 206, train loss: 0.8720959424972534, train acuracy: 0.7275390625
step: 206, val loss: 1.0535311698913574, val acuracy: 0.6800000667572021
step: 207, train loss: 0.9740346074104309, train acuracy: 0.7119140625
step: 207, val loss: 1.0411689281463623, val acuracy: 0.6853333711624146
step: 208, train loss: 0.9846131801605225, train acuracy: 0.681640625
step: 208, val loss: 1.0493173599243164, val acuracy: 0.6843334436416626
step: 209, train loss: 1.0197833776474, train acuracy: 0.6884765625
step: 209, val loss: 1.0269670486450195, val acuracy: 0.6860001087188721
step: 210, train loss: 0.8916202783584595, train acuracy: 0.7177734375
step: 210, val loss: 1.0314111709594727, val acuracy: 0.6843333840370178
step: 211, train loss: 1.0607136487960815, train acuracy: 0.66015625
step: 211, val loss: 1.0462510585784912, val acuracy: 0.6760000586509705
step: 212, train loss: 1.0403085947036743, train acuracy: 0.671875
step: 212, val loss: 1.0442075729370117, val acuracy: 0.6845000982284546
step: 213, train loss: 0.9573837518692017, train acuracy: 0.7041015625
step: 213, val loss: 1.0342427492141724, val acuracy: 0.686500072479248
step: 214, train loss: 1.0363065004348755, train acuracy: 0.697265625
step: 214, val loss: 1.0630418062210083, val acuracy: 0.668666660785675
step: 215, train loss: 0.9852926731109619, train acuracy: 0.6943359375
step: 215, val loss: 1.0566548109054565, val acuracy: 0.6826667189598083
step: 216, train loss: 0.9827089309692383, train acuracy: 0.6962890625
step: 216, val loss: 1.0809223651885986, val acuracy: 0.6620000004768372
step: 217, train loss: 0.977285623550415, train acuracy: 0.69921875
step: 217, val loss: 1.0557255744934082, val acuracy: 0.684333324432373
step: 218, train loss: 0.9455054998397827, train acuracy: 0.693359375
step: 218, val loss: 1.0513973236083984, val acuracy: 0.6771666407585144
step: 219, train loss: 0.9968709349632263, train acuracy: 0.6796875
step: 219, val loss: 1.0516791343688965, val acuracy: 0.6803333759307861
step: 220, train loss: 0.9756587147712708, train acuracy: 0.6953125
step: 220, val loss: 1.0651249885559082, val acuracy: 0.671500027179718
step: 221, train loss: 1.0458807945251465, train acuracy: 0.6845703125
step: 221, val loss: 1.051065444946289, val acuracy: 0.671833336353302
step: 222, train loss: 0.9980511665344238, train acuracy: 0.7197265625
step: 222, val loss: 1.0409120321273804, val acuracy: 0.6876667141914368
step: 223, train loss: 1.0585222244262695, train acuracy: 0.6767578125
step: 223, val loss: 1.0474936962127686, val acuracy: 0.6800000667572021
step: 224, train loss: 1.0004549026489258, train acuracy: 0.6884765625
step: 224, val loss: 1.0448405742645264, val acuracy: 0.6785000562667847
step: 225, train loss: 0.9758676886558533, train acuracy: 0.6982421875
step: 225, val loss: 1.0714519023895264, val acuracy: 0.6830000281333923
step: 226, train loss: 1.0324420928955078, train acuracy: 0.6845703125
step: 226, val loss: 1.0453338623046875, val acuracy: 0.6733334064483643
step: 227, train loss: 0.9808536767959595, train acuracy: 0.7119140625
step: 227, val loss: 1.0612907409667969, val acuracy: 0.6706668138504028
step: 228, train loss: 1.1368112564086914, train acuracy: 0.630859375
step: 228, val loss: 1.0853849649429321, val acuracy: 0.6531667113304138
step: 229, train loss: 1.0343855619430542, train acuracy: 0.689453125
step: 229, val loss: 1.0520541667938232, val acuracy: 0.6733334064483643
step: 230, train loss: 0.9472483396530151, train acuracy: 0.705078125
step: 230, val loss: 1.0641640424728394, val acuracy: 0.6640000939369202
step: 231, train loss: 0.9680843353271484, train acuracy: 0.72265625
step: 231, val loss: 1.0666941404342651, val acuracy: 0.6881667375564575
step: 232, train loss: 1.1846519708633423, train acuracy: 0.63671875
step: 232, val loss: 1.0668973922729492, val acuracy: 0.6576667428016663
step: 233, train loss: 1.0709967613220215, train acuracy: 0.669921875
step: 233, val loss: 1.070853352546692, val acuracy: 0.6660000681877136
step: 234, train loss: 0.999439001083374, train acuracy: 0.697265625
step: 234, val loss: 1.0644896030426025, val acuracy: 0.6681667566299438
step: 235, train loss: 1.0111775398254395, train acuracy: 0.703125
step: 235, val loss: 1.07833731174469, val acuracy: 0.6623333692550659
step: 236, train loss: 1.021340012550354, train acuracy: 0.677734375
step: 236, val loss: 1.0602755546569824, val acuracy: 0.6818333864212036
step: 237, train loss: 0.981200098991394, train acuracy: 0.68359375
step: 237, val loss: 1.0513402223587036, val acuracy: 0.6815000772476196
step: 238, train loss: 1.0256311893463135, train acuracy: 0.6787109375
step: 238, val loss: 1.070436716079712, val acuracy: 0.6759999990463257
step: 239, train loss: 1.1327874660491943, train acuracy: 0.673828125
step: 239, val loss: 1.0670347213745117, val acuracy: 0.6771667003631592
step: 240, train loss: 0.9673229455947876, train acuracy: 0.701171875
step: 240, val loss: 1.078326940536499, val acuracy: 0.6815000772476196
step: 241, train loss: 0.9609140753746033, train acuracy: 0.72265625
step: 241, val loss: 1.0903874635696411, val acuracy: 0.6811667680740356
step: 242, train loss: 1.0361554622650146, train acuracy: 0.6923828125
step: 242, val loss: 1.0967234373092651, val acuracy: 0.6826667189598083
step: 243, train loss: 1.1010876893997192, train acuracy: 0.66015625
step: 243, val loss: 1.1068565845489502, val acuracy: 0.658500075340271
step: 244, train loss: 1.1217411756515503, train acuracy: 0.6767578125
step: 244, val loss: 1.1233820915222168, val acuracy: 0.671999990940094
step: 245, train loss: 0.9952594041824341, train acuracy: 0.6826171875
step: 245, val loss: 1.1459773778915405, val acuracy: 0.6465000510215759
step: 246, train loss: 1.0659539699554443, train acuracy: 0.6962890625
step: 246, val loss: 1.1026642322540283, val acuracy: 0.6685000658035278
step: 247, train loss: 1.0526988506317139, train acuracy: 0.6533203125
step: 247, val loss: 1.104961633682251, val acuracy: 0.661500096321106
step: 248, train loss: 1.1834570169448853, train acuracy: 0.6513671875
step: 248, val loss: 1.0957237482070923, val acuracy: 0.6705000400543213
step: 249, train loss: 1.1065948009490967, train acuracy: 0.66015625
step: 249, val loss: 1.0981091260910034, val acuracy: 0.6630001068115234
step: 250, train loss: 1.046082854270935, train acuracy: 0.67578125
step: 250, val loss: 1.10892653465271, val acuracy: 0.6756666898727417
step: 251, train loss: 1.1662592887878418, train acuracy: 0.6513671875
step: 251, val loss: 1.1074907779693604, val acuracy: 0.6568333506584167
step: 252, train loss: 1.0004475116729736, train acuracy: 0.708984375
step: 252, val loss: 1.1341793537139893, val acuracy: 0.6730000376701355
step: 253, train loss: 1.122376799583435, train acuracy: 0.6416015625
step: 253, val loss: 1.132727861404419, val acuracy: 0.6410000324249268
step: 254, train loss: 1.1240036487579346, train acuracy: 0.6630859375
step: 254, val loss: 1.1080299615859985, val acuracy: 0.6700000166893005
step: 255, train loss: 1.0548195838928223, train acuracy: 0.6923828125
step: 255, val loss: 1.1142094135284424, val acuracy: 0.6568334102630615
step: 256, train loss: 1.053840160369873, train acuracy: 0.6552734375
step: 256, val loss: 1.1380581855773926, val acuracy: 0.6473333835601807
step: 257, train loss: 1.079396367073059, train acuracy: 0.6748046875
step: 257, val loss: 1.1294541358947754, val acuracy: 0.6525000333786011
step: 258, train loss: 0.9119434356689453, train acuracy: 0.7138671875
step: 258, val loss: 1.1248466968536377, val acuracy: 0.661666750907898
step: 259, train loss: 1.032712459564209, train acuracy: 0.6953125
step: 259, val loss: 1.1138345003128052, val acuracy: 0.65583336353302
step: 260, train loss: 1.0466240644454956, train acuracy: 0.66796875
step: 260, val loss: 1.1207748651504517, val acuracy: 0.6625000238418579
step: 261, train loss: 1.118641972541809, train acuracy: 0.666015625
step: 261, val loss: 1.1366124153137207, val acuracy: 0.655333399772644
step: 262, train loss: 1.026102066040039, train acuracy: 0.6923828125
step: 262, val loss: 1.1952109336853027, val acuracy: 0.6490000486373901
step: 263, train loss: 1.232598066329956, train acuracy: 0.60546875
step: 263, val loss: 1.2546534538269043, val acuracy: 0.6213333606719971
step: 264, train loss: 1.1372978687286377, train acuracy: 0.646484375
step: 264, val loss: 1.1418468952178955, val acuracy: 0.6496667861938477
step: 265, train loss: 1.0783653259277344, train acuracy: 0.6748046875
step: 265, val loss: 1.16300630569458, val acuracy: 0.6610000133514404
step: 266, train loss: 1.1426578760147095, train acuracy: 0.69140625
step: 266, val loss: 1.1541523933410645, val acuracy: 0.6611666679382324
step: 267, train loss: 1.083364725112915, train acuracy: 0.65625
step: 267, val loss: 1.1535582542419434, val acuracy: 0.6611666679382324
step: 268, train loss: 1.0745248794555664, train acuracy: 0.677734375
step: 268, val loss: 1.1566485166549683, val acuracy: 0.6601666808128357
step: 269, train loss: 1.1535968780517578, train acuracy: 0.6259765625
step: 269, val loss: 1.24068284034729, val acuracy: 0.624666690826416
step: 270, train loss: 1.0573915243148804, train acuracy: 0.650390625
step: 270, val loss: 1.1930646896362305, val acuracy: 0.6324999928474426
step: 271, train loss: 1.1421995162963867, train acuracy: 0.63671875
step: 271, val loss: 1.1977134943008423, val acuracy: 0.6343333721160889
step: 272, train loss: 1.1528211832046509, train acuracy: 0.6611328125
step: 272, val loss: 1.2026753425598145, val acuracy: 0.6296667456626892
step: 273, train loss: 1.189651608467102, train acuracy: 0.6337890625
step: 273, val loss: 1.204880952835083, val acuracy: 0.6231666803359985
step: 274, train loss: 1.1780320405960083, train acuracy: 0.6494140625
step: 274, val loss: 1.223496437072754, val acuracy: 0.6260001063346863
step: 275, train loss: 1.2374296188354492, train acuracy: 0.609375
step: 275, val loss: 1.2399200201034546, val acuracy: 0.6133334040641785
step: 276, train loss: 1.1671980619430542, train acuracy: 0.6435546875
step: 276, val loss: 1.2528114318847656, val acuracy: 0.6166666746139526
step: 277, train loss: 1.143640398979187, train acuracy: 0.638671875
step: 277, val loss: 1.20332932472229, val acuracy: 0.624500036239624
step: 278, train loss: 1.1816461086273193, train acuracy: 0.6455078125
step: 278, val loss: 1.2021392583847046, val acuracy: 0.6251667141914368
step: 279, train loss: 1.1085004806518555, train acuracy: 0.662109375
step: 279, val loss: 1.2144807577133179, val acuracy: 0.6263334155082703
step: 280, train loss: 1.2998175621032715, train acuracy: 0.5908203125
step: 280, val loss: 1.2583123445510864, val acuracy: 0.5800000429153442
step: 281, train loss: 1.215270757675171, train acuracy: 0.6142578125
step: 281, val loss: 1.2509791851043701, val acuracy: 0.5861666798591614
step: 282, train loss: 1.3659589290618896, train acuracy: 0.5166015625
step: 282, val loss: 1.5118242502212524, val acuracy: 0.4818333387374878
step: 283, train loss: 1.3366600275039673, train acuracy: 0.51171875
step: 283, val loss: 1.3793838024139404, val acuracy: 0.5023333430290222
step: 284, train loss: 1.4827641248703003, train acuracy: 0.498046875
step: 284, val loss: 1.3870527744293213, val acuracy: 0.49433332681655884
step: 285, train loss: 1.3553472757339478, train acuracy: 0.5166015625
step: 285, val loss: 1.3519678115844727, val acuracy: 0.5148333311080933
step: 286, train loss: 1.3092191219329834, train acuracy: 0.53125
step: 286, val loss: 1.354441523551941, val acuracy: 0.5190000534057617
step: 287, train loss: 1.3321648836135864, train acuracy: 0.5244140625
step: 287, val loss: 1.3513948917388916, val acuracy: 0.5206667184829712
step: 288, train loss: 1.3325690031051636, train acuracy: 0.5107421875
step: 288, val loss: 1.3565725088119507, val acuracy: 0.5214999914169312
step: 289, train loss: 1.296250343322754, train acuracy: 0.525390625
step: 289, val loss: 1.3622446060180664, val acuracy: 0.5318334102630615
step: 290, train loss: 1.295159101486206, train acuracy: 0.5576171875
step: 290, val loss: 1.3502997159957886, val acuracy: 0.5266667008399963
step: 291, train loss: 1.4033119678497314, train acuracy: 0.494140625
step: 291, val loss: 1.3663794994354248, val acuracy: 0.5010000467300415
step: 292, train loss: 1.2815194129943848, train acuracy: 0.537109375
step: 292, val loss: 1.3786026239395142, val acuracy: 0.5356667041778564
step: 293, train loss: 1.2332539558410645, train acuracy: 0.55859375
step: 293, val loss: 1.3555938005447388, val acuracy: 0.5258333683013916
step: 294, train loss: 1.3681859970092773, train acuracy: 0.494140625
step: 294, val loss: 1.3925433158874512, val acuracy: 0.49183332920074463
step: 295, train loss: 1.3707597255706787, train acuracy: 0.51953125
step: 295, val loss: 1.3884543180465698, val acuracy: 0.49166667461395264
step: 296, train loss: 1.3402459621429443, train acuracy: 0.529296875
step: 296, val loss: 1.4112179279327393, val acuracy: 0.5091667175292969
step: 297, train loss: 1.2865142822265625, train acuracy: 0.5283203125
step: 297, val loss: 1.3996751308441162, val acuracy: 0.49266672134399414
step: 298, train loss: 1.331694483757019, train acuracy: 0.5419921875
step: 298, val loss: 1.4130918979644775, val acuracy: 0.5095000267028809
step: 299, train loss: 1.4078409671783447, train acuracy: 0.48828125
step: 299, val loss: 1.4105615615844727, val acuracy: 0.5081666707992554
step: 300, train loss: 1.4443364143371582, train acuracy: 0.5107421875
step: 300, val loss: 1.403627634048462, val acuracy: 0.5130000710487366
step: 301, train loss: 1.40179443359375, train acuracy: 0.5126953125
step: 301, val loss: 1.4080545902252197, val acuracy: 0.5085000395774841
step: 302, train loss: 1.284385323524475, train acuracy: 0.5341796875
step: 302, val loss: 1.4093014001846313, val acuracy: 0.5076667070388794
step: 303, train loss: 2.449507713317871, train acuracy: 0.4140625
step: 303, val loss: 2.383774757385254, val acuracy: 0.41216665506362915
step: 304, train loss: 1.662989616394043, train acuracy: 0.5234375
step: 304, val loss: 1.8336009979248047, val acuracy: 0.47550004720687866
step: 305, train loss: 1.8451495170593262, train acuracy: 0.4873046875
step: 305, val loss: 1.8520137071609497, val acuracy: 0.48350000381469727
step: 306, train loss: 1.6499468088150024, train acuracy: 0.4833984375
step: 306, val loss: 1.7248648405075073, val acuracy: 0.4700000286102295
step: 307, train loss: 1.672276496887207, train acuracy: 0.435546875
step: 307, val loss: 1.6837652921676636, val acuracy: 0.43383336067199707
step: 308, train loss: 1.5812125205993652, train acuracy: 0.4501953125
step: 308, val loss: 1.6695537567138672, val acuracy: 0.4371667206287384
step: 309, train loss: 1.639676809310913, train acuracy: 0.4287109375
step: 309, val loss: 1.680991291999817, val acuracy: 0.43800002336502075
step: 310, train loss: 1.4963074922561646, train acuracy: 0.4736328125
step: 310, val loss: 1.7005382776260376, val acuracy: 0.45216670632362366
step: 311, train loss: 1.642924427986145, train acuracy: 0.455078125
step: 311, val loss: 1.7070484161376953, val acuracy: 0.45366665720939636
step: 312, train loss: 1.6093405485153198, train acuracy: 0.470703125
step: 312, val loss: 1.702399730682373, val acuracy: 0.4545000195503235
step: 313, train loss: 1.7482554912567139, train acuracy: 0.4375
step: 313, val loss: 1.7109575271606445, val acuracy: 0.45100003480911255
step: 314, train loss: 1.5200693607330322, train acuracy: 0.4921875
step: 314, val loss: 1.7089259624481201, val acuracy: 0.45250004529953003
step: 315, train loss: 1.7793183326721191, train acuracy: 0.419921875
step: 315, val loss: 1.7098298072814941, val acuracy: 0.43933334946632385
step: 316, train loss: 1.6861376762390137, train acuracy: 0.4521484375
step: 316, val loss: 1.7015726566314697, val acuracy: 0.44200003147125244
step: 317, train loss: 1.9179165363311768, train acuracy: 0.4091796875
step: 317, val loss: 2.0219147205352783, val acuracy: 0.413833349943161
step: 318, train loss: 1.914045810699463, train acuracy: 0.4384765625
step: 318, val loss: 1.9903405904769897, val acuracy: 0.4205000400543213
step: 319, train loss: 2.0056471824645996, train acuracy: 0.4208984375
step: 319, val loss: 1.992761492729187, val acuracy: 0.4206666648387909
step: 320, train loss: 1.9177422523498535, train acuracy: 0.43359375
step: 320, val loss: 1.9824891090393066, val acuracy: 0.4398333430290222
step: 321, train loss: 1.8677235841751099, train acuracy: 0.42578125
step: 321, val loss: 1.98817777633667, val acuracy: 0.4271666705608368
step: 322, train loss: 1.8491675853729248, train acuracy: 0.4345703125
step: 322, val loss: 1.9863157272338867, val acuracy: 0.42633330821990967
step: 323, train loss: 1.928531289100647, train acuracy: 0.4326171875
step: 323, val loss: 1.9832873344421387, val acuracy: 0.4271667003631592
step: 324, train loss: 2.0110154151916504, train acuracy: 0.3837890625
step: 324, val loss: 2.03024959564209, val acuracy: 0.38983336091041565
step: 325, train loss: 1.9994864463806152, train acuracy: 0.3828125
step: 325, val loss: 2.0208027362823486, val acuracy: 0.3930000364780426
step: 326, train loss: 1.981031894683838, train acuracy: 0.392578125
step: 326, val loss: 2.053652048110962, val acuracy: 0.367166668176651
step: 327, train loss: 2.090623378753662, train acuracy: 0.3779296875
step: 327, val loss: 2.051201581954956, val acuracy: 0.3958333730697632
step: 328, train loss: 2.114354133605957, train acuracy: 0.4052734375
step: 328, val loss: 2.0646934509277344, val acuracy: 0.39383333921432495
step: 329, train loss: 1.9791038036346436, train acuracy: 0.3828125
step: 329, val loss: 2.0475215911865234, val acuracy: 0.3863333463668823
step: 330, train loss: 2.0728092193603516, train acuracy: 0.3642578125
step: 330, val loss: 2.0595762729644775, val acuracy: 0.3786666989326477
step: 331, train loss: 2.081005573272705, train acuracy: 0.375
step: 331, val loss: 2.097249984741211, val acuracy: 0.38066667318344116
step: 332, train loss: 1.9940972328186035, train acuracy: 0.392578125
step: 332, val loss: 2.0550427436828613, val acuracy: 0.37000003457069397
step: 333, train loss: 2.142035961151123, train acuracy: 0.3564453125
step: 333, val loss: 2.0581445693969727, val acuracy: 0.3581666946411133
step: 334, train loss: 1.9425806999206543, train acuracy: 0.4140625
step: 334, val loss: 2.058913469314575, val acuracy: 0.37050002813339233
step: 335, train loss: 2.0801186561584473, train acuracy: 0.3896484375
step: 335, val loss: 2.0658605098724365, val acuracy: 0.40966665744781494
step: 336, train loss: 2.2231099605560303, train acuracy: 0.34375
step: 336, val loss: 2.073965072631836, val acuracy: 0.37433335185050964
step: 337, train loss: 2.0355191230773926, train acuracy: 0.390625
step: 337, val loss: 2.0880630016326904, val acuracy: 0.3675000071525574
step: 338, train loss: 2.182483196258545, train acuracy: 0.427734375
step: 338, val loss: 2.2291202545166016, val acuracy: 0.4148333668708801
step: 339, train loss: 2.1649329662323, train acuracy: 0.4326171875
step: 339, val loss: 2.218425989151001, val acuracy: 0.3946666717529297
step: 340, train loss: 1.6846808195114136, train acuracy: 0.556640625
step: 340, val loss: 1.6644963026046753, val acuracy: 0.5648333430290222
step: 341, train loss: 1.692716360092163, train acuracy: 0.5341796875
step: 341, val loss: 1.690617322921753, val acuracy: 0.5428333878517151
step: 342, train loss: 1.3535360097885132, train acuracy: 0.5458984375
step: 342, val loss: 1.4042344093322754, val acuracy: 0.5293333530426025
step: 343, train loss: 1.1145416498184204, train acuracy: 0.6142578125
step: 343, val loss: 1.0698164701461792, val acuracy: 0.6415000557899475
step: 344, train loss: 1.0512139797210693, train acuracy: 0.6923828125
step: 344, val loss: 1.0273483991622925, val acuracy: 0.6951667070388794
step: 345, train loss: 0.9949229955673218, train acuracy: 0.6533203125
step: 345, val loss: 1.0348395109176636, val acuracy: 0.6481667757034302
step: 346, train loss: 0.6989614367485046, train acuracy: 0.7734375
step: 346, val loss: 0.7036616802215576, val acuracy: 0.7751667499542236
step: 347, train loss: 0.5927726030349731, train acuracy: 0.8193359375
step: 347, val loss: 0.5344898700714111, val acuracy: 0.8475000858306885
step: 348, train loss: 0.5575857162475586, train acuracy: 0.8310546875
step: 348, val loss: 0.5266197323799133, val acuracy: 0.8496667146682739
step: 349, train loss: 0.5037482380867004, train acuracy: 0.8369140625
step: 349, val loss: 0.5345066785812378, val acuracy: 0.8365001082420349
step: 350, train loss: 0.5253292322158813, train acuracy: 0.8466796875
step: 350, val loss: 0.5276704430580139, val acuracy: 0.8326667547225952
step: 351, train loss: 0.47134658694267273, train acuracy: 0.8525390625
step: 351, val loss: 0.5007251501083374, val acuracy: 0.8478333950042725
step: 352, train loss: 0.5310814380645752, train acuracy: 0.845703125
step: 352, val loss: 0.49696987867355347, val acuracy: 0.8495001196861267
step: 353, train loss: 0.5699549913406372, train acuracy: 0.8388671875
step: 353, val loss: 0.517926812171936, val acuracy: 0.8380000591278076
step: 354, train loss: 0.5203105807304382, train acuracy: 0.8408203125
step: 354, val loss: 0.5059717297554016, val acuracy: 0.8496667146682739
step: 355, train loss: 0.5419020652770996, train acuracy: 0.83203125
step: 355, val loss: 0.49318236112594604, val acuracy: 0.8521667122840881
step: 356, train loss: 0.4871566593647003, train acuracy: 0.8564453125
step: 356, val loss: 0.504754364490509, val acuracy: 0.8501667380332947
step: 357, train loss: 0.5508139133453369, train acuracy: 0.833984375
step: 357, val loss: 0.49685680866241455, val acuracy: 0.8523333072662354
step: 358, train loss: 0.5518632531166077, train acuracy: 0.83984375
step: 358, val loss: 0.5052292346954346, val acuracy: 0.8503333926200867
step: 359, train loss: 0.5057167410850525, train acuracy: 0.83984375
step: 359, val loss: 0.49419543147087097, val acuracy: 0.8536667823791504
step: 360, train loss: 0.45177996158599854, train acuracy: 0.859375
step: 360, val loss: 0.5077391862869263, val acuracy: 0.8470000624656677
step: 361, train loss: 0.4868704676628113, train acuracy: 0.8515625
step: 361, val loss: 0.5148983001708984, val acuracy: 0.8348334431648254
step: 362, train loss: 0.46213698387145996, train acuracy: 0.8515625
step: 362, val loss: 0.5345115661621094, val acuracy: 0.8331667184829712
step: 363, train loss: 0.5447237491607666, train acuracy: 0.818359375
step: 363, val loss: 0.5141036510467529, val acuracy: 0.8380000591278076
step: 364, train loss: 0.5255811214447021, train acuracy: 0.8466796875
step: 364, val loss: 0.5153716802597046, val acuracy: 0.8435000777244568
step: 365, train loss: 0.5300452709197998, train acuracy: 0.814453125
step: 365, val loss: 0.49808430671691895, val acuracy: 0.8545000553131104
step: 366, train loss: 0.42301076650619507, train acuracy: 0.8701171875
step: 366, val loss: 0.49911630153656006, val acuracy: 0.8501667976379395
step: 367, train loss: 0.5429060459136963, train acuracy: 0.84375
step: 367, val loss: 0.49542713165283203, val acuracy: 0.856333315372467
step: 368, train loss: 0.6057997941970825, train acuracy: 0.8310546875
step: 368, val loss: 0.5053337216377258, val acuracy: 0.8516668081283569
step: 369, train loss: 0.5019954442977905, train acuracy: 0.86328125
step: 369, val loss: 0.49113357067108154, val acuracy: 0.8573334217071533
step: 370, train loss: 0.49990737438201904, train acuracy: 0.8466796875
step: 370, val loss: 0.514548659324646, val acuracy: 0.8511667251586914
step: 371, train loss: 0.5070066452026367, train acuracy: 0.845703125
step: 371, val loss: 0.5193759799003601, val acuracy: 0.8413333892822266
step: 372, train loss: 0.49934402108192444, train acuracy: 0.84765625
step: 372, val loss: 0.5184228420257568, val acuracy: 0.8440001010894775
step: 373, train loss: 0.5103783011436462, train acuracy: 0.83984375
step: 373, val loss: 0.5032878518104553, val acuracy: 0.8515000939369202
step: 374, train loss: 0.5055014491081238, train acuracy: 0.84375
step: 374, val loss: 0.49260467290878296, val acuracy: 0.8575001358985901
step: 375, train loss: 0.5374675989151001, train acuracy: 0.8505859375
step: 375, val loss: 0.4913138747215271, val acuracy: 0.8600000739097595
step: 376, train loss: 0.46987199783325195, train acuracy: 0.8642578125
step: 376, val loss: 0.49449998140335083, val acuracy: 0.8538333773612976
step: 377, train loss: 0.5995295643806458, train acuracy: 0.814453125
step: 377, val loss: 0.5001011490821838, val acuracy: 0.8550000786781311
step: 378, train loss: 0.5056105256080627, train acuracy: 0.8583984375
step: 378, val loss: 0.4984585642814636, val acuracy: 0.8558334708213806
step: 379, train loss: 0.5579279065132141, train acuracy: 0.8203125
step: 379, val loss: 0.4978741705417633, val acuracy: 0.8566668033599854
step: 380, train loss: 0.4821876287460327, train acuracy: 0.8623046875
step: 380, val loss: 0.49763041734695435, val acuracy: 0.8565000891685486
step: 381, train loss: 0.5248367190361023, train acuracy: 0.8515625
step: 381, val loss: 0.4970613718032837, val acuracy: 0.8570001125335693
step: 382, train loss: 0.480712354183197, train acuracy: 0.859375
step: 382, val loss: 0.4967752695083618, val acuracy: 0.8568334579467773
step: 383, train loss: 0.520552933216095, train acuracy: 0.8466796875
step: 383, val loss: 0.4967903196811676, val acuracy: 0.8573334217071533
step: 384, train loss: 0.5668908357620239, train acuracy: 0.830078125
step: 384, val loss: 0.496717244386673, val acuracy: 0.8576667904853821
step: 385, train loss: 0.51463782787323, train acuracy: 0.849609375
step: 385, val loss: 0.4964737892150879, val acuracy: 0.8573334217071533
step: 386, train loss: 0.46994662284851074, train acuracy: 0.890625
step: 386, val loss: 0.5030160546302795, val acuracy: 0.8571667671203613
step: 387, train loss: 0.5394226312637329, train acuracy: 0.841796875
step: 387, val loss: 0.503875732421875, val acuracy: 0.8546666502952576
step: 388, train loss: 0.5617213249206543, train acuracy: 0.8271484375
step: 388, val loss: 0.5027980804443359, val acuracy: 0.8553333878517151
step: 389, train loss: 0.5318629741668701, train acuracy: 0.826171875
step: 389, val loss: 0.5023518800735474, val acuracy: 0.8565000295639038
step: 390, train loss: 0.5166129469871521, train acuracy: 0.849609375
step: 390, val loss: 0.5020800828933716, val acuracy: 0.8558334708213806
step: 391, train loss: 0.5240020155906677, train acuracy: 0.8486328125
step: 391, val loss: 0.501866340637207, val acuracy: 0.8555001020431519
step: 392, train loss: 0.5477830767631531, train acuracy: 0.841796875
step: 392, val loss: 0.5071958303451538, val acuracy: 0.8536667227745056
step: 393, train loss: 0.5145949125289917, train acuracy: 0.8427734375
step: 393, val loss: 0.5019325613975525, val acuracy: 0.8544999957084656
step: 394, train loss: 0.5183259844779968, train acuracy: 0.8359375
step: 394, val loss: 0.5081444978713989, val acuracy: 0.8526667356491089
step: 395, train loss: 0.5212372541427612, train acuracy: 0.8564453125
step: 395, val loss: 0.5181536078453064, val acuracy: 0.8425000905990601
step: 396, train loss: 0.49596017599105835, train acuracy: 0.861328125
step: 396, val loss: 0.5088716149330139, val acuracy: 0.8520000576972961
step: 397, train loss: 0.4956895112991333, train acuracy: 0.8525390625
step: 397, val loss: 0.508468747138977, val acuracy: 0.8513333797454834
step: 398, train loss: 0.4842962622642517, train acuracy: 0.8544921875
step: 398, val loss: 0.5062482357025146, val acuracy: 0.849000096321106
step: 399, train loss: 0.5749759078025818, train acuracy: 0.8212890625
step: 399, val loss: 0.518479585647583, val acuracy: 0.8481667637825012
2017-12-04 16:06:28.434712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 16:06:28.677964: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0xbc95680 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 16:06:28.678651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 16:06:28.678900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 16:06:28.678915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 16:06:28.678920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 16:06:28.678931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 16:06:28.678938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
m=20, batch = 128
step: 0, train loss: 2.4134409427642822, train acuracy: 0.140625
step: 0, val loss: 2.6077523231506348, val acuracy: 0.09816666692495346
step: 1, train loss: 2.247610569000244, train acuracy: 0.1640625
step: 1, val loss: 2.3171186447143555, val acuracy: 0.09699999541044235
step: 2, train loss: 2.24448823928833, train acuracy: 0.125
step: 2, val loss: 2.3186495304107666, val acuracy: 0.10400000214576721
step: 3, train loss: 2.186246395111084, train acuracy: 0.1640625
step: 3, val loss: 2.3267698287963867, val acuracy: 0.11533332616090775
step: 4, train loss: 2.25112247467041, train acuracy: 0.15625
step: 4, val loss: 2.29693603515625, val acuracy: 0.09666666388511658
step: 5, train loss: 2.255678415298462, train acuracy: 0.25
step: 5, val loss: 2.2810769081115723, val acuracy: 0.23200000822544098
step: 6, train loss: 2.2948334217071533, train acuracy: 0.09375
step: 6, val loss: 2.3076388835906982, val acuracy: 0.09666666388511658
step: 7, train loss: 2.2704150676727295, train acuracy: 0.1953125
step: 7, val loss: 2.2851319313049316, val acuracy: 0.12833333015441895
step: 8, train loss: 2.2760043144226074, train acuracy: 0.1171875
step: 8, val loss: 2.2772767543792725, val acuracy: 0.1054999902844429
step: 9, train loss: 2.1956326961517334, train acuracy: 0.171875
step: 9, val loss: 2.270864963531494, val acuracy: 0.11349999904632568
step: 10, train loss: 2.2207789421081543, train acuracy: 0.1796875
step: 10, val loss: 2.334355354309082, val acuracy: 0.09666666388511658
step: 11, train loss: 2.3424859046936035, train acuracy: 0.1484375
step: 11, val loss: 2.3092517852783203, val acuracy: 0.14783333241939545
step: 12, train loss: 2.2709333896636963, train acuracy: 0.171875
step: 12, val loss: 2.3062033653259277, val acuracy: 0.15049999952316284
step: 13, train loss: 2.2844560146331787, train acuracy: 0.1875
step: 13, val loss: 2.305114984512329, val acuracy: 0.14166665077209473
step: 14, train loss: 2.3132150173187256, train acuracy: 0.15625
step: 14, val loss: 2.3038330078125, val acuracy: 0.1561666578054428
step: 15, train loss: 2.2714192867279053, train acuracy: 0.1875
step: 15, val loss: 2.3034486770629883, val acuracy: 0.2003333419561386
step: 16, train loss: 2.292856216430664, train acuracy: 0.2109375
step: 16, val loss: 2.3030035495758057, val acuracy: 0.21533334255218506
step: 17, train loss: 2.3058061599731445, train acuracy: 0.25
step: 17, val loss: 2.3026020526885986, val acuracy: 0.2238333374261856
step: 18, train loss: 2.2957777976989746, train acuracy: 0.1953125
step: 18, val loss: 2.302800178527832, val acuracy: 0.20266668498516083
step: 19, train loss: 2.322026014328003, train acuracy: 0.109375
step: 19, val loss: 2.3734183311462402, val acuracy: 0.09183333814144135
step: 20, train loss: 2.274451971054077, train acuracy: 0.203125
step: 20, val loss: 2.3113698959350586, val acuracy: 0.1665000021457672
step: 21, train loss: 2.2391934394836426, train acuracy: 0.125
step: 21, val loss: 2.2893972396850586, val acuracy: 0.10566666722297668
step: 22, train loss: 2.24117374420166, train acuracy: 0.09375
step: 22, val loss: 2.2812891006469727, val acuracy: 0.10649999976158142
step: 23, train loss: 2.239344596862793, train acuracy: 0.15625
step: 23, val loss: 2.2743403911590576, val acuracy: 0.10700000077486038
step: 24, train loss: 2.203092575073242, train acuracy: 0.1796875
step: 24, val loss: 2.2397098541259766, val acuracy: 0.15599998831748962
step: 25, train loss: 2.1806585788726807, train acuracy: 0.2421875
step: 25, val loss: 2.179365396499634, val acuracy: 0.2253333330154419
step: 26, train loss: 2.098186731338501, train acuracy: 0.390625
step: 26, val loss: 2.1330316066741943, val acuracy: 0.29383334517478943
step: 27, train loss: 2.096325397491455, train acuracy: 0.390625
step: 27, val loss: 2.13633131980896, val acuracy: 0.3525000214576721
step: 28, train loss: 2.051591396331787, train acuracy: 0.4296875
step: 28, val loss: 2.110024929046631, val acuracy: 0.3408333659172058
step: 29, train loss: 2.08293080329895, train acuracy: 0.34375
step: 29, val loss: 2.340874195098877, val acuracy: 0.24449998140335083
step: 30, train loss: 2.3747663497924805, train acuracy: 0.125
step: 30, val loss: 2.4541871547698975, val acuracy: 0.11649999022483826
step: 31, train loss: 1.5445806980133057, train acuracy: 0.5390625
step: 31, val loss: 1.8049346208572388, val acuracy: 0.5466666221618652
step: 32, train loss: 1.4199401140213013, train acuracy: 0.6484375
step: 32, val loss: 1.5228455066680908, val acuracy: 0.612500011920929
step: 33, train loss: 1.418928861618042, train acuracy: 0.578125
step: 33, val loss: 1.4818897247314453, val acuracy: 0.5825001001358032
step: 34, train loss: 1.5458848476409912, train acuracy: 0.609375
step: 34, val loss: 1.5272244215011597, val acuracy: 0.6328333616256714
step: 35, train loss: 1.4237563610076904, train acuracy: 0.5859375
step: 35, val loss: 1.4975310564041138, val acuracy: 0.5550000071525574
step: 36, train loss: 1.537627100944519, train acuracy: 0.5625
step: 36, val loss: 1.4952975511550903, val acuracy: 0.5458333492279053
step: 37, train loss: 1.531505823135376, train acuracy: 0.6484375
step: 37, val loss: 1.5593509674072266, val acuracy: 0.6143333911895752
step: 38, train loss: 1.3035169839859009, train acuracy: 0.625
step: 38, val loss: 1.5288745164871216, val acuracy: 0.5983333587646484
step: 39, train loss: 1.4169847965240479, train acuracy: 0.5703125
step: 39, val loss: 1.5313230752944946, val acuracy: 0.6020000576972961
step: 40, train loss: 27.281410217285156, train acuracy: 0.1640625
step: 40, val loss: 27.138818740844727, val acuracy: 0.15416665375232697
step: 41, train loss: 13.199918746948242, train acuracy: 0.1015625
step: 41, val loss: 13.598774909973145, val acuracy: 0.09666666388511658
step: 42, train loss: 14.171473503112793, train acuracy: 0.09375
step: 42, val loss: 13.590265274047852, val acuracy: 0.1053333431482315
step: 43, train loss: 3.137545347213745, train acuracy: 0.0625
step: 43, val loss: 2.9406282901763916, val acuracy: 0.09666666388511658
step: 44, train loss: 2.481200695037842, train acuracy: 0.109375
step: 44, val loss: 2.6202590465545654, val acuracy: 0.08900000154972076
step: 45, train loss: 2.455630302429199, train acuracy: 0.171875
step: 45, val loss: 2.8557159900665283, val acuracy: 0.11566665768623352
step: 46, train loss: 2.2724409103393555, train acuracy: 0.2421875
step: 46, val loss: 2.4455316066741943, val acuracy: 0.14433333277702332
step: 47, train loss: 2.3427157402038574, train acuracy: 0.1640625
step: 47, val loss: 2.3640055656433105, val acuracy: 0.12833333015441895
step: 48, train loss: 2.2375311851501465, train acuracy: 0.1953125
step: 48, val loss: 2.322347640991211, val acuracy: 0.16699999570846558
step: 49, train loss: 2.2759149074554443, train acuracy: 0.09375
step: 49, val loss: 2.338517427444458, val acuracy: 0.109333336353302
step: 50, train loss: 2.1246047019958496, train acuracy: 0.1796875
step: 50, val loss: 2.2214107513427734, val acuracy: 0.17733334004878998
step: 51, train loss: 2.102299690246582, train acuracy: 0.234375
step: 51, val loss: 2.20373797416687, val acuracy: 0.1768333464860916
step: 52, train loss: 2.1357927322387695, train acuracy: 0.25
step: 52, val loss: 2.2002956867218018, val acuracy: 0.19716665148735046
step: 53, train loss: 2.1552767753601074, train acuracy: 0.203125
step: 53, val loss: 2.2061309814453125, val acuracy: 0.16899999976158142
step: 54, train loss: 2.1173293590545654, train acuracy: 0.1796875
step: 54, val loss: 2.2049975395202637, val acuracy: 0.1898333579301834
step: 55, train loss: 2.086826801300049, train acuracy: 0.2109375
step: 55, val loss: 2.2002370357513428, val acuracy: 0.1886666715145111
step: 56, train loss: 2.185096025466919, train acuracy: 0.1875
step: 56, val loss: 2.2339184284210205, val acuracy: 0.17216667532920837
step: 57, train loss: 2.18042254447937, train acuracy: 0.171875
step: 57, val loss: 2.214576482772827, val acuracy: 0.17033334076404572
step: 58, train loss: 2.1778931617736816, train acuracy: 0.1640625
step: 58, val loss: 2.2123184204101562, val acuracy: 0.1679999828338623
step: 59, train loss: 2.1783573627471924, train acuracy: 0.2265625
step: 59, val loss: 2.2100820541381836, val acuracy: 0.1706666499376297
step: 60, train loss: 2.2023706436157227, train acuracy: 0.1640625
step: 60, val loss: 2.209052801132202, val acuracy: 0.17133332788944244
step: 61, train loss: 2.2004804611206055, train acuracy: 0.171875
step: 61, val loss: 2.208561658859253, val acuracy: 0.17000000178813934
step: 62, train loss: 2.2147016525268555, train acuracy: 0.15625
step: 62, val loss: 2.2211410999298096, val acuracy: 0.17083334922790527
step: 63, train loss: 2.158414363861084, train acuracy: 0.21875
step: 63, val loss: 2.1978986263275146, val acuracy: 0.1823333352804184
step: 64, train loss: 2.2617874145507812, train acuracy: 0.125
step: 64, val loss: 2.2127761840820312, val acuracy: 0.17249999940395355
step: 65, train loss: 2.1238529682159424, train acuracy: 0.203125
step: 65, val loss: 2.204777240753174, val acuracy: 0.15349999070167542
step: 66, train loss: 2.152568817138672, train acuracy: 0.1640625
step: 66, val loss: 2.2928948402404785, val acuracy: 0.1316666603088379
step: 67, train loss: 2.149768829345703, train acuracy: 0.171875
step: 67, val loss: 2.251600980758667, val acuracy: 0.1433333307504654
step: 68, train loss: 2.1196627616882324, train acuracy: 0.21875
step: 68, val loss: 2.2191572189331055, val acuracy: 0.1691666692495346
step: 69, train loss: 2.190185546875, train acuracy: 0.2109375
step: 69, val loss: 2.2085015773773193, val acuracy: 0.18700000643730164
step: 70, train loss: 2.181863784790039, train acuracy: 0.1953125
step: 70, val loss: 2.20818829536438, val acuracy: 0.18733331561088562
step: 71, train loss: 2.2230334281921387, train acuracy: 0.15625
step: 71, val loss: 2.2080206871032715, val acuracy: 0.18716666102409363
step: 72, train loss: 2.2510793209075928, train acuracy: 0.1640625
step: 72, val loss: 2.2081217765808105, val acuracy: 0.18766666948795319
step: 73, train loss: 2.2644217014312744, train acuracy: 0.15625
step: 73, val loss: 2.2074599266052246, val acuracy: 0.1875
step: 74, train loss: 2.1809728145599365, train acuracy: 0.203125
step: 74, val loss: 2.2258992195129395, val acuracy: 0.18683332204818726
step: 75, train loss: 2.130129098892212, train acuracy: 0.25
step: 75, val loss: 2.2137980461120605, val acuracy: 0.1574999988079071
step: 76, train loss: 2.1601500511169434, train acuracy: 0.234375
step: 76, val loss: 2.2116830348968506, val acuracy: 0.15933331847190857
step: 77, train loss: 2.230112075805664, train acuracy: 0.140625
step: 77, val loss: 2.2109124660491943, val acuracy: 0.15983334183692932
step: 78, train loss: 2.218508720397949, train acuracy: 0.171875
step: 78, val loss: 2.2101008892059326, val acuracy: 0.16066667437553406
step: 79, train loss: 2.2283854484558105, train acuracy: 0.1875
step: 79, val loss: 2.2053825855255127, val acuracy: 0.17499998211860657
step: 80, train loss: 2.1944727897644043, train acuracy: 0.2265625
step: 80, val loss: 2.206514835357666, val acuracy: 0.19433332979679108
step: 81, train loss: 2.255213737487793, train acuracy: 0.1640625
step: 81, val loss: 2.2062275409698486, val acuracy: 0.19499999284744263
step: 82, train loss: 2.211219310760498, train acuracy: 0.1875
step: 82, val loss: 2.2060978412628174, val acuracy: 0.19500000774860382
step: 83, train loss: 2.2233879566192627, train acuracy: 0.1953125
step: 83, val loss: 2.205786943435669, val acuracy: 0.19483333826065063
step: 84, train loss: 2.231140375137329, train acuracy: 0.171875
step: 84, val loss: 2.205839157104492, val acuracy: 0.19450001418590546
step: 85, train loss: 2.1659066677093506, train acuracy: 0.2421875
step: 85, val loss: 2.2059476375579834, val acuracy: 0.19433332979679108
step: 86, train loss: 2.193901777267456, train acuracy: 0.203125
step: 86, val loss: 2.205805540084839, val acuracy: 0.19383332133293152
step: 87, train loss: 2.1842594146728516, train acuracy: 0.2421875
step: 87, val loss: 2.2058866024017334, val acuracy: 0.19350001215934753
step: 88, train loss: 2.1910338401794434, train acuracy: 0.234375
step: 88, val loss: 2.205861806869507, val acuracy: 0.19349999725818634
step: 89, train loss: 2.1948423385620117, train acuracy: 0.25
step: 89, val loss: 2.2057979106903076, val acuracy: 0.19416667520999908
step: 90, train loss: 2.1885108947753906, train acuracy: 0.21875
step: 90, val loss: 2.206578493118286, val acuracy: 0.19200001657009125
step: 91, train loss: 2.301923990249634, train acuracy: 0.1171875
step: 91, val loss: 2.283813238143921, val acuracy: 0.13066665828227997
step: 92, train loss: 2.2225170135498047, train acuracy: 0.171875
step: 92, val loss: 2.2810378074645996, val acuracy: 0.13166667520999908
step: 93, train loss: 2.3004679679870605, train acuracy: 0.09375
step: 93, val loss: 2.280510902404785, val acuracy: 0.13116666674613953
step: 94, train loss: 2.167818307876587, train acuracy: 0.3359375
step: 94, val loss: 2.3657543659210205, val acuracy: 0.22183333337306976
step: 95, train loss: 2.2579333782196045, train acuracy: 0.25
step: 95, val loss: 2.2948532104492188, val acuracy: 0.23016667366027832
step: 96, train loss: 2.277561664581299, train acuracy: 0.2734375
step: 96, val loss: 2.272871494293213, val acuracy: 0.2380000203847885
step: 97, train loss: 2.252671480178833, train acuracy: 0.1640625
step: 97, val loss: 2.27532696723938, val acuracy: 0.16700001060962677
step: 98, train loss: 2.2449581623077393, train acuracy: 0.234375
step: 98, val loss: 2.274454116821289, val acuracy: 0.16600000858306885
step: 99, train loss: 2.2489614486694336, train acuracy: 0.1640625
step: 99, val loss: 2.262322187423706, val acuracy: 0.16249999403953552
step: 100, train loss: 2.1611289978027344, train acuracy: 0.203125
step: 100, val loss: 2.2428970336914062, val acuracy: 0.16300000250339508
step: 101, train loss: 2.1132867336273193, train acuracy: 0.2265625
step: 101, val loss: 2.175506830215454, val acuracy: 0.21566668152809143
step: 102, train loss: 2.0804758071899414, train acuracy: 0.2734375
step: 102, val loss: 2.1627626419067383, val acuracy: 0.21250000596046448
step: 103, train loss: 2.112696886062622, train acuracy: 0.296875
step: 103, val loss: 2.1073601245880127, val acuracy: 0.2891666889190674
step: 104, train loss: 1.9696239233016968, train acuracy: 0.28125
step: 104, val loss: 1.9926873445510864, val acuracy: 0.2951667010784149
step: 105, train loss: 2.0215721130371094, train acuracy: 0.25
step: 105, val loss: 1.9571762084960938, val acuracy: 0.289166659116745
step: 106, train loss: 1.94024658203125, train acuracy: 0.265625
step: 106, val loss: 1.8649821281433105, val acuracy: 0.3205000162124634
step: 107, train loss: 1.9372539520263672, train acuracy: 0.3125
step: 107, val loss: 2.0238547325134277, val acuracy: 0.2903333604335785
step: 108, train loss: 1.5800414085388184, train acuracy: 0.4765625
step: 108, val loss: 1.8942967653274536, val acuracy: 0.37316668033599854
step: 109, train loss: 1.8387428522109985, train acuracy: 0.34375
step: 109, val loss: 1.894141674041748, val acuracy: 0.3411667048931122
step: 110, train loss: 1.8998513221740723, train acuracy: 0.3359375
step: 110, val loss: 2.0986573696136475, val acuracy: 0.28333336114883423
step: 111, train loss: 1.9946315288543701, train acuracy: 0.3125
step: 111, val loss: 2.118170738220215, val acuracy: 0.30416667461395264
step: 112, train loss: 1.5918941497802734, train acuracy: 0.4296875
step: 112, val loss: 1.6778229475021362, val acuracy: 0.4153333306312561
step: 113, train loss: 2.3761377334594727, train acuracy: 0.2109375
step: 113, val loss: 2.4622254371643066, val acuracy: 0.23066668212413788
step: 114, train loss: 1.8918880224227905, train acuracy: 0.296875
step: 114, val loss: 2.003204345703125, val acuracy: 0.28200000524520874
step: 115, train loss: 1.9943205118179321, train acuracy: 0.3359375
step: 115, val loss: 2.06040620803833, val acuracy: 0.31066668033599854
step: 116, train loss: 1.8090780973434448, train acuracy: 0.359375
step: 116, val loss: 1.9213064908981323, val acuracy: 0.34466665983200073
step: 117, train loss: 1.7346444129943848, train acuracy: 0.390625
step: 117, val loss: 1.7191107273101807, val acuracy: 0.4205000102519989
step: 118, train loss: 256.422607421875, train acuracy: 0.0703125
step: 118, val loss: 267.0733947753906, val acuracy: 0.09183333069086075
step: 119, train loss: 203.72055053710938, train acuracy: 0.1015625
step: 119, val loss: 234.1798858642578, val acuracy: 0.09666666388511658
step: 120, train loss: 197.9715118408203, train acuracy: 0.1640625
step: 120, val loss: 228.35414123535156, val acuracy: 0.15133333206176758
step: 121, train loss: 198.40243530273438, train acuracy: 0.078125
step: 121, val loss: 198.90072631835938, val acuracy: 0.09733332693576813
step: 122, train loss: 1054.2301025390625, train acuracy: 0.09375
step: 122, val loss: 1016.4462890625, val acuracy: 0.09933333098888397
step: 123, train loss: 1410.0660400390625, train acuracy: 0.125
step: 123, val loss: 1587.607421875, val acuracy: 0.1093333289027214
step: 124, train loss: 37559.8515625, train acuracy: 0.125
step: 124, val loss: 41389.328125, val acuracy: 0.09033332765102386
step: 125, train loss: 31693248.0, train acuracy: 0.125
step: 125, val loss: 33006552.0, val acuracy: 0.09433334320783615
step: 126, train loss: 2.868920256875725e+16, train acuracy: 0.1171875
step: 126, val loss: 2.9425267621494784e+16, val acuracy: 0.09183333069086075
step: 127, train loss: nan, train acuracy: 0.15625
step: 127, val loss: nan, val acuracy: 0.10899999737739563
step: 128, train loss: nan, train acuracy: 0.1171875
step: 128, val loss: nan, val acuracy: 0.10400000214576721
step: 129, train loss: nan, train acuracy: 0.1015625
step: 129, val loss: nan, val acuracy: 0.10400000214576721
step: 130, train loss: nan, train acuracy: 0.125
step: 130, val loss: nan, val acuracy: 0.10400000214576721
step: 131, train loss: nan, train acuracy: 0.0859375
step: 131, val loss: nan, val acuracy: 0.10400000214576721
step: 132, train loss: nan, train acuracy: 0.1171875
step: 132, val loss: nan, val acuracy: 0.10400000214576721
step: 133, train loss: nan, train acuracy: 0.0859375
step: 133, val loss: nan, val acuracy: 0.10400000214576721
step: 134, train loss: nan, train acuracy: 0.09375
step: 134, val loss: nan, val acuracy: 0.10400000214576721
step: 135, train loss: nan, train acuracy: 0.1015625
step: 135, val loss: nan, val acuracy: 0.10400000214576721
step: 136, train loss: nan, train acuracy: 0.125
step: 136, val loss: nan, val acuracy: 0.10400000214576721
step: 137, train loss: nan, train acuracy: 0.0859375
step: 137, val loss: nan, val acuracy: 0.10400000214576721
step: 138, train loss: nan, train acuracy: 0.0390625
step: 138, val loss: nan, val acuracy: 0.10400000214576721
step: 139, train loss: nan, train acuracy: 0.1171875
step: 139, val loss: nan, val acuracy: 0.10400000214576721
step: 140, train loss: nan, train acuracy: 0.046875
step: 140, val loss: nan, val acuracy: 0.10400000214576721
step: 141, train loss: nan, train acuracy: 0.0703125
step: 141, val loss: nan, val acuracy: 0.10400000214576721
step: 142, train loss: nan, train acuracy: 0.1171875
step: 142, val loss: nan, val acuracy: 0.10400000214576721
step: 143, train loss: nan, train acuracy: 0.0703125
step: 143, val loss: nan, val acuracy: 0.10400000214576721
step: 144, train loss: nan, train acuracy: 0.09375
step: 144, val loss: nan, val acuracy: 0.10400000214576721
step: 145, train loss: nan, train acuracy: 0.0859375
step: 145, val loss: nan, val acuracy: 0.10400000214576721
step: 146, train loss: nan, train acuracy: 0.1015625
step: 146, val loss: nan, val acuracy: 0.10400000214576721
step: 147, train loss: nan, train acuracy: 0.09375
step: 147, val loss: nan, val acuracy: 0.10400000214576721
step: 148, train loss: nan, train acuracy: 0.0625
step: 148, val loss: nan, val acuracy: 0.10400000214576721
step: 149, train loss: nan, train acuracy: 0.1875
step: 149, val loss: nan, val acuracy: 0.10400000214576721
step: 150, train loss: nan, train acuracy: 0.1171875
step: 150, val loss: nan, val acuracy: 0.10400000214576721
step: 151, train loss: nan, train acuracy: 0.1015625
step: 151, val loss: nan, val acuracy: 0.10400000214576721
step: 152, train loss: nan, train acuracy: 0.078125
step: 152, val loss: nan, val acuracy: 0.10400000214576721
step: 153, train loss: nan, train acuracy: 0.109375
step: 153, val loss: nan, val acuracy: 0.10400000214576721
step: 154, train loss: nan, train acuracy: 0.0703125
step: 154, val loss: nan, val acuracy: 0.10400000214576721
step: 155, train loss: nan, train acuracy: 0.1171875
step: 155, val loss: nan, val acuracy: 0.10400000214576721
step: 156, train loss: nan, train acuracy: 0.0859375
step: 156, val loss: nan, val acuracy: 0.10400000214576721
step: 157, train loss: nan, train acuracy: 0.09375
step: 157, val loss: nan, val acuracy: 0.10400000959634781
step: 158, train loss: nan, train acuracy: 0.0625
step: 158, val loss: nan, val acuracy: 0.10400000214576721
step: 159, train loss: nan, train acuracy: 0.0859375
step: 159, val loss: nan, val acuracy: 0.10400000214576721
step: 160, train loss: nan, train acuracy: 0.1171875
step: 160, val loss: nan, val acuracy: 0.10400000214576721
step: 161, train loss: nan, train acuracy: 0.1171875
step: 161, val loss: nan, val acuracy: 0.10400000214576721
step: 162, train loss: nan, train acuracy: 0.078125
step: 162, val loss: nan, val acuracy: 0.10400000214576721
step: 163, train loss: nan, train acuracy: 0.0546875
step: 163, val loss: nan, val acuracy: 0.10400000214576721
step: 164, train loss: nan, train acuracy: 0.09375
step: 164, val loss: nan, val acuracy: 0.10400000214576721
step: 165, train loss: nan, train acuracy: 0.1015625
step: 165, val loss: nan, val acuracy: 0.10400000214576721
step: 166, train loss: nan, train acuracy: 0.1328125
step: 166, val loss: nan, val acuracy: 0.10400000214576721
step: 167, train loss: nan, train acuracy: 0.109375
step: 167, val loss: nan, val acuracy: 0.10400000214576721
step: 168, train loss: nan, train acuracy: 0.109375
step: 168, val loss: nan, val acuracy: 0.10400000214576721
step: 169, train loss: nan, train acuracy: 0.125
step: 169, val loss: nan, val acuracy: 0.10400000214576721
step: 170, train loss: nan, train acuracy: 0.15625
step: 170, val loss: nan, val acuracy: 0.10400000214576721
step: 171, train loss: nan, train acuracy: 0.09375
step: 171, val loss: nan, val acuracy: 0.10400000214576721
step: 172, train loss: nan, train acuracy: 0.0859375
step: 172, val loss: nan, val acuracy: 0.10400000214576721
step: 173, train loss: nan, train acuracy: 0.09375
step: 173, val loss: nan, val acuracy: 0.10400000214576721
step: 174, train loss: nan, train acuracy: 0.0625
step: 174, val loss: nan, val acuracy: 0.10400000214576721
step: 175, train loss: nan, train acuracy: 0.0703125
step: 175, val loss: nan, val acuracy: 0.10400000214576721
step: 176, train loss: nan, train acuracy: 0.1015625
step: 176, val loss: nan, val acuracy: 0.10400000214576721
step: 177, train loss: nan, train acuracy: 0.109375
step: 177, val loss: nan, val acuracy: 0.10400000214576721
step: 178, train loss: nan, train acuracy: 0.09375
step: 178, val loss: nan, val acuracy: 0.10400000214576721
step: 179, train loss: nan, train acuracy: 0.1015625
step: 179, val loss: nan, val acuracy: 0.10400000214576721
step: 180, train loss: nan, train acuracy: 0.1328125
step: 180, val loss: nan, val acuracy: 0.10400000214576721
step: 181, train loss: nan, train acuracy: 0.1015625
step: 181, val loss: nan, val acuracy: 0.10400000214576721
step: 182, train loss: nan, train acuracy: 0.0703125
step: 182, val loss: nan, val acuracy: 0.10400000214576721
step: 183, train loss: nan, train acuracy: 0.1328125
step: 183, val loss: nan, val acuracy: 0.10400000214576721
step: 184, train loss: nan, train acuracy: 0.109375
step: 184, val loss: nan, val acuracy: 0.10400000214576721
step: 185, train loss: nan, train acuracy: 0.0703125
step: 185, val loss: nan, val acuracy: 0.10400000214576721
step: 186, train loss: nan, train acuracy: 0.125
step: 186, val loss: nan, val acuracy: 0.10400000214576721
step: 187, train loss: nan, train acuracy: 0.0859375
step: 187, val loss: nan, val acuracy: 0.10400000214576721
step: 188, train loss: nan, train acuracy: 0.1015625
step: 188, val loss: nan, val acuracy: 0.10400000214576721
step: 189, train loss: nan, train acuracy: 0.1328125
step: 189, val loss: nan, val acuracy: 0.10400000214576721
step: 190, train loss: nan, train acuracy: 0.0859375
step: 190, val loss: nan, val acuracy: 0.10400000214576721
step: 191, train loss: nan, train acuracy: 0.09375
step: 191, val loss: nan, val acuracy: 0.10400000214576721
step: 192, train loss: nan, train acuracy: 0.109375
step: 192, val loss: nan, val acuracy: 0.10400000214576721
step: 193, train loss: nan, train acuracy: 0.109375
step: 193, val loss: nan, val acuracy: 0.10400000214576721
step: 194, train loss: nan, train acuracy: 0.1171875
step: 194, val loss: nan, val acuracy: 0.10400000214576721
step: 195, train loss: nan, train acuracy: 0.0703125
step: 195, val loss: nan, val acuracy: 0.10400000214576721
step: 196, train loss: nan, train acuracy: 0.0859375
step: 196, val loss: nan, val acuracy: 0.10400000214576721
step: 197, train loss: nan, train acuracy: 0.1171875
step: 197, val loss: nan, val acuracy: 0.10400000214576721
step: 198, train loss: nan, train acuracy: 0.09375
step: 198, val loss: nan, val acuracy: 0.10400000214576721
step: 199, train loss: nan, train acuracy: 0.1015625
step: 199, val loss: nan, val acuracy: 0.10400000214576721
step: 200, train loss: nan, train acuracy: 0.0703125
step: 200, val loss: nan, val acuracy: 0.10400000214576721
step: 201, train loss: nan, train acuracy: 0.1328125
step: 201, val loss: nan, val acuracy: 0.10400000214576721
step: 202, train loss: nan, train acuracy: 0.09375
step: 202, val loss: nan, val acuracy: 0.10400000214576721
step: 203, train loss: nan, train acuracy: 0.140625
step: 203, val loss: nan, val acuracy: 0.10400000214576721
step: 204, train loss: nan, train acuracy: 0.0859375
step: 204, val loss: nan, val acuracy: 0.10400000214576721
step: 205, train loss: nan, train acuracy: 0.1015625
step: 205, val loss: nan, val acuracy: 0.10400000214576721
step: 206, train loss: nan, train acuracy: 0.1171875
step: 206, val loss: nan, val acuracy: 0.10400000214576721
step: 207, train loss: nan, train acuracy: 0.09375
step: 207, val loss: nan, val acuracy: 0.10400000214576721
step: 208, train loss: nan, train acuracy: 0.0546875
step: 208, val loss: nan, val acuracy: 0.10400000214576721
step: 209, train loss: nan, train acuracy: 0.0859375
step: 209, val loss: nan, val acuracy: 0.10400000214576721
step: 210, train loss: nan, train acuracy: 0.0625
step: 210, val loss: nan, val acuracy: 0.10400000214576721
step: 211, train loss: nan, train acuracy: 0.0546875
step: 211, val loss: nan, val acuracy: 0.10400000214576721
step: 212, train loss: nan, train acuracy: 0.078125
step: 212, val loss: nan, val acuracy: 0.10400000214576721
step: 213, train loss: nan, train acuracy: 0.09375
step: 213, val loss: nan, val acuracy: 0.10400000214576721
step: 214, train loss: nan, train acuracy: 0.0703125
step: 214, val loss: nan, val acuracy: 0.10400000214576721
step: 215, train loss: nan, train acuracy: 0.0703125
step: 215, val loss: nan, val acuracy: 0.10400000214576721
step: 216, train loss: nan, train acuracy: 0.1640625
step: 216, val loss: nan, val acuracy: 0.10400000214576721
step: 217, train loss: nan, train acuracy: 0.09375
step: 217, val loss: nan, val acuracy: 0.10400000214576721
step: 218, train loss: nan, train acuracy: 0.109375
step: 218, val loss: nan, val acuracy: 0.10400000214576721
step: 219, train loss: nan, train acuracy: 0.109375
step: 219, val loss: nan, val acuracy: 0.10400000214576721
step: 220, train loss: nan, train acuracy: 0.109375
step: 220, val loss: nan, val acuracy: 0.10400000214576721
step: 221, train loss: nan, train acuracy: 0.140625
step: 221, val loss: nan, val acuracy: 0.10400000214576721
step: 222, train loss: nan, train acuracy: 0.0859375
step: 222, val loss: nan, val acuracy: 0.10400000214576721
step: 223, train loss: nan, train acuracy: 0.1484375
step: 223, val loss: nan, val acuracy: 0.10400000214576721
step: 224, train loss: nan, train acuracy: 0.125
step: 224, val loss: nan, val acuracy: 0.10400000214576721
step: 225, train loss: nan, train acuracy: 0.0859375
step: 225, val loss: nan, val acuracy: 0.10400000214576721
step: 226, train loss: nan, train acuracy: 0.09375
step: 226, val loss: nan, val acuracy: 0.10400000214576721
step: 227, train loss: nan, train acuracy: 0.0703125
step: 227, val loss: nan, val acuracy: 0.10400000214576721
step: 228, train loss: nan, train acuracy: 0.1328125
step: 228, val loss: nan, val acuracy: 0.10400000214576721
step: 229, train loss: nan, train acuracy: 0.1328125
step: 229, val loss: nan, val acuracy: 0.10400000214576721
step: 230, train loss: nan, train acuracy: 0.078125
step: 230, val loss: nan, val acuracy: 0.10400000214576721
step: 231, train loss: nan, train acuracy: 0.0859375
step: 231, val loss: nan, val acuracy: 0.10400000214576721
step: 232, train loss: nan, train acuracy: 0.09375
step: 232, val loss: nan, val acuracy: 0.10400000214576721
step: 233, train loss: nan, train acuracy: 0.1328125
step: 233, val loss: nan, val acuracy: 0.10400000214576721
step: 234, train loss: nan, train acuracy: 0.0859375
step: 234, val loss: nan, val acuracy: 0.10400000214576721
step: 235, train loss: nan, train acuracy: 0.125
step: 235, val loss: nan, val acuracy: 0.10400000214576721
step: 236, train loss: nan, train acuracy: 0.1015625
step: 236, val loss: nan, val acuracy: 0.10400000214576721
step: 237, train loss: nan, train acuracy: 0.125
step: 237, val loss: nan, val acuracy: 0.10400000214576721
step: 238, train loss: nan, train acuracy: 0.0546875
step: 238, val loss: nan, val acuracy: 0.10400000214576721
step: 239, train loss: nan, train acuracy: 0.0625
step: 239, val loss: nan, val acuracy: 0.10400000214576721
step: 240, train loss: nan, train acuracy: 0.125
step: 240, val loss: nan, val acuracy: 0.10400000214576721
step: 241, train loss: nan, train acuracy: 0.109375
step: 241, val loss: nan, val acuracy: 0.10400000214576721
step: 242, train loss: nan, train acuracy: 0.078125
step: 242, val loss: nan, val acuracy: 0.10400000214576721
step: 243, train loss: nan, train acuracy: 0.1171875
step: 243, val loss: nan, val acuracy: 0.10400000214576721
step: 244, train loss: nan, train acuracy: 0.078125
step: 244, val loss: nan, val acuracy: 0.10400000214576721
step: 245, train loss: nan, train acuracy: 0.09375
step: 245, val loss: nan, val acuracy: 0.10400000214576721
step: 246, train loss: nan, train acuracy: 0.1328125
step: 246, val loss: nan, val acuracy: 0.10400000214576721
step: 247, train loss: nan, train acuracy: 0.125
step: 247, val loss: nan, val acuracy: 0.10400000214576721
step: 248, train loss: nan, train acuracy: 0.1015625
step: 248, val loss: nan, val acuracy: 0.10400000214576721
step: 249, train loss: nan, train acuracy: 0.0625
step: 249, val loss: nan, val acuracy: 0.10400000214576721
step: 250, train loss: nan, train acuracy: 0.078125
step: 250, val loss: nan, val acuracy: 0.10400000214576721
step: 251, train loss: nan, train acuracy: 0.0703125
step: 251, val loss: nan, val acuracy: 0.10400000214576721
step: 252, train loss: nan, train acuracy: 0.0859375
step: 252, val loss: nan, val acuracy: 0.10400000214576721
step: 253, train loss: nan, train acuracy: 0.1953125
step: 253, val loss: nan, val acuracy: 0.10400000214576721
step: 254, train loss: nan, train acuracy: 0.1171875
step: 254, val loss: nan, val acuracy: 0.10400000214576721
step: 255, train loss: nan, train acuracy: 0.078125
step: 255, val loss: nan, val acuracy: 0.10400000214576721
step: 256, train loss: nan, train acuracy: 0.125
step: 256, val loss: nan, val acuracy: 0.10400000214576721
step: 257, train loss: nan, train acuracy: 0.125
step: 257, val loss: nan, val acuracy: 0.10400000214576721
step: 258, train loss: nan, train acuracy: 0.078125
step: 258, val loss: nan, val acuracy: 0.10400000214576721
step: 259, train loss: nan, train acuracy: 0.0625
step: 259, val loss: nan, val acuracy: 0.10400000214576721
step: 260, train loss: nan, train acuracy: 0.0703125
step: 260, val loss: nan, val acuracy: 0.10400000214576721
step: 261, train loss: nan, train acuracy: 0.125
step: 261, val loss: nan, val acuracy: 0.10400000214576721
step: 262, train loss: nan, train acuracy: 0.078125
step: 262, val loss: nan, val acuracy: 0.10400000214576721
step: 263, train loss: nan, train acuracy: 0.140625
step: 263, val loss: nan, val acuracy: 0.10400000214576721
step: 264, train loss: nan, train acuracy: 0.1015625
step: 264, val loss: nan, val acuracy: 0.10400000214576721
step: 265, train loss: nan, train acuracy: 0.09375
step: 265, val loss: nan, val acuracy: 0.10400000214576721
step: 266, train loss: nan, train acuracy: 0.0703125
step: 266, val loss: nan, val acuracy: 0.10400000214576721
step: 267, train loss: nan, train acuracy: 0.0703125
step: 267, val loss: nan, val acuracy: 0.10400000214576721
step: 268, train loss: nan, train acuracy: 0.1015625
step: 268, val loss: nan, val acuracy: 0.10400000214576721
step: 269, train loss: nan, train acuracy: 0.1015625
step: 269, val loss: nan, val acuracy: 0.10400000214576721
step: 270, train loss: nan, train acuracy: 0.1484375
step: 270, val loss: nan, val acuracy: 0.10400000214576721
step: 271, train loss: nan, train acuracy: 0.078125
step: 271, val loss: nan, val acuracy: 0.10400000214576721
step: 272, train loss: nan, train acuracy: 0.140625
step: 272, val loss: nan, val acuracy: 0.10400000214576721
step: 273, train loss: nan, train acuracy: 0.0625
step: 273, val loss: nan, val acuracy: 0.10400000214576721
step: 274, train loss: nan, train acuracy: 0.0703125
step: 274, val loss: nan, val acuracy: 0.10400000214576721
step: 275, train loss: nan, train acuracy: 0.1015625
step: 275, val loss: nan, val acuracy: 0.10400000214576721
step: 276, train loss: nan, train acuracy: 0.1171875
step: 276, val loss: nan, val acuracy: 0.10400000214576721
step: 277, train loss: nan, train acuracy: 0.109375
step: 277, val loss: nan, val acuracy: 0.10400000214576721
step: 278, train loss: nan, train acuracy: 0.0625
step: 278, val loss: nan, val acuracy: 0.10400000214576721
step: 279, train loss: nan, train acuracy: 0.15625
step: 279, val loss: nan, val acuracy: 0.10400000214576721
step: 280, train loss: nan, train acuracy: 0.09375
step: 280, val loss: nan, val acuracy: 0.10400000214576721
step: 281, train loss: nan, train acuracy: 0.0546875
step: 281, val loss: nan, val acuracy: 0.10400000214576721
step: 282, train loss: nan, train acuracy: 0.0703125
step: 282, val loss: nan, val acuracy: 0.10400000214576721
step: 283, train loss: nan, train acuracy: 0.09375
step: 283, val loss: nan, val acuracy: 0.10400000214576721
step: 284, train loss: nan, train acuracy: 0.0859375
step: 284, val loss: nan, val acuracy: 0.10400000214576721
step: 285, train loss: nan, train acuracy: 0.1171875
step: 285, val loss: nan, val acuracy: 0.10400000214576721
step: 286, train loss: nan, train acuracy: 0.0625
step: 286, val loss: nan, val acuracy: 0.10400000214576721
step: 287, train loss: nan, train acuracy: 0.1171875
step: 287, val loss: nan, val acuracy: 0.10400000214576721
step: 288, train loss: nan, train acuracy: 0.09375
step: 288, val loss: nan, val acuracy: 0.10400000214576721
step: 289, train loss: nan, train acuracy: 0.109375
step: 289, val loss: nan, val acuracy: 0.10400000214576721
step: 290, train loss: nan, train acuracy: 0.03125
step: 290, val loss: nan, val acuracy: 0.10400000214576721
step: 291, train loss: nan, train acuracy: 0.0859375
step: 291, val loss: nan, val acuracy: 0.10400000214576721
step: 292, train loss: nan, train acuracy: 0.0703125
step: 292, val loss: nan, val acuracy: 0.10400000214576721
step: 293, train loss: nan, train acuracy: 0.0546875
step: 293, val loss: nan, val acuracy: 0.10400000214576721
step: 294, train loss: nan, train acuracy: 0.1171875
step: 294, val loss: nan, val acuracy: 0.10400000214576721
step: 295, train loss: nan, train acuracy: 0.0859375
step: 295, val loss: nan, val acuracy: 0.10400000214576721
step: 296, train loss: nan, train acuracy: 0.0859375
step: 296, val loss: nan, val acuracy: 0.10400000214576721
step: 297, train loss: nan, train acuracy: 0.125
step: 297, val loss: nan, val acuracy: 0.10400000214576721
step: 298, train loss: nan, train acuracy: 0.0859375
step: 298, val loss: nan, val acuracy: 0.10400000214576721
step: 299, train loss: nan, train acuracy: 0.0859375
step: 299, val loss: nan, val acuracy: 0.10400000214576721
step: 300, train loss: nan, train acuracy: 0.09375
step: 300, val loss: nan, val acuracy: 0.10400000214576721
step: 301, train loss: nan, train acuracy: 0.1015625
step: 301, val loss: nan, val acuracy: 0.10400000214576721
step: 302, train loss: nan, train acuracy: 0.09375
step: 302, val loss: nan, val acuracy: 0.10400000214576721
step: 303, train loss: nan, train acuracy: 0.1328125
step: 303, val loss: nan, val acuracy: 0.10400000214576721
step: 304, train loss: nan, train acuracy: 0.1015625
step: 304, val loss: nan, val acuracy: 0.10400000214576721
step: 305, train loss: nan, train acuracy: 0.046875
step: 305, val loss: nan, val acuracy: 0.10400000214576721
step: 306, train loss: nan, train acuracy: 0.1171875
step: 306, val loss: nan, val acuracy: 0.10400000214576721
step: 307, train loss: nan, train acuracy: 0.1640625
step: 307, val loss: nan, val acuracy: 0.10400000214576721
step: 308, train loss: nan, train acuracy: 0.078125
step: 308, val loss: nan, val acuracy: 0.10400000214576721
step: 309, train loss: nan, train acuracy: 0.1171875
step: 309, val loss: nan, val acuracy: 0.10400000214576721
step: 310, train loss: nan, train acuracy: 0.09375
step: 310, val loss: nan, val acuracy: 0.10400000214576721
step: 311, train loss: nan, train acuracy: 0.046875
step: 311, val loss: nan, val acuracy: 0.10400000214576721
step: 312, train loss: nan, train acuracy: 0.1015625
step: 312, val loss: nan, val acuracy: 0.10400000214576721
step: 313, train loss: nan, train acuracy: 0.09375
step: 313, val loss: nan, val acuracy: 0.10400000214576721
step: 314, train loss: nan, train acuracy: 0.140625
step: 314, val loss: nan, val acuracy: 0.10400000214576721
step: 315, train loss: nan, train acuracy: 0.1015625
step: 315, val loss: nan, val acuracy: 0.10400000214576721
step: 316, train loss: nan, train acuracy: 0.125
step: 316, val loss: nan, val acuracy: 0.10400000214576721
step: 317, train loss: nan, train acuracy: 0.140625
step: 317, val loss: nan, val acuracy: 0.10400000214576721
step: 318, train loss: nan, train acuracy: 0.1171875
step: 318, val loss: nan, val acuracy: 0.10400000214576721
step: 319, train loss: nan, train acuracy: 0.078125
step: 319, val loss: nan, val acuracy: 0.10400000214576721
step: 320, train loss: nan, train acuracy: 0.0859375
step: 320, val loss: nan, val acuracy: 0.10400000214576721
step: 321, train loss: nan, train acuracy: 0.0703125
step: 321, val loss: nan, val acuracy: 0.10400000214576721
step: 322, train loss: nan, train acuracy: 0.140625
step: 322, val loss: nan, val acuracy: 0.10400000214576721
step: 323, train loss: nan, train acuracy: 0.109375
step: 323, val loss: nan, val acuracy: 0.10400000214576721
step: 324, train loss: nan, train acuracy: 0.109375
step: 324, val loss: nan, val acuracy: 0.10400000214576721
step: 325, train loss: nan, train acuracy: 0.125
step: 325, val loss: nan, val acuracy: 0.10400000214576721
step: 326, train loss: nan, train acuracy: 0.125
step: 326, val loss: nan, val acuracy: 0.10400000214576721
step: 327, train loss: nan, train acuracy: 0.0703125
step: 327, val loss: nan, val acuracy: 0.10400000214576721
step: 328, train loss: nan, train acuracy: 0.09375
step: 328, val loss: nan, val acuracy: 0.10400000214576721
step: 329, train loss: nan, train acuracy: 0.0859375
step: 329, val loss: nan, val acuracy: 0.10400000214576721
step: 330, train loss: nan, train acuracy: 0.1015625
step: 330, val loss: nan, val acuracy: 0.10400000214576721
step: 331, train loss: nan, train acuracy: 0.109375
step: 331, val loss: nan, val acuracy: 0.10400000214576721
step: 332, train loss: nan, train acuracy: 0.109375
step: 332, val loss: nan, val acuracy: 0.10400000214576721
step: 333, train loss: nan, train acuracy: 0.1015625
step: 333, val loss: nan, val acuracy: 0.10400000214576721
step: 334, train loss: nan, train acuracy: 0.078125
step: 334, val loss: nan, val acuracy: 0.10400000214576721
step: 335, train loss: nan, train acuracy: 0.15625
step: 335, val loss: nan, val acuracy: 0.10400000214576721
step: 336, train loss: nan, train acuracy: 0.0625
step: 336, val loss: nan, val acuracy: 0.10400000214576721
step: 337, train loss: nan, train acuracy: 0.125
step: 337, val loss: nan, val acuracy: 0.10400000214576721
step: 338, train loss: nan, train acuracy: 0.0859375
step: 338, val loss: nan, val acuracy: 0.10400000214576721
step: 339, train loss: nan, train acuracy: 0.1328125
step: 339, val loss: nan, val acuracy: 0.10400000214576721
step: 340, train loss: nan, train acuracy: 0.1015625
step: 340, val loss: nan, val acuracy: 0.10400000214576721
step: 341, train loss: nan, train acuracy: 0.0703125
step: 341, val loss: nan, val acuracy: 0.10400000214576721
step: 342, train loss: nan, train acuracy: 0.046875
step: 342, val loss: nan, val acuracy: 0.10400000214576721
step: 343, train loss: nan, train acuracy: 0.0703125
step: 343, val loss: nan, val acuracy: 0.10400000214576721
step: 344, train loss: nan, train acuracy: 0.109375
step: 344, val loss: nan, val acuracy: 0.10400000214576721
step: 345, train loss: nan, train acuracy: 0.09375
step: 345, val loss: nan, val acuracy: 0.10400000214576721
step: 346, train loss: nan, train acuracy: 0.0859375
step: 346, val loss: nan, val acuracy: 0.10400000214576721
step: 347, train loss: nan, train acuracy: 0.1484375
step: 347, val loss: nan, val acuracy: 0.10400000214576721
step: 348, train loss: nan, train acuracy: 0.0859375
step: 348, val loss: nan, val acuracy: 0.10400000214576721
step: 349, train loss: nan, train acuracy: 0.0859375
step: 349, val loss: nan, val acuracy: 0.10400000214576721
step: 350, train loss: nan, train acuracy: 0.1015625
step: 350, val loss: nan, val acuracy: 0.10400000214576721
step: 351, train loss: nan, train acuracy: 0.0859375
step: 351, val loss: nan, val acuracy: 0.10400000214576721
step: 352, train loss: nan, train acuracy: 0.0859375
step: 352, val loss: nan, val acuracy: 0.10400000214576721
step: 353, train loss: nan, train acuracy: 0.109375
step: 353, val loss: nan, val acuracy: 0.10400000214576721
step: 354, train loss: nan, train acuracy: 0.1015625
step: 354, val loss: nan, val acuracy: 0.10400000214576721
step: 355, train loss: nan, train acuracy: 0.1015625
step: 355, val loss: nan, val acuracy: 0.10400000214576721
step: 356, train loss: nan, train acuracy: 0.1328125
step: 356, val loss: nan, val acuracy: 0.10400000214576721
step: 357, train loss: nan, train acuracy: 0.078125
step: 357, val loss: nan, val acuracy: 0.10400000214576721
step: 358, train loss: nan, train acuracy: 0.1015625
step: 358, val loss: nan, val acuracy: 0.10400000214576721
step: 359, train loss: nan, train acuracy: 0.0859375
step: 359, val loss: nan, val acuracy: 0.10400000214576721
step: 360, train loss: nan, train acuracy: 0.0703125
step: 360, val loss: nan, val acuracy: 0.10400000214576721
step: 361, train loss: nan, train acuracy: 0.09375
step: 361, val loss: nan, val acuracy: 0.10400000214576721
step: 362, train loss: nan, train acuracy: 0.0859375
step: 362, val loss: nan, val acuracy: 0.10400000214576721
step: 363, train loss: nan, train acuracy: 0.1015625
step: 363, val loss: nan, val acuracy: 0.10400000214576721
step: 364, train loss: nan, train acuracy: 0.078125
step: 364, val loss: nan, val acuracy: 0.10400000214576721
step: 365, train loss: nan, train acuracy: 0.125
step: 365, val loss: nan, val acuracy: 0.10400000214576721
step: 366, train loss: nan, train acuracy: 0.0859375
step: 366, val loss: nan, val acuracy: 0.10400000214576721
step: 367, train loss: nan, train acuracy: 0.125
step: 367, val loss: nan, val acuracy: 0.10400000214576721
step: 368, train loss: nan, train acuracy: 0.078125
step: 368, val loss: nan, val acuracy: 0.10400000214576721
step: 369, train loss: nan, train acuracy: 0.109375
step: 369, val loss: nan, val acuracy: 0.10400000214576721
step: 370, train loss: nan, train acuracy: 0.0859375
step: 370, val loss: nan, val acuracy: 0.10400000214576721
step: 371, train loss: nan, train acuracy: 0.109375
step: 371, val loss: nan, val acuracy: 0.10400000214576721
step: 372, train loss: nan, train acuracy: 0.0859375
step: 372, val loss: nan, val acuracy: 0.10400000214576721
step: 373, train loss: nan, train acuracy: 0.0625
step: 373, val loss: nan, val acuracy: 0.10400000214576721
step: 374, train loss: nan, train acuracy: 0.1015625
step: 374, val loss: nan, val acuracy: 0.10400000214576721
step: 375, train loss: nan, train acuracy: 0.0703125
step: 375, val loss: nan, val acuracy: 0.10400000214576721
step: 376, train loss: nan, train acuracy: 0.125
step: 376, val loss: nan, val acuracy: 0.10400000214576721
step: 377, train loss: nan, train acuracy: 0.1015625
step: 377, val loss: nan, val acuracy: 0.10400000214576721
step: 378, train loss: nan, train acuracy: 0.078125
step: 378, val loss: nan, val acuracy: 0.10400000214576721
step: 379, train loss: nan, train acuracy: 0.1328125
step: 379, val loss: nan, val acuracy: 0.10400000214576721
step: 380, train loss: nan, train acuracy: 0.09375
step: 380, val loss: nan, val acuracy: 0.10400000214576721
step: 381, train loss: nan, train acuracy: 0.109375
step: 381, val loss: nan, val acuracy: 0.10400000214576721
step: 382, train loss: nan, train acuracy: 0.078125
step: 382, val loss: nan, val acuracy: 0.10400000214576721
step: 383, train loss: nan, train acuracy: 0.1015625
step: 383, val loss: nan, val acuracy: 0.10400000214576721
step: 384, train loss: nan, train acuracy: 0.125
step: 384, val loss: nan, val acuracy: 0.10400000214576721
step: 385, train loss: nan, train acuracy: 0.09375
step: 385, val loss: nan, val acuracy: 0.10400000214576721
step: 386, train loss: nan, train acuracy: 0.0859375
step: 386, val loss: nan, val acuracy: 0.10400000214576721
step: 387, train loss: nan, train acuracy: 0.140625
step: 387, val loss: nan, val acuracy: 0.10400000214576721
step: 388, train loss: nan, train acuracy: 0.0859375
step: 388, val loss: nan, val acuracy: 0.10400000214576721
step: 389, train loss: nan, train acuracy: 0.078125
step: 389, val loss: nan, val acuracy: 0.10400000214576721
step: 390, train loss: nan, train acuracy: 0.109375
step: 390, val loss: nan, val acuracy: 0.10400000214576721
step: 391, train loss: nan, train acuracy: 0.078125
step: 391, val loss: nan, val acuracy: 0.10400000214576721
step: 392, train loss: nan, train acuracy: 0.1484375
step: 392, val loss: nan, val acuracy: 0.10400000214576721
step: 393, train loss: nan, train acuracy: 0.1015625
step: 393, val loss: nan, val acuracy: 0.10400000214576721
step: 394, train loss: nan, train acuracy: 0.125
step: 394, val loss: nan, val acuracy: 0.10400000214576721
step: 395, train loss: nan, train acuracy: 0.109375
step: 395, val loss: nan, val acuracy: 0.10400000214576721
step: 396, train loss: nan, train acuracy: 0.09375
step: 396, val loss: nan, val acuracy: 0.10400000214576721
step: 397, train loss: nan, train acuracy: 0.0703125
step: 397, val loss: nan, val acuracy: 0.10400000214576721
step: 398, train loss: nan, train acuracy: 0.1015625
step: 398, val loss: nan, val acuracy: 0.10400000214576721
step: 399, train loss: nan, train acuracy: 0.1171875
step: 399, val loss: nan, val acuracy: 0.10400000214576721
2017-12-04 16:11:50.092251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 16:11:50.335691: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0xbec7d80 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 16:11:50.336398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 16:11:50.336649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 16:11:50.336663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 16:11:50.336669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 16:11:50.336680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 16:11:50.336686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
m=20, bathc =256
step: 0, train loss: 2.333765745162964, train acuracy: 0.1328125
step: 0, val loss: 2.409027576446533, val acuracy: 0.09183333814144135
step: 1, train loss: 2.3395919799804688, train acuracy: 0.09375
step: 1, val loss: 2.3851709365844727, val acuracy: 0.09183333069086075
step: 2, train loss: 2.3809163570404053, train acuracy: 0.078125
step: 2, val loss: 2.3771355152130127, val acuracy: 0.09183333814144135
step: 3, train loss: 2.3917713165283203, train acuracy: 0.0625
step: 3, val loss: 2.3820695877075195, val acuracy: 0.09183333069086075
step: 4, train loss: 2.3973493576049805, train acuracy: 0.08203125
step: 4, val loss: 2.394103527069092, val acuracy: 0.09183333069086075
step: 5, train loss: 2.3689370155334473, train acuracy: 0.0625
step: 5, val loss: 2.398531436920166, val acuracy: 0.09183333069086075
step: 6, train loss: 2.368511915206909, train acuracy: 0.09375
step: 6, val loss: 2.3946144580841064, val acuracy: 0.09183333814144135
step: 7, train loss: 2.3800463676452637, train acuracy: 0.09765625
step: 7, val loss: 2.416212797164917, val acuracy: 0.09183333069086075
step: 8, train loss: 2.38474178314209, train acuracy: 0.11328125
step: 8, val loss: 2.3991661071777344, val acuracy: 0.09183333069086075
step: 9, train loss: 2.386209011077881, train acuracy: 0.09375
step: 9, val loss: 2.3973662853240967, val acuracy: 0.09183333069086075
step: 10, train loss: 2.390571117401123, train acuracy: 0.09765625
step: 10, val loss: 2.3949081897735596, val acuracy: 0.09183333814144135
step: 11, train loss: 2.3995862007141113, train acuracy: 0.1328125
step: 11, val loss: 2.4150736331939697, val acuracy: 0.10466665774583817
step: 12, train loss: 2.4117698669433594, train acuracy: 0.0859375
step: 12, val loss: 2.4259538650512695, val acuracy: 0.09183333069086075
step: 13, train loss: 2.4319000244140625, train acuracy: 0.0859375
step: 13, val loss: 2.392274856567383, val acuracy: 0.09183333814144135
step: 14, train loss: 2.401005744934082, train acuracy: 0.08203125
step: 14, val loss: 2.413968563079834, val acuracy: 0.09183333069086075
step: 15, train loss: 2.421013832092285, train acuracy: 0.10546875
step: 15, val loss: 2.4109761714935303, val acuracy: 0.09183333069086075
step: 16, train loss: 2.4052414894104004, train acuracy: 0.10546875
step: 16, val loss: 2.410045862197876, val acuracy: 0.09183333069086075
step: 17, train loss: 2.4551446437835693, train acuracy: 0.06640625
step: 17, val loss: 2.4090347290039062, val acuracy: 0.09183333814144135
step: 18, train loss: 2.450716495513916, train acuracy: 0.09375
step: 18, val loss: 2.408838987350464, val acuracy: 0.09183333069086075
step: 19, train loss: 2.4653820991516113, train acuracy: 0.0859375
step: 19, val loss: 2.4087164402008057, val acuracy: 0.09183333069086075
step: 20, train loss: 2.363119602203369, train acuracy: 0.1015625
step: 20, val loss: 2.408367395401001, val acuracy: 0.09183333814144135
step: 21, train loss: 2.3860597610473633, train acuracy: 0.08203125
step: 21, val loss: 2.408346176147461, val acuracy: 0.09183333069086075
step: 22, train loss: 2.4734644889831543, train acuracy: 0.08203125
step: 22, val loss: 2.537297487258911, val acuracy: 0.09683332592248917
step: 23, train loss: 2.2869625091552734, train acuracy: 0.12109375
step: 23, val loss: 2.359281539916992, val acuracy: 0.09950000047683716
step: 24, train loss: 2.261627674102783, train acuracy: 0.12890625
step: 24, val loss: 2.308497190475464, val acuracy: 0.10899999737739563
step: 25, train loss: 2.2722299098968506, train acuracy: 0.26171875
step: 25, val loss: 2.285526752471924, val acuracy: 0.22983333468437195
step: 26, train loss: 2.276832103729248, train acuracy: 0.1640625
step: 26, val loss: 2.3181509971618652, val acuracy: 0.13366666436195374
step: 27, train loss: 2.3313796520233154, train acuracy: 0.18359375
step: 27, val loss: 2.3079164028167725, val acuracy: 0.19233334064483643
step: 28, train loss: 2.3278961181640625, train acuracy: 0.171875
step: 28, val loss: 2.353756904602051, val acuracy: 0.15666665136814117
step: 29, train loss: 2.3838138580322266, train acuracy: 0.1171875
step: 29, val loss: 2.4323890209198, val acuracy: 0.09666666388511658
step: 30, train loss: 2.3100643157958984, train acuracy: 0.15625
step: 30, val loss: 2.3096745014190674, val acuracy: 0.16599999368190765
step: 31, train loss: 2.3222522735595703, train acuracy: 0.11328125
step: 31, val loss: 2.3557510375976562, val acuracy: 0.11183331906795502
step: 32, train loss: 2.3692240715026855, train acuracy: 0.12109375
step: 32, val loss: 2.435175895690918, val acuracy: 0.10400000214576721
step: 33, train loss: 2.4526219367980957, train acuracy: 0.12890625
step: 33, val loss: 2.474705219268799, val acuracy: 0.09666666388511658
step: 34, train loss: 2.411449432373047, train acuracy: 0.1796875
step: 34, val loss: 2.42753005027771, val acuracy: 0.19699999690055847
step: 35, train loss: 2.3769054412841797, train acuracy: 0.11328125
step: 35, val loss: 2.4490792751312256, val acuracy: 0.1054999977350235
step: 36, train loss: 2.414921998977661, train acuracy: 0.09765625
step: 36, val loss: 2.4076507091522217, val acuracy: 0.11600000411272049
step: 37, train loss: 2.480417013168335, train acuracy: 0.11328125
step: 37, val loss: 2.5387988090515137, val acuracy: 0.09666666388511658
step: 38, train loss: 2.498291015625, train acuracy: 0.109375
step: 38, val loss: 2.4792768955230713, val acuracy: 0.10899999737739563
step: 39, train loss: 2.3745315074920654, train acuracy: 0.140625
step: 39, val loss: 2.443023443222046, val acuracy: 0.12333332002162933
step: 40, train loss: 2.378615140914917, train acuracy: 0.1640625
step: 40, val loss: 2.407899856567383, val acuracy: 0.14233332872390747
step: 41, train loss: 2.305197238922119, train acuracy: 0.171875
step: 41, val loss: 2.3734943866729736, val acuracy: 0.11933332681655884
step: 42, train loss: 2.31453537940979, train acuracy: 0.1484375
step: 42, val loss: 2.3898215293884277, val acuracy: 0.09533333778381348
step: 43, train loss: 2.367811679840088, train acuracy: 0.11328125
step: 43, val loss: 2.419159412384033, val acuracy: 0.09816667437553406
step: 44, train loss: 2.30336594581604, train acuracy: 0.13671875
step: 44, val loss: 2.4309139251708984, val acuracy: 0.09933333098888397
step: 45, train loss: 2.433016777038574, train acuracy: 0.12890625
step: 45, val loss: 2.497926712036133, val acuracy: 0.09566666930913925
step: 46, train loss: 2.487752914428711, train acuracy: 0.13671875
step: 46, val loss: 2.5066466331481934, val acuracy: 0.09749999642372131
step: 47, train loss: 2.408233165740967, train acuracy: 0.2421875
step: 47, val loss: 2.4388675689697266, val acuracy: 0.22200000286102295
step: 48, train loss: 2.330986738204956, train acuracy: 0.13671875
step: 48, val loss: 2.428260087966919, val acuracy: 0.10783332586288452
step: 49, train loss: 2.381784200668335, train acuracy: 0.13671875
step: 49, val loss: 2.5174717903137207, val acuracy: 0.10400000214576721
step: 50, train loss: 2.5036609172821045, train acuracy: 0.14453125
step: 50, val loss: 2.6088037490844727, val acuracy: 0.10899999737739563
step: 51, train loss: 2.5332252979278564, train acuracy: 0.125
step: 51, val loss: 2.4933300018310547, val acuracy: 0.1184999942779541
step: 52, train loss: 2.359041213989258, train acuracy: 0.10546875
step: 52, val loss: 2.386162042617798, val acuracy: 0.11900000274181366
step: 53, train loss: 2.3998842239379883, train acuracy: 0.12109375
step: 53, val loss: 2.3922922611236572, val acuracy: 0.10400000214576721
step: 54, train loss: 2.361461639404297, train acuracy: 0.125
step: 54, val loss: 2.4241044521331787, val acuracy: 0.10899999737739563
step: 55, train loss: 2.410696506500244, train acuracy: 0.19140625
step: 55, val loss: 2.503836154937744, val acuracy: 0.15433332324028015
step: 56, train loss: 2.463132619857788, train acuracy: 0.140625
step: 56, val loss: 2.5773611068725586, val acuracy: 0.11249999701976776
step: 57, train loss: 2.548463821411133, train acuracy: 0.1015625
step: 57, val loss: 2.569998264312744, val acuracy: 0.09549999982118607
step: 58, train loss: 2.5738625526428223, train acuracy: 0.20703125
step: 58, val loss: 2.622685432434082, val acuracy: 0.20066668093204498
step: 59, train loss: 2.5111868381500244, train acuracy: 0.09375
step: 59, val loss: 2.5521295070648193, val acuracy: 0.10899999737739563
step: 60, train loss: 2.4438982009887695, train acuracy: 0.2109375
step: 60, val loss: 2.4614529609680176, val acuracy: 0.1574999839067459
step: 61, train loss: 2.4626471996307373, train acuracy: 0.12890625
step: 61, val loss: 2.6003198623657227, val acuracy: 0.10899998992681503
step: 62, train loss: 2.6093828678131104, train acuracy: 0.125
step: 62, val loss: 2.7501449584960938, val acuracy: 0.09533333778381348
step: 63, train loss: 2.683239698410034, train acuracy: 0.1328125
step: 63, val loss: 2.753424882888794, val acuracy: 0.10899999737739563
step: 64, train loss: 2.6952836513519287, train acuracy: 0.109375
step: 64, val loss: 2.730034351348877, val acuracy: 0.09533333778381348
step: 65, train loss: 2.694753646850586, train acuracy: 0.1171875
step: 65, val loss: 2.8482518196105957, val acuracy: 0.10899998992681503
step: 66, train loss: 2.4927783012390137, train acuracy: 0.109375
step: 66, val loss: 2.588993787765503, val acuracy: 0.09583333134651184
step: 67, train loss: 2.5430893898010254, train acuracy: 0.140625
step: 67, val loss: 2.6266534328460693, val acuracy: 0.10899998992681503
step: 68, train loss: 2.570342540740967, train acuracy: 0.13671875
step: 68, val loss: 2.5707192420959473, val acuracy: 0.14999999105930328
step: 69, train loss: 2.588106632232666, train acuracy: 0.1171875
step: 69, val loss: 2.61592960357666, val acuracy: 0.10533333569765091
step: 70, train loss: 2.452000856399536, train acuracy: 0.203125
step: 70, val loss: 2.4160616397857666, val acuracy: 0.20016667246818542
step: 71, train loss: 2.3819003105163574, train acuracy: 0.21484375
step: 71, val loss: 2.4139838218688965, val acuracy: 0.19249999523162842
step: 72, train loss: 2.2651872634887695, train acuracy: 0.140625
step: 72, val loss: 2.3202693462371826, val acuracy: 0.10666666179895401
step: 73, train loss: 2.2506918907165527, train acuracy: 0.25
step: 73, val loss: 2.261277675628662, val acuracy: 0.2521666884422302
step: 74, train loss: 2.2122840881347656, train acuracy: 0.21484375
step: 74, val loss: 2.2311930656433105, val acuracy: 0.19433332979679108
step: 75, train loss: 1.9572876691818237, train acuracy: 0.484375
step: 75, val loss: 2.1485793590545654, val acuracy: 0.4036666750907898
step: 76, train loss: 1.7349120378494263, train acuracy: 0.51171875
step: 76, val loss: 1.7407935857772827, val acuracy: 0.5365000367164612
step: 77, train loss: 1.7127984762191772, train acuracy: 0.5
step: 77, val loss: 1.6779391765594482, val acuracy: 0.5015000104904175
step: 78, train loss: 1.3304669857025146, train acuracy: 0.7265625
step: 78, val loss: 1.3522627353668213, val acuracy: 0.7046667337417603
step: 79, train loss: 1.309861421585083, train acuracy: 0.57421875
step: 79, val loss: 1.3453948497772217, val acuracy: 0.530666708946228
step: 80, train loss: 0.8779110312461853, train acuracy: 0.68359375
step: 80, val loss: 0.955731987953186, val acuracy: 0.6731666922569275
step: 81, train loss: 0.9849575757980347, train acuracy: 0.69140625
step: 81, val loss: 0.9328805208206177, val acuracy: 0.6884999871253967
step: 82, train loss: 0.9295826554298401, train acuracy: 0.6953125
step: 82, val loss: 0.9627000689506531, val acuracy: 0.6810000538825989
step: 83, train loss: 0.8348102569580078, train acuracy: 0.69921875
step: 83, val loss: 0.9471012353897095, val acuracy: 0.6856667399406433
step: 84, train loss: 0.7595140933990479, train acuracy: 0.75
step: 84, val loss: 0.9279298782348633, val acuracy: 0.684499979019165
step: 85, train loss: 0.9159680008888245, train acuracy: 0.703125
step: 85, val loss: 0.9393476247787476, val acuracy: 0.6831666827201843
step: 86, train loss: 0.8890979290008545, train acuracy: 0.70703125
step: 86, val loss: 0.9375624060630798, val acuracy: 0.6836667656898499
step: 87, train loss: 0.9405614137649536, train acuracy: 0.71875
step: 87, val loss: 0.9713000059127808, val acuracy: 0.6606667041778564
step: 88, train loss: 0.872265100479126, train acuracy: 0.7109375
step: 88, val loss: 0.9482111930847168, val acuracy: 0.677333414554596
step: 89, train loss: 0.8761284351348877, train acuracy: 0.6875
step: 89, val loss: 0.9660873413085938, val acuracy: 0.6741666793823242
step: 90, train loss: 0.9601491689682007, train acuracy: 0.68359375
step: 90, val loss: 0.9959303736686707, val acuracy: 0.655500054359436
step: 91, train loss: 0.8034554719924927, train acuracy: 0.71875
step: 91, val loss: 0.971131443977356, val acuracy: 0.6623334288597107
step: 92, train loss: 0.9199859499931335, train acuracy: 0.6875
step: 92, val loss: 0.9822630882263184, val acuracy: 0.6573334336280823
step: 93, train loss: 1.1018778085708618, train acuracy: 0.640625
step: 93, val loss: 1.0512776374816895, val acuracy: 0.6471667289733887
step: 94, train loss: 0.9706442356109619, train acuracy: 0.671875
step: 94, val loss: 1.0497775077819824, val acuracy: 0.639666736125946
step: 95, train loss: 1.0104069709777832, train acuracy: 0.6796875
step: 95, val loss: 0.987535834312439, val acuracy: 0.6606667041778564
step: 96, train loss: 0.9955883026123047, train acuracy: 0.65234375
step: 96, val loss: 1.0113496780395508, val acuracy: 0.6476666927337646
step: 97, train loss: 0.957545280456543, train acuracy: 0.66796875
step: 97, val loss: 1.0029144287109375, val acuracy: 0.661666750907898
step: 98, train loss: 1.0035041570663452, train acuracy: 0.640625
step: 98, val loss: 0.974217414855957, val acuracy: 0.6571667194366455
step: 99, train loss: 0.7729408740997314, train acuracy: 0.734375
step: 99, val loss: 0.9485766887664795, val acuracy: 0.6715000867843628
step: 100, train loss: 1.0186747312545776, train acuracy: 0.66796875
step: 100, val loss: 0.9905486106872559, val acuracy: 0.659166693687439
step: 101, train loss: 1.0256091356277466, train acuracy: 0.640625
step: 101, val loss: 1.0180997848510742, val acuracy: 0.6471667289733887
step: 102, train loss: 1.077545404434204, train acuracy: 0.66796875
step: 102, val loss: 1.0438835620880127, val acuracy: 0.6501666903495789
step: 103, train loss: 1.0761795043945312, train acuracy: 0.6171875
step: 103, val loss: 1.0581488609313965, val acuracy: 0.6350000500679016
step: 104, train loss: 1.0315319299697876, train acuracy: 0.64453125
step: 104, val loss: 1.1108641624450684, val acuracy: 0.6259999871253967
step: 105, train loss: 1.183107852935791, train acuracy: 0.61328125
step: 105, val loss: 1.1767462491989136, val acuracy: 0.6003333926200867
step: 106, train loss: 1.184485912322998, train acuracy: 0.5625
step: 106, val loss: 1.2676304578781128, val acuracy: 0.5763333439826965
step: 107, train loss: 1.0375020503997803, train acuracy: 0.65625
step: 107, val loss: 1.1887913942337036, val acuracy: 0.6110000014305115
step: 108, train loss: 1.1945037841796875, train acuracy: 0.625
step: 108, val loss: 1.16585373878479, val acuracy: 0.6145000457763672
step: 109, train loss: 1.002941370010376, train acuracy: 0.6796875
step: 109, val loss: 1.216392993927002, val acuracy: 0.6106666326522827
step: 110, train loss: 1.0936105251312256, train acuracy: 0.66796875
step: 110, val loss: 1.328603982925415, val acuracy: 0.6010000109672546
step: 111, train loss: 1.2447869777679443, train acuracy: 0.58203125
step: 111, val loss: 1.2201416492462158, val acuracy: 0.5746666789054871
step: 112, train loss: 1.334409475326538, train acuracy: 0.60546875
step: 112, val loss: 1.2767975330352783, val acuracy: 0.624500036239624
step: 113, train loss: 1.3179309368133545, train acuracy: 0.5625
step: 113, val loss: 1.3406987190246582, val acuracy: 0.5488333702087402
step: 114, train loss: 1.0813193321228027, train acuracy: 0.62109375
step: 114, val loss: 1.1919225454330444, val acuracy: 0.6158333420753479
step: 115, train loss: 1.2583363056182861, train acuracy: 0.56640625
step: 115, val loss: 1.3088127374649048, val acuracy: 0.5501667261123657
step: 116, train loss: 1.2495837211608887, train acuracy: 0.6015625
step: 116, val loss: 1.1843572854995728, val acuracy: 0.6098334193229675
step: 117, train loss: 1.065921425819397, train acuracy: 0.63671875
step: 117, val loss: 1.2824639081954956, val acuracy: 0.5613333582878113
step: 118, train loss: 1.320560336112976, train acuracy: 0.5859375
step: 118, val loss: 1.3306448459625244, val acuracy: 0.5946667194366455
step: 119, train loss: 1.27568781375885, train acuracy: 0.58203125
step: 119, val loss: 1.2206937074661255, val acuracy: 0.5870000720024109
step: 120, train loss: 1.2344294786453247, train acuracy: 0.6171875
step: 120, val loss: 1.2510544061660767, val acuracy: 0.5963333249092102
step: 121, train loss: 1.1087547540664673, train acuracy: 0.60546875
step: 121, val loss: 1.2131648063659668, val acuracy: 0.5843333601951599
step: 122, train loss: 1.1356593370437622, train acuracy: 0.61328125
step: 122, val loss: 1.2566771507263184, val acuracy: 0.6061667203903198
step: 123, train loss: 1.1877336502075195, train acuracy: 0.6015625
step: 123, val loss: 1.2152811288833618, val acuracy: 0.5899999737739563
step: 124, train loss: 1.2773418426513672, train acuracy: 0.5390625
step: 124, val loss: 1.204103708267212, val acuracy: 0.5821666717529297
step: 125, train loss: 1.1526610851287842, train acuracy: 0.61328125
step: 125, val loss: 1.1902841329574585, val acuracy: 0.5951666831970215
step: 126, train loss: 1.2312639951705933, train acuracy: 0.57421875
step: 126, val loss: 1.2087838649749756, val acuracy: 0.6069999933242798
step: 127, train loss: 1.0742436647415161, train acuracy: 0.6484375
step: 127, val loss: 1.2068144083023071, val acuracy: 0.60833340883255
step: 128, train loss: 1.19380521774292, train acuracy: 0.5625
step: 128, val loss: 1.187960147857666, val acuracy: 0.5826667547225952
step: 129, train loss: 1.247866153717041, train acuracy: 0.5625
step: 129, val loss: 1.166224479675293, val acuracy: 0.5920000076293945
step: 130, train loss: 1.0634187459945679, train acuracy: 0.640625
step: 130, val loss: 1.194746732711792, val acuracy: 0.5978333353996277
step: 131, train loss: 1.1400220394134521, train acuracy: 0.5703125
step: 131, val loss: 1.16621732711792, val acuracy: 0.5811666250228882
step: 132, train loss: 1.119240164756775, train acuracy: 0.6171875
step: 132, val loss: 1.1763426065444946, val acuracy: 0.5954999923706055
step: 133, train loss: 1.0257465839385986, train acuracy: 0.62890625
step: 133, val loss: 1.133959174156189, val acuracy: 0.6018334031105042
step: 134, train loss: 1.134698510169983, train acuracy: 0.609375
step: 134, val loss: 1.1749659776687622, val acuracy: 0.5733333230018616
step: 135, train loss: 1.0917131900787354, train acuracy: 0.625
step: 135, val loss: 1.2251794338226318, val acuracy: 0.5918333530426025
step: 136, train loss: 1.0270437002182007, train acuracy: 0.6484375
step: 136, val loss: 1.175794005393982, val acuracy: 0.5863333940505981
step: 137, train loss: 1.1081669330596924, train acuracy: 0.625
step: 137, val loss: 1.0988463163375854, val acuracy: 0.6186666488647461
step: 138, train loss: 1.0699931383132935, train acuracy: 0.6328125
step: 138, val loss: 1.1639931201934814, val acuracy: 0.5881667137145996
step: 139, train loss: 1.0197103023529053, train acuracy: 0.65625
step: 139, val loss: 1.2439181804656982, val acuracy: 0.6145000457763672
step: 140, train loss: 1.0873816013336182, train acuracy: 0.60546875
step: 140, val loss: 1.1161861419677734, val acuracy: 0.6200000047683716
step: 141, train loss: 1.0699653625488281, train acuracy: 0.62109375
step: 141, val loss: 1.1198146343231201, val acuracy: 0.6051666736602783
step: 142, train loss: 1.1684179306030273, train acuracy: 0.58984375
step: 142, val loss: 1.1136274337768555, val acuracy: 0.6071667075157166
step: 143, train loss: 1.200707197189331, train acuracy: 0.53125
step: 143, val loss: 1.1116610765457153, val acuracy: 0.6091667413711548
step: 144, train loss: 1.0970823764801025, train acuracy: 0.609375
step: 144, val loss: 1.1111421585083008, val acuracy: 0.6076667308807373
step: 145, train loss: 1.318474292755127, train acuracy: 0.53125
step: 145, val loss: 1.1457659006118774, val acuracy: 0.597000002861023
step: 146, train loss: 1.2684099674224854, train acuracy: 0.55859375
step: 146, val loss: 1.1431899070739746, val acuracy: 0.599166750907898
step: 147, train loss: 1.2005757093429565, train acuracy: 0.5859375
step: 147, val loss: 1.1446905136108398, val acuracy: 0.6100000739097595
step: 148, train loss: 1.1479859352111816, train acuracy: 0.61328125
step: 148, val loss: 1.169146180152893, val acuracy: 0.6043334007263184
step: 149, train loss: 1.1367199420928955, train acuracy: 0.56640625
step: 149, val loss: 1.1303222179412842, val acuracy: 0.6190000176429749
step: 150, train loss: 1.2138086557388306, train acuracy: 0.61328125
step: 150, val loss: 1.1830310821533203, val acuracy: 0.5978333353996277
step: 151, train loss: 0.9971450567245483, train acuracy: 0.65234375
step: 151, val loss: 1.1773147583007812, val acuracy: 0.6010000705718994
step: 152, train loss: 1.1393145322799683, train acuracy: 0.625
step: 152, val loss: 1.1750251054763794, val acuracy: 0.6025000810623169
step: 153, train loss: 1.240741491317749, train acuracy: 0.55078125
step: 153, val loss: 1.1823333501815796, val acuracy: 0.593166708946228
step: 154, train loss: 1.1734766960144043, train acuracy: 0.60546875
step: 154, val loss: 1.1970635652542114, val acuracy: 0.5988333225250244
step: 155, train loss: 1.306984543800354, train acuracy: 0.609375
step: 155, val loss: 1.1918375492095947, val acuracy: 0.6006666421890259
step: 156, train loss: 1.2648147344589233, train acuracy: 0.6015625
step: 156, val loss: 1.1885707378387451, val acuracy: 0.6025000214576721
step: 157, train loss: 1.0995534658432007, train acuracy: 0.6171875
step: 157, val loss: 1.1862857341766357, val acuracy: 0.6038333773612976
step: 158, train loss: 1.2270855903625488, train acuracy: 0.60546875
step: 158, val loss: 1.1854084730148315, val acuracy: 0.6050000786781311
step: 159, train loss: 1.2108049392700195, train acuracy: 0.59375
step: 159, val loss: 1.1848820447921753, val acuracy: 0.6054999828338623
step: 160, train loss: 1.2194445133209229, train acuracy: 0.62109375
step: 160, val loss: 1.1849143505096436, val acuracy: 0.6056666970252991
step: 161, train loss: 1.2867268323898315, train acuracy: 0.5625
step: 161, val loss: 1.1847012042999268, val acuracy: 0.6055001020431519
step: 162, train loss: 1.1153582334518433, train acuracy: 0.62109375
step: 162, val loss: 1.184291958808899, val acuracy: 0.6053333878517151
step: 163, train loss: 1.2227665185928345, train acuracy: 0.578125
step: 163, val loss: 1.2385625839233398, val acuracy: 0.5874999761581421
step: 164, train loss: 1.108850121498108, train acuracy: 0.6328125
step: 164, val loss: 1.2116292715072632, val acuracy: 0.5821666717529297
step: 165, train loss: 1.114530324935913, train acuracy: 0.609375
step: 165, val loss: 1.2079448699951172, val acuracy: 0.5851666927337646
step: 166, train loss: 1.2747968435287476, train acuracy: 0.58203125
step: 166, val loss: 1.225144624710083, val acuracy: 0.6015000939369202
step: 167, train loss: 1.2179267406463623, train acuracy: 0.6015625
step: 167, val loss: 1.2208210229873657, val acuracy: 0.6011667847633362
step: 168, train loss: 1.1594139337539673, train acuracy: 0.6171875
step: 168, val loss: 1.2058384418487549, val acuracy: 0.5993332862854004
step: 169, train loss: 1.2432247400283813, train acuracy: 0.60546875
step: 169, val loss: 1.272830843925476, val acuracy: 0.5830000638961792
step: 170, train loss: 1.466281533241272, train acuracy: 0.53515625
step: 170, val loss: 1.2242344617843628, val acuracy: 0.6080000996589661
step: 171, train loss: 1.220929741859436, train acuracy: 0.58984375
step: 171, val loss: 1.2504209280014038, val acuracy: 0.5893333554267883
step: 172, train loss: 1.1279311180114746, train acuracy: 0.6171875
step: 172, val loss: 1.2189960479736328, val acuracy: 0.6043334007263184
step: 173, train loss: 1.2354201078414917, train acuracy: 0.609375
step: 173, val loss: 1.2601454257965088, val acuracy: 0.596333384513855
step: 174, train loss: 1.1583701372146606, train acuracy: 0.6328125
step: 174, val loss: 1.243561863899231, val acuracy: 0.5978333950042725
step: 175, train loss: 1.1969496011734009, train acuracy: 0.61328125
step: 175, val loss: 1.2407697439193726, val acuracy: 0.5998333692550659
step: 176, train loss: 1.3078210353851318, train acuracy: 0.578125
step: 176, val loss: 1.2957775592803955, val acuracy: 0.5691666603088379
step: 177, train loss: 1.133392333984375, train acuracy: 0.5859375
step: 177, val loss: 1.259156346321106, val acuracy: 0.5833333730697632
step: 178, train loss: 1.1806371212005615, train acuracy: 0.58984375
step: 178, val loss: 1.2926766872406006, val acuracy: 0.5641666650772095
step: 179, train loss: 1.3403334617614746, train acuracy: 0.58203125
step: 179, val loss: 1.288884162902832, val acuracy: 0.5691666603088379
step: 180, train loss: 1.385602355003357, train acuracy: 0.52734375
step: 180, val loss: 1.432347059249878, val acuracy: 0.5233333706855774
step: 181, train loss: 1.4903316497802734, train acuracy: 0.48828125
step: 181, val loss: 1.482580304145813, val acuracy: 0.5090000033378601
step: 182, train loss: 1.450148105621338, train acuracy: 0.515625
step: 182, val loss: 1.4553217887878418, val acuracy: 0.5225000381469727
step: 183, train loss: 1.5093138217926025, train acuracy: 0.51171875
step: 183, val loss: 1.478732705116272, val acuracy: 0.5173333883285522
step: 184, train loss: 1.5141385793685913, train acuracy: 0.4921875
step: 184, val loss: 1.4742923974990845, val acuracy: 0.5191667079925537
step: 185, train loss: 1.46620512008667, train acuracy: 0.54296875
step: 185, val loss: 1.4724061489105225, val acuracy: 0.518500030040741
step: 186, train loss: 1.5311905145645142, train acuracy: 0.484375
step: 186, val loss: 1.498582363128662, val acuracy: 0.5099999904632568
step: 187, train loss: 1.462048053741455, train acuracy: 0.49609375
step: 187, val loss: 1.474395990371704, val acuracy: 0.5161666870117188
step: 188, train loss: 1.5868014097213745, train acuracy: 0.48046875
step: 188, val loss: 1.5081186294555664, val acuracy: 0.5088334083557129
step: 189, train loss: 1.4175119400024414, train acuracy: 0.51953125
step: 189, val loss: 1.4891244173049927, val acuracy: 0.5103333592414856
step: 190, train loss: 1.4433192014694214, train acuracy: 0.52734375
step: 190, val loss: 1.4742870330810547, val acuracy: 0.5264999866485596
step: 191, train loss: 1.4490684270858765, train acuracy: 0.53125
step: 191, val loss: 1.4671881198883057, val acuracy: 0.5208333730697632
step: 192, train loss: 1.415978193283081, train acuracy: 0.55078125
step: 192, val loss: 1.5014135837554932, val acuracy: 0.4920000433921814
step: 193, train loss: 1.4804723262786865, train acuracy: 0.51953125
step: 193, val loss: 1.4862241744995117, val acuracy: 0.5136666893959045
step: 194, train loss: 1.3355202674865723, train acuracy: 0.5625
step: 194, val loss: 1.472586989402771, val acuracy: 0.5128333568572998
step: 195, train loss: 1.464374303817749, train acuracy: 0.5078125
step: 195, val loss: 1.5157212018966675, val acuracy: 0.48533332347869873
step: 196, train loss: 1.4434657096862793, train acuracy: 0.4921875
step: 196, val loss: 1.4872764348983765, val acuracy: 0.5038333535194397
step: 197, train loss: 1.348421573638916, train acuracy: 0.5625
step: 197, val loss: 1.4836616516113281, val acuracy: 0.5060000419616699
step: 198, train loss: 1.419523000717163, train acuracy: 0.58203125
step: 198, val loss: 1.467463493347168, val acuracy: 0.5225000381469727
step: 199, train loss: 1.5307221412658691, train acuracy: 0.49609375
step: 199, val loss: 1.4695385694503784, val acuracy: 0.5320000648498535
step: 200, train loss: 1.4264180660247803, train acuracy: 0.51953125
step: 200, val loss: 1.4677331447601318, val acuracy: 0.5329999923706055
step: 201, train loss: 1.4031728506088257, train acuracy: 0.55078125
step: 201, val loss: 1.4539834260940552, val acuracy: 0.5163333415985107
step: 202, train loss: 1.3565374612808228, train acuracy: 0.5625
step: 202, val loss: 1.4593712091445923, val acuracy: 0.5725000500679016
step: 203, train loss: 1.4614899158477783, train acuracy: 0.55859375
step: 203, val loss: 1.4525034427642822, val acuracy: 0.5703333616256714
step: 204, train loss: 1.5811892747879028, train acuracy: 0.40625
step: 204, val loss: 1.4358092546463013, val acuracy: 0.4751666784286499
step: 205, train loss: 1.4243171215057373, train acuracy: 0.546875
step: 205, val loss: 1.4158616065979004, val acuracy: 0.5163333415985107
step: 206, train loss: 1.5231972932815552, train acuracy: 0.4765625
step: 206, val loss: 1.4044623374938965, val acuracy: 0.5176666975021362
step: 207, train loss: 1.3961083889007568, train acuracy: 0.5234375
step: 207, val loss: 1.3954765796661377, val acuracy: 0.5256667137145996
step: 208, train loss: 1.3827033042907715, train acuracy: 0.57421875
step: 208, val loss: 1.3611845970153809, val acuracy: 0.5601667165756226
step: 209, train loss: 1.3540318012237549, train acuracy: 0.57421875
step: 209, val loss: 1.3556607961654663, val acuracy: 0.5688333511352539
step: 210, train loss: 1.3205485343933105, train acuracy: 0.59765625
step: 210, val loss: 1.3274809122085571, val acuracy: 0.5748334527015686
step: 211, train loss: 1.3570457696914673, train acuracy: 0.58203125
step: 211, val loss: 1.395241141319275, val acuracy: 0.5586667060852051
step: 212, train loss: 1.305072546005249, train acuracy: 0.62109375
step: 212, val loss: 1.366516351699829, val acuracy: 0.5780000686645508
step: 213, train loss: 1.2986265420913696, train acuracy: 0.57421875
step: 213, val loss: 1.3876020908355713, val acuracy: 0.5751667022705078
step: 214, train loss: 1.4686131477355957, train acuracy: 0.5390625
step: 214, val loss: 1.383375883102417, val acuracy: 0.5760000348091125
step: 215, train loss: 1.3974435329437256, train acuracy: 0.58203125
step: 215, val loss: 1.3830503225326538, val acuracy: 0.5763333439826965
step: 216, train loss: 1.4232162237167358, train acuracy: 0.53515625
step: 216, val loss: 1.3822942972183228, val acuracy: 0.5760000348091125
step: 217, train loss: 1.3557701110839844, train acuracy: 0.57421875
step: 217, val loss: 1.3807533979415894, val acuracy: 0.5761667490005493
step: 218, train loss: 1.3148096799850464, train acuracy: 0.625
step: 218, val loss: 1.385958194732666, val acuracy: 0.5710000395774841
step: 219, train loss: 1.3213893175125122, train acuracy: 0.59765625
step: 219, val loss: 1.3846440315246582, val acuracy: 0.5695000290870667
step: 220, train loss: 1.3072891235351562, train acuracy: 0.59375
step: 220, val loss: 1.3942739963531494, val acuracy: 0.5716667175292969
step: 221, train loss: 1.7680330276489258, train acuracy: 0.421875
step: 221, val loss: 1.7039084434509277, val acuracy: 0.43650001287460327
step: 222, train loss: 1.6751933097839355, train acuracy: 0.4296875
step: 222, val loss: 1.6841340065002441, val acuracy: 0.4401666522026062
step: 223, train loss: 1.6734867095947266, train acuracy: 0.453125
step: 223, val loss: 1.681041955947876, val acuracy: 0.4414999783039093
step: 224, train loss: 1.5656712055206299, train acuracy: 0.484375
step: 224, val loss: 1.678302526473999, val acuracy: 0.4411666691303253
step: 225, train loss: 1.7125012874603271, train acuracy: 0.4296875
step: 225, val loss: 1.6765830516815186, val acuracy: 0.44083335995674133
step: 226, train loss: 1.6932320594787598, train acuracy: 0.3984375
step: 226, val loss: 1.6798572540283203, val acuracy: 0.4425000548362732
step: 227, train loss: 1.6718544960021973, train acuracy: 0.45703125
step: 227, val loss: 1.7048373222351074, val acuracy: 0.43383336067199707
step: 228, train loss: 1.6663818359375, train acuracy: 0.43359375
step: 228, val loss: 1.7163162231445312, val acuracy: 0.41350001096725464
step: 229, train loss: 1.810107707977295, train acuracy: 0.43359375
step: 229, val loss: 1.6784504652023315, val acuracy: 0.44200003147125244
step: 230, train loss: 1.6627271175384521, train acuracy: 0.45703125
step: 230, val loss: 1.6879734992980957, val acuracy: 0.4306666851043701
step: 231, train loss: 1.6552455425262451, train acuracy: 0.45703125
step: 231, val loss: 1.7463033199310303, val acuracy: 0.4268333613872528
step: 232, train loss: 1.7073991298675537, train acuracy: 0.41015625
step: 232, val loss: 1.6792718172073364, val acuracy: 0.43783339858055115
step: 233, train loss: 1.7928324937820435, train acuracy: 0.41015625
step: 233, val loss: 1.8369519710540771, val acuracy: 0.39250001311302185
step: 234, train loss: 1.7112810611724854, train acuracy: 0.4375
step: 234, val loss: 1.7451266050338745, val acuracy: 0.4141666889190674
step: 235, train loss: 24.055294036865234, train acuracy: 0.1015625
step: 235, val loss: 24.066753387451172, val acuracy: 0.1053333431482315
step: 236, train loss: 3.767007350921631, train acuracy: 0.109375
step: 236, val loss: 3.8556084632873535, val acuracy: 0.09749999642372131
step: 237, train loss: 3.701197624206543, train acuracy: 0.1015625
step: 237, val loss: 3.7940914630889893, val acuracy: 0.10733333230018616
step: 238, train loss: 3.6119611263275146, train acuracy: 0.10546875
step: 238, val loss: 3.656008720397949, val acuracy: 0.0885000005364418
step: 239, train loss: 2.409040927886963, train acuracy: 0.11328125
step: 239, val loss: 2.4006316661834717, val acuracy: 0.10483333468437195
step: 240, train loss: 2.2229843139648438, train acuracy: 0.12890625
step: 240, val loss: 2.300955295562744, val acuracy: 0.13116666674613953
step: 241, train loss: 2.1752541065216064, train acuracy: 0.22265625
step: 241, val loss: 2.2115235328674316, val acuracy: 0.20716668665409088
step: 242, train loss: 2.2000796794891357, train acuracy: 0.19921875
step: 242, val loss: 2.197118043899536, val acuracy: 0.21783334016799927
step: 243, train loss: 2.129157543182373, train acuracy: 0.1328125
step: 243, val loss: 2.089707374572754, val acuracy: 0.1653333157300949
step: 244, train loss: 1.7650048732757568, train acuracy: 0.46484375
step: 244, val loss: 1.819004774093628, val acuracy: 0.4286666512489319
step: 245, train loss: 1.4696968793869019, train acuracy: 0.59375
step: 245, val loss: 1.5062294006347656, val acuracy: 0.5803332924842834
step: 246, train loss: 1.4436322450637817, train acuracy: 0.48046875
step: 246, val loss: 1.6060937643051147, val acuracy: 0.4424999952316284
step: 247, train loss: 1.2053521871566772, train acuracy: 0.61328125
step: 247, val loss: 1.233566403388977, val acuracy: 0.611833393573761
step: 248, train loss: 0.9275162816047668, train acuracy: 0.70703125
step: 248, val loss: 0.9813424348831177, val acuracy: 0.6966666579246521
step: 249, train loss: 0.9417412877082825, train acuracy: 0.7421875
step: 249, val loss: 0.9734673500061035, val acuracy: 0.7009999752044678
step: 250, train loss: 1.0443058013916016, train acuracy: 0.6796875
step: 250, val loss: 0.9783620834350586, val acuracy: 0.6966667175292969
step: 251, train loss: 0.9777121543884277, train acuracy: 0.6796875
step: 251, val loss: 0.9689756631851196, val acuracy: 0.6965000629425049
step: 252, train loss: 0.9011996984481812, train acuracy: 0.71484375
step: 252, val loss: 0.9551304578781128, val acuracy: 0.7033333778381348
step: 253, train loss: 0.9848269820213318, train acuracy: 0.67578125
step: 253, val loss: 1.084558367729187, val acuracy: 0.6418333053588867
step: 254, train loss: 1.2668075561523438, train acuracy: 0.5625
step: 254, val loss: 1.0836803913116455, val acuracy: 0.6553333401679993
step: 255, train loss: 1.0511490106582642, train acuracy: 0.6328125
step: 255, val loss: 1.1085478067398071, val acuracy: 0.6153333187103271
step: 256, train loss: 1.1129755973815918, train acuracy: 0.640625
step: 256, val loss: 1.1363617181777954, val acuracy: 0.6410000324249268
step: 257, train loss: 0.9991072416305542, train acuracy: 0.66796875
step: 257, val loss: 1.1179895401000977, val acuracy: 0.611333429813385
step: 258, train loss: 0.9873156547546387, train acuracy: 0.6953125
step: 258, val loss: 1.0874683856964111, val acuracy: 0.6543333530426025
step: 259, train loss: 0.9447697401046753, train acuracy: 0.6640625
step: 259, val loss: 1.0739364624023438, val acuracy: 0.6335000395774841
step: 260, train loss: 1.007893681526184, train acuracy: 0.6875
step: 260, val loss: 1.0700373649597168, val acuracy: 0.6626667380332947
step: 261, train loss: 0.9923527240753174, train acuracy: 0.6640625
step: 261, val loss: 1.0472326278686523, val acuracy: 0.6508334279060364
step: 262, train loss: 0.9392155408859253, train acuracy: 0.66796875
step: 262, val loss: 1.0481165647506714, val acuracy: 0.6518334150314331
step: 263, train loss: 4.051140785217285, train acuracy: 0.19140625
step: 263, val loss: 4.110143184661865, val acuracy: 0.19866666197776794
step: 264, train loss: 1.9763312339782715, train acuracy: 0.28515625
step: 264, val loss: 2.0202391147613525, val acuracy: 0.27650001645088196
step: 265, train loss: 1.9202004671096802, train acuracy: 0.37109375
step: 265, val loss: 1.8955575227737427, val acuracy: 0.3941666781902313
step: 266, train loss: 1.6705925464630127, train acuracy: 0.4375
step: 266, val loss: 1.8700999021530151, val acuracy: 0.3761667013168335
step: 267, train loss: 1.7482104301452637, train acuracy: 0.5
step: 267, val loss: 1.7297613620758057, val acuracy: 0.5040000677108765
step: 268, train loss: 1.7351490259170532, train acuracy: 0.46484375
step: 268, val loss: 1.7095221281051636, val acuracy: 0.5135000348091125
step: 269, train loss: 1.7112658023834229, train acuracy: 0.47265625
step: 269, val loss: 1.6782348155975342, val acuracy: 0.4633333384990692
step: 270, train loss: 1.3964178562164307, train acuracy: 0.53515625
step: 270, val loss: 1.3947919607162476, val acuracy: 0.5240000486373901
step: 271, train loss: 1.0179164409637451, train acuracy: 0.66796875
step: 271, val loss: 1.0547748804092407, val acuracy: 0.6668334007263184
step: 272, train loss: 0.9162796139717102, train acuracy: 0.71875
step: 272, val loss: 0.9201041460037231, val acuracy: 0.7210000157356262
step: 273, train loss: 0.9860361218452454, train acuracy: 0.6875
step: 273, val loss: 0.9873496294021606, val acuracy: 0.689666748046875
step: 274, train loss: 0.8544589281082153, train acuracy: 0.765625
step: 274, val loss: 0.9038991928100586, val acuracy: 0.7343333959579468
step: 275, train loss: 0.9504618644714355, train acuracy: 0.74609375
step: 275, val loss: 0.8968997597694397, val acuracy: 0.7361667156219482
step: 276, train loss: 0.9180259108543396, train acuracy: 0.7109375
step: 276, val loss: 0.9414966106414795, val acuracy: 0.7016667127609253
step: 277, train loss: 0.8895272016525269, train acuracy: 0.7421875
step: 277, val loss: 0.9337022304534912, val acuracy: 0.705333411693573
step: 278, train loss: 0.821956992149353, train acuracy: 0.7734375
step: 278, val loss: 0.8543543219566345, val acuracy: 0.7296666502952576
step: 279, train loss: 0.8144097328186035, train acuracy: 0.7578125
step: 279, val loss: 0.8516968488693237, val acuracy: 0.7220000624656677
step: 280, train loss: 0.7749728560447693, train acuracy: 0.7578125
step: 280, val loss: 0.7963448166847229, val acuracy: 0.7408334612846375
step: 281, train loss: 0.8505807518959045, train acuracy: 0.7109375
step: 281, val loss: 0.7909227609634399, val acuracy: 0.7361666560173035
step: 282, train loss: 0.7914047837257385, train acuracy: 0.7421875
step: 282, val loss: 0.7879842519760132, val acuracy: 0.736666738986969
step: 283, train loss: 0.7045316696166992, train acuracy: 0.7421875
step: 283, val loss: 0.7856572866439819, val acuracy: 0.7375001311302185
step: 284, train loss: 0.7775141000747681, train acuracy: 0.7578125
step: 284, val loss: 0.7764666080474854, val acuracy: 0.7456667423248291
step: 285, train loss: 0.7024223804473877, train acuracy: 0.79296875
step: 285, val loss: 0.7888010740280151, val acuracy: 0.7381667494773865
step: 286, train loss: 0.760007381439209, train acuracy: 0.77734375
step: 286, val loss: 0.8102041482925415, val acuracy: 0.7304999828338623
step: 287, train loss: 0.7647222280502319, train acuracy: 0.7734375
step: 287, val loss: 0.7731623649597168, val acuracy: 0.7421667575836182
step: 288, train loss: 0.7611046433448792, train acuracy: 0.74609375
step: 288, val loss: 0.8713027238845825, val acuracy: 0.706333339214325
step: 289, train loss: 0.6691534519195557, train acuracy: 0.80078125
step: 289, val loss: 0.8029842972755432, val acuracy: 0.7298334240913391
step: 290, train loss: 0.7843028903007507, train acuracy: 0.75
step: 290, val loss: 0.798336386680603, val acuracy: 0.7303333878517151
step: 291, train loss: 0.7859408855438232, train acuracy: 0.734375
step: 291, val loss: 0.7972846627235413, val acuracy: 0.7310000658035278
step: 292, train loss: 0.8817047476768494, train acuracy: 0.72265625
step: 292, val loss: 0.7962031960487366, val acuracy: 0.7320000529289246
step: 293, train loss: 0.746814489364624, train acuracy: 0.75390625
step: 293, val loss: 0.7954661846160889, val acuracy: 0.7315000295639038
step: 294, train loss: 0.8390464782714844, train acuracy: 0.6875
step: 294, val loss: 0.8503280878067017, val acuracy: 0.7070001363754272
step: 295, train loss: 0.8194965124130249, train acuracy: 0.71484375
step: 295, val loss: 0.7932640910148621, val acuracy: 0.73333340883255
step: 296, train loss: 0.6964710354804993, train acuracy: 0.78125
step: 296, val loss: 0.7932665348052979, val acuracy: 0.7335001230239868
step: 297, train loss: 14.015342712402344, train acuracy: 0.15234375
step: 297, val loss: 15.429023742675781, val acuracy: 0.10083332657814026
step: 298, train loss: 2.984337329864502, train acuracy: 0.2421875
step: 298, val loss: 2.933774948120117, val acuracy: 0.2516666650772095
step: 299, train loss: 2.2463080883026123, train acuracy: 0.20703125
step: 299, val loss: 2.3446402549743652, val acuracy: 0.20333331823349
step: 300, train loss: 2.005228042602539, train acuracy: 0.29296875
step: 300, val loss: 2.017531394958496, val acuracy: 0.2915000319480896
step: 301, train loss: 1.9882590770721436, train acuracy: 0.3046875
step: 301, val loss: 1.9818965196609497, val acuracy: 0.3231666684150696
step: 302, train loss: 1.7975987195968628, train acuracy: 0.41015625
step: 302, val loss: 1.7894140481948853, val acuracy: 0.44083333015441895
step: 303, train loss: 1.5534602403640747, train acuracy: 0.55078125
step: 303, val loss: 1.5926727056503296, val acuracy: 0.5518333315849304
step: 304, train loss: 1.3197038173675537, train acuracy: 0.62109375
step: 304, val loss: 1.4190481901168823, val acuracy: 0.5756666660308838
step: 305, train loss: 1.1296213865280151, train acuracy: 0.65234375
step: 305, val loss: 1.2072782516479492, val acuracy: 0.6161666512489319
step: 306, train loss: 1.0173362493515015, train acuracy: 0.66015625
step: 306, val loss: 1.0777071714401245, val acuracy: 0.6328333616256714
step: 307, train loss: 0.8455970287322998, train acuracy: 0.7578125
step: 307, val loss: 0.9114488363265991, val acuracy: 0.7121667861938477
step: 308, train loss: 0.8644205331802368, train acuracy: 0.734375
step: 308, val loss: 0.8926909565925598, val acuracy: 0.705333411693573
step: 309, train loss: 0.7782396674156189, train acuracy: 0.73828125
step: 309, val loss: 0.9654786586761475, val acuracy: 0.671000063419342
step: 310, train loss: 0.8469070792198181, train acuracy: 0.7265625
step: 310, val loss: 0.8575124740600586, val acuracy: 0.7201667428016663
step: 311, train loss: 0.8521766662597656, train acuracy: 0.7265625
step: 311, val loss: 0.9068632125854492, val acuracy: 0.6910000443458557
step: 312, train loss: 0.8657265901565552, train acuracy: 0.73046875
step: 312, val loss: 0.8769086003303528, val acuracy: 0.7115000486373901
step: 313, train loss: 0.8496928811073303, train acuracy: 0.73046875
step: 313, val loss: 0.877287745475769, val acuracy: 0.7045000791549683
step: 314, train loss: 0.7460319995880127, train acuracy: 0.765625
step: 314, val loss: 0.8441866040229797, val acuracy: 0.733500063419342
step: 315, train loss: 0.9085487127304077, train acuracy: 0.68359375
step: 315, val loss: 0.9070631861686707, val acuracy: 0.702333390712738
step: 316, train loss: 0.7893143892288208, train acuracy: 0.7578125
step: 316, val loss: 0.8494358062744141, val acuracy: 0.7318333983421326
step: 317, train loss: 0.8276102542877197, train acuracy: 0.734375
step: 317, val loss: 0.8716393709182739, val acuracy: 0.7150000333786011
step: 318, train loss: 0.8445239663124084, train acuracy: 0.71875
step: 318, val loss: 0.8850586414337158, val acuracy: 0.7156667709350586
step: 319, train loss: 0.7191981077194214, train acuracy: 0.796875
step: 319, val loss: 0.833466649055481, val acuracy: 0.7401666641235352
step: 320, train loss: 1.0349079370498657, train acuracy: 0.65234375
step: 320, val loss: 1.0908342599868774, val acuracy: 0.6508333683013916
step: 321, train loss: 0.868844211101532, train acuracy: 0.7109375
step: 321, val loss: 0.9311960339546204, val acuracy: 0.6768332719802856
step: 322, train loss: 1.0307964086532593, train acuracy: 0.66015625
step: 322, val loss: 1.0279825925827026, val acuracy: 0.6579999923706055
step: 323, train loss: 1.0557284355163574, train acuracy: 0.69921875
step: 323, val loss: 1.0807486772537231, val acuracy: 0.6538334488868713
step: 324, train loss: 1.0291037559509277, train acuracy: 0.640625
step: 324, val loss: 1.0600003004074097, val acuracy: 0.6573333740234375
step: 325, train loss: 1.0805950164794922, train acuracy: 0.640625
step: 325, val loss: 1.0582561492919922, val acuracy: 0.6565001010894775
step: 326, train loss: 1.1304296255111694, train acuracy: 0.62109375
step: 326, val loss: 1.0569559335708618, val acuracy: 0.655166745185852
step: 327, train loss: 0.9789530038833618, train acuracy: 0.7109375
step: 327, val loss: 1.0556546449661255, val acuracy: 0.656166672706604
step: 328, train loss: 1.1088002920150757, train acuracy: 0.640625
step: 328, val loss: 1.0553430318832397, val acuracy: 0.6565000414848328
step: 329, train loss: 1.1656908988952637, train acuracy: 0.640625
step: 329, val loss: 1.05550217628479, val acuracy: 0.6580000519752502
step: 330, train loss: 1.0151424407958984, train acuracy: 0.69140625
step: 330, val loss: 1.078739047050476, val acuracy: 0.6575000286102295
step: 331, train loss: 128.32679748535156, train acuracy: 0.09765625
step: 331, val loss: 122.50220489501953, val acuracy: 0.10899999737739563
step: 332, train loss: 86.06978607177734, train acuracy: 0.13671875
step: 332, val loss: 82.088134765625, val acuracy: 0.10300000011920929
step: 333, train loss: 73.407470703125, train acuracy: 0.12890625
step: 333, val loss: 76.38379669189453, val acuracy: 0.10400000214576721
step: 334, train loss: 68.41986083984375, train acuracy: 0.12890625
step: 334, val loss: 72.32337951660156, val acuracy: 0.09483332931995392
step: 335, train loss: 54.23615264892578, train acuracy: 0.09375
step: 335, val loss: 54.83988952636719, val acuracy: 0.09166666120290756
step: 336, train loss: 49.09146499633789, train acuracy: 0.09375
step: 336, val loss: 51.595428466796875, val acuracy: 0.09183333069086075
step: 337, train loss: 54.25880813598633, train acuracy: 0.0859375
step: 337, val loss: 51.542850494384766, val acuracy: 0.09216666221618652
step: 338, train loss: 50.674949645996094, train acuracy: 0.07421875
step: 338, val loss: 51.129459381103516, val acuracy: 0.09233332425355911
step: 339, train loss: 49.844818115234375, train acuracy: 0.10546875
step: 339, val loss: 52.62982177734375, val acuracy: 0.0976666659116745
step: 340, train loss: 54.31052780151367, train acuracy: 0.078125
step: 340, val loss: 53.73193359375, val acuracy: 0.09216666221618652
step: 341, train loss: 50.664024353027344, train acuracy: 0.09375
step: 341, val loss: 53.249595642089844, val acuracy: 0.0976666659116745
step: 342, train loss: 54.52836227416992, train acuracy: 0.08203125
step: 342, val loss: 52.78606414794922, val acuracy: 0.09216666966676712
step: 343, train loss: 53.067359924316406, train acuracy: 0.09765625
step: 343, val loss: 52.40391540527344, val acuracy: 0.0976666659116745
step: 344, train loss: 51.06523132324219, train acuracy: 0.09375
step: 344, val loss: 52.574832916259766, val acuracy: 0.09200000017881393
step: 345, train loss: 58.81846618652344, train acuracy: 0.08984375
step: 345, val loss: 51.854827880859375, val acuracy: 0.09233332425355911
step: 346, train loss: 51.895606994628906, train acuracy: 0.07421875
step: 346, val loss: 51.823936462402344, val acuracy: 0.09183332324028015
step: 347, train loss: 49.406978607177734, train acuracy: 0.10546875
step: 347, val loss: 51.85169219970703, val acuracy: 0.0925000011920929
step: 348, train loss: 47.2080192565918, train acuracy: 0.0859375
step: 348, val loss: 51.81482696533203, val acuracy: 0.0925000011920929
step: 349, train loss: 50.812461853027344, train acuracy: 0.0703125
step: 349, val loss: 51.81855773925781, val acuracy: 0.0925000011920929
step: 350, train loss: 51.76527786254883, train acuracy: 0.09765625
step: 350, val loss: 51.98115539550781, val acuracy: 0.09183333069086075
step: 351, train loss: 46.03996276855469, train acuracy: 0.12109375
step: 351, val loss: 51.847129821777344, val acuracy: 0.09233333170413971
step: 352, train loss: 52.90160369873047, train acuracy: 0.09765625
step: 352, val loss: 51.52568817138672, val acuracy: 0.09316666424274445
step: 353, train loss: 49.80663299560547, train acuracy: 0.11328125
step: 353, val loss: 57.167015075683594, val acuracy: 0.09183333069086075
step: 354, train loss: 52.90226364135742, train acuracy: 0.10546875
step: 354, val loss: 57.450862884521484, val acuracy: 0.09183333069086075
step: 355, train loss: 62.47334289550781, train acuracy: 0.08203125
step: 355, val loss: 61.58256149291992, val acuracy: 0.09983333200216293
step: 356, train loss: 70.77671813964844, train acuracy: 0.0859375
step: 356, val loss: 63.980918884277344, val acuracy: 0.09950000047683716
step: 357, train loss: 53.79138946533203, train acuracy: 0.10546875
step: 357, val loss: 59.65050506591797, val acuracy: 0.0923333391547203
step: 358, train loss: 58.1457633972168, train acuracy: 0.11328125
step: 358, val loss: 57.3980712890625, val acuracy: 0.12849998474121094
step: 359, train loss: 75.19388580322266, train acuracy: 0.12109375
step: 359, val loss: 80.85035705566406, val acuracy: 0.09950000047683716
step: 360, train loss: 108.09690856933594, train acuracy: 0.10546875
step: 360, val loss: 103.31974029541016, val acuracy: 0.09750000387430191
step: 361, train loss: 127.78238677978516, train acuracy: 0.05859375
step: 361, val loss: 117.5447006225586, val acuracy: 0.1054999977350235
step: 362, train loss: 133.2922821044922, train acuracy: 0.109375
step: 362, val loss: 123.75066375732422, val acuracy: 0.09749999642372131
step: 363, train loss: 126.8082046508789, train acuracy: 0.08203125
step: 363, val loss: 122.0499496459961, val acuracy: 0.09750000387430191
step: 364, train loss: 129.18826293945312, train acuracy: 0.07421875
step: 364, val loss: 122.21040344238281, val acuracy: 0.09749999642372131
step: 365, train loss: 124.74988555908203, train acuracy: 0.109375
step: 365, val loss: 122.17652893066406, val acuracy: 0.09750000387430191
step: 366, train loss: 123.9080810546875, train acuracy: 0.078125
step: 366, val loss: 121.88969421386719, val acuracy: 0.09749999642372131
step: 367, train loss: 122.63661193847656, train acuracy: 0.07421875
step: 367, val loss: 121.86498260498047, val acuracy: 0.09749999642372131
step: 368, train loss: 124.46002197265625, train acuracy: 0.0859375
step: 368, val loss: 120.05847930908203, val acuracy: 0.09749999642372131
step: 369, train loss: 123.11656188964844, train acuracy: 0.07421875
step: 369, val loss: 119.97262573242188, val acuracy: 0.09750000387430191
step: 370, train loss: 128.14781188964844, train acuracy: 0.09765625
step: 370, val loss: 117.46121978759766, val acuracy: 0.09749999642372131
step: 371, train loss: 111.31793212890625, train acuracy: 0.1015625
step: 371, val loss: 114.4740982055664, val acuracy: 0.09783333539962769
step: 372, train loss: 113.43315887451172, train acuracy: 0.10546875
step: 372, val loss: 107.67365264892578, val acuracy: 0.09983332455158234
step: 373, train loss: 107.62846374511719, train acuracy: 0.13671875
step: 373, val loss: 106.87313079833984, val acuracy: 0.11483332514762878
step: 374, train loss: 90.59053039550781, train acuracy: 0.13671875
step: 374, val loss: 91.14978790283203, val acuracy: 0.12566666305065155
step: 375, train loss: 76.62236022949219, train acuracy: 0.15234375
step: 375, val loss: 85.25489807128906, val acuracy: 0.14750000834465027
step: 376, train loss: 83.3061752319336, train acuracy: 0.1015625
step: 376, val loss: 85.39405822753906, val acuracy: 0.09383333474397659
step: 377, train loss: 89.16024780273438, train acuracy: 0.15625
step: 377, val loss: 81.21864318847656, val acuracy: 0.12866665422916412
step: 378, train loss: 80.7291488647461, train acuracy: 0.140625
step: 378, val loss: 83.92965698242188, val acuracy: 0.14799998700618744
step: 379, train loss: 87.36784362792969, train acuracy: 0.1015625
step: 379, val loss: 82.72827911376953, val acuracy: 0.13650000095367432
step: 380, train loss: 87.6949691772461, train acuracy: 0.12109375
step: 380, val loss: 86.71758270263672, val acuracy: 0.13233333826065063
step: 381, train loss: 88.86518859863281, train acuracy: 0.05859375
step: 381, val loss: 89.25074005126953, val acuracy: 0.09883333742618561
step: 382, train loss: 82.12201690673828, train acuracy: 0.10546875
step: 382, val loss: 89.41190338134766, val acuracy: 0.10583334416151047
step: 383, train loss: 85.83766174316406, train acuracy: 0.1015625
step: 383, val loss: 89.31892395019531, val acuracy: 0.11016666889190674
step: 384, train loss: 95.20541381835938, train acuracy: 0.125
step: 384, val loss: 86.68824005126953, val acuracy: 0.1054999977350235
step: 385, train loss: 88.68428802490234, train acuracy: 0.09765625
step: 385, val loss: 89.2603530883789, val acuracy: 0.11683332920074463
step: 386, train loss: 228.5010986328125, train acuracy: 0.09765625
step: 386, val loss: 200.31150817871094, val acuracy: 0.12266666442155838
step: 387, train loss: 230.22213745117188, train acuracy: 0.09375
step: 387, val loss: 236.916015625, val acuracy: 0.09866666048765182
step: 388, train loss: 230.30458068847656, train acuracy: 0.12109375
step: 388, val loss: 202.5942840576172, val acuracy: 0.10050000250339508
step: 389, train loss: 199.14634704589844, train acuracy: 0.1953125
step: 389, val loss: 194.72853088378906, val acuracy: 0.18416665494441986
step: 390, train loss: 183.12806701660156, train acuracy: 0.12109375
step: 390, val loss: 190.5669708251953, val acuracy: 0.11050000041723251
step: 391, train loss: 175.96348571777344, train acuracy: 0.11328125
step: 391, val loss: 168.476806640625, val acuracy: 0.1158333271741867
step: 392, train loss: 129.73751831054688, train acuracy: 0.25390625
step: 392, val loss: 160.26907348632812, val acuracy: 0.18850001692771912
step: 393, train loss: 148.49505615234375, train acuracy: 0.1875
step: 393, val loss: 152.123291015625, val acuracy: 0.1993333250284195
step: 394, train loss: 170.557373046875, train acuracy: 0.13671875
step: 394, val loss: 173.5009765625, val acuracy: 0.10399999469518661
step: 395, train loss: 183.9641571044922, train acuracy: 0.17578125
step: 395, val loss: 194.09779357910156, val acuracy: 0.16183331608772278
step: 396, train loss: 179.9631805419922, train acuracy: 0.15234375
step: 396, val loss: 180.9187469482422, val acuracy: 0.15149998664855957
step: 397, train loss: 218.16485595703125, train acuracy: 0.11328125
step: 397, val loss: 218.5426483154297, val acuracy: 0.10533333569765091
step: 398, train loss: 205.59278869628906, train acuracy: 0.1171875
step: 398, val loss: 224.00003051757812, val acuracy: 0.09233333170413971
step: 399, train loss: 220.380859375, train acuracy: 0.078125
step: 399, val loss: 249.0641632080078, val acuracy: 0.0885000005364418
2017-12-04 16:16:06.096730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 16:16:06.396560: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0xbc4bed0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 16:16:06.397318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 16:16:06.397586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 16:16:06.397601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 16:16:06.397607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 16:16:06.397619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 16:16:06.397625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
m=20, batch=512
step: 0, train loss: 2.3583827018737793, train acuracy: 0.173828125
step: 0, val loss: 2.4181628227233887, val acuracy: 0.19499999284744263
step: 1, train loss: 2.2508091926574707, train acuracy: 0.28515625
step: 1, val loss: 2.260662317276001, val acuracy: 0.2541666626930237
step: 2, train loss: 2.256023406982422, train acuracy: 0.15234375
step: 2, val loss: 2.2576088905334473, val acuracy: 0.16433332860469818
step: 3, train loss: 2.270719528198242, train acuracy: 0.154296875
step: 3, val loss: 2.253068208694458, val acuracy: 0.1599999964237213
step: 4, train loss: 2.2530508041381836, train acuracy: 0.15625
step: 4, val loss: 2.253410577774048, val acuracy: 0.15916666388511658
step: 5, train loss: 2.260664463043213, train acuracy: 0.15625
step: 5, val loss: 2.253139019012451, val acuracy: 0.15866665542125702
step: 6, train loss: 2.2483530044555664, train acuracy: 0.169921875
step: 6, val loss: 2.2530341148376465, val acuracy: 0.16033333539962769
step: 7, train loss: 2.2599151134490967, train acuracy: 0.1484375
step: 7, val loss: 2.252467155456543, val acuracy: 0.15649999678134918
step: 8, train loss: 2.2513110637664795, train acuracy: 0.1484375
step: 8, val loss: 2.2523980140686035, val acuracy: 0.15549999475479126
step: 9, train loss: 2.266474485397339, train acuracy: 0.1484375
step: 9, val loss: 2.2562103271484375, val acuracy: 0.16349999606609344
step: 10, train loss: 2.232433795928955, train acuracy: 0.14453125
step: 10, val loss: 2.2521250247955322, val acuracy: 0.11483333259820938
step: 11, train loss: 2.2557642459869385, train acuracy: 0.125
step: 11, val loss: 2.253628730773926, val acuracy: 0.12783333659172058
step: 12, train loss: 2.245551586151123, train acuracy: 0.09765625
step: 12, val loss: 2.2523794174194336, val acuracy: 0.11900000274181366
step: 13, train loss: 2.252617359161377, train acuracy: 0.103515625
step: 13, val loss: 2.252253532409668, val acuracy: 0.12049999088048935
step: 14, train loss: 2.253904342651367, train acuracy: 0.1953125
step: 14, val loss: 2.2565290927886963, val acuracy: 0.2096666693687439
step: 15, train loss: 2.263451099395752, train acuracy: 0.18359375
step: 15, val loss: 2.2560932636260986, val acuracy: 0.2031666785478592
step: 16, train loss: 2.251085042953491, train acuracy: 0.123046875
step: 16, val loss: 2.2528669834136963, val acuracy: 0.1301666796207428
step: 17, train loss: 2.26113224029541, train acuracy: 0.107421875
step: 17, val loss: 2.254348039627075, val acuracy: 0.12933331727981567
step: 18, train loss: 2.267857313156128, train acuracy: 0.099609375
step: 18, val loss: 2.2541537284851074, val acuracy: 0.12983332574367523
step: 19, train loss: 2.2323036193847656, train acuracy: 0.150390625
step: 19, val loss: 2.254085063934326, val acuracy: 0.1301666647195816
step: 20, train loss: 2.2582831382751465, train acuracy: 0.107421875
step: 20, val loss: 2.254079580307007, val acuracy: 0.12383332848548889
step: 21, train loss: 2.258026123046875, train acuracy: 0.150390625
step: 21, val loss: 2.2787535190582275, val acuracy: 0.14733333885669708
step: 22, train loss: 2.2733194828033447, train acuracy: 0.1328125
step: 22, val loss: 2.276456117630005, val acuracy: 0.1509999930858612
step: 23, train loss: 2.2599503993988037, train acuracy: 0.177734375
step: 23, val loss: 2.2762579917907715, val acuracy: 0.15000000596046448
step: 24, train loss: 2.271479606628418, train acuracy: 0.125
step: 24, val loss: 2.2838592529296875, val acuracy: 0.1053333431482315
step: 25, train loss: 2.267505407333374, train acuracy: 0.11328125
step: 25, val loss: 2.28332257270813, val acuracy: 0.10533333569765091
step: 26, train loss: 2.280134677886963, train acuracy: 0.115234375
step: 26, val loss: 2.2830145359039307, val acuracy: 0.10533333569765091
step: 27, train loss: 2.2874510288238525, train acuracy: 0.08984375
step: 27, val loss: 2.282493829727173, val acuracy: 0.1053333431482315
step: 28, train loss: 2.2661423683166504, train acuracy: 0.16796875
step: 28, val loss: 2.288328170776367, val acuracy: 0.1536666750907898
step: 29, train loss: 2.25872802734375, train acuracy: 0.193359375
step: 29, val loss: 2.2887325286865234, val acuracy: 0.16716666519641876
step: 30, train loss: 2.2860333919525146, train acuracy: 0.24609375
step: 30, val loss: 2.3015849590301514, val acuracy: 0.23216667771339417
step: 31, train loss: 2.31215500831604, train acuracy: 0.2265625
step: 31, val loss: 2.2994511127471924, val acuracy: 0.22466668486595154
step: 32, train loss: 2.307800769805908, train acuracy: 0.142578125
step: 32, val loss: 2.2961668968200684, val acuracy: 0.14016665518283844
step: 33, train loss: 2.3018033504486084, train acuracy: 0.1484375
step: 33, val loss: 2.296018600463867, val acuracy: 0.13749998807907104
step: 34, train loss: 2.3153235912323, train acuracy: 0.109375
step: 34, val loss: 2.293926954269409, val acuracy: 0.10766666382551193
step: 35, train loss: 2.279362440109253, train acuracy: 0.109375
step: 35, val loss: 2.292605400085449, val acuracy: 0.10749999433755875
step: 36, train loss: 2.301445245742798, train acuracy: 0.107421875
step: 36, val loss: 2.2927539348602295, val acuracy: 0.11500000208616257
step: 37, train loss: 2.284281015396118, train acuracy: 0.12109375
step: 37, val loss: 2.2915611267089844, val acuracy: 0.11349999159574509
step: 38, train loss: 2.30141544342041, train acuracy: 0.095703125
step: 38, val loss: 2.2882192134857178, val acuracy: 0.1055000051856041
step: 39, train loss: 2.282526969909668, train acuracy: 0.1015625
step: 39, val loss: 2.2921199798583984, val acuracy: 0.10533333569765091
step: 40, train loss: 2.2889535427093506, train acuracy: 0.146484375
step: 40, val loss: 2.2888381481170654, val acuracy: 0.14783331751823425
step: 41, train loss: 2.2641870975494385, train acuracy: 0.11328125
step: 41, val loss: 2.2688705921173096, val acuracy: 0.10633333027362823
step: 42, train loss: 2.2181248664855957, train acuracy: 0.15625
step: 42, val loss: 2.2425856590270996, val acuracy: 0.12699998915195465
step: 43, train loss: 2.161968469619751, train acuracy: 0.3125
step: 43, val loss: 2.186577320098877, val acuracy: 0.2644999921321869
step: 44, train loss: 2.170243501663208, train acuracy: 0.181640625
step: 44, val loss: 2.1931400299072266, val acuracy: 0.17233332991600037
step: 45, train loss: 2.0167598724365234, train acuracy: 0.3828125
step: 45, val loss: 2.035040855407715, val acuracy: 0.35350000858306885
step: 46, train loss: 1.8821601867675781, train acuracy: 0.517578125
step: 46, val loss: 1.9026482105255127, val acuracy: 0.4925000071525574
step: 47, train loss: 1.9012172222137451, train acuracy: 0.4375
step: 47, val loss: 1.9364947080612183, val acuracy: 0.4243333637714386
step: 48, train loss: 1.6821746826171875, train acuracy: 0.42578125
step: 48, val loss: 1.711954116821289, val acuracy: 0.4235000014305115
step: 49, train loss: 1.4684919118881226, train acuracy: 0.509765625
step: 49, val loss: 1.5406280755996704, val acuracy: 0.4766666889190674
step: 50, train loss: 1.539208173751831, train acuracy: 0.458984375
step: 50, val loss: 1.5618215799331665, val acuracy: 0.45000001788139343
step: 51, train loss: 1.5809431076049805, train acuracy: 0.443359375
step: 51, val loss: 1.5488951206207275, val acuracy: 0.4663333296775818
step: 52, train loss: 1.318830132484436, train acuracy: 0.52734375
step: 52, val loss: 1.454668641090393, val acuracy: 0.47966668009757996
step: 53, train loss: 0.9660924077033997, train acuracy: 0.712890625
step: 53, val loss: 1.0450104475021362, val acuracy: 0.6630000472068787
step: 54, train loss: 4.451363563537598, train acuracy: 0.310546875
step: 54, val loss: 4.413359642028809, val acuracy: 0.3148333728313446
step: 55, train loss: 1.5461236238479614, train acuracy: 0.47265625
step: 55, val loss: 1.642511010169983, val acuracy: 0.45216667652130127
step: 56, train loss: 1.6877704858779907, train acuracy: 0.46484375
step: 56, val loss: 1.6807326078414917, val acuracy: 0.46783334016799927
step: 57, train loss: 1.6099200248718262, train acuracy: 0.490234375
step: 57, val loss: 1.6128766536712646, val acuracy: 0.49316665530204773
step: 58, train loss: 1.6090075969696045, train acuracy: 0.482421875
step: 58, val loss: 1.6162785291671753, val acuracy: 0.49133336544036865
step: 59, train loss: 1.633811354637146, train acuracy: 0.484375
step: 59, val loss: 1.614234209060669, val acuracy: 0.49283334612846375
step: 60, train loss: 1.59769606590271, train acuracy: 0.498046875
step: 60, val loss: 1.613274097442627, val acuracy: 0.4935000240802765
step: 61, train loss: 1.6090881824493408, train acuracy: 0.484375
step: 61, val loss: 1.6127551794052124, val acuracy: 0.4933333396911621
step: 62, train loss: 1.6578041315078735, train acuracy: 0.474609375
step: 62, val loss: 1.6125950813293457, val acuracy: 0.4945000410079956
step: 63, train loss: 1.6084034442901611, train acuracy: 0.509765625
step: 63, val loss: 1.612295150756836, val acuracy: 0.49283331632614136
step: 64, train loss: 1.638289451599121, train acuracy: 0.50390625
step: 64, val loss: 1.6120471954345703, val acuracy: 0.49366670846939087
step: 65, train loss: 1.5894008874893188, train acuracy: 0.494140625
step: 65, val loss: 1.611823558807373, val acuracy: 0.4938333332538605
step: 66, train loss: 1.5784037113189697, train acuracy: 0.529296875
step: 66, val loss: 1.6116975545883179, val acuracy: 0.4934999942779541
step: 67, train loss: 1.5531542301177979, train acuracy: 0.54296875
step: 67, val loss: 1.61155104637146, val acuracy: 0.49366670846939087
step: 68, train loss: 1.5932965278625488, train acuracy: 0.509765625
step: 68, val loss: 1.611493468284607, val acuracy: 0.49416667222976685
step: 69, train loss: 1.5829092264175415, train acuracy: 0.509765625
step: 69, val loss: 1.6114081144332886, val acuracy: 0.49416667222976685
step: 70, train loss: 1.6487534046173096, train acuracy: 0.490234375
step: 70, val loss: 1.6113141775131226, val acuracy: 0.4950000047683716
step: 71, train loss: 1.627124547958374, train acuracy: 0.47265625
step: 71, val loss: 1.6112313270568848, val acuracy: 0.4950000047683716
step: 72, train loss: 1.6537001132965088, train acuracy: 0.466796875
step: 72, val loss: 1.6112549304962158, val acuracy: 0.49500003457069397
step: 73, train loss: 1.6347086429595947, train acuracy: 0.505859375
step: 73, val loss: 1.6112157106399536, val acuracy: 0.4948333501815796
step: 74, train loss: 1.6400094032287598, train acuracy: 0.4921875
step: 74, val loss: 1.6111946105957031, val acuracy: 0.49533337354660034
step: 75, train loss: 1.5670742988586426, train acuracy: 0.51171875
step: 75, val loss: 1.6110961437225342, val acuracy: 0.4958333671092987
step: 76, train loss: 1.5889058113098145, train acuracy: 0.509765625
step: 76, val loss: 1.6110527515411377, val acuracy: 0.49533334374427795
step: 77, train loss: 1.6272814273834229, train acuracy: 0.494140625
step: 77, val loss: 1.6110717058181763, val acuracy: 0.49549999833106995
step: 78, train loss: 1.5785808563232422, train acuracy: 0.515625
step: 78, val loss: 1.61104416847229, val acuracy: 0.49516668915748596
step: 79, train loss: 1.596097707748413, train acuracy: 0.53125
step: 79, val loss: 1.6100634336471558, val acuracy: 0.49550002813339233
step: 80, train loss: 1.5654890537261963, train acuracy: 0.435546875
step: 80, val loss: 1.572413444519043, val acuracy: 0.4228333532810211
step: 81, train loss: 1.6686862707138062, train acuracy: 0.435546875
step: 81, val loss: 1.6879013776779175, val acuracy: 0.46483340859413147
step: 82, train loss: 1.5944143533706665, train acuracy: 0.5
step: 82, val loss: 1.689711570739746, val acuracy: 0.46800002455711365
step: 83, train loss: 1.9126765727996826, train acuracy: 0.423828125
step: 83, val loss: 1.862586498260498, val acuracy: 0.4071667194366455
step: 84, train loss: 1.8621562719345093, train acuracy: 0.45703125
step: 84, val loss: 1.8675190210342407, val acuracy: 0.46133339405059814
step: 85, train loss: 1.865233302116394, train acuracy: 0.396484375
step: 85, val loss: 1.7180566787719727, val acuracy: 0.44350001215934753
step: 86, train loss: 1.907702088356018, train acuracy: 0.37890625
step: 86, val loss: 1.9412786960601807, val acuracy: 0.3998333513736725
step: 87, train loss: 1.6850900650024414, train acuracy: 0.44921875
step: 87, val loss: 1.7081775665283203, val acuracy: 0.4335000216960907
step: 88, train loss: 1.5982695817947388, train acuracy: 0.509765625
step: 88, val loss: 1.7316205501556396, val acuracy: 0.4773333668708801
step: 89, train loss: 1.6104493141174316, train acuracy: 0.564453125
step: 89, val loss: 1.6138861179351807, val acuracy: 0.5526666641235352
step: 90, train loss: 1.5621336698532104, train acuracy: 0.5234375
step: 90, val loss: 1.6511783599853516, val acuracy: 0.534166693687439
step: 91, train loss: 1.4982554912567139, train acuracy: 0.552734375
step: 91, val loss: 1.6075721979141235, val acuracy: 0.533666729927063
step: 92, train loss: 1.4480035305023193, train acuracy: 0.56640625
step: 92, val loss: 1.5169239044189453, val acuracy: 0.5418333411216736
step: 93, train loss: 1.4223272800445557, train acuracy: 0.57421875
step: 93, val loss: 1.3729839324951172, val acuracy: 0.5798333287239075
step: 94, train loss: 1.377387285232544, train acuracy: 0.607421875
step: 94, val loss: 1.5006840229034424, val acuracy: 0.5821666717529297
step: 95, train loss: 1.4067339897155762, train acuracy: 0.568359375
step: 95, val loss: 1.3924652338027954, val acuracy: 0.5673333406448364
step: 96, train loss: 1.2658119201660156, train acuracy: 0.630859375
step: 96, val loss: 1.2477080821990967, val acuracy: 0.6288333535194397
step: 97, train loss: 1.2044718265533447, train acuracy: 0.638671875
step: 97, val loss: 1.3423457145690918, val acuracy: 0.5895000696182251
step: 98, train loss: 1.1035537719726562, train acuracy: 0.63671875
step: 98, val loss: 1.1870414018630981, val acuracy: 0.6158334016799927
step: 99, train loss: 1.1724492311477661, train acuracy: 0.6328125
step: 99, val loss: 1.1738615036010742, val acuracy: 0.6291667819023132
step: 100, train loss: 1.0926719903945923, train acuracy: 0.677734375
step: 100, val loss: 1.1724766492843628, val acuracy: 0.6188334226608276
step: 101, train loss: 0.983160138130188, train acuracy: 0.658203125
step: 101, val loss: 1.1067006587982178, val acuracy: 0.6333333849906921
step: 102, train loss: 1.0947531461715698, train acuracy: 0.62109375
step: 102, val loss: 1.1629283428192139, val acuracy: 0.5998333692550659
step: 103, train loss: 1.1725021600723267, train acuracy: 0.60546875
step: 103, val loss: 1.2897443771362305, val acuracy: 0.5920000672340393
step: 104, train loss: 1.2220103740692139, train acuracy: 0.578125
step: 104, val loss: 1.3259779214859009, val acuracy: 0.5753333568572998
step: 105, train loss: 1.3323484659194946, train acuracy: 0.599609375
step: 105, val loss: 1.4930851459503174, val acuracy: 0.5596666932106018
step: 106, train loss: 1.5028804540634155, train acuracy: 0.5234375
step: 106, val loss: 1.5989315509796143, val acuracy: 0.5048334002494812
step: 107, train loss: 1.3380846977233887, train acuracy: 0.611328125
step: 107, val loss: 1.4031578302383423, val acuracy: 0.5863333344459534
step: 108, train loss: 1.4614359140396118, train acuracy: 0.509765625
step: 108, val loss: 1.5654985904693604, val acuracy: 0.49816668033599854
step: 109, train loss: 1.5688304901123047, train acuracy: 0.556640625
step: 109, val loss: 1.632802963256836, val acuracy: 0.5350000262260437
step: 110, train loss: 1.568744421005249, train acuracy: 0.515625
step: 110, val loss: 1.689087986946106, val acuracy: 0.49633336067199707
step: 111, train loss: 1.6662942171096802, train acuracy: 0.5078125
step: 111, val loss: 1.7262520790100098, val acuracy: 0.4971666932106018
step: 112, train loss: 1.5828864574432373, train acuracy: 0.466796875
step: 112, val loss: 1.8037216663360596, val acuracy: 0.42633333802223206
step: 113, train loss: 1.7653698921203613, train acuracy: 0.50390625
step: 113, val loss: 1.8092855215072632, val acuracy: 0.48633337020874023
step: 114, train loss: 1.8677281141281128, train acuracy: 0.416015625
step: 114, val loss: 1.9462424516677856, val acuracy: 0.37650004029273987
step: 115, train loss: 1.8879610300064087, train acuracy: 0.529296875
step: 115, val loss: 2.1095070838928223, val acuracy: 0.49016666412353516
step: 116, train loss: 1.6787347793579102, train acuracy: 0.44921875
step: 116, val loss: 1.7121022939682007, val acuracy: 0.44966667890548706
step: 117, train loss: 1.5732219219207764, train acuracy: 0.544921875
step: 117, val loss: 1.6940847635269165, val acuracy: 0.5085000395774841
step: 118, train loss: 1.4218591451644897, train acuracy: 0.5703125
step: 118, val loss: 1.4693602323532104, val acuracy: 0.5661666989326477
step: 119, train loss: 18.767000198364258, train acuracy: 0.123046875
step: 119, val loss: 18.920021057128906, val acuracy: 0.12833333015441895
step: 120, train loss: 8.791489601135254, train acuracy: 0.236328125
step: 120, val loss: 8.446818351745605, val acuracy: 0.22333335876464844
step: 121, train loss: 7.429434776306152, train acuracy: 0.169921875
step: 121, val loss: 7.483410358428955, val acuracy: 0.17283332347869873
step: 122, train loss: 7.293023586273193, train acuracy: 0.08203125
step: 122, val loss: 6.873147487640381, val acuracy: 0.07649999856948853
step: 123, train loss: 2.9986464977264404, train acuracy: 0.033203125
step: 123, val loss: 2.948072671890259, val acuracy: 0.03633333370089531
step: 124, train loss: 2.7021806240081787, train acuracy: 0.107421875
step: 124, val loss: 2.7961277961730957, val acuracy: 0.09749999642372131
step: 125, train loss: 2.4540514945983887, train acuracy: 0.197265625
step: 125, val loss: 2.4260239601135254, val acuracy: 0.19683334231376648
step: 126, train loss: 2.3081796169281006, train acuracy: 0.1875
step: 126, val loss: 2.2805261611938477, val acuracy: 0.19299998879432678
step: 127, train loss: 2.0802500247955322, train acuracy: 0.3203125
step: 127, val loss: 2.066460371017456, val acuracy: 0.3268333673477173
step: 128, train loss: 1.9501906633377075, train acuracy: 0.341796875
step: 128, val loss: 1.9850643873214722, val acuracy: 0.32249999046325684
step: 129, train loss: 1.4404124021530151, train acuracy: 0.509765625
step: 129, val loss: 1.517836093902588, val acuracy: 0.49916666746139526
step: 130, train loss: 1.5402312278747559, train acuracy: 0.49609375
step: 130, val loss: 1.482872486114502, val acuracy: 0.51500004529953
step: 131, train loss: 1.4203379154205322, train acuracy: 0.513671875
step: 131, val loss: 1.3635574579238892, val acuracy: 0.531499981880188
step: 132, train loss: 1.278494119644165, train acuracy: 0.564453125
step: 132, val loss: 1.3432033061981201, val acuracy: 0.5393334031105042
step: 133, train loss: 1.2251561880111694, train acuracy: 0.583984375
step: 133, val loss: 1.3829481601715088, val acuracy: 0.5435000658035278
step: 134, train loss: 1.1569385528564453, train acuracy: 0.634765625
step: 134, val loss: 1.2392497062683105, val acuracy: 0.6061667203903198
step: 135, train loss: 1.2659859657287598, train acuracy: 0.603515625
step: 135, val loss: 1.2212624549865723, val acuracy: 0.6100000739097595
step: 136, train loss: 1.2100138664245605, train acuracy: 0.5859375
step: 136, val loss: 1.2113606929779053, val acuracy: 0.6135001182556152
step: 137, train loss: 1.1571022272109985, train acuracy: 0.64453125
step: 137, val loss: 1.2105321884155273, val acuracy: 0.6144999861717224
step: 138, train loss: 1.157439947128296, train acuracy: 0.625
step: 138, val loss: 1.232230305671692, val acuracy: 0.6078333854675293
step: 139, train loss: 1.2325657606124878, train acuracy: 0.63671875
step: 139, val loss: 1.2306426763534546, val acuracy: 0.609000027179718
step: 140, train loss: 1.1683986186981201, train acuracy: 0.603515625
step: 140, val loss: 1.2286548614501953, val acuracy: 0.6098333597183228
step: 141, train loss: 1.0755075216293335, train acuracy: 0.638671875
step: 141, val loss: 1.2280747890472412, val acuracy: 0.6095000505447388
step: 142, train loss: 1.1030324697494507, train acuracy: 0.662109375
step: 142, val loss: 1.2276660203933716, val acuracy: 0.609666645526886
step: 143, train loss: 1.1486713886260986, train acuracy: 0.650390625
step: 143, val loss: 1.2274930477142334, val acuracy: 0.60916668176651
step: 144, train loss: 1.1184781789779663, train acuracy: 0.654296875
step: 144, val loss: 1.2267707586288452, val acuracy: 0.608833372592926
step: 145, train loss: 1.27473783493042, train acuracy: 0.583984375
step: 145, val loss: 1.2266342639923096, val acuracy: 0.6088334321975708
step: 146, train loss: 1.1885108947753906, train acuracy: 0.595703125
step: 146, val loss: 1.2266968488693237, val acuracy: 0.608833372592926
step: 147, train loss: 1.2441190481185913, train acuracy: 0.60546875
step: 147, val loss: 1.2243058681488037, val acuracy: 0.6036667227745056
step: 148, train loss: 1.119457483291626, train acuracy: 0.626953125
step: 148, val loss: 1.2268635034561157, val acuracy: 0.6018333435058594
step: 149, train loss: 2.950915813446045, train acuracy: 0.267578125
step: 149, val loss: 3.1068572998046875, val acuracy: 0.27550002932548523
step: 150, train loss: 1.7372214794158936, train acuracy: 0.400390625
step: 150, val loss: 1.7052136659622192, val acuracy: 0.41850003600120544
step: 151, train loss: 1.715599536895752, train acuracy: 0.458984375
step: 151, val loss: 1.7016723155975342, val acuracy: 0.4478333592414856
step: 152, train loss: 1.4816759824752808, train acuracy: 0.5078125
step: 152, val loss: 1.5300034284591675, val acuracy: 0.48616668581962585
step: 153, train loss: 1.4607948064804077, train acuracy: 0.498046875
step: 153, val loss: 1.5195801258087158, val acuracy: 0.49150002002716064
step: 154, train loss: 1.3862885236740112, train acuracy: 0.529296875
step: 154, val loss: 1.5104047060012817, val acuracy: 0.4961666464805603
step: 155, train loss: 1.5486242771148682, train acuracy: 0.556640625
step: 155, val loss: 1.4691290855407715, val acuracy: 0.5649999976158142
step: 156, train loss: 1.5687718391418457, train acuracy: 0.564453125
step: 156, val loss: 1.5244016647338867, val acuracy: 0.5718333721160889
step: 157, train loss: 1.475447654724121, train acuracy: 0.55859375
step: 157, val loss: 1.4943512678146362, val acuracy: 0.5756667256355286
step: 158, train loss: 1.5213510990142822, train acuracy: 0.564453125
step: 158, val loss: 1.4999027252197266, val acuracy: 0.5663333535194397
step: 159, train loss: 1.3815577030181885, train acuracy: 0.58984375
step: 159, val loss: 1.4936435222625732, val acuracy: 0.5683333873748779
step: 160, train loss: 1.3598549365997314, train acuracy: 0.611328125
step: 160, val loss: 1.5152522325515747, val acuracy: 0.5820000171661377
step: 161, train loss: 1.5175341367721558, train acuracy: 0.5859375
step: 161, val loss: 1.560600996017456, val acuracy: 0.5635000467300415
step: 162, train loss: 1.585140347480774, train acuracy: 0.578125
step: 162, val loss: 1.6477503776550293, val acuracy: 0.5501667261123657
step: 163, train loss: 1.4020320177078247, train acuracy: 0.59375
step: 163, val loss: 1.497681736946106, val acuracy: 0.5701667070388794
step: 164, train loss: 1.4768493175506592, train acuracy: 0.59375
step: 164, val loss: 1.4907400608062744, val acuracy: 0.5691666603088379
step: 165, train loss: 1.2851887941360474, train acuracy: 0.62109375
step: 165, val loss: 1.483449101448059, val acuracy: 0.5826666355133057
step: 166, train loss: 1.4806740283966064, train acuracy: 0.576171875
step: 166, val loss: 1.5035117864608765, val acuracy: 0.5560000538825989
step: 167, train loss: 1.4082735776901245, train acuracy: 0.6015625
step: 167, val loss: 1.5071282386779785, val acuracy: 0.5685000419616699
step: 168, train loss: 1.5108797550201416, train acuracy: 0.5625
step: 168, val loss: 1.5558322668075562, val acuracy: 0.5515000224113464
step: 169, train loss: 1.585239291191101, train acuracy: 0.52734375
step: 169, val loss: 1.501112461090088, val acuracy: 0.5548333525657654
step: 170, train loss: 1.3647738695144653, train acuracy: 0.615234375
step: 170, val loss: 1.5295357704162598, val acuracy: 0.5550000071525574
step: 171, train loss: 1.3850243091583252, train acuracy: 0.580078125
step: 171, val loss: 1.5159366130828857, val acuracy: 0.546000063419342
step: 172, train loss: 1.464716911315918, train acuracy: 0.5859375
step: 172, val loss: 1.564584732055664, val acuracy: 0.565000057220459
step: 173, train loss: 1.4026261568069458, train acuracy: 0.564453125
step: 173, val loss: 1.5352802276611328, val acuracy: 0.5356667041778564
step: 174, train loss: 1.3732008934020996, train acuracy: 0.57421875
step: 174, val loss: 1.5401201248168945, val acuracy: 0.5433334112167358
step: 175, train loss: 1.5844002962112427, train acuracy: 0.513671875
step: 175, val loss: 1.622641682624817, val acuracy: 0.5199999809265137
step: 176, train loss: 1.576599359512329, train acuracy: 0.533203125
step: 176, val loss: 1.5381900072097778, val acuracy: 0.5261666774749756
step: 177, train loss: 1.5461581945419312, train acuracy: 0.556640625
step: 177, val loss: 1.5303473472595215, val acuracy: 0.5400000810623169
step: 178, train loss: 1.706636667251587, train acuracy: 0.515625
step: 178, val loss: 1.5993092060089111, val acuracy: 0.5203333497047424
step: 179, train loss: 1.5633656978607178, train acuracy: 0.52734375
step: 179, val loss: 1.555221676826477, val acuracy: 0.5458333492279053
step: 180, train loss: 1.5837163925170898, train acuracy: 0.52734375
step: 180, val loss: 1.5889647006988525, val acuracy: 0.5160000324249268
step: 181, train loss: 1.4678419828414917, train acuracy: 0.51171875
step: 181, val loss: 1.5694602727890015, val acuracy: 0.5175000429153442
step: 182, train loss: 1.4645931720733643, train acuracy: 0.513671875
step: 182, val loss: 1.5908576250076294, val acuracy: 0.5101666450500488
step: 183, train loss: 1.4528814554214478, train acuracy: 0.5546875
step: 183, val loss: 1.585494875907898, val acuracy: 0.5048333406448364
step: 184, train loss: 1.4355804920196533, train acuracy: 0.54296875
step: 184, val loss: 1.5482895374298096, val acuracy: 0.5163333415985107
step: 185, train loss: 1.5095531940460205, train acuracy: 0.544921875
step: 185, val loss: 1.5087265968322754, val acuracy: 0.5361666679382324
step: 186, train loss: 2.5547378063201904, train acuracy: 0.228515625
step: 186, val loss: 2.6095192432403564, val acuracy: 0.21966667473316193
step: 187, train loss: 2.040299654006958, train acuracy: 0.228515625
step: 187, val loss: 2.1021041870117188, val acuracy: 0.22483333945274353
step: 188, train loss: 1.928138017654419, train acuracy: 0.3515625
step: 188, val loss: 1.9461722373962402, val acuracy: 0.3500000238418579
step: 189, train loss: 1.9044010639190674, train acuracy: 0.318359375
step: 189, val loss: 1.922627568244934, val acuracy: 0.2901666760444641
step: 190, train loss: 1.7674659490585327, train acuracy: 0.396484375
step: 190, val loss: 1.734588623046875, val acuracy: 0.4110000729560852
step: 191, train loss: 1.639146089553833, train acuracy: 0.421875
step: 191, val loss: 1.7055474519729614, val acuracy: 0.42116668820381165
step: 192, train loss: 1.3936930894851685, train acuracy: 0.556640625
step: 192, val loss: 1.4171793460845947, val acuracy: 0.5521667003631592
step: 193, train loss: 1.3858060836791992, train acuracy: 0.576171875
step: 193, val loss: 1.3661456108093262, val acuracy: 0.5866667628288269
step: 194, train loss: 1.0291329622268677, train acuracy: 0.693359375
step: 194, val loss: 1.0904326438903809, val acuracy: 0.6536666750907898
step: 195, train loss: 1.1406625509262085, train acuracy: 0.630859375
step: 195, val loss: 1.1350507736206055, val acuracy: 0.6500000357627869
step: 196, train loss: 0.8429933786392212, train acuracy: 0.728515625
step: 196, val loss: 0.9071884155273438, val acuracy: 0.7195000648498535
step: 197, train loss: 0.9175108075141907, train acuracy: 0.72265625
step: 197, val loss: 0.8897273540496826, val acuracy: 0.7188334465026855
step: 198, train loss: 0.6687848567962646, train acuracy: 0.787109375
step: 198, val loss: 0.8072293400764465, val acuracy: 0.7481666803359985
step: 199, train loss: 0.784384548664093, train acuracy: 0.75
step: 199, val loss: 0.8004723787307739, val acuracy: 0.7505000829696655
step: 200, train loss: 0.7763888239860535, train acuracy: 0.763671875
step: 200, val loss: 0.7874408960342407, val acuracy: 0.7511667013168335
step: 201, train loss: 0.7502555847167969, train acuracy: 0.763671875
step: 201, val loss: 0.7937272191047668, val acuracy: 0.7503333687782288
step: 202, train loss: 0.6727697849273682, train acuracy: 0.791015625
step: 202, val loss: 0.8003533482551575, val acuracy: 0.7458333969116211
step: 203, train loss: 0.8734719753265381, train acuracy: 0.7265625
step: 203, val loss: 0.9356575608253479, val acuracy: 0.7226666808128357
step: 204, train loss: 0.8519542217254639, train acuracy: 0.73828125
step: 204, val loss: 0.8329134583473206, val acuracy: 0.7403334379196167
step: 205, train loss: 0.7650614380836487, train acuracy: 0.763671875
step: 205, val loss: 0.8541267514228821, val acuracy: 0.7305001020431519
step: 206, train loss: 0.8254461884498596, train acuracy: 0.75390625
step: 206, val loss: 0.8461505770683289, val acuracy: 0.7343333959579468
step: 207, train loss: 0.9195095896720886, train acuracy: 0.701171875
step: 207, val loss: 0.8429603576660156, val acuracy: 0.7348333597183228
step: 208, train loss: 0.8226194381713867, train acuracy: 0.728515625
step: 208, val loss: 0.8418281674385071, val acuracy: 0.7355000376701355
step: 209, train loss: 0.786381721496582, train acuracy: 0.73828125
step: 209, val loss: 0.840950608253479, val acuracy: 0.7361667156219482
step: 210, train loss: 0.7889891862869263, train acuracy: 0.76171875
step: 210, val loss: 0.8408583402633667, val acuracy: 0.7356667518615723
step: 211, train loss: 0.834321916103363, train acuracy: 0.7421875
step: 211, val loss: 0.8400785326957703, val acuracy: 0.735666811466217
step: 212, train loss: 0.8398197889328003, train acuracy: 0.724609375
step: 212, val loss: 0.8397137522697449, val acuracy: 0.737000048160553
step: 213, train loss: 0.8213223814964294, train acuracy: 0.732421875
step: 213, val loss: 0.8395595550537109, val acuracy: 0.736666738986969
step: 214, train loss: 0.7267358303070068, train acuracy: 0.7421875
step: 214, val loss: 0.8392582535743713, val acuracy: 0.736500084400177
step: 215, train loss: 0.7194396257400513, train acuracy: 0.775390625
step: 215, val loss: 0.8390467762947083, val acuracy: 0.7370001077651978
step: 216, train loss: 0.8736034631729126, train acuracy: 0.734375
step: 216, val loss: 0.8387532830238342, val acuracy: 0.736666738986969
step: 217, train loss: 0.8564008474349976, train acuracy: 0.734375
step: 217, val loss: 0.8384149074554443, val acuracy: 0.737333357334137
step: 218, train loss: 0.907228946685791, train acuracy: 0.724609375
step: 218, val loss: 0.8381555676460266, val acuracy: 0.7376667261123657
step: 219, train loss: 0.9794737100601196, train acuracy: 0.71875
step: 219, val loss: 0.8380290865898132, val acuracy: 0.7378333806991577
step: 220, train loss: 0.900268018245697, train acuracy: 0.708984375
step: 220, val loss: 0.8377602100372314, val acuracy: 0.7373334169387817
step: 221, train loss: 0.8324834704399109, train acuracy: 0.734375
step: 221, val loss: 0.8374692797660828, val acuracy: 0.7381666898727417
step: 222, train loss: 0.7949148416519165, train acuracy: 0.75
step: 222, val loss: 0.8371548056602478, val acuracy: 0.7378334403038025
step: 223, train loss: 0.7930760383605957, train acuracy: 0.76171875
step: 223, val loss: 0.8370136022567749, val acuracy: 0.7378333806991577
step: 224, train loss: 0.8281620740890503, train acuracy: 0.75
step: 224, val loss: 0.8410993218421936, val acuracy: 0.7363333702087402
step: 225, train loss: 0.7657409906387329, train acuracy: 0.75390625
step: 225, val loss: 0.8397936820983887, val acuracy: 0.7358334064483643
step: 226, train loss: 0.8608096241950989, train acuracy: 0.732421875
step: 226, val loss: 0.8394235968589783, val acuracy: 0.7353333234786987
step: 227, train loss: 0.8099308013916016, train acuracy: 0.75
step: 227, val loss: 0.8535480499267578, val acuracy: 0.7315000891685486
step: 228, train loss: 0.7369837760925293, train acuracy: 0.763671875
step: 228, val loss: 0.8506984114646912, val acuracy: 0.7325000166893005
step: 229, train loss: 0.8375457525253296, train acuracy: 0.736328125
step: 229, val loss: 0.8583707809448242, val acuracy: 0.7285001277923584
step: 230, train loss: 0.8854774236679077, train acuracy: 0.7109375
step: 230, val loss: 0.858027994632721, val acuracy: 0.7286667227745056
step: 231, train loss: 0.9069480895996094, train acuracy: 0.712890625
step: 231, val loss: 0.8703474998474121, val acuracy: 0.7226667404174805
step: 232, train loss: 0.8998942375183105, train acuracy: 0.71484375
step: 232, val loss: 0.868104100227356, val acuracy: 0.7248334288597107
step: 233, train loss: 0.9249236583709717, train acuracy: 0.69921875
step: 233, val loss: 0.8679957389831543, val acuracy: 0.7253333926200867
step: 234, train loss: 0.7905671000480652, train acuracy: 0.740234375
step: 234, val loss: 0.9222357869148254, val acuracy: 0.7040001153945923
step: 235, train loss: 0.8730822205543518, train acuracy: 0.705078125
step: 235, val loss: 0.9008036851882935, val acuracy: 0.7068333625793457
step: 236, train loss: 0.9159051179885864, train acuracy: 0.708984375
step: 236, val loss: 0.8991272449493408, val acuracy: 0.7090001106262207
step: 237, train loss: 0.9585086703300476, train acuracy: 0.69140625
step: 237, val loss: 0.8975011706352234, val acuracy: 0.7090001106262207
step: 238, train loss: 0.8285009264945984, train acuracy: 0.744140625
step: 238, val loss: 0.9275116920471191, val acuracy: 0.6978334188461304
step: 239, train loss: 0.93562912940979, train acuracy: 0.716796875
step: 239, val loss: 0.9566357135772705, val acuracy: 0.705833375453949
step: 240, train loss: 0.9303520321846008, train acuracy: 0.703125
step: 240, val loss: 0.9411206245422363, val acuracy: 0.6905000805854797
step: 241, train loss: 0.9062488079071045, train acuracy: 0.7109375
step: 241, val loss: 0.9231777191162109, val acuracy: 0.7073334455490112
step: 242, train loss: 0.8955068588256836, train acuracy: 0.73828125
step: 242, val loss: 0.9769611954689026, val acuracy: 0.7083333730697632
step: 243, train loss: 0.9273777604103088, train acuracy: 0.689453125
step: 243, val loss: 0.9635380506515503, val acuracy: 0.6873334050178528
step: 244, train loss: 0.7951017618179321, train acuracy: 0.744140625
step: 244, val loss: 0.9250178337097168, val acuracy: 0.7128334045410156
step: 245, train loss: 0.8150646090507507, train acuracy: 0.755859375
step: 245, val loss: 0.9472127556800842, val acuracy: 0.7135000824928284
step: 246, train loss: 0.7856400012969971, train acuracy: 0.744140625
step: 246, val loss: 0.9097251892089844, val acuracy: 0.7146667242050171
step: 247, train loss: 0.8891488909721375, train acuracy: 0.681640625
step: 247, val loss: 0.9257469773292542, val acuracy: 0.7021667957305908
step: 248, train loss: 0.8707937002182007, train acuracy: 0.7265625
step: 248, val loss: 0.9185954928398132, val acuracy: 0.7048333883285522
step: 249, train loss: 0.882662296295166, train acuracy: 0.708984375
step: 249, val loss: 0.9373581409454346, val acuracy: 0.702166736125946
step: 250, train loss: 0.922014594078064, train acuracy: 0.68359375
step: 250, val loss: 0.907427966594696, val acuracy: 0.7118334174156189
step: 251, train loss: 1.1005399227142334, train acuracy: 0.658203125
step: 251, val loss: 1.0858666896820068, val acuracy: 0.6566666960716248
step: 252, train loss: 1.238935112953186, train acuracy: 0.630859375
step: 252, val loss: 1.0691006183624268, val acuracy: 0.6623333692550659
step: 253, train loss: 1.0547611713409424, train acuracy: 0.66796875
step: 253, val loss: 1.0769892930984497, val acuracy: 0.6656667590141296
step: 254, train loss: 0.9028447866439819, train acuracy: 0.71484375
step: 254, val loss: 1.0567293167114258, val acuracy: 0.6773333549499512
step: 255, train loss: 0.9723511338233948, train acuracy: 0.69140625
step: 255, val loss: 1.0729743242263794, val acuracy: 0.6685000061988831
step: 256, train loss: 1.0661263465881348, train acuracy: 0.6875
step: 256, val loss: 1.052809238433838, val acuracy: 0.6646667122840881
step: 257, train loss: 1.008792519569397, train acuracy: 0.69140625
step: 257, val loss: 1.0516748428344727, val acuracy: 0.6703333258628845
step: 258, train loss: 1.1534056663513184, train acuracy: 0.65625
step: 258, val loss: 1.0497783422470093, val acuracy: 0.671166718006134
step: 259, train loss: 0.9870889782905579, train acuracy: 0.689453125
step: 259, val loss: 1.0665451288223267, val acuracy: 0.6568334102630615
step: 260, train loss: 0.9888968467712402, train acuracy: 0.67578125
step: 260, val loss: 1.09746253490448, val acuracy: 0.6606667041778564
step: 261, train loss: 1.1418914794921875, train acuracy: 0.66796875
step: 261, val loss: 1.1032631397247314, val acuracy: 0.6538333892822266
step: 262, train loss: 1.030761480331421, train acuracy: 0.693359375
step: 262, val loss: 1.0680142641067505, val acuracy: 0.6683333516120911
step: 263, train loss: 1.0413646697998047, train acuracy: 0.673828125
step: 263, val loss: 1.0447514057159424, val acuracy: 0.6676667928695679
step: 264, train loss: 1.0074732303619385, train acuracy: 0.693359375
step: 264, val loss: 1.0684747695922852, val acuracy: 0.659333348274231
step: 265, train loss: 1.0524612665176392, train acuracy: 0.658203125
step: 265, val loss: 1.0654667615890503, val acuracy: 0.6598334312438965
step: 266, train loss: 1.1768664121627808, train acuracy: 0.66015625
step: 266, val loss: 1.0635323524475098, val acuracy: 0.6605000495910645
step: 267, train loss: 1.0308564901351929, train acuracy: 0.654296875
step: 267, val loss: 1.0620148181915283, val acuracy: 0.6618334054946899
step: 268, train loss: 0.9628908634185791, train acuracy: 0.712890625
step: 268, val loss: 1.0614370107650757, val acuracy: 0.6615000367164612
step: 269, train loss: 1.1033947467803955, train acuracy: 0.669921875
step: 269, val loss: 1.1097831726074219, val acuracy: 0.6453334093093872
step: 270, train loss: 1.0589468479156494, train acuracy: 0.669921875
step: 270, val loss: 1.1025861501693726, val acuracy: 0.6470000743865967
step: 271, train loss: 1.2514890432357788, train acuracy: 0.62890625
step: 271, val loss: 1.0995280742645264, val acuracy: 0.6481667160987854
step: 272, train loss: 1.0820213556289673, train acuracy: 0.6796875
step: 272, val loss: 1.097425103187561, val acuracy: 0.6488333344459534
step: 273, train loss: 1.0791209936141968, train acuracy: 0.658203125
step: 273, val loss: 1.1252063512802124, val acuracy: 0.6520000696182251
step: 274, train loss: 1.1701312065124512, train acuracy: 0.625
step: 274, val loss: 1.0857884883880615, val acuracy: 0.659333348274231
step: 275, train loss: 1.1267478466033936, train acuracy: 0.62890625
step: 275, val loss: 1.1966158151626587, val acuracy: 0.6155000329017639
step: 276, train loss: 1.1131929159164429, train acuracy: 0.625
step: 276, val loss: 1.185584545135498, val acuracy: 0.6195001006126404
step: 277, train loss: 1.224941372871399, train acuracy: 0.595703125
step: 277, val loss: 1.1773889064788818, val acuracy: 0.6295000314712524
step: 278, train loss: 1.1244311332702637, train acuracy: 0.654296875
step: 278, val loss: 1.2241973876953125, val acuracy: 0.6426666975021362
step: 279, train loss: 1.2163453102111816, train acuracy: 0.642578125
step: 279, val loss: 1.20547354221344, val acuracy: 0.6440000534057617
step: 280, train loss: 1.3045589923858643, train acuracy: 0.634765625
step: 280, val loss: 1.2404979467391968, val acuracy: 0.6411667466163635
step: 281, train loss: 1.1570658683776855, train acuracy: 0.654296875
step: 281, val loss: 1.1943942308425903, val acuracy: 0.6486667394638062
step: 282, train loss: 1.219112515449524, train acuracy: 0.638671875
step: 282, val loss: 1.1940525770187378, val acuracy: 0.6495000720024109
step: 283, train loss: 1.2346793413162231, train acuracy: 0.65234375
step: 283, val loss: 1.1933090686798096, val acuracy: 0.6503333449363708
step: 284, train loss: 1.3352893590927124, train acuracy: 0.640625
step: 284, val loss: 1.210879921913147, val acuracy: 0.6449999809265137
step: 285, train loss: 1.2129013538360596, train acuracy: 0.634765625
step: 285, val loss: 1.2105579376220703, val acuracy: 0.6445000767707825
step: 286, train loss: 1.0786874294281006, train acuracy: 0.640625
step: 286, val loss: 1.23085355758667, val acuracy: 0.6393333673477173
step: 287, train loss: 1.233708381652832, train acuracy: 0.623046875
step: 287, val loss: 1.222994089126587, val acuracy: 0.6398333311080933
step: 288, train loss: 1.1729168891906738, train acuracy: 0.640625
step: 288, val loss: 1.2215367555618286, val acuracy: 0.6366667151451111
step: 289, train loss: 1.28281831741333, train acuracy: 0.619140625
step: 289, val loss: 1.2599269151687622, val acuracy: 0.6356666684150696
step: 290, train loss: 1.24612557888031, train acuracy: 0.630859375
step: 290, val loss: 1.2259854078292847, val acuracy: 0.6320000290870667
step: 291, train loss: 1.31116783618927, train acuracy: 0.630859375
step: 291, val loss: 1.2933489084243774, val acuracy: 0.6320000886917114
step: 292, train loss: 1.0770231485366821, train acuracy: 0.681640625
step: 292, val loss: 1.2313439846038818, val acuracy: 0.6413333415985107
step: 293, train loss: 1.315284252166748, train acuracy: 0.6484375
step: 293, val loss: 1.247632384300232, val acuracy: 0.6318333745002747
step: 294, train loss: 1.0954360961914062, train acuracy: 0.658203125
step: 294, val loss: 1.2260726690292358, val acuracy: 0.6436667442321777
step: 295, train loss: 1.3204939365386963, train acuracy: 0.607421875
step: 295, val loss: 1.2244139909744263, val acuracy: 0.6336667537689209
step: 296, train loss: 1.0840383768081665, train acuracy: 0.65234375
step: 296, val loss: 1.2241268157958984, val acuracy: 0.6363334059715271
step: 297, train loss: 1.1796077489852905, train acuracy: 0.650390625
step: 297, val loss: 1.2218366861343384, val acuracy: 0.6350000500679016
step: 298, train loss: 1.2108575105667114, train acuracy: 0.634765625
step: 298, val loss: 1.2437855005264282, val acuracy: 0.62416672706604
step: 299, train loss: 1.285027265548706, train acuracy: 0.619140625
step: 299, val loss: 1.3100625276565552, val acuracy: 0.6258333325386047
step: 300, train loss: 1.4264230728149414, train acuracy: 0.580078125
step: 300, val loss: 1.3319629430770874, val acuracy: 0.6250000596046448
step: 301, train loss: 1.3472789525985718, train acuracy: 0.578125
step: 301, val loss: 1.376694679260254, val acuracy: 0.5838333964347839
step: 302, train loss: 1.3416463136672974, train acuracy: 0.6171875
step: 302, val loss: 1.2887746095657349, val acuracy: 0.608833372592926
step: 303, train loss: 1.3145134449005127, train acuracy: 0.58203125
step: 303, val loss: 1.33811354637146, val acuracy: 0.5711666941642761
step: 304, train loss: 1.3424229621887207, train acuracy: 0.587890625
step: 304, val loss: 1.3307549953460693, val acuracy: 0.5741666555404663
step: 305, train loss: 1.278916835784912, train acuracy: 0.599609375
step: 305, val loss: 1.3348840475082397, val acuracy: 0.580666720867157
step: 306, train loss: 1.2490499019622803, train acuracy: 0.564453125
step: 306, val loss: 1.3569117784500122, val acuracy: 0.5693333745002747
step: 307, train loss: 1.3082678318023682, train acuracy: 0.59765625
step: 307, val loss: 1.3298487663269043, val acuracy: 0.5818333625793457
step: 308, train loss: 1.3071552515029907, train acuracy: 0.60546875
step: 308, val loss: 1.3369529247283936, val acuracy: 0.5764999985694885
step: 309, train loss: 1.3468810319900513, train acuracy: 0.576171875
step: 309, val loss: 1.3352981805801392, val acuracy: 0.577166736125946
step: 310, train loss: 1.2921136617660522, train acuracy: 0.595703125
step: 310, val loss: 1.334458827972412, val acuracy: 0.5773333311080933
step: 311, train loss: 1.2591084241867065, train acuracy: 0.607421875
step: 311, val loss: 1.3336173295974731, val acuracy: 0.5781667232513428
step: 312, train loss: 1.453135371208191, train acuracy: 0.544921875
step: 312, val loss: 1.348985195159912, val acuracy: 0.5671666860580444
step: 313, train loss: 1.3285043239593506, train acuracy: 0.5859375
step: 313, val loss: 1.387256145477295, val acuracy: 0.5715000033378601
step: 314, train loss: 1.313592791557312, train acuracy: 0.5859375
step: 314, val loss: 1.3814183473587036, val acuracy: 0.5730000734329224
step: 315, train loss: 1.336521029472351, train acuracy: 0.599609375
step: 315, val loss: 1.3793375492095947, val acuracy: 0.5721666812896729
step: 316, train loss: 1.33417809009552, train acuracy: 0.587890625
step: 316, val loss: 1.3784518241882324, val acuracy: 0.5720000267028809
step: 317, train loss: 1.3405249118804932, train acuracy: 0.568359375
step: 317, val loss: 1.377414345741272, val acuracy: 0.5724999904632568
step: 318, train loss: 1.4060828685760498, train acuracy: 0.548828125
step: 318, val loss: 1.3899070024490356, val acuracy: 0.562166690826416
step: 319, train loss: 1.2711485624313354, train acuracy: 0.603515625
step: 319, val loss: 1.3899643421173096, val acuracy: 0.5883333683013916
step: 320, train loss: 1.094118595123291, train acuracy: 0.642578125
step: 320, val loss: 1.390723466873169, val acuracy: 0.5891667008399963
step: 321, train loss: 1.410919189453125, train acuracy: 0.595703125
step: 321, val loss: 1.3888931274414062, val acuracy: 0.5885000228881836
step: 322, train loss: 1.316558599472046, train acuracy: 0.580078125
step: 322, val loss: 1.40846586227417, val acuracy: 0.5550000071525574
step: 323, train loss: 1.5152415037155151, train acuracy: 0.525390625
step: 323, val loss: 1.4061946868896484, val acuracy: 0.5561666488647461
step: 324, train loss: 1.4554024934768677, train acuracy: 0.556640625
step: 324, val loss: 1.4057331085205078, val acuracy: 0.5558333396911621
step: 325, train loss: 1.5245312452316284, train acuracy: 0.494140625
step: 325, val loss: 1.4516363143920898, val acuracy: 0.5300000309944153
step: 326, train loss: 1.3661444187164307, train acuracy: 0.583984375
step: 326, val loss: 1.4473505020141602, val acuracy: 0.5326666831970215
step: 327, train loss: 1.317616581916809, train acuracy: 0.583984375
step: 327, val loss: 1.4266383647918701, val acuracy: 0.5523333549499512
step: 328, train loss: 1.3937798738479614, train acuracy: 0.572265625
step: 328, val loss: 1.4129316806793213, val acuracy: 0.5640000700950623
step: 329, train loss: 1.398754358291626, train acuracy: 0.552734375
step: 329, val loss: 1.421278715133667, val acuracy: 0.5545000433921814
step: 330, train loss: 1.2868627309799194, train acuracy: 0.615234375
step: 330, val loss: 1.4164098501205444, val acuracy: 0.5631667375564575
step: 331, train loss: 1.4750648736953735, train acuracy: 0.53515625
step: 331, val loss: 1.500921368598938, val acuracy: 0.5193333029747009
step: 332, train loss: 1.4127155542373657, train acuracy: 0.53515625
step: 332, val loss: 1.4942959547042847, val acuracy: 0.5148333311080933
step: 333, train loss: 1.328540563583374, train acuracy: 0.56640625
step: 333, val loss: 1.455249309539795, val acuracy: 0.5248333811759949
step: 334, train loss: 5.093928813934326, train acuracy: 0.333984375
step: 334, val loss: 5.1545329093933105, val acuracy: 0.30133333802223206
step: 335, train loss: 5.580439567565918, train acuracy: 0.25
step: 335, val loss: 5.195854663848877, val acuracy: 0.27133333683013916
step: 336, train loss: 3.222747325897217, train acuracy: 0.10546875
step: 336, val loss: 3.25649356842041, val acuracy: 0.10899999737739563
step: 337, train loss: 2.6165237426757812, train acuracy: 0.0859375
step: 337, val loss: 2.6120376586914062, val acuracy: 0.09399999678134918
step: 338, train loss: 2.403046131134033, train acuracy: 0.076171875
step: 338, val loss: 2.401573419570923, val acuracy: 0.10400000214576721
step: 339, train loss: 2.3462350368499756, train acuracy: 0.115234375
step: 339, val loss: 2.3568639755249023, val acuracy: 0.10400000214576721
step: 340, train loss: 2.317081928253174, train acuracy: 0.11328125
step: 340, val loss: 2.314267158508301, val acuracy: 0.12533332407474518
step: 341, train loss: 2.3130054473876953, train acuracy: 0.115234375
step: 341, val loss: 2.3156495094299316, val acuracy: 0.10500000417232513
step: 342, train loss: 2.30470871925354, train acuracy: 0.162109375
step: 342, val loss: 2.3130407333374023, val acuracy: 0.15316668152809143
step: 343, train loss: 2.3119499683380127, train acuracy: 0.091796875
step: 343, val loss: 2.305837392807007, val acuracy: 0.10516667366027832
step: 344, train loss: 2.2925853729248047, train acuracy: 0.10546875
step: 344, val loss: 2.291247844696045, val acuracy: 0.1236666664481163
step: 345, train loss: 2.2783396244049072, train acuracy: 0.162109375
step: 345, val loss: 2.2914578914642334, val acuracy: 0.14933334290981293
step: 346, train loss: 2.289095401763916, train acuracy: 0.107421875
step: 346, val loss: 2.282487392425537, val acuracy: 0.12983332574367523
step: 347, train loss: 2.2412967681884766, train acuracy: 0.16015625
step: 347, val loss: 2.2436251640319824, val acuracy: 0.16700001060962677
step: 348, train loss: 2.1984689235687256, train acuracy: 0.189453125
step: 348, val loss: 2.168107509613037, val acuracy: 0.2163333147764206
step: 349, train loss: 2.0722413063049316, train acuracy: 0.26171875
step: 349, val loss: 2.081951141357422, val acuracy: 0.2616666555404663
step: 350, train loss: 2.079643726348877, train acuracy: 0.240234375
step: 350, val loss: 2.0761961936950684, val acuracy: 0.2639999985694885
step: 351, train loss: 2.085740089416504, train acuracy: 0.296875
step: 351, val loss: 2.0752756595611572, val acuracy: 0.2643333673477173
step: 352, train loss: 2.0576438903808594, train acuracy: 0.28125
step: 352, val loss: 2.062498092651367, val acuracy: 0.26883333921432495
step: 353, train loss: 2.0812551975250244, train acuracy: 0.271484375
step: 353, val loss: 2.051501750946045, val acuracy: 0.2668333649635315
step: 354, train loss: 2.036295175552368, train acuracy: 0.275390625
step: 354, val loss: 2.0420827865600586, val acuracy: 0.2698333263397217
step: 355, train loss: 2.059248685836792, train acuracy: 0.24609375
step: 355, val loss: 2.0375566482543945, val acuracy: 0.265500009059906
step: 356, train loss: 2.043935775756836, train acuracy: 0.259765625
step: 356, val loss: 2.0401878356933594, val acuracy: 0.2600000202655792
step: 357, train loss: 1.953525424003601, train acuracy: 0.314453125
step: 357, val loss: 2.0245933532714844, val acuracy: 0.2516666650772095
step: 358, train loss: 2.0530874729156494, train acuracy: 0.212890625
step: 358, val loss: 2.0234334468841553, val acuracy: 0.25333335995674133
step: 359, train loss: 2.020186185836792, train acuracy: 0.251953125
step: 359, val loss: 2.0231964588165283, val acuracy: 0.25850000977516174
step: 360, train loss: 2.029812812805176, train acuracy: 0.2734375
step: 360, val loss: 2.0228049755096436, val acuracy: 0.25833335518836975
step: 361, train loss: 2.0082883834838867, train acuracy: 0.275390625
step: 361, val loss: 2.0224013328552246, val acuracy: 0.257666677236557
step: 362, train loss: 2.021639585494995, train acuracy: 0.23828125
step: 362, val loss: 2.0210750102996826, val acuracy: 0.2566666901111603
step: 363, train loss: 2.023261785507202, train acuracy: 0.263671875
step: 363, val loss: 2.0285322666168213, val acuracy: 0.25966668128967285
step: 364, train loss: 2.000668525695801, train acuracy: 0.255859375
step: 364, val loss: 2.028268814086914, val acuracy: 0.2593333423137665
step: 365, train loss: 2.022869348526001, train acuracy: 0.27734375
step: 365, val loss: 2.0282623767852783, val acuracy: 0.2601666748523712
step: 366, train loss: 2.025132656097412, train acuracy: 0.26953125
step: 366, val loss: 2.0281143188476562, val acuracy: 0.25983333587646484
step: 367, train loss: 2.0267741680145264, train acuracy: 0.279296875
step: 367, val loss: 2.028094530105591, val acuracy: 0.25966668128967285
step: 368, train loss: 2.049356698989868, train acuracy: 0.267578125
step: 368, val loss: 2.027991771697998, val acuracy: 0.2593333423137665
step: 369, train loss: 1.9887423515319824, train acuracy: 0.27734375
step: 369, val loss: 2.0266475677490234, val acuracy: 0.2524999976158142
step: 370, train loss: 1.972023367881775, train acuracy: 0.306640625
step: 370, val loss: 2.026510715484619, val acuracy: 0.2528333365917206
step: 371, train loss: 2.041722297668457, train acuracy: 0.263671875
step: 371, val loss: 2.0286359786987305, val acuracy: 0.2565000057220459
step: 372, train loss: 1.992666244506836, train acuracy: 0.314453125
step: 372, val loss: 2.0137600898742676, val acuracy: 0.29766666889190674
step: 373, train loss: 1.9725673198699951, train acuracy: 0.34375
step: 373, val loss: 1.9844419956207275, val acuracy: 0.31450000405311584
step: 374, train loss: 2.043175220489502, train acuracy: 0.248046875
step: 374, val loss: 1.9772045612335205, val acuracy: 0.3230000138282776
step: 375, train loss: 1.9567217826843262, train acuracy: 0.33203125
step: 375, val loss: 1.9738484621047974, val acuracy: 0.32483333349227905
step: 376, train loss: 1.9198626279830933, train acuracy: 0.369140625
step: 376, val loss: 1.9600852727890015, val acuracy: 0.335999995470047
step: 377, train loss: 2.027712106704712, train acuracy: 0.3125
step: 377, val loss: 1.9595489501953125, val acuracy: 0.335666686296463
step: 378, train loss: 1.8828222751617432, train acuracy: 0.318359375
step: 378, val loss: 1.966784954071045, val acuracy: 0.2915000021457672
step: 379, train loss: 1.9990708827972412, train acuracy: 0.314453125
step: 379, val loss: 1.9665091037750244, val acuracy: 0.3141666650772095
step: 380, train loss: 1.9157737493515015, train acuracy: 0.31640625
step: 380, val loss: 1.894863247871399, val acuracy: 0.3420000374317169
step: 381, train loss: 1.9139759540557861, train acuracy: 0.32421875
step: 381, val loss: 1.8978428840637207, val acuracy: 0.3343333601951599
step: 382, train loss: 1.8502142429351807, train acuracy: 0.314453125
step: 382, val loss: 1.848487138748169, val acuracy: 0.35916668176651
step: 383, train loss: 1.9284379482269287, train acuracy: 0.376953125
step: 383, val loss: 1.8682376146316528, val acuracy: 0.3733333349227905
step: 384, train loss: 1.8679722547531128, train acuracy: 0.373046875
step: 384, val loss: 1.8618439435958862, val acuracy: 0.37433335185050964
step: 385, train loss: 1.9679253101348877, train acuracy: 0.330078125
step: 385, val loss: 1.8843690156936646, val acuracy: 0.3434999883174896
step: 386, train loss: 1.8433640003204346, train acuracy: 0.365234375
step: 386, val loss: 1.8148553371429443, val acuracy: 0.4020000100135803
step: 387, train loss: 1.8547221422195435, train acuracy: 0.376953125
step: 387, val loss: 1.8042360544204712, val acuracy: 0.3880000114440918
step: 388, train loss: 1.8161593675613403, train acuracy: 0.40625
step: 388, val loss: 1.7599282264709473, val acuracy: 0.41350001096725464
step: 389, train loss: 1.8261771202087402, train acuracy: 0.390625
step: 389, val loss: 1.7919895648956299, val acuracy: 0.38183334469795227
step: 390, train loss: 1.6687486171722412, train acuracy: 0.412109375
step: 390, val loss: 1.7336366176605225, val acuracy: 0.4033333361148834
step: 391, train loss: 1.7701350450515747, train acuracy: 0.37109375
step: 391, val loss: 1.7545082569122314, val acuracy: 0.3973333239555359
step: 392, train loss: 1.7627599239349365, train acuracy: 0.3828125
step: 392, val loss: 1.7323657274246216, val acuracy: 0.4124999940395355
step: 393, train loss: 1.7111670970916748, train acuracy: 0.390625
step: 393, val loss: 1.7480933666229248, val acuracy: 0.4101666808128357
step: 394, train loss: 1.6965049505233765, train acuracy: 0.439453125
step: 394, val loss: 1.705519199371338, val acuracy: 0.4336667060852051
step: 395, train loss: 1.7635152339935303, train acuracy: 0.39453125
step: 395, val loss: 1.7224962711334229, val acuracy: 0.40416669845581055
step: 396, train loss: 1.743262767791748, train acuracy: 0.3984375
step: 396, val loss: 1.7168116569519043, val acuracy: 0.40533334016799927
step: 397, train loss: 1.725497841835022, train acuracy: 0.41796875
step: 397, val loss: 1.7241814136505127, val acuracy: 0.4153333604335785
step: 398, train loss: 1.742828369140625, train acuracy: 0.4375
step: 398, val loss: 1.7229763269424438, val acuracy: 0.4163333773612976
step: 399, train loss: 1.7067829370498657, train acuracy: 0.4375
step: 399, val loss: 1.7226847410202026, val acuracy: 0.4153333604335785
2017-12-04 16:22:39.141063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:02:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 16:22:39.384998: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0xc82c0e0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-04 16:22:39.385689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K20m
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.56GiB
2017-12-04 16:22:39.385944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2017-12-04 16:22:39.385958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2017-12-04 16:22:39.385964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2017-12-04 16:22:39.385975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20m, pci bus id: 0000:02:00.0)
2017-12-04 16:22:39.385982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20m, pci bus id: 0000:03:00.0)
Extracting ./data/train-images-idx3-ubyte.gz
Extracting ./data/train-labels-idx1-ubyte.gz
Extracting ./data/t10k-images-idx3-ubyte.gz
Extracting ./data/t10k-labels-idx1-ubyte.gz
----------------------------------------------
architecture: LeNet-5 --- Data Set: MNIST
----------------------------------------------
----------------------------------------------
TRAINGING REFERENCE NET for LeNet-5
----------------------------------------------
step: 0, train loss: 2.3885529041290283, train acuracy: 0.138671875
step: 0, val loss: 2.449415683746338, val acuracy: 0.12333332747220993
step: 1, train loss: 2.271069288253784, train acuracy: 0.2236328125
step: 1, val loss: 2.278412342071533, val acuracy: 0.20399999618530273
step: 2, train loss: 2.2523367404937744, train acuracy: 0.376953125
step: 2, val loss: 2.2604010105133057, val acuracy: 0.3630000054836273
step: 3, train loss: 2.2559967041015625, train acuracy: 0.365234375
step: 3, val loss: 2.2555508613586426, val acuracy: 0.3643333613872528
step: 4, train loss: 2.2495994567871094, train acuracy: 0.22265625
step: 4, val loss: 2.272718906402588, val acuracy: 0.22183334827423096
step: 5, train loss: 1.8600530624389648, train acuracy: 0.4599609375
step: 5, val loss: 1.863319993019104, val acuracy: 0.45100003480911255
step: 6, train loss: 1.4112353324890137, train acuracy: 0.6142578125
step: 6, val loss: 1.4570960998535156, val acuracy: 0.5841667056083679
step: 7, train loss: 1.470289707183838, train acuracy: 0.4423828125
step: 7, val loss: 1.4699718952178955, val acuracy: 0.4388333559036255
step: 8, train loss: 1.264364242553711, train acuracy: 0.6005859375
step: 8, val loss: 1.305077075958252, val acuracy: 0.5921666622161865
step: 9, train loss: 0.9893606305122375, train acuracy: 0.6806640625
step: 9, val loss: 1.0489983558654785, val acuracy: 0.6615000367164612
step: 10, train loss: 0.8578023910522461, train acuracy: 0.7373046875
step: 10, val loss: 0.8476342558860779, val acuracy: 0.7386667728424072
step: 11, train loss: 0.8965380787849426, train acuracy: 0.7021484375
step: 11, val loss: 0.853365421295166, val acuracy: 0.7246667146682739
step: 12, train loss: 0.800696611404419, train acuracy: 0.740234375
step: 12, val loss: 0.8640878796577454, val acuracy: 0.7036667466163635
step: 13, train loss: 0.9031203389167786, train acuracy: 0.6982421875
step: 13, val loss: 0.8481526374816895, val acuracy: 0.7116667628288269
step: 14, train loss: 0.6852732300758362, train acuracy: 0.7890625
step: 14, val loss: 0.7167807221412659, val acuracy: 0.7666667699813843
step: 15, train loss: 0.7900048494338989, train acuracy: 0.7431640625
step: 15, val loss: 0.7359229326248169, val acuracy: 0.767833411693573
step: 16, train loss: 0.6436203122138977, train acuracy: 0.7919921875
step: 16, val loss: 0.669983446598053, val acuracy: 0.7856667041778564
step: 17, train loss: 0.5887400507926941, train acuracy: 0.8203125
step: 17, val loss: 0.5819933414459229, val acuracy: 0.8126667141914368
step: 18, train loss: 0.5622256994247437, train acuracy: 0.8251953125
step: 18, val loss: 0.5934313535690308, val acuracy: 0.8183333873748779
step: 19, train loss: 0.6253038644790649, train acuracy: 0.8251953125
step: 19, val loss: 0.6366991996765137, val acuracy: 0.7988333702087402
step: 20, train loss: 0.695165753364563, train acuracy: 0.78515625
step: 20, val loss: 0.7107135653495789, val acuracy: 0.783000111579895
step: 21, train loss: 0.7392375469207764, train acuracy: 0.7744140625
step: 21, val loss: 0.7233669757843018, val acuracy: 0.7746666669845581
step: 22, train loss: 0.6074388027191162, train acuracy: 0.8251953125
step: 22, val loss: 0.6116199493408203, val acuracy: 0.8126667737960815
step: 23, train loss: 0.5529090166091919, train acuracy: 0.830078125
step: 23, val loss: 0.5523374676704407, val acuracy: 0.82750004529953
step: 24, train loss: 0.5537974834442139, train acuracy: 0.833984375
step: 24, val loss: 0.5534182190895081, val acuracy: 0.8235000371932983
step: 25, train loss: 0.643029510974884, train acuracy: 0.80859375
step: 25, val loss: 0.5653760433197021, val acuracy: 0.8225000500679016
step: 26, train loss: 0.4957602918148041, train acuracy: 0.8369140625
step: 26, val loss: 0.5350656509399414, val acuracy: 0.8331667184829712
step: 27, train loss: 0.5404340028762817, train acuracy: 0.830078125
step: 27, val loss: 0.5437484979629517, val acuracy: 0.8300000429153442
step: 28, train loss: 0.5375643968582153, train acuracy: 0.833984375
step: 28, val loss: 0.5402175784111023, val acuracy: 0.8258334398269653
step: 29, train loss: 0.5358738899230957, train acuracy: 0.837890625
step: 29, val loss: 0.5419714450836182, val acuracy: 0.8290001153945923
step: 30, train loss: 0.5164864659309387, train acuracy: 0.8408203125
step: 30, val loss: 0.5515333414077759, val acuracy: 0.8203333616256714
step: 31, train loss: 0.5800186395645142, train acuracy: 0.833984375
step: 31, val loss: 0.5552282929420471, val acuracy: 0.8271667957305908
step: 32, train loss: 0.5474632978439331, train acuracy: 0.8095703125
step: 32, val loss: 0.5502249002456665, val acuracy: 0.8223333358764648
step: 33, train loss: 0.4855329990386963, train acuracy: 0.8486328125
step: 33, val loss: 0.569298505783081, val acuracy: 0.8245001435279846
step: 34, train loss: 0.5169313549995422, train acuracy: 0.8447265625
step: 34, val loss: 0.546159029006958, val acuracy: 0.8235000371932983
step: 35, train loss: 0.5809062719345093, train acuracy: 0.822265625
step: 35, val loss: 0.5673121809959412, val acuracy: 0.8223334550857544
step: 36, train loss: 0.6488678455352783, train acuracy: 0.77734375
step: 36, val loss: 0.5910025835037231, val acuracy: 0.8050000667572021
step: 37, train loss: 0.5665072202682495, train acuracy: 0.8173828125
step: 37, val loss: 0.6714645624160767, val acuracy: 0.7901667356491089
step: 38, train loss: 0.559803307056427, train acuracy: 0.8095703125
step: 38, val loss: 0.5942764282226562, val acuracy: 0.802000105381012
step: 39, train loss: 0.5548174381256104, train acuracy: 0.8251953125
step: 39, val loss: 0.5571482181549072, val acuracy: 0.8253334760665894
step: 40, train loss: 0.5561302900314331, train acuracy: 0.830078125
step: 40, val loss: 0.545578122138977, val acuracy: 0.8230000138282776
step: 41, train loss: 0.6487649083137512, train acuracy: 0.81640625
step: 41, val loss: 0.5582079291343689, val acuracy: 0.8236666917800903
step: 42, train loss: 0.5711027383804321, train acuracy: 0.8232421875
step: 42, val loss: 0.5776148438453674, val acuracy: 0.8160000443458557
step: 43, train loss: 0.5672702193260193, train acuracy: 0.837890625
step: 43, val loss: 0.5435128211975098, val acuracy: 0.827166736125946
step: 44, train loss: 0.5601305961608887, train acuracy: 0.814453125
step: 44, val loss: 0.5339342355728149, val acuracy: 0.8310000896453857
step: 45, train loss: 30.387489318847656, train acuracy: 0.208984375
step: 45, val loss: 30.624271392822266, val acuracy: 0.1941666603088379
step: 46, train loss: 2.7460849285125732, train acuracy: 0.12109375
step: 46, val loss: 2.778496742248535, val acuracy: 0.12083332985639572
step: 47, train loss: 2.3951973915100098, train acuracy: 0.12109375
step: 47, val loss: 2.414341688156128, val acuracy: 0.10899999737739563
step: 48, train loss: 2.254063606262207, train acuracy: 0.1953125
step: 48, val loss: 2.26893949508667, val acuracy: 0.17533335089683533
step: 49, train loss: 2.057062864303589, train acuracy: 0.376953125
step: 49, val loss: 2.0879440307617188, val acuracy: 0.3461666405200958
step: 50, train loss: 1.8930774927139282, train acuracy: 0.3525390625
step: 50, val loss: 1.9134448766708374, val acuracy: 0.3448333442211151
step: 51, train loss: 1.442258596420288, train acuracy: 0.5615234375
step: 51, val loss: 1.5031684637069702, val acuracy: 0.5366666913032532
step: 52, train loss: 1.2163662910461426, train acuracy: 0.6806640625
step: 52, val loss: 1.2362552881240845, val acuracy: 0.6575000882148743
step: 53, train loss: 1.2915674448013306, train acuracy: 0.5908203125
step: 53, val loss: 1.2894439697265625, val acuracy: 0.5888333916664124
step: 54, train loss: 1.0435019731521606, train acuracy: 0.6328125
step: 54, val loss: 1.1098461151123047, val acuracy: 0.6271666884422302
step: 55, train loss: 0.9793733954429626, train acuracy: 0.71484375
step: 55, val loss: 0.9662283062934875, val acuracy: 0.7160000205039978
step: 56, train loss: 1.0107051134109497, train acuracy: 0.654296875
step: 56, val loss: 1.006211519241333, val acuracy: 0.658333420753479
step: 57, train loss: 0.9450864791870117, train acuracy: 0.7412109375
step: 57, val loss: 0.9692727327346802, val acuracy: 0.7171667218208313
step: 58, train loss: 0.9080573320388794, train acuracy: 0.705078125
step: 58, val loss: 0.9787589311599731, val acuracy: 0.6699999570846558
step: 59, train loss: 0.9681038856506348, train acuracy: 0.7412109375
step: 59, val loss: 0.9602227210998535, val acuracy: 0.7286667227745056
step: 60, train loss: 0.8916405439376831, train acuracy: 0.7119140625
step: 60, val loss: 0.9465948343276978, val acuracy: 0.6878334283828735
step: 61, train loss: 0.89356929063797, train acuracy: 0.7587890625
step: 61, val loss: 0.9228091835975647, val acuracy: 0.7546666860580444
step: 62, train loss: 0.8791131377220154, train acuracy: 0.734375
step: 62, val loss: 0.9076486825942993, val acuracy: 0.7081667184829712
step: 63, train loss: 0.9003738760948181, train acuracy: 0.7568359375
step: 63, val loss: 0.8961209058761597, val acuracy: 0.7503333687782288
step: 64, train loss: 0.8629394173622131, train acuracy: 0.7490234375
step: 64, val loss: 0.902805507183075, val acuracy: 0.7276667356491089
step: 65, train loss: 0.9409758448600769, train acuracy: 0.705078125
step: 65, val loss: 0.9011253118515015, val acuracy: 0.7313333749771118
step: 66, train loss: 0.8608764410018921, train acuracy: 0.7470703125
step: 66, val loss: 0.9004696607589722, val acuracy: 0.7288334369659424
step: 67, train loss: 0.9662449359893799, train acuracy: 0.7001953125
step: 67, val loss: 0.8999773859977722, val acuracy: 0.7300000786781311
step: 68, train loss: 0.8764041662216187, train acuracy: 0.7509765625
step: 68, val loss: 0.8997481465339661, val acuracy: 0.7291666865348816
step: 69, train loss: 0.9020830988883972, train acuracy: 0.7275390625
step: 69, val loss: 0.8994706869125366, val acuracy: 0.7291667461395264
step: 70, train loss: 0.8669190406799316, train acuracy: 0.74609375
step: 70, val loss: 0.8991711735725403, val acuracy: 0.7286667227745056
step: 71, train loss: 0.8935009837150574, train acuracy: 0.7373046875
step: 71, val loss: 0.8991559147834778, val acuracy: 0.7276667356491089
step: 72, train loss: 0.906348466873169, train acuracy: 0.734375
step: 72, val loss: 0.907852828502655, val acuracy: 0.7358334064483643
step: 73, train loss: 1.0293501615524292, train acuracy: 0.65625
step: 73, val loss: 1.0168516635894775, val acuracy: 0.6643334031105042
step: 74, train loss: 0.9676328301429749, train acuracy: 0.6904296875
step: 74, val loss: 1.0074870586395264, val acuracy: 0.6671666502952576
step: 75, train loss: 1.0511589050292969, train acuracy: 0.666015625
step: 75, val loss: 1.0076121091842651, val acuracy: 0.6681666970252991
step: 76, train loss: 1.0127884149551392, train acuracy: 0.6748046875
step: 76, val loss: 1.0113869905471802, val acuracy: 0.6736666560173035
step: 77, train loss: 1.0004220008850098, train acuracy: 0.689453125
step: 77, val loss: 1.0107730627059937, val acuracy: 0.6731666922569275
step: 78, train loss: 0.9751564264297485, train acuracy: 0.6845703125
step: 78, val loss: 1.0105196237564087, val acuracy: 0.673666775226593
step: 79, train loss: 0.944373369216919, train acuracy: 0.6953125
step: 79, val loss: 1.0103206634521484, val acuracy: 0.6735000610351562
step: 80, train loss: 1.0092695951461792, train acuracy: 0.671875
step: 80, val loss: 1.0099718570709229, val acuracy: 0.674500048160553
step: 81, train loss: 1.0056729316711426, train acuracy: 0.6650390625
step: 81, val loss: 1.0098310708999634, val acuracy: 0.6735000610351562
step: 82, train loss: 0.9657374620437622, train acuracy: 0.6767578125
step: 82, val loss: 1.009686827659607, val acuracy: 0.673833429813385
step: 83, train loss: 0.9927930235862732, train acuracy: 0.685546875
step: 83, val loss: 1.009582281112671, val acuracy: 0.6738333702087402
step: 84, train loss: 1.061882495880127, train acuracy: 0.6669921875
step: 84, val loss: 1.0094285011291504, val acuracy: 0.6733333468437195
step: 85, train loss: 0.9380670785903931, train acuracy: 0.693359375
step: 85, val loss: 1.0094069242477417, val acuracy: 0.6736667156219482
step: 86, train loss: 0.9478538632392883, train acuracy: 0.69140625
step: 86, val loss: 1.009399175643921, val acuracy: 0.6735000610351562
step: 87, train loss: 1.0489366054534912, train acuracy: 0.6796875
step: 87, val loss: 1.009376883506775, val acuracy: 0.6736667156219482
step: 88, train loss: 1.0326216220855713, train acuracy: 0.6689453125
step: 88, val loss: 1.01272451877594, val acuracy: 0.6790000200271606
step: 89, train loss: 1.0153452157974243, train acuracy: 0.673828125
step: 89, val loss: 1.020844578742981, val acuracy: 0.6775001287460327
step: 90, train loss: 0.9570637941360474, train acuracy: 0.69921875
step: 90, val loss: 1.0222877264022827, val acuracy: 0.6700000762939453
step: 91, train loss: 0.9757430553436279, train acuracy: 0.6796875
step: 91, val loss: 1.0266016721725464, val acuracy: 0.6700000166893005
step: 92, train loss: 1.0799379348754883, train acuracy: 0.6572265625
step: 92, val loss: 1.029985785484314, val acuracy: 0.6666667461395264
step: 93, train loss: 1.0089303255081177, train acuracy: 0.6943359375
step: 93, val loss: 1.0277531147003174, val acuracy: 0.6673333644866943
step: 94, train loss: 1.0627361536026, train acuracy: 0.6591796875
step: 94, val loss: 1.0271003246307373, val acuracy: 0.6663334369659424
step: 95, train loss: 0.9852989315986633, train acuracy: 0.69921875
step: 95, val loss: 1.032247543334961, val acuracy: 0.6670000553131104
step: 96, train loss: 1.085243821144104, train acuracy: 0.666015625
step: 96, val loss: 1.031823754310608, val acuracy: 0.6673333644866943
step: 97, train loss: 1.0693202018737793, train acuracy: 0.654296875
step: 97, val loss: 1.0343354940414429, val acuracy: 0.6535000801086426
step: 98, train loss: 1.0364091396331787, train acuracy: 0.6728515625
step: 98, val loss: 1.0441534519195557, val acuracy: 0.6525000333786011
step: 99, train loss: 1.0079271793365479, train acuracy: 0.6923828125
step: 99, val loss: 1.04323148727417, val acuracy: 0.671833336353302
step: 100, train loss: 1.0116275548934937, train acuracy: 0.705078125
step: 100, val loss: 1.0439726114273071, val acuracy: 0.6765000224113464
step: 101, train loss: 0.9063645601272583, train acuracy: 0.697265625
step: 101, val loss: 1.0338881015777588, val acuracy: 0.6648333072662354
step: 102, train loss: 0.9671284556388855, train acuracy: 0.6884765625
step: 102, val loss: 1.0342743396759033, val acuracy: 0.6513333916664124
step: 103, train loss: 0.9605715870857239, train acuracy: 0.6875
step: 103, val loss: 1.0381066799163818, val acuracy: 0.6669999957084656
step: 104, train loss: 1.0112618207931519, train acuracy: 0.6826171875
step: 104, val loss: 1.0359466075897217, val acuracy: 0.6791667342185974
step: 105, train loss: 1.0118904113769531, train acuracy: 0.677734375
step: 105, val loss: 1.0377247333526611, val acuracy: 0.6673333644866943
step: 106, train loss: 1.009856104850769, train acuracy: 0.662109375
step: 106, val loss: 1.05757737159729, val acuracy: 0.6418334245681763
step: 107, train loss: 1.0636224746704102, train acuracy: 0.68359375
step: 107, val loss: 1.0588308572769165, val acuracy: 0.6766666769981384
step: 108, train loss: 1.0508623123168945, train acuracy: 0.65234375
step: 108, val loss: 1.0546505451202393, val acuracy: 0.6506666541099548
step: 109, train loss: 1.0192060470581055, train acuracy: 0.68359375
step: 109, val loss: 1.0430822372436523, val acuracy: 0.6658334136009216
step: 110, train loss: 1.0039377212524414, train acuracy: 0.6513671875
step: 110, val loss: 1.0731289386749268, val acuracy: 0.628333330154419
step: 111, train loss: 1.1060667037963867, train acuracy: 0.6552734375
step: 111, val loss: 1.079400897026062, val acuracy: 0.6563333868980408
step: 112, train loss: 0.9785432815551758, train acuracy: 0.681640625
step: 112, val loss: 1.0519503355026245, val acuracy: 0.655500054359436
step: 113, train loss: 1.0492380857467651, train acuracy: 0.6259765625
step: 113, val loss: 1.0686414241790771, val acuracy: 0.6318333148956299
step: 114, train loss: 1.0347962379455566, train acuracy: 0.658203125
step: 114, val loss: 1.096492886543274, val acuracy: 0.6353333592414856
step: 115, train loss: 1.0762276649475098, train acuracy: 0.6328125
step: 115, val loss: 1.084151029586792, val acuracy: 0.6500000357627869
step: 116, train loss: 1.005188226699829, train acuracy: 0.65625
step: 116, val loss: 1.0800777673721313, val acuracy: 0.6321666836738586
step: 117, train loss: 1.1037153005599976, train acuracy: 0.6376953125
step: 117, val loss: 1.1090084314346313, val acuracy: 0.6433333158493042
step: 118, train loss: 0.9945148825645447, train acuracy: 0.6865234375
step: 118, val loss: 1.0537316799163818, val acuracy: 0.6733334064483643
step: 119, train loss: 1.0919119119644165, train acuracy: 0.6328125
step: 119, val loss: 1.0292422771453857, val acuracy: 0.6801666617393494
step: 120, train loss: 1.0266004800796509, train acuracy: 0.6767578125
step: 120, val loss: 1.042267084121704, val acuracy: 0.6768333911895752
step: 121, train loss: 1.04203200340271, train acuracy: 0.6875
step: 121, val loss: 1.0171992778778076, val acuracy: 0.690333366394043
step: 122, train loss: 0.9670242071151733, train acuracy: 0.7109375
step: 122, val loss: 1.0176421403884888, val acuracy: 0.6856666803359985
step: 123, train loss: 1.0099422931671143, train acuracy: 0.7021484375
step: 123, val loss: 1.0176386833190918, val acuracy: 0.68666672706604
step: 124, train loss: 1.06276273727417, train acuracy: 0.68359375
step: 124, val loss: 1.0427531003952026, val acuracy: 0.6806668043136597
step: 125, train loss: 1.0385794639587402, train acuracy: 0.658203125
step: 125, val loss: 1.059901475906372, val acuracy: 0.6638334393501282
step: 126, train loss: 1.0047613382339478, train acuracy: 0.69921875
step: 126, val loss: 1.0291072130203247, val acuracy: 0.6933333873748779
step: 127, train loss: 1.0847290754318237, train acuracy: 0.662109375
step: 127, val loss: 1.0143030881881714, val acuracy: 0.6961666941642761
step: 128, train loss: 1.5524929761886597, train acuracy: 0.5556640625
step: 128, val loss: 1.6732417345046997, val acuracy: 0.5220000147819519
step: 129, train loss: 1.5683830976486206, train acuracy: 0.541015625
step: 129, val loss: 1.6458632946014404, val acuracy: 0.5246666669845581
step: 130, train loss: 1.2325094938278198, train acuracy: 0.6298828125
step: 130, val loss: 1.305000901222229, val acuracy: 0.6208333969116211
step: 131, train loss: 1.155064582824707, train acuracy: 0.654296875
step: 131, val loss: 1.3085055351257324, val acuracy: 0.5950000286102295
step: 132, train loss: 1.3430818319320679, train acuracy: 0.583984375
step: 132, val loss: 1.293031096458435, val acuracy: 0.5973333716392517
step: 133, train loss: 1.3162004947662354, train acuracy: 0.5966796875
step: 133, val loss: 1.2938432693481445, val acuracy: 0.596166729927063
step: 134, train loss: 1.2306751012802124, train acuracy: 0.6103515625
step: 134, val loss: 1.2867933511734009, val acuracy: 0.5958333015441895
step: 135, train loss: 1.2803566455841064, train acuracy: 0.599609375
step: 135, val loss: 1.2975176572799683, val acuracy: 0.593166708946228
step: 136, train loss: 1.299492359161377, train acuracy: 0.59375
step: 136, val loss: 1.2949776649475098, val acuracy: 0.5963333249092102
step: 137, train loss: 1.2541017532348633, train acuracy: 0.60546875
step: 137, val loss: 1.2941927909851074, val acuracy: 0.596000075340271
step: 138, train loss: 1.2037044763565063, train acuracy: 0.6259765625
step: 138, val loss: 1.301202654838562, val acuracy: 0.5936667323112488
step: 139, train loss: 1.3180147409439087, train acuracy: 0.58984375
step: 139, val loss: 1.2979027032852173, val acuracy: 0.5898333191871643
step: 140, train loss: 1.333925485610962, train acuracy: 0.578125
step: 140, val loss: 1.2973335981369019, val acuracy: 0.5908333659172058
step: 141, train loss: 1.288037896156311, train acuracy: 0.5830078125
step: 141, val loss: 1.2982077598571777, val acuracy: 0.5920000672340393
step: 142, train loss: 1.24222731590271, train acuracy: 0.6240234375
step: 142, val loss: 1.2961149215698242, val acuracy: 0.5943334102630615
step: 143, train loss: 1.2631831169128418, train acuracy: 0.5927734375
step: 143, val loss: 1.3032084703445435, val acuracy: 0.5860000848770142
step: 144, train loss: 1.3430255651474, train acuracy: 0.5791015625
step: 144, val loss: 1.3279962539672852, val acuracy: 0.5856666564941406
step: 145, train loss: 1.2943201065063477, train acuracy: 0.5810546875
step: 145, val loss: 1.2979202270507812, val acuracy: 0.5920000076293945
step: 146, train loss: 1.356985092163086, train acuracy: 0.5615234375
step: 146, val loss: 1.3051155805587769, val acuracy: 0.5896667242050171
step: 147, train loss: 1.2965726852416992, train acuracy: 0.591796875
step: 147, val loss: 1.2984429597854614, val acuracy: 0.5905000567436218
step: 148, train loss: 1.3811755180358887, train acuracy: 0.5703125
step: 148, val loss: 1.323874592781067, val acuracy: 0.5855000019073486
step: 149, train loss: 1.286170244216919, train acuracy: 0.5947265625
step: 149, val loss: 1.2961807250976562, val acuracy: 0.5921667218208313
step: 150, train loss: 1.3446465730667114, train acuracy: 0.5751953125
step: 150, val loss: 1.3053405284881592, val acuracy: 0.5888333916664124
step: 151, train loss: 1.2539286613464355, train acuracy: 0.619140625
step: 151, val loss: 1.2996246814727783, val acuracy: 0.5916666388511658
step: 152, train loss: 1.237680196762085, train acuracy: 0.6103515625
step: 152, val loss: 1.2998237609863281, val acuracy: 0.5889999866485596
step: 153, train loss: 1.2739965915679932, train acuracy: 0.5947265625
step: 153, val loss: 1.379612684249878, val acuracy: 0.5700000524520874
step: 154, train loss: 1.3094037771224976, train acuracy: 0.611328125
step: 154, val loss: 1.3867148160934448, val acuracy: 0.5753333568572998
step: 155, train loss: 1.3281586170196533, train acuracy: 0.578125
step: 155, val loss: 1.378188967704773, val acuracy: 0.5688333511352539
step: 156, train loss: 1.2959048748016357, train acuracy: 0.5966796875
step: 156, val loss: 1.3377068042755127, val acuracy: 0.5855000019073486
step: 157, train loss: 1.2929496765136719, train acuracy: 0.6025390625
step: 157, val loss: 1.336233139038086, val acuracy: 0.5808333158493042
step: 158, train loss: 1.324761152267456, train acuracy: 0.5810546875
step: 158, val loss: 1.3479536771774292, val acuracy: 0.5701667070388794
step: 159, train loss: 1.3308601379394531, train acuracy: 0.591796875
step: 159, val loss: 1.3252393007278442, val acuracy: 0.5870000123977661
step: 160, train loss: 24.991958618164062, train acuracy: 0.1533203125
step: 160, val loss: 25.565265655517578, val acuracy: 0.14633333683013916
step: 161, train loss: 24.01567840576172, train acuracy: 0.2265625
step: 161, val loss: 22.907318115234375, val acuracy: 0.24033334851264954
step: 162, train loss: 20.542537689208984, train acuracy: 0.068359375
step: 162, val loss: 21.138273239135742, val acuracy: 0.06016666442155838
step: 163, train loss: 3.9771807193756104, train acuracy: 0.083984375
step: 163, val loss: 3.9878246784210205, val acuracy: 0.09166666120290756
step: 164, train loss: 3.862180709838867, train acuracy: 0.04296875
step: 164, val loss: 3.9088430404663086, val acuracy: 0.048499997705221176
step: 165, train loss: 2.820742130279541, train acuracy: 0.1103515625
step: 165, val loss: 2.8631603717803955, val acuracy: 0.10699999332427979
step: 166, train loss: 2.8682055473327637, train acuracy: 0.177734375
step: 166, val loss: 2.78196120262146, val acuracy: 0.20816665887832642
step: 167, train loss: 2.5268611907958984, train acuracy: 0.162109375
step: 167, val loss: 2.5472583770751953, val acuracy: 0.17133334279060364
step: 168, train loss: 2.3928563594818115, train acuracy: 0.25390625
step: 168, val loss: 2.375638961791992, val acuracy: 0.25866666436195374
step: 169, train loss: 2.399756669998169, train acuracy: 0.177734375
step: 169, val loss: 2.398253917694092, val acuracy: 0.17783333361148834
step: 170, train loss: 2.0704755783081055, train acuracy: 0.330078125
step: 170, val loss: 2.0921647548675537, val acuracy: 0.31800001859664917
step: 171, train loss: 2.0817747116088867, train acuracy: 0.35546875
step: 171, val loss: 2.072507858276367, val acuracy: 0.3610000014305115
step: 172, train loss: 1.8595548868179321, train acuracy: 0.3310546875
step: 172, val loss: 1.9142436981201172, val acuracy: 0.31150001287460327
step: 173, train loss: 1.7295745611190796, train acuracy: 0.4453125
step: 173, val loss: 1.7225288152694702, val acuracy: 0.43900004029273987
step: 174, train loss: 1.4647831916809082, train acuracy: 0.4951171875
step: 174, val loss: 1.508188009262085, val acuracy: 0.4881667196750641
step: 175, train loss: 1.4487524032592773, train acuracy: 0.5830078125
step: 175, val loss: 1.5330734252929688, val acuracy: 0.5706666707992554
step: 176, train loss: 1.4972293376922607, train acuracy: 0.546875
step: 176, val loss: 1.4974892139434814, val acuracy: 0.533833384513855
step: 177, train loss: 0.978257417678833, train acuracy: 0.685546875
step: 177, val loss: 1.027628779411316, val acuracy: 0.6741666793823242
step: 178, train loss: 0.8959789276123047, train acuracy: 0.6787109375
step: 178, val loss: 0.9484065175056458, val acuracy: 0.6925000548362732
step: 179, train loss: 0.7974565029144287, train acuracy: 0.74609375
step: 179, val loss: 0.779797375202179, val acuracy: 0.7601667642593384
step: 180, train loss: 0.743867039680481, train acuracy: 0.771484375
step: 180, val loss: 0.767067551612854, val acuracy: 0.7643333673477173
step: 181, train loss: 0.7920820116996765, train acuracy: 0.76171875
step: 181, val loss: 0.7669145464897156, val acuracy: 0.7651667594909668
step: 182, train loss: 0.7235103845596313, train acuracy: 0.7861328125
step: 182, val loss: 0.7774478793144226, val acuracy: 0.7596667408943176
step: 183, train loss: 0.7510045766830444, train acuracy: 0.767578125
step: 183, val loss: 0.7788617610931396, val acuracy: 0.7615000605583191
step: 184, train loss: 0.7583489418029785, train acuracy: 0.779296875
step: 184, val loss: 0.7744601368904114, val acuracy: 0.762666642665863
step: 185, train loss: 0.7585194706916809, train acuracy: 0.7744140625
step: 185, val loss: 0.782098650932312, val acuracy: 0.7580000758171082
step: 186, train loss: 0.7393540143966675, train acuracy: 0.77734375
step: 186, val loss: 0.7721863389015198, val acuracy: 0.7636667490005493
step: 187, train loss: 0.7701862454414368, train acuracy: 0.7568359375
step: 187, val loss: 0.764076828956604, val acuracy: 0.7663334012031555
step: 188, train loss: 0.7541525959968567, train acuracy: 0.7734375
step: 188, val loss: 0.764629065990448, val acuracy: 0.7665000557899475
step: 189, train loss: 0.7367837429046631, train acuracy: 0.771484375
step: 189, val loss: 0.7649693489074707, val acuracy: 0.7661667466163635
step: 190, train loss: 0.6984776258468628, train acuracy: 0.796875
step: 190, val loss: 0.7648431658744812, val acuracy: 0.7668333649635315
step: 191, train loss: 0.8260772824287415, train acuracy: 0.7548828125
step: 191, val loss: 0.7644210457801819, val acuracy: 0.7669999599456787
step: 192, train loss: 0.779365062713623, train acuracy: 0.7607421875
step: 192, val loss: 0.7678906917572021, val acuracy: 0.7656667232513428
step: 193, train loss: 0.9882147312164307, train acuracy: 0.7041015625
step: 193, val loss: 0.9842160940170288, val acuracy: 0.7001667022705078
step: 194, train loss: 0.8740878105163574, train acuracy: 0.732421875
step: 194, val loss: 0.8848283290863037, val acuracy: 0.7311667203903198
step: 195, train loss: 0.8425153493881226, train acuracy: 0.7392578125
step: 195, val loss: 0.8694698214530945, val acuracy: 0.7320000529289246
step: 196, train loss: 0.8826068043708801, train acuracy: 0.7470703125
step: 196, val loss: 0.8796996474266052, val acuracy: 0.7315000295639038
step: 197, train loss: 0.9203754663467407, train acuracy: 0.70703125
step: 197, val loss: 0.8761364817619324, val acuracy: 0.7328334450721741
step: 198, train loss: 0.9003323316574097, train acuracy: 0.7197265625
step: 198, val loss: 0.8755121827125549, val acuracy: 0.7330000996589661
step: 199, train loss: 0.8647890686988831, train acuracy: 0.751953125
step: 199, val loss: 0.8752574324607849, val acuracy: 0.733500063419342
step: 200, train loss: 0.9298709630966187, train acuracy: 0.7236328125
step: 200, val loss: 0.8793298006057739, val acuracy: 0.7335000038146973
step: 201, train loss: 203439.28125, train acuracy: 0.095703125
step: 201, val loss: 206804.53125, val acuracy: 0.09783333539962769
step: 202, train loss: 375199872.0, train acuracy: 0.087890625
step: 202, val loss: 367236288.0, val acuracy: 0.10400000214576721
step: 203, train loss: 23781611405312.0, train acuracy: 0.103515625
step: 203, val loss: 24590388559872.0, val acuracy: 0.10533333569765091
step: 204, train loss: 2.882408888478576e+30, train acuracy: 0.0869140625
step: 204, val loss: 2.8995321137875975e+30, val acuracy: 0.08233333379030228
step: 205, train loss: nan, train acuracy: 0.1083984375
step: 205, val loss: nan, val acuracy: 0.10400000214576721
step: 206, train loss: nan, train acuracy: 0.0927734375
step: 206, val loss: nan, val acuracy: 0.10400000214576721
step: 207, train loss: nan, train acuracy: 0.1201171875
step: 207, val loss: nan, val acuracy: 0.10400000214576721
step: 208, train loss: nan, train acuracy: 0.0947265625
step: 208, val loss: nan, val acuracy: 0.10400000214576721
step: 209, train loss: nan, train acuracy: 0.1025390625
step: 209, val loss: nan, val acuracy: 0.10400000214576721
step: 210, train loss: nan, train acuracy: 0.083984375
step: 210, val loss: nan, val acuracy: 0.10400000214576721
step: 211, train loss: nan, train acuracy: 0.099609375
step: 211, val loss: nan, val acuracy: 0.10400000214576721
step: 212, train loss: nan, train acuracy: 0.1015625
step: 212, val loss: nan, val acuracy: 0.10400000214576721
step: 213, train loss: nan, train acuracy: 0.0966796875
step: 213, val loss: nan, val acuracy: 0.10400000214576721
step: 214, train loss: nan, train acuracy: 0.1123046875
step: 214, val loss: nan, val acuracy: 0.10400000214576721
step: 215, train loss: nan, train acuracy: 0.09375
step: 215, val loss: nan, val acuracy: 0.10400000214576721
step: 216, train loss: nan, train acuracy: 0.1025390625
step: 216, val loss: nan, val acuracy: 0.10400000214576721
step: 217, train loss: nan, train acuracy: 0.0947265625
step: 217, val loss: nan, val acuracy: 0.10400000214576721
step: 218, train loss: nan, train acuracy: 0.0869140625
step: 218, val loss: nan, val acuracy: 0.10400000214576721
step: 219, train loss: nan, train acuracy: 0.0810546875
step: 219, val loss: nan, val acuracy: 0.10400000214576721
step: 220, train loss: nan, train acuracy: 0.0927734375
step: 220, val loss: nan, val acuracy: 0.10400000214576721
step: 221, train loss: nan, train acuracy: 0.0986328125
step: 221, val loss: nan, val acuracy: 0.10400000214576721
step: 222, train loss: nan, train acuracy: 0.1083984375
step: 222, val loss: nan, val acuracy: 0.10400000214576721
step: 223, train loss: nan, train acuracy: 0.0869140625
step: 223, val loss: nan, val acuracy: 0.10400000214576721
step: 224, train loss: nan, train acuracy: 0.103515625
step: 224, val loss: nan, val acuracy: 0.10400000214576721
step: 225, train loss: nan, train acuracy: 0.083984375
step: 225, val loss: nan, val acuracy: 0.10400000214576721
step: 226, train loss: nan, train acuracy: 0.10546875
step: 226, val loss: nan, val acuracy: 0.10400000214576721
step: 227, train loss: nan, train acuracy: 0.087890625
step: 227, val loss: nan, val acuracy: 0.10400000214576721
step: 228, train loss: nan, train acuracy: 0.1005859375
step: 228, val loss: nan, val acuracy: 0.10400000214576721
step: 229, train loss: nan, train acuracy: 0.099609375
step: 229, val loss: nan, val acuracy: 0.10400000214576721
step: 230, train loss: nan, train acuracy: 0.10546875
step: 230, val loss: nan, val acuracy: 0.10400000214576721
step: 231, train loss: nan, train acuracy: 0.1005859375
step: 231, val loss: nan, val acuracy: 0.10400000214576721
step: 232, train loss: nan, train acuracy: 0.1005859375
step: 232, val loss: nan, val acuracy: 0.10400000214576721
step: 233, train loss: nan, train acuracy: 0.1044921875
step: 233, val loss: nan, val acuracy: 0.10400000214576721
step: 234, train loss: nan, train acuracy: 0.0712890625
step: 234, val loss: nan, val acuracy: 0.10400000214576721
step: 235, train loss: nan, train acuracy: 0.1201171875
step: 235, val loss: nan, val acuracy: 0.10400000214576721
step: 236, train loss: nan, train acuracy: 0.1005859375
step: 236, val loss: nan, val acuracy: 0.10400000214576721
step: 237, train loss: nan, train acuracy: 0.09765625
step: 237, val loss: nan, val acuracy: 0.10400000214576721
step: 238, train loss: nan, train acuracy: 0.107421875
step: 238, val loss: nan, val acuracy: 0.10400000214576721
step: 239, train loss: nan, train acuracy: 0.0986328125
step: 239, val loss: nan, val acuracy: 0.10400000214576721
step: 240, train loss: nan, train acuracy: 0.1005859375
step: 240, val loss: nan, val acuracy: 0.10400000214576721
step: 241, train loss: nan, train acuracy: 0.095703125
step: 241, val loss: nan, val acuracy: 0.10400000214576721
step: 242, train loss: nan, train acuracy: 0.1025390625
step: 242, val loss: nan, val acuracy: 0.10400000214576721
step: 243, train loss: nan, train acuracy: 0.0869140625
step: 243, val loss: nan, val acuracy: 0.10400000214576721
step: 244, train loss: nan, train acuracy: 0.0810546875
step: 244, val loss: nan, val acuracy: 0.10400000214576721
step: 245, train loss: nan, train acuracy: 0.1005859375
step: 245, val loss: nan, val acuracy: 0.10400000214576721
step: 246, train loss: nan, train acuracy: 0.095703125
step: 246, val loss: nan, val acuracy: 0.10400000214576721
step: 247, train loss: nan, train acuracy: 0.1123046875
step: 247, val loss: nan, val acuracy: 0.10400000214576721
step: 248, train loss: nan, train acuracy: 0.1044921875
step: 248, val loss: nan, val acuracy: 0.10400000214576721
step: 249, train loss: nan, train acuracy: 0.1044921875
step: 249, val loss: nan, val acuracy: 0.10400000214576721
step: 250, train loss: nan, train acuracy: 0.0869140625
step: 250, val loss: nan, val acuracy: 0.10400000214576721
step: 251, train loss: nan, train acuracy: 0.099609375
step: 251, val loss: nan, val acuracy: 0.10400000214576721
step: 252, train loss: nan, train acuracy: 0.099609375
step: 252, val loss: nan, val acuracy: 0.10400000214576721
step: 253, train loss: nan, train acuracy: 0.095703125
step: 253, val loss: nan, val acuracy: 0.10400000214576721
step: 254, train loss: nan, train acuracy: 0.087890625
step: 254, val loss: nan, val acuracy: 0.10400000214576721
step: 255, train loss: nan, train acuracy: 0.1025390625
step: 255, val loss: nan, val acuracy: 0.10400000214576721
step: 256, train loss: nan, train acuracy: 0.099609375
step: 256, val loss: nan, val acuracy: 0.10400000214576721
step: 257, train loss: nan, train acuracy: 0.1083984375
step: 257, val loss: nan, val acuracy: 0.10400000214576721
step: 258, train loss: nan, train acuracy: 0.0927734375
step: 258, val loss: nan, val acuracy: 0.10400000214576721
step: 259, train loss: nan, train acuracy: 0.1201171875
step: 259, val loss: nan, val acuracy: 0.10400000214576721
step: 260, train loss: nan, train acuracy: 0.0947265625
step: 260, val loss: nan, val acuracy: 0.10400000214576721
step: 261, train loss: nan, train acuracy: 0.1025390625
step: 261, val loss: nan, val acuracy: 0.10400000214576721
step: 262, train loss: nan, train acuracy: 0.083984375
step: 262, val loss: nan, val acuracy: 0.10400000214576721
step: 263, train loss: nan, train acuracy: 0.099609375
step: 263, val loss: nan, val acuracy: 0.10400000214576721
step: 264, train loss: nan, train acuracy: 0.1015625
step: 264, val loss: nan, val acuracy: 0.10400000214576721
step: 265, train loss: nan, train acuracy: 0.0966796875
step: 265, val loss: nan, val acuracy: 0.10400000214576721
step: 266, train loss: nan, train acuracy: 0.1123046875
step: 266, val loss: nan, val acuracy: 0.10400000214576721
step: 267, train loss: nan, train acuracy: 0.09375
step: 267, val loss: nan, val acuracy: 0.10400000214576721
step: 268, train loss: nan, train acuracy: 0.1025390625
step: 268, val loss: nan, val acuracy: 0.10400000214576721
step: 269, train loss: nan, train acuracy: 0.0947265625
step: 269, val loss: nan, val acuracy: 0.10400000214576721
step: 270, train loss: nan, train acuracy: 0.0869140625
step: 270, val loss: nan, val acuracy: 0.10400000214576721
step: 271, train loss: nan, train acuracy: 0.0810546875
step: 271, val loss: nan, val acuracy: 0.10400000214576721
step: 272, train loss: nan, train acuracy: 0.0927734375
step: 272, val loss: nan, val acuracy: 0.10400000214576721
step: 273, train loss: nan, train acuracy: 0.0986328125
step: 273, val loss: nan, val acuracy: 0.10400000214576721
step: 274, train loss: nan, train acuracy: 0.1083984375
step: 274, val loss: nan, val acuracy: 0.10400000214576721
step: 275, train loss: nan, train acuracy: 0.0869140625
step: 275, val loss: nan, val acuracy: 0.10400000214576721
step: 276, train loss: nan, train acuracy: 0.103515625
step: 276, val loss: nan, val acuracy: 0.10400000214576721
step: 277, train loss: nan, train acuracy: 0.083984375
step: 277, val loss: nan, val acuracy: 0.10400000214576721
step: 278, train loss: nan, train acuracy: 0.10546875
step: 278, val loss: nan, val acuracy: 0.10400000214576721
step: 279, train loss: nan, train acuracy: 0.087890625
step: 279, val loss: nan, val acuracy: 0.10400000214576721
step: 280, train loss: nan, train acuracy: 0.1005859375
step: 280, val loss: nan, val acuracy: 0.10400000214576721
step: 281, train loss: nan, train acuracy: 0.099609375
step: 281, val loss: nan, val acuracy: 0.10400000214576721
step: 282, train loss: nan, train acuracy: 0.10546875
step: 282, val loss: nan, val acuracy: 0.10400000214576721
step: 283, train loss: nan, train acuracy: 0.1005859375
step: 283, val loss: nan, val acuracy: 0.10400000214576721
step: 284, train loss: nan, train acuracy: 0.1005859375
step: 284, val loss: nan, val acuracy: 0.10400000214576721
step: 285, train loss: nan, train acuracy: 0.1044921875
step: 285, val loss: nan, val acuracy: 0.10400000214576721
step: 286, train loss: nan, train acuracy: 0.0712890625
step: 286, val loss: nan, val acuracy: 0.10400000214576721
step: 287, train loss: nan, train acuracy: 0.1201171875
step: 287, val loss: nan, val acuracy: 0.10400000214576721
step: 288, train loss: nan, train acuracy: 0.1005859375
step: 288, val loss: nan, val acuracy: 0.10400000214576721
step: 289, train loss: nan, train acuracy: 0.09765625
step: 289, val loss: nan, val acuracy: 0.10400000214576721
step: 290, train loss: nan, train acuracy: 0.107421875
step: 290, val loss: nan, val acuracy: 0.10400000214576721
step: 291, train loss: nan, train acuracy: 0.0986328125
step: 291, val loss: nan, val acuracy: 0.10400000214576721
step: 292, train loss: nan, train acuracy: 0.1005859375
step: 292, val loss: nan, val acuracy: 0.10400000214576721
step: 293, train loss: nan, train acuracy: 0.095703125
step: 293, val loss: nan, val acuracy: 0.10400000214576721
step: 294, train loss: nan, train acuracy: 0.1025390625
step: 294, val loss: nan, val acuracy: 0.10400000214576721
step: 295, train loss: nan, train acuracy: 0.0869140625
step: 295, val loss: nan, val acuracy: 0.10400000214576721
step: 296, train loss: nan, train acuracy: 0.0810546875
step: 296, val loss: nan, val acuracy: 0.10400000214576721
step: 297, train loss: nan, train acuracy: 0.1005859375
step: 297, val loss: nan, val acuracy: 0.10400000214576721
step: 298, train loss: nan, train acuracy: 0.095703125
step: 298, val loss: nan, val acuracy: 0.10400000214576721
step: 299, train loss: nan, train acuracy: 0.1123046875
step: 299, val loss: nan, val acuracy: 0.10400000214576721
step: 300, train loss: nan, train acuracy: 0.1044921875
step: 300, val loss: nan, val acuracy: 0.10400000214576721
step: 301, train loss: nan, train acuracy: 0.1044921875
step: 301, val loss: nan, val acuracy: 0.10400000214576721
step: 302, train loss: nan, train acuracy: 0.0869140625
step: 302, val loss: nan, val acuracy: 0.10400000214576721
step: 303, train loss: nan, train acuracy: 0.099609375
step: 303, val loss: nan, val acuracy: 0.10400000214576721
step: 304, train loss: nan, train acuracy: 0.099609375
step: 304, val loss: nan, val acuracy: 0.10400000214576721
step: 305, train loss: nan, train acuracy: 0.095703125
step: 305, val loss: nan, val acuracy: 0.10400000214576721
step: 306, train loss: nan, train acuracy: 0.087890625
step: 306, val loss: nan, val acuracy: 0.10400000214576721
step: 307, train loss: nan, train acuracy: 0.1025390625
step: 307, val loss: nan, val acuracy: 0.10400000214576721
step: 308, train loss: nan, train acuracy: 0.099609375
step: 308, val loss: nan, val acuracy: 0.10400000214576721
step: 309, train loss: nan, train acuracy: 0.1083984375
step: 309, val loss: nan, val acuracy: 0.10400000214576721
step: 310, train loss: nan, train acuracy: 0.0927734375
step: 310, val loss: nan, val acuracy: 0.10400000214576721
step: 311, train loss: nan, train acuracy: 0.1201171875
step: 311, val loss: nan, val acuracy: 0.10400000214576721
step: 312, train loss: nan, train acuracy: 0.0947265625
step: 312, val loss: nan, val acuracy: 0.10400000214576721
step: 313, train loss: nan, train acuracy: 0.1025390625
step: 313, val loss: nan, val acuracy: 0.10400000214576721
step: 314, train loss: nan, train acuracy: 0.083984375
step: 314, val loss: nan, val acuracy: 0.10400000214576721
step: 315, train loss: nan, train acuracy: 0.099609375
step: 315, val loss: nan, val acuracy: 0.10400000214576721
step: 316, train loss: nan, train acuracy: 0.1015625
step: 316, val loss: nan, val acuracy: 0.10400000214576721
step: 317, train loss: nan, train acuracy: 0.0966796875
step: 317, val loss: nan, val acuracy: 0.10400000214576721
step: 318, train loss: nan, train acuracy: 0.1123046875
step: 318, val loss: nan, val acuracy: 0.10400000214576721
step: 319, train loss: nan, train acuracy: 0.09375
step: 319, val loss: nan, val acuracy: 0.10400000214576721
step: 320, train loss: nan, train acuracy: 0.1025390625
step: 320, val loss: nan, val acuracy: 0.10400000214576721
step: 321, train loss: nan, train acuracy: 0.0947265625
step: 321, val loss: nan, val acuracy: 0.10400000214576721
step: 322, train loss: nan, train acuracy: 0.0869140625
step: 322, val loss: nan, val acuracy: 0.10400000214576721
step: 323, train loss: nan, train acuracy: 0.0810546875
step: 323, val loss: nan, val acuracy: 0.10400000214576721
step: 324, train loss: nan, train acuracy: 0.0927734375
step: 324, val loss: nan, val acuracy: 0.10400000214576721
step: 325, train loss: nan, train acuracy: 0.0986328125
step: 325, val loss: nan, val acuracy: 0.10400000214576721
step: 326, train loss: nan, train acuracy: 0.1083984375
step: 326, val loss: nan, val acuracy: 0.10400000214576721
step: 327, train loss: nan, train acuracy: 0.0869140625
step: 327, val loss: nan, val acuracy: 0.10400000214576721
step: 328, train loss: nan, train acuracy: 0.103515625
step: 328, val loss: nan, val acuracy: 0.10400000214576721
step: 329, train loss: nan, train acuracy: 0.083984375
step: 329, val loss: nan, val acuracy: 0.10400000214576721
step: 330, train loss: nan, train acuracy: 0.10546875
step: 330, val loss: nan, val acuracy: 0.10400000214576721
step: 331, train loss: nan, train acuracy: 0.087890625
step: 331, val loss: nan, val acuracy: 0.10400000214576721
step: 332, train loss: nan, train acuracy: 0.1005859375
step: 332, val loss: nan, val acuracy: 0.10400000214576721
step: 333, train loss: nan, train acuracy: 0.099609375
step: 333, val loss: nan, val acuracy: 0.10400000214576721
step: 334, train loss: nan, train acuracy: 0.10546875
step: 334, val loss: nan, val acuracy: 0.10400000214576721
step: 335, train loss: nan, train acuracy: 0.1005859375
step: 335, val loss: nan, val acuracy: 0.10400000214576721
step: 336, train loss: nan, train acuracy: 0.1005859375
step: 336, val loss: nan, val acuracy: 0.10400000214576721
step: 337, train loss: nan, train acuracy: 0.1044921875
step: 337, val loss: nan, val acuracy: 0.10400000214576721
step: 338, train loss: nan, train acuracy: 0.0712890625
step: 338, val loss: nan, val acuracy: 0.10400000214576721
step: 339, train loss: nan, train acuracy: 0.1201171875
step: 339, val loss: nan, val acuracy: 0.10400000214576721
step: 340, train loss: nan, train acuracy: 0.1005859375
step: 340, val loss: nan, val acuracy: 0.10400000214576721
step: 341, train loss: nan, train acuracy: 0.09765625
step: 341, val loss: nan, val acuracy: 0.10400000214576721
step: 342, train loss: nan, train acuracy: 0.107421875
step: 342, val loss: nan, val acuracy: 0.10400000214576721
step: 343, train loss: nan, train acuracy: 0.0986328125
step: 343, val loss: nan, val acuracy: 0.10400000214576721
step: 344, train loss: nan, train acuracy: 0.1005859375
step: 344, val loss: nan, val acuracy: 0.10400000214576721
step: 345, train loss: nan, train acuracy: 0.095703125
step: 345, val loss: nan, val acuracy: 0.10400000214576721
step: 346, train loss: nan, train acuracy: 0.1025390625
step: 346, val loss: nan, val acuracy: 0.10400000214576721
step: 347, train loss: nan, train acuracy: 0.0869140625
step: 347, val loss: nan, val acuracy: 0.10400000214576721
step: 348, train loss: nan, train acuracy: 0.0810546875
step: 348, val loss: nan, val acuracy: 0.10400000214576721
step: 349, train loss: nan, train acuracy: 0.1005859375
step: 349, val loss: nan, val acuracy: 0.10400000214576721
step: 350, train loss: nan, train acuracy: 0.095703125
step: 350, val loss: nan, val acuracy: 0.10400000214576721
step: 351, train loss: nan, train acuracy: 0.1123046875
step: 351, val loss: nan, val acuracy: 0.10400000959634781
step: 352, train loss: nan, train acuracy: 0.1044921875
step: 352, val loss: nan, val acuracy: 0.10400000214576721
step: 353, train loss: nan, train acuracy: 0.1044921875
step: 353, val loss: nan, val acuracy: 0.10400000214576721
step: 354, train loss: nan, train acuracy: 0.0869140625
step: 354, val loss: nan, val acuracy: 0.10400000214576721
step: 355, train loss: nan, train acuracy: 0.099609375
step: 355, val loss: nan, val acuracy: 0.10400000214576721
step: 356, train loss: nan, train acuracy: 0.099609375
step: 356, val loss: nan, val acuracy: 0.10400000214576721
step: 357, train loss: nan, train acuracy: 0.095703125
step: 357, val loss: nan, val acuracy: 0.10400000214576721
step: 358, train loss: nan, train acuracy: 0.087890625
step: 358, val loss: nan, val acuracy: 0.10400000214576721
step: 359, train loss: nan, train acuracy: 0.1025390625
step: 359, val loss: nan, val acuracy: 0.10400000214576721
step: 360, train loss: nan, train acuracy: 0.099609375
step: 360, val loss: nan, val acuracy: 0.10400000214576721
step: 361, train loss: nan, train acuracy: 0.1083984375
step: 361, val loss: nan, val acuracy: 0.10400000214576721
step: 362, train loss: nan, train acuracy: 0.0927734375
step: 362, val loss: nan, val acuracy: 0.10400000214576721
step: 363, train loss: nan, train acuracy: 0.1201171875
step: 363, val loss: nan, val acuracy: 0.10400000214576721
step: 364, train loss: nan, train acuracy: 0.0947265625
step: 364, val loss: nan, val acuracy: 0.10400000214576721
step: 365, train loss: nan, train acuracy: 0.1025390625
step: 365, val loss: nan, val acuracy: 0.10400000214576721
step: 366, train loss: nan, train acuracy: 0.083984375
step: 366, val loss: nan, val acuracy: 0.10400000214576721
step: 367, train loss: nan, train acuracy: 0.099609375
step: 367, val loss: nan, val acuracy: 0.10400000214576721
step: 368, train loss: nan, train acuracy: 0.1015625
step: 368, val loss: nan, val acuracy: 0.10400000214576721
step: 369, train loss: nan, train acuracy: 0.0966796875
step: 369, val loss: nan, val acuracy: 0.10400000214576721
step: 370, train loss: nan, train acuracy: 0.1123046875
step: 370, val loss: nan, val acuracy: 0.10400000214576721
step: 371, train loss: nan, train acuracy: 0.09375
step: 371, val loss: nan, val acuracy: 0.10400000214576721
step: 372, train loss: nan, train acuracy: 0.1025390625
step: 372, val loss: nan, val acuracy: 0.10400000214576721
step: 373, train loss: nan, train acuracy: 0.0947265625
step: 373, val loss: nan, val acuracy: 0.10400000214576721
step: 374, train loss: nan, train acuracy: 0.0869140625
step: 374, val loss: nan, val acuracy: 0.10400000214576721
step: 375, train loss: nan, train acuracy: 0.0810546875
step: 375, val loss: nan, val acuracy: 0.10400000214576721
step: 376, train loss: nan, train acuracy: 0.0927734375
step: 376, val loss: nan, val acuracy: 0.10400000214576721
step: 377, train loss: nan, train acuracy: 0.0986328125
step: 377, val loss: nan, val acuracy: 0.10400000214576721
step: 378, train loss: nan, train acuracy: 0.1083984375
step: 378, val loss: nan, val acuracy: 0.10400000214576721
step: 379, train loss: nan, train acuracy: 0.0869140625
step: 379, val loss: nan, val acuracy: 0.10400000214576721
step: 380, train loss: nan, train acuracy: 0.103515625
step: 380, val loss: nan, val acuracy: 0.10400000214576721
step: 381, train loss: nan, train acuracy: 0.083984375
step: 381, val loss: nan, val acuracy: 0.10400000214576721
step: 382, train loss: nan, train acuracy: 0.10546875
step: 382, val loss: nan, val acuracy: 0.10400000214576721
step: 383, train loss: nan, train acuracy: 0.087890625
step: 383, val loss: nan, val acuracy: 0.10400000214576721
step: 384, train loss: nan, train acuracy: 0.1005859375
step: 384, val loss: nan, val acuracy: 0.10400000214576721
step: 385, train loss: nan, train acuracy: 0.099609375
step: 385, val loss: nan, val acuracy: 0.10400000214576721
step: 386, train loss: nan, train acuracy: 0.10546875
step: 386, val loss: nan, val acuracy: 0.10400000214576721
step: 387, train loss: nan, train acuracy: 0.1005859375
step: 387, val loss: nan, val acuracy: 0.10400000214576721
step: 388, train loss: nan, train acuracy: 0.1005859375
step: 388, val loss: nan, val acuracy: 0.10400000214576721
step: 389, train loss: nan, train acuracy: 0.1044921875
step: 389, val loss: nan, val acuracy: 0.10400000214576721
step: 390, train loss: nan, train acuracy: 0.0712890625
step: 390, val loss: nan, val acuracy: 0.10400000214576721
step: 391, train loss: nan, train acuracy: 0.1201171875
step: 391, val loss: nan, val acuracy: 0.10400000214576721
step: 392, train loss: nan, train acuracy: 0.1005859375
step: 392, val loss: nan, val acuracy: 0.10400000214576721
step: 393, train loss: nan, train acuracy: 0.09765625
step: 393, val loss: nan, val acuracy: 0.10400000214576721
step: 394, train loss: nan, train acuracy: 0.107421875
step: 394, val loss: nan, val acuracy: 0.10400000214576721
step: 395, train loss: nan, train acuracy: 0.0986328125
step: 395, val loss: nan, val acuracy: 0.10400000214576721
step: 396, train loss: nan, train acuracy: 0.1005859375
step: 396, val loss: nan, val acuracy: 0.10400000214576721
step: 397, train loss: nan, train acuracy: 0.095703125
step: 397, val loss: nan, val acuracy: 0.10400000214576721
step: 398, train loss: nan, train acuracy: 0.1025390625
step: 398, val loss: nan, val acuracy: 0.10400000214576721
step: 399, train loss: nan, train acuracy: 0.0869140625
step: 399, val loss: nan, val acuracy: 0.10400000214576721
